{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "### 19_ \\<a1713814>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "### 1. Reading dataset and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e967e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crossing/miniconda3/envs/scispacy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-09 14:35:25.237573: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-09 14:35:26.575253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-09 14:35:26.575510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-09 14:35:26.575578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import spacy\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The original dataset on Kaggle huge, which contains 1056660 samples. To make this runable on my local pc, I randomly sampled 10,000 samples from the original dataset on Kaggle Notebook online, so I don't need to download the whole 20GB.\n",
    " Since I sampled these online, I am going to describe how I sampled the data and what attributes I chose. Here are the detailed steps of how I sampled 10,000 data in Kaggle Notebook:\n",
    "1. use random.sample() to select 25,000 article json path\n",
    "2. read the sampled json get the whole body text, and first 5 bibliographies\n",
    "3. match the paper_id to metadata.csv to get more useful attributes of the articles, including title, authors, and journal\n",
    "4. Data cleaning, including remove samples with missing attributes, non-English, and duplicates.\n",
    "5. Then randomly sampled 10,000 samples from the cleaned data\n",
    "5. save to a csv file called 'sampled_df.csv' and download this sampled dataset to my local PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of na: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "     paper_id                                              title  \\\n0  PMC8419652  Curriculum tinkering in situations of crises a...   \n1  PMC8527883  Similarities and Differences in the Acute-Phas...   \n2  PMC7107128  Effect of insoluble fiber supplementation appl...   \n3  PMC7972757  Narrating Arabic Translation Online: Another P...   \n4  PMC8834262  Roles of Podoplanin in Malignant Progression o...   \n\n                                             authors  \\\n0                        Amin, Nyna; Mahabeer, Pryah   \n1  Coleman, Celeste; Doyle-Meyers, Lara A.; Russe...   \n2      Yokhana, J. S.; Parkinson, G.; Frankel, T. L.   \n3                               Alonayq, Abdulmohsen   \n4  Suzuki, Hiroyuki; Kaneko, Mika K.; Kato, Yukinari   \n\n                         journal  \\\n0              Prospects (Paris)   \n1                  Front Immunol   \n2                      Poult Sci   \n3  When Translation Goes Digital   \n4                          Cells   \n\n                                            abstract  \\\n0  This article interrogates a curriculum recover...   \n1  Understanding SARS-CoV-2 immune pathology is c...   \n2  Two experiments were conducted to study effect...   \n3  This chapter takes a socionarrative approach t...   \n4  Podoplanin (PDPN) is a cell-surface mucin-like...   \n\n                                           body_text  \\\n0  In this section, we provide an overview of Sou...   \n1  The rapid emergence and dissemination of sever...   \n2  Growth and development in layer pullets during...   \n3  The translation sector has seen an increase in...   \n4  Podoplanin (PDPN)/T1α/E11 antigen/PA2.26 antig...   \n\n                                                 bib  \n0  ['Big policies/small world: An introduction to...  \n1  ['Clinical Characteristics of Coronavirus Dise...  \n2  ['The estimation of pepsin, trypsin, papain, a...  \n3  ['Arabic tradition', 'The narrative constructi...  \n4  ['Podoplanin: An emerging cancer biomarker and...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>journal</th>\n      <th>abstract</th>\n      <th>body_text</th>\n      <th>bib</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PMC8419652</td>\n      <td>Curriculum tinkering in situations of crises a...</td>\n      <td>Amin, Nyna; Mahabeer, Pryah</td>\n      <td>Prospects (Paris)</td>\n      <td>This article interrogates a curriculum recover...</td>\n      <td>In this section, we provide an overview of Sou...</td>\n      <td>['Big policies/small world: An introduction to...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PMC8527883</td>\n      <td>Similarities and Differences in the Acute-Phas...</td>\n      <td>Coleman, Celeste; Doyle-Meyers, Lara A.; Russe...</td>\n      <td>Front Immunol</td>\n      <td>Understanding SARS-CoV-2 immune pathology is c...</td>\n      <td>The rapid emergence and dissemination of sever...</td>\n      <td>['Clinical Characteristics of Coronavirus Dise...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PMC7107128</td>\n      <td>Effect of insoluble fiber supplementation appl...</td>\n      <td>Yokhana, J. S.; Parkinson, G.; Frankel, T. L.</td>\n      <td>Poult Sci</td>\n      <td>Two experiments were conducted to study effect...</td>\n      <td>Growth and development in layer pullets during...</td>\n      <td>['The estimation of pepsin, trypsin, papain, a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PMC7972757</td>\n      <td>Narrating Arabic Translation Online: Another P...</td>\n      <td>Alonayq, Abdulmohsen</td>\n      <td>When Translation Goes Digital</td>\n      <td>This chapter takes a socionarrative approach t...</td>\n      <td>The translation sector has seen an increase in...</td>\n      <td>['Arabic tradition', 'The narrative constructi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PMC8834262</td>\n      <td>Roles of Podoplanin in Malignant Progression o...</td>\n      <td>Suzuki, Hiroyuki; Kaneko, Mika K.; Kato, Yukinari</td>\n      <td>Cells</td>\n      <td>Podoplanin (PDPN) is a cell-surface mucin-like...</td>\n      <td>Podoplanin (PDPN)/T1α/E11 antigen/PA2.26 antig...</td>\n      <td>['Podoplanin: An emerging cancer biomarker and...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './sampled_df.csv'\n",
    "sampled_df = pd.read_csv(data_path, index_col=0) # index_col = 0 -> avoid fist 'unnamed col'\n",
    "print(f'number of na: {sampled_df.isnull().any().sum()}')\n",
    "sampled_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   paper_id                                              title  \\\n0         0  Curriculum tinkering in situations of crises a...   \n1         1  Similarities and Differences in the Acute-Phas...   \n2         2  Effect of insoluble fiber supplementation appl...   \n3         3  Narrating Arabic Translation Online: Another P...   \n4         4  Roles of Podoplanin in Malignant Progression o...   \n\n                                             authors  \\\n0                      [Amin, Nyna, Mahabeer, Pryah]   \n1  [Coleman, Celeste, Doyle-Meyers, Lara A., Russ...   \n2    [Yokhana, J. S., Parkinson, G., Frankel, T. L.]   \n3                             [Alonayq, Abdulmohsen]   \n4  [Suzuki, Hiroyuki, Kaneko, Mika K., Kato, Yuki...   \n\n                         journal  \\\n0              Prospects (Paris)   \n1                  Front Immunol   \n2                      Poult Sci   \n3  When Translation Goes Digital   \n4                          Cells   \n\n                                            abstract  \\\n0  This article interrogates curriculum recovery ...   \n1  Understanding SARS-CoV-2 immune pathology crit...   \n2  Two experiments conducted study effects dietar...   \n3  This chapter takes socionarrative approach exa...   \n4  Podoplanin PDPN cell-surface mucin-like glycop...   \n\n                                           body_text  \\\n0  In section provide overview South Africa demog...   \n1  The rapid emergence dissemination severe acute...   \n2  Growth development layer pullets rearing early...   \n3  The translation sector seen increase volunteer...   \n4  Podoplanin PDPN T1 E11 antigen PA2.26 antigen ...   \n\n                                                 bib paper_identifier  \\\n0  [Big policies/small world: An introduction to ...       PMC8419652   \n1  [Clinical Characteristics of Coronavirus Disea...       PMC8527883   \n2  [The estimation of pepsin, trypsin, papain, an...       PMC7107128   \n3  [Arabic tradition, The narrative construction ...       PMC7972757   \n4  [Podoplanin: An emerging cancer biomarker and ...       PMC8834262   \n\n                                  original_body_text  \\\n0  In this section, we provide an overview of Sou...   \n1  The rapid emergence and dissemination of sever...   \n2  Growth and development in layer pullets during...   \n3  The translation sector has seen an increase in...   \n4  Podoplanin (PDPN)/T1α/E11 antigen/PA2.26 antig...   \n\n                                   original_abstract  \n0  This article interrogates a curriculum recover...  \n1  Understanding SARS-CoV-2 immune pathology is c...  \n2  Two experiments were conducted to study effect...  \n3  This chapter takes a socionarrative approach t...  \n4  Podoplanin (PDPN) is a cell-surface mucin-like...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>title</th>\n      <th>authors</th>\n      <th>journal</th>\n      <th>abstract</th>\n      <th>body_text</th>\n      <th>bib</th>\n      <th>paper_identifier</th>\n      <th>original_body_text</th>\n      <th>original_abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Curriculum tinkering in situations of crises a...</td>\n      <td>[Amin, Nyna, Mahabeer, Pryah]</td>\n      <td>Prospects (Paris)</td>\n      <td>This article interrogates curriculum recovery ...</td>\n      <td>In section provide overview South Africa demog...</td>\n      <td>[Big policies/small world: An introduction to ...</td>\n      <td>PMC8419652</td>\n      <td>In this section, we provide an overview of Sou...</td>\n      <td>This article interrogates a curriculum recover...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Similarities and Differences in the Acute-Phas...</td>\n      <td>[Coleman, Celeste, Doyle-Meyers, Lara A., Russ...</td>\n      <td>Front Immunol</td>\n      <td>Understanding SARS-CoV-2 immune pathology crit...</td>\n      <td>The rapid emergence dissemination severe acute...</td>\n      <td>[Clinical Characteristics of Coronavirus Disea...</td>\n      <td>PMC8527883</td>\n      <td>The rapid emergence and dissemination of sever...</td>\n      <td>Understanding SARS-CoV-2 immune pathology is c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Effect of insoluble fiber supplementation appl...</td>\n      <td>[Yokhana, J. S., Parkinson, G., Frankel, T. L.]</td>\n      <td>Poult Sci</td>\n      <td>Two experiments conducted study effects dietar...</td>\n      <td>Growth development layer pullets rearing early...</td>\n      <td>[The estimation of pepsin, trypsin, papain, an...</td>\n      <td>PMC7107128</td>\n      <td>Growth and development in layer pullets during...</td>\n      <td>Two experiments were conducted to study effect...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Narrating Arabic Translation Online: Another P...</td>\n      <td>[Alonayq, Abdulmohsen]</td>\n      <td>When Translation Goes Digital</td>\n      <td>This chapter takes socionarrative approach exa...</td>\n      <td>The translation sector seen increase volunteer...</td>\n      <td>[Arabic tradition, The narrative construction ...</td>\n      <td>PMC7972757</td>\n      <td>The translation sector has seen an increase in...</td>\n      <td>This chapter takes a socionarrative approach t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Roles of Podoplanin in Malignant Progression o...</td>\n      <td>[Suzuki, Hiroyuki, Kaneko, Mika K., Kato, Yuki...</td>\n      <td>Cells</td>\n      <td>Podoplanin PDPN cell-surface mucin-like glycop...</td>\n      <td>Podoplanin PDPN T1 E11 antigen PA2.26 antigen ...</td>\n      <td>[Podoplanin: An emerging cancer biomarker and ...</td>\n      <td>PMC8834262</td>\n      <td>Podoplanin (PDPN)/T1α/E11 antigen/PA2.26 antig...</td>\n      <td>Podoplanin (PDPN) is a cell-surface mucin-like...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from ast import literal_eval\n",
    "\n",
    "# only need to download these 3 once\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "def pre_processing(df):\n",
    "    path = './processed_df.csv'\n",
    "    if not os.path.isfile(path):\n",
    "        df_c = df.copy()\n",
    "        #no punctuation or non-alphanumeric chars except periods\n",
    "        df_c['body_text'] = df_c.body_text.str.replace('[^A-Za-z0-9\\s+\\-+\\.]',' ') #replace special character with a space\n",
    "        df_c['abstract'] = df_c.abstract.str.replace('[^A-Za-z0-9\\s+\\-+\\.]',' ') #replace special character with a space\n",
    "\n",
    "        # remove in-text reference e.g., [3-4]\n",
    "        df_c['body_text'] = df_c.body_text.str.replace('\\[.*?\\]',' ')\n",
    "\n",
    "        # remove new lines and back slash\n",
    "        df_c['body_text'] = df_c.body_text.str.replace('\\n',' ')\n",
    "        df_c['body_text'] = df_c.body_text.str.replace('\\s+',' ')\n",
    "\n",
    "        df_c['abstract'] = df_c.abstract.str.replace('\\n',' ')\n",
    "        df_c['abstract'] = df_c.abstract.str.replace('\\s+',' ')\n",
    "\n",
    "        # no stopwords\n",
    "        stops = stopwords.words('english') # english stopwords, because our data is in english\n",
    "        df_c['body_text'] = df_c.body_text.apply(lambda x: \" \".join([word for word in x.split() if word not in stops]))\n",
    "        df_c['abstract'] = df_c.abstract.apply(lambda x: \" \".join([word for word in x.split() if word not in stops]))\n",
    "\n",
    "        df_c['authors'] = df_c.authors.apply(lambda x: x.split(';'))\n",
    "        df_c['authors'] = df_c.authors.apply(lambda x: [name.strip() for name in x if name.strip() != ''])\n",
    "\n",
    "        df_c['paper_identifier'] = df_c['paper_id']\n",
    "        df_c['paper_id'] = [i for i in range(df_c.shape[0])]\n",
    "\n",
    "        # keep the original body text and abstract for showing IR result\n",
    "        df_c['original_body_text'] = df['body_text'].copy()\n",
    "        df_c['original_abstract'] = df['abstract'].copy()\n",
    "\n",
    "\n",
    "        # save to csv file (pre-process is time-consuming, avoid processing everytime)\n",
    "        df_c.to_csv(path)\n",
    "    else:\n",
    "        df_c = pd.read_csv(path,index_col=0,converters={\"bib\": literal_eval,\"authors\": literal_eval}) # body-text col is list of sentences\n",
    "\n",
    "    return df_c\n",
    "\n",
    "processed_df = pre_processing(sampled_df)\n",
    "\n",
    "processed_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the pre-processing step, I processed on body text, abstract, and authors. The detailed steps are as follows:\n",
    "1. Removed non-alphanumeric chars (except '-' and '.'): Because they are most likely to be greek letters that used in the equations or experiment variables, which is not informative in out task. However, '-' used a lot in medical named entities, such as 'COVID-19', 'SARS-CoV-2', 'whole-blood', therefore, I did not remove '-'. Otherwise it would have negative impact on the performance of NER and thus the following downstream tasks. Also '.' is useful for differntiate sentences when perform summarization.\n",
    "\n",
    "2. Removed in-text references, new lines, back slashes and stopwords, because they are not informative, and removing them will not affect the NER and other following downstream tasks.\n",
    "\n",
    "3. Processed authors from a string containing all names seperated by ';\" to a list of individual's name (using .split(';'))\n",
    "\n",
    "4. Renamed the 'paper_id' to 'paper_identifier', and use the index of the sample to be the 'paper_id'\n",
    "\n",
    "Some Notes:\n",
    "\n",
    "- I did not perform lowercasing here, because in biomedical cases there are a lot of abbreviations, which will be specifically resolved in the entity linker pipeline when building the KB.\n",
    "- I also didn't perform lemmatization nor stemming, because they might modify the named entity, and would be difficult to be recognized by the NER model. Also, lemmatization and stemming works on token level, but there are named entities consist of multiple word tokens, and modified a token in a named entity phrase would affect the NER and the following downstream tasks.For example, 'lung kidney lymphatic vascular systems', 'lymphatic' will be stemmed to 'lymphat'.\n",
    "- I did not convert the text to BOW as the assignment spec 1.c said, because I will use scispacy to perform NER, which takes text as input. And also in the 'assignment tips' and assignment specification step 4 (d), we are encouraged to use word embeddings, so I am not using BOW to vectorise the text in this assignment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "31d75afc",
   "metadata": {},
   "source": [
    "### 2. Named Entity Recognition and Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "# ! pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_md-0.5.1.tar.gz\n",
    "# ! pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
    "\n",
    "from scispacy.linking import EntityLinker\n",
    "class Knowledge_Base:\n",
    "    def __init__(self, processed_df):\n",
    "        self.processed_df = processed_df\n",
    "\n",
    "        # init nlp model, model will be loaded when bulding kb\n",
    "        self.nlp = None\n",
    "\n",
    "        # init kb, or load kb if it's already built\n",
    "        self.kb = None\n",
    "        self.kb_path = 'knowledge_base.pkl'\n",
    "        if os.path.isfile(self.kb_path):\n",
    "            with open(self.kb_path, 'rb') as kb_pickled:\n",
    "                self.kb = pickle.load(kb_pickled)\n",
    "        else:\n",
    "            self.build_KB_with_entities()\n",
    "\n",
    "    def __init_nlp(self):\n",
    "        self.nlp = spacy.load(\"en_core_sci_sm\") # for NER #en_ner_bc5cdr_md #en_core_sci_sm\n",
    "\n",
    "        # k=1: return the top candidate (concept with the highest score)\n",
    "        # default score thresh = 0.7, but change to 0.8\n",
    "        # umls: Unified Medical Language System.\n",
    "        self.nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\", 'k':1, 'threshold':0.8}) # for getting canonical name and aliases\n",
    "        return\n",
    "\n",
    "    def __init_KB(self):\n",
    "        # This function only pre-process the paper and author part.\n",
    "        kb = {'paper':{id_str:{} for id_str in self.processed_df['paper_id'].tolist()}}\n",
    "        authors_dict = {}\n",
    "        for id,dic in tqdm.tqdm(kb['paper'].items(), desc = 'Initialize KB', unit = ' article'):\n",
    "            title = self.processed_df.loc[self.processed_df['paper_id']==id]['title'].values[0]\n",
    "            dic.update({'title':title})\n",
    "\n",
    "            authors_lst = self.processed_df.loc[self.processed_df['paper_id']==id]['authors'].values[0]\n",
    "            dic.update({'authors':authors_lst})\n",
    "\n",
    "            for author in authors_lst:\n",
    "                if author not in authors_dict.keys():\n",
    "                    authors_dict.update({author:{'paper_lst':{id}}})\n",
    "                else:\n",
    "                    authors_dict[author]['paper_lst'].add(id)\n",
    "\n",
    "        kb.update({'authors':authors_dict})\n",
    "\n",
    "        # init entity part for futher entity related processes\n",
    "        kb.update({'entities':{}})\n",
    "        return kb\n",
    "\n",
    "    def __update_entity_dict(self,entity_dict,doc,linker,paper_id):\n",
    "        for entity in doc.ents: # for each recognised entities\n",
    "            for umls_ent in entity._.kb_ents: # for each matched umls concept matched\n",
    "                # 'umls_ent[0]' is the concept entity with the highest score\n",
    "                concept_id = (linker.kb.cui_to_entity[umls_ent[0]]).concept_id\n",
    "                canonical_name = (linker.kb.cui_to_entity[umls_ent[0]]).canonical_name\n",
    "                definition = (linker.kb.cui_to_entity[umls_ent[0]]).definition\n",
    "                if len((linker.kb.cui_to_entity[umls_ent[0]]).aliases) == 0:\n",
    "                    umls_aliases_set = set()\n",
    "                else:\n",
    "                    umls_aliases_set = set((linker.kb.cui_to_entity[umls_ent[0]]).aliases)\n",
    "\n",
    "                entity_name = (entity.text).strip()\n",
    "\n",
    "                # if this a new entity for both current KB and this paper\n",
    "                if canonical_name not in self.kb['entities'].keys() and canonical_name not in entity_dict.keys():\n",
    "                    if entity.text != canonical_name:\n",
    "                        umls_aliases_set.add(entity_name)\n",
    "\n",
    "                    # entity_dict.update({canonical_name:{'cid': concept_id, 'definition':definition, 'aliases':umls_aliases_set, 'paper_lst':{paper_id}}})\n",
    "                    entity_dict.update({canonical_name:{'cid': concept_id, 'definition':definition, 'aliases':umls_aliases_set, 'paper_lst':{paper_id},'tf_lst':[[paper_id,1]]}})#*\n",
    "\n",
    "                # if it both in kb and the paper, just +1 in term freq\n",
    "                elif canonical_name in self.kb['entities'].keys() and canonical_name in entity_dict.keys():\n",
    "                    for i,tf_lst in enumerate(entity_dict[canonical_name]['tf_lst']):\n",
    "                        if tf_lst[0] == paper_id:\n",
    "                            entity_dict[canonical_name]['tf_lst'][i][1] = entity_dict[canonical_name]['tf_lst'][i][1]+1\n",
    "                            break\n",
    "\n",
    "                # if this entity not in the KB but in this paper\n",
    "                elif canonical_name not in self.kb['entities'].keys() and canonical_name in entity_dict.keys():\n",
    "                    entity_dict[canonical_name]['paper_lst'].add(paper_id)\n",
    "                    for i,tf_lst in enumerate(entity_dict[canonical_name]['tf_lst']):\n",
    "                        if tf_lst[0] == paper_id:\n",
    "                            entity_dict[canonical_name]['tf_lst'][i][1] = entity_dict[canonical_name]['tf_lst'][i][1]+1\n",
    "                            break\n",
    "                    # entity_dict[canonical_name]['tf_lst'][paper_id] = entity_dict[canonical_name]['tf_lst'][paper_id] +1 #*\n",
    "                    if entity_name != canonical_name:\n",
    "                        entity_dict[canonical_name]['aliases'].add(entity_name)\n",
    "\n",
    "\n",
    "                # if this entity appears in th KB, but new to this paper\n",
    "                elif canonical_name in self.kb['entities'].keys() and canonical_name not in entity_dict.keys():\n",
    "                    self.kb['entities'][canonical_name]['paper_lst'].add(paper_id)\n",
    "                    self.kb['entities'][canonical_name]['tf_lst'].append([paper_id,1])\n",
    "\n",
    "                    # self.kb['entities'][canonical_name]['tf_lst'][paper_id] = self.kb['entities'][canonical_name]['tf_lst'][paper_id] + 1\n",
    "                    if entity_name != canonical_name:\n",
    "                        self.kb['entities'][canonical_name]['aliases'].add(entity_name)\n",
    "                    entity_dict.update(self.kb['entities'][canonical_name])\n",
    "\n",
    "        return entity_dict\n",
    "\n",
    "    def __build_all_entity_dict(self,text,title,paper_id,body_text):\n",
    "        # This function is keeping updating this paper's entity dictionary\n",
    "        # during process paper's title, abstract and the first 500 and last 500 words in body text\n",
    "        entity_dict = {}\n",
    "        linker = self.nlp.get_pipe(\"scispacy_linker\")\n",
    "        text_doc = self.nlp(text)\n",
    "        entity_dict.update(self.__update_entity_dict(entity_dict,text_doc,linker,paper_id))\n",
    "\n",
    "        title_doc = self.nlp(title)\n",
    "        entity_dict.update(self.__update_entity_dict(entity_dict,title_doc,linker,paper_id))\n",
    "\n",
    "        body_text_doc = self.nlp(body_text)\n",
    "        entity_dict.update(self.__update_entity_dict(entity_dict,body_text_doc,linker,paper_id))\n",
    "\n",
    "        return entity_dict\n",
    "\n",
    "    def build_KB_with_entities(self):\n",
    "        self.kb = self.__init_KB()\n",
    "        self.__init_nlp()\n",
    "\n",
    "        for paper_id,paper_dict in tqdm.tqdm(self.kb['paper'].items(), desc = 'Building entities', unit = ' article'):\n",
    "            abstract = self.processed_df.loc[self.processed_df['paper_id']==paper_id]['abstract'].values[0]\n",
    "            title = paper_dict['title']\n",
    "            # only process the 1st 500 and the last 500 words in the body text,\n",
    "            # these might be the introduction and the conclusion of the article, which is more representative of this paper\n",
    "            body_text = self.processed_df.loc[self.processed_df['paper_id']==paper_id]['body_text'].values[0]\n",
    "            body_text_intro = ' '.join(body_text.split()[:500])\n",
    "            body_text_conclu = ' '.join(body_text.split()[-500:])\n",
    "            sampled_body_text = body_text_intro + body_text_conclu\n",
    "\n",
    "            entity_dict = self.__build_all_entity_dict(abstract, title,paper_id, sampled_body_text)\n",
    "            for k in ['cid', 'definition', 'aliases', 'paper_lst']:\n",
    "                entity_dict.pop(k, None)\n",
    "            self.kb['entities'].update(entity_dict)\n",
    "            paper_dict.update({'entities': list(entity_dict.keys())})\n",
    "        for canonical in self.kb['entities'].keys():\n",
    "            temp = []\n",
    "            if isinstance(self.kb['entities'][canonical],dict):\n",
    "                for tf_lst in self.kb['entities'][canonical]['tf_lst']:\n",
    "                    if len(temp) == 0:\n",
    "                        temp.append(tf_lst)\n",
    "                    else:\n",
    "                        if tf_lst[0] == temp[-1][0]:\n",
    "                            temp[-1][1] = temp[-1][1]+1\n",
    "                        else:\n",
    "                            temp.append(tf_lst)\n",
    "                self.kb['entities'][canonical].update({'tf_lst':temp})\n",
    "        self.kb['entities'].pop('tf_lst')\n",
    "        self.__save_kb()\n",
    "        return\n",
    "\n",
    "    def __save_kb(self):\n",
    "        with open(self.kb_path,'wb') as kb_pickled:\n",
    "            pickle.dump(self.kb,kb_pickled)\n",
    "            print('Knowledge base saved successfully!')\n",
    "        return\n",
    "\n",
    "\n",
    "k = Knowledge_Base(processed_df)\n",
    "KB = k.kb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The structure of my knowledge base:\n",
    "\n",
    "```\n",
    "├── KB\n",
    "    ├── 'paper'\n",
    "        ├── 'paper_id 1'\n",
    "            ├── 'title' : xxx\n",
    "            ├── 'authors' : [xxx,xxx,...]\n",
    "            ├── 'entities' : [xxx,xxx,...]\n",
    "        ├── 'paper_id 2'\n",
    "            ├── 'title' : xxx\n",
    "            ├── 'authors' : [xxx,xxx,...]\n",
    "            ├── 'entities' : [xxx,xxx,...]\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "\n",
    "    ├── 'authors'\n",
    "        ├── 'author name 1'\n",
    "            ├── 'paper_lst' : [xxx,xxx,...]\n",
    "        ├── 'author name 2'\n",
    "            ├── 'paper_lst' : [xxx,xxx,...]\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "\n",
    "    ├── 'entities'\n",
    "        ├── 'canonical_name 1'\n",
    "            ├── 'cid' (concept id, or CUI) : xxx\n",
    "            ├── 'definition' : xxx\n",
    "            ├── 'aliases' : [xxx,xxx,...]\n",
    "            ├── 'paper_lst' : [xxx,xxx,...]\n",
    "            ├── 'tf_lst' : [xxx,xxx,...]\n",
    "        ├── 'canonical_name 2'\n",
    "            ├── 'cid' (concept id, or CUI) : xxx\n",
    "            ├── 'definition' : xxx\n",
    "            ├── 'aliases' : [xxx,xxx,...]\n",
    "            ├── 'paper_lst' : [xxx,xxx,...]\n",
    "            ├── 'tf_lst' : [xxx,xxx,...]\n",
    "        ├── 'canonical_name 3'\n",
    "            ├── 'cid' (concept id, or CUI) : xxx\n",
    "            ├── 'definition' : xxx\n",
    "            ├── 'aliases' : [xxx,xxx,...]\n",
    "            ├── 'paper_lst' : [xxx,xxx,...]\n",
    "            ├── 'tf_lst' : [xxx,xxx,...]\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "```\n",
    "In this section, I only processed the paper title, abstract and first 500 words and last 500 words of the body text, because these two parts of the body text can introduce and conclude this paper, which are more representative of the body text. (I tried to process the whole body_text previously, but my computer always froze and could not process all 10000 samples' whole body text, so I sub-sampled the body text to these two parts to represent the whole body text). The process pipeline consists of NER, abbrev resolution, and a further text normalisation using UMLS's concept id (cui). The detailed processing steps are as follows: <br>\n",
    "\n",
    "I utilized the library sciSpaCy 'en_core_sci_sm' pretrained model to perform Named Entity Recognition, and added extra pipeline ,entity_linker with abbreviation resolution, to link the recognized entity to the UMLS knowledge base, where the 'UMLS' stands for the Unified Medical Language System. The entity linker will link the entity to an external medical knowledge base. In this case, I used UMLS, which contains around 3M biomedical concepts. There are other options of the external knowledge base, such as MESH (Medical Subject Headings, 30K entities), but I am using the UMLS, because it is the largest medical knowledge base in SciSpaCy. In this step, the entity linker will map the recognised entity to the known entity (or concept) in th UMLS. This process will also resolve the abbreviations, by adding \"resolve_abbreviations\": True. Abbreviation resolution is an important step because abbreviations are commonly exist in biomedical texts. For each recognised entity, I will only link it to the top 1 match (by setting 'k':1), with a threshold of 0.8 (the default thresh is 0.7, but I tuned it up to 0.8, for a more fine-grained output).\n",
    "Once I match it to a concept entity in UMLS, then I keep its canonical name and other alias recorded in UMLS. If the entities are recognised but not the same as the UMLS canonical name nor any UMLS alias, then this entity name will be added to its alias list as well, and its UMLS canonical name will be the key of this entity entry in the KB. Therefore, during the construction of the KB, the number of entities is growing as the model scanning through the articles, and at the same time, each entities' aliases list are growing too. Furthermore, if the entity is already exist in the KB, its 'paper_lst' is also updated when scanning new articles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Indexing method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def generate_inverted_index(KB,processed_df):\n",
    "    inverted_dict = {}\n",
    "    # for key in ['authors']:\n",
    "    for key in ['authors','entities']:\n",
    "        canonical_lst = list(set(KB[key].keys()))\n",
    "        for can in canonical_lst:\n",
    "            inverted_dict.update({can:[]})\n",
    "            if key == 'entities':\n",
    "                for id_tf_tupe in KB['entities'][can]['tf_lst']:\n",
    "                    inverted_dict[can].append(id_tf_tupe)\n",
    "                    inverted_dict[can].append((paper_id,tf))\n",
    "            else:\n",
    "                for paper_id in KB[key][can]['paper_lst']:\n",
    "                    tf = 1 # author name will only apperar once in the paper\n",
    "                    inverted_dict[can].append((paper_id,tf))\n",
    "            inverted_dict[can].sort(key=lambda x: x[0])\n",
    "    return inverted_dict\n",
    "\n",
    "inverted_index = generate_inverted_index(KB,processed_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 paper mentioned COVID-19 (or its aliases):  [0, 1, 5, 6, 7, 8, 9, 10, 11, 12] \n",
      "\n",
      "Show 5 article mentioned mRNA Expression (idx):  [1, 4, 10, 11, 13] \n",
      "\n",
      "Show 5 article mentioned mRNA Expression (title):\n",
      "Similarities and Differences in the Acute-Phase Response to SARS-CoV-2 in Rhesus Macaques and African Green Monkeys\n",
      "Roles of Podoplanin in Malignant Progression of Tumor\n",
      "COVID-19: Clinical features, case fatality, and the effect of symptoms on mortality in hospitalized cases in Iran\n",
      "Coronary Thrombo-Embolic Events after Covid-19 Vaccination- A Single Centre Study\n",
      "Do suicide rates in children and adolescents change during school closure in Japan? The acute effect of the first wave of COVID-19 pandemic on child and adolescent mental health\n",
      " \n",
      " len inverted index: 126308\n"
     ]
    }
   ],
   "source": [
    "print('First 10 paper mentioned COVID-19 (or its aliases): ',[lst[0] for lst in inverted_index['COVID-19'][:10]],'\\n')\n",
    "print('Show 5 article mentioned mRNA Expression (idx): ', [lst[0] for lst in inverted_index['mRNA Expression'][:5]],'\\n')\n",
    "print('Show 5 article mentioned mRNA Expression (title):')\n",
    "for id in inverted_index['mRNA Expression'][:5]:\n",
    "    title = processed_df.loc[processed_df['paper_id']==id[0]]['title'].values[0]\n",
    "    print(title)\n",
    "\n",
    "print(f' \\n len inverted index: {len(inverted_index)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section, the article indexing method is inverted index by named entities.\n",
    "<br>\n",
    " Each canonical name is a key in inverted_index dictionary, its value is a list of tuples, where each tuple contains a id of the paper that mentioned this entity, and the term frequency of this entity in this paper (tf). By utilizing the information in the KB, it's very efficient to build the inverted index. Because these information can be directly obtained from the KB. Note, the term frequency here is the value after the text normalisation, because the term frequency in the KB considered the UMLS alias and other names mapped to the same UMLS concept as well. <br>\n",
    "\n",
    "With the help of inverted index, we can significantly reduce the search space during the retrieval of documents."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40914/60760 [09:44<08:44, 37.81it/s]"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067cebcf",
   "metadata": {},
   "source": [
    "### 4. Text matching utility"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This function will read the clove file, and create a dictionary for our vocabulary\n",
    "def build_glove_embedding_dict():\n",
    "    glove_final_dict_path = 'glove_final_dict.pkl'\n",
    "    if os.path.isfile(glove_final_dict_path):\n",
    "        with open(glove_final_dict_path, 'rb') as kb_pickled:\n",
    "            embedding_vector = pickle.load(kb_pickled)\n",
    "    else:\n",
    "        WV_PATH = 'glove.840B.300d.txt'\n",
    "        embedding_vector = {}\n",
    "        f = open(WV_PATH,encoding=\"utf8\") #embedding dim = 300\n",
    "        for line in tqdm.tqdm(f,desc = 'Building word vector dictionary'):\n",
    "            value = line.split(' ')\n",
    "            word = value[0]\n",
    "            coef = np.array(value[1:],dtype = 'float32')\n",
    "            embedding_vector[word] = coef\n",
    "        f.close()\n",
    "        print('Loaded %s word vectors.' % len(embedding_vector))\n",
    "        with open(glove_final_dict_path,'wb') as f_pickled:\n",
    "            pickle.dump(embedding_vector,f_pickled)\n",
    "            print('glove_final_dict saved successfully!')\n",
    "    return embedding_vector\n",
    "\n",
    "glove_dict = build_glove_embedding_dict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I used the pre-trained embedding layer GloVe 840B 300d.(download through: https://nlp.stanford.edu/projects/glove/) GloVe is pre-trained to capture the context of the word in the embedding through explicitly capturing the co-occurrence probability. It aims to be built not just on the word probabilities, but their co-occurrence probabilities within the context, and this is used in its loss function in its pre-train process. <br>\n",
    "\n",
    "Steps: <br>\n",
    "Download Glove, open the text file, and create a dictionary with word as a key and its corresponding embedding vector as its value. <br>\n",
    "\n",
    "Note: I found GloVe is not very good when working with biomedical text, because GloVe is not sufficiently trained on biomedical texts. For example, the Glove I am using (840B 300d) was just trained on common crawled text. There are many medical word not in Glove Embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Check the percentage of words mentioned in KB and also exists in GloVe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_glove_available_percentage(glove_dict,KB):\n",
    "    all_ent = []\n",
    "    for can in list(set(KB['entities'].keys())):\n",
    "        all_ent.append(can)\n",
    "        alias_lst = list(KB['entities'][can]['aliases'])\n",
    "        all_ent.extend(alias_lst)\n",
    "    unique_token = list({token for ent in all_ent for token in ent.split(' ')})\n",
    "    num_token_exist = 0\n",
    "    for token in unique_token:\n",
    "        if token in glove_dict.keys():\n",
    "            num_token_exist += 1\n",
    "    percent = num_token_exist/len(unique_token)\n",
    "    print(f\"There are {len(unique_token)} tokens exist in the KB, and {num_token_exist} of these tokens are available in GloVe ({round(percent*100,2)}% vocabulary availabel in GloVe)\")\n",
    "    return\n",
    "check_glove_available_percentage(glove_dict,KB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The lack of medical vocabulary is the major drawback of using GloVe embedding in this assignment. However, using pretrained word embedding is asked in the assignment step 4(d). Therefore, I am still going to implement my IR system using GloVe. Furthermore, integrating the pre-trained word embedding into the Information Retrival System can generally improve the performance of the retrival, because TF-IDF cannot imply the semantic similarity, whereas, the pre-trained word embeddings learned the semantic meaning of the words over a large amount of text. Therefore, I am going to integrate GloVe into the IR System.\n",
    "<br>\n",
    "Potential Improvement: <br>\n",
    "1. It's better to use a word embedding that can capture more medical terms' meanings, instead of using general-purpose word embedding GloVe. I did some research on this and found a publically available biomedical word embedding 'cui2vec' (GitHub: https://github.com/beamandrew/cui2vec , download: https://figshare.com/s/00d69861786cd0156d81 , paper: https://arxiv.org/abs/1804.01486 ). 'cui2vec' can map UMLS concept unique identifier (cui) to a vector. This implies 'cui2vec' word embedding is highly aligned and consistent with our knowledge base that is built with UMLS concepts as well. However, 'cui2vec' does not cover a lot of the entity concepts that are in out CORD-19 article KB (only 32.43% available, which is even worse than GloVe. 'cui2vec' is in entity phrase levels, GloVe is in word token level, but generally speaking, 32.43% in entity level is worse than 44.63% in token level, because even there is one unknown word in a medical phrase, but if we can embed other tokens, the model can still contain partial information of this token). Other than 'cui2vec', there is an available 'BioWordVec'. 'BioWordVec' is a biomedical word embedding pre-trained on PubMed+MIMIC-III using FastText, but this embedding is too big (13GB) for my local computer. Therefore, I am going to use GloVe embedding, which can be used on my local PC, and also covers larger amount of medical terms compared with 'cui2vec'. However, if I have a computer with better computation power and bigger memory, I will definitely give 'BioWordVec' a try.\n",
    "<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Due to the lack of coverage of medical terminologies in GloVe embedding, I am going to use both TF-IDF and pre-trained GloVe word embeddings in my IR system. By combining these two scores, the retrival performance can be more robust, especially in the cases of out-of-vocabulary in GloVe. The detailed implementation of my IR system as follows:\n",
    "\n",
    "- query pre-processing:\n",
    "    - In my IR system, I pre-process the query by removing the stopwords. Then perform NER by using two models, one is 'en_core_sci_sm' for medical entity recognition, and 'en_core_web_sm' for general named entity recognition. This is because the SciSpaCy medical NER model are not good at recognising general entities, such as, author names, etc. Therefore, we also need a general NER model too.\n",
    "- matching common entities and get the posting list to reduce the paper search space:\n",
    "    - if the entity in the query is matched to a canonical name in the inverted index key, then we store this entity for further embedding and tf-idf computation, also get id of the articles mentioned this entity.\n",
    "    - if this entity in the query is an alias (other associated names) of a canonical name, then we will get its canonical name. Then do the same steps above.\n",
    "    - If query entity is neither a canonical name nor an alias, then I compute the cosine similarity of this query entity with all the canonical names in the inverted index. if all the similarities are < 0.7, it won't match to any doc canonical entities, and we will ignore this query entity. Otherwise, the query entity will match to the canonical name with the highest similarity score. (This text normalisation step can also be done with the scispacy UMLS entitylinker, but it's a very heavy model, and it is very time-consuming. Therefore, I am utilising the cosine similarity of the embedding to perform the soft match. Normalising the query text is important, because there will be query entities that are neither the canonical name nor the known aliases in the KB, but they might describe the same concept. Using cosine similarity to perform the soft match can mitigate this issue)\n",
    "    - Finally, the query will be represented by these matched entities, and at the same time we also obtained a reduced doc search space from inverted index method\n",
    "- Compute the score for all the doc in the reduced search space\n",
    "    - The score of the retrival rank contains two parts, the tf-idf and the cosine similarity of the query and document vectors\n",
    "        - The query and the document are both represented by their recognised entities. If an entity is composed of multiple word tokens, then this entity will be represented as a mean-pooling of all the tokens, therefore, all the entity embeddings are 300d (the dimension is the same as the GloVe embedding for a single token). Then the query embedding and the document embedding vector is the mean-pooling vector of all their recognised entities, so the query and the documents vectors are both 300d.\n",
    "        - To alleviate the limited medical vocabulary coverage of the GloVe embedding, I utilised both tf-idf and the GloVe embedding cosine similarity.\n",
    "        - I first standardise the embedding cosine similarity list and the tfidf list both in the range of 0-1. For each document I averaged its standardised tf-idf score and the standardised embedding cosine score, and this average will be the final score of ranking. By doing this, some rare medical words that are not in the GloVe embedding can still obtain some ranking score from tf-idf part. There are some out-of-vocabulary retrival test examples below.\n",
    "        - Finally, rank the documents based on the scores.\n",
    "\n",
    "##### The detailed implementation is shown in the code below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Retriever_glove:\n",
    "    def __init__(self,inverted_index,glove_dict,KB,data_df):\n",
    "        self.nlp = spacy.load(\"en_core_sci_sm\") # for medical NER on query\n",
    "        self.nlp_general = spacy.load(\"en_core_web_sm\") # for general NER on query, such as author names, etc\n",
    "        self.word_embedding = glove_dict\n",
    "        self.inverted_index = inverted_index\n",
    "        self.KB = KB\n",
    "        self.norm_dict = self.__canonical_aliases_normalization()\n",
    "        self.data_df = data_df\n",
    "        return\n",
    "\n",
    "    def __get_vec(self,word):\n",
    "        if word in self.word_embedding.keys():\n",
    "            return self.word_embedding.get(word)\n",
    "        else:\n",
    "            # if the word is unknown in GloVe, then return a zero vector with the same dim i.e. 300\n",
    "            return np.zeros(300)\n",
    "\n",
    "    def __embed_text(self,ent_lst):\n",
    "        entity_embedding_dict = {}\n",
    "        for ent in ent_lst:\n",
    "            # if the entity is a term consists of multiple word tokens, then just avergae it\n",
    "            if ' ' in ent:\n",
    "                stack = np.vstack((self.__get_vec(w) for w in ent.split()))\n",
    "                ent_vector = np.mean(stack,axis = 0)\n",
    "            else:\n",
    "                ent_vector = self.__get_vec(ent)\n",
    "            entity_embedding_dict.update({ent:ent_vector})\n",
    "        return entity_embedding_dict\n",
    "\n",
    "    def __canonical_aliases_normalization(self):\n",
    "        norm_dict = {}\n",
    "        for can in list(set(self.KB['entities'].keys())):\n",
    "            for alias in list(self.KB['entities'][can]['aliases']):\n",
    "                norm_dict.update({alias:can})\n",
    "        return norm_dict\n",
    "\n",
    "    def __cal_wv_similarity(self,entity_vec_dict1,entity_vec_dict2):\n",
    "        # if the text contain multiple entities,\n",
    "        # then the vector that represents this text is the average of all the entity vector\n",
    "        for i, embedding_dict in enumerate([entity_vec_dict1,entity_vec_dict2]):\n",
    "            # if there's no embedding, then return similarity of 0\n",
    "            if len(embedding_dict) == 0:\n",
    "                return 0\n",
    "            if len(embedding_dict) == 1:\n",
    "                text_vec = list(embedding_dict.values())[0]\n",
    "            else:\n",
    "                stack = np.vstack((v for v in embedding_dict.values()))\n",
    "                text_vec = np.mean(stack,axis = 0)\n",
    "            if i == 0:\n",
    "                text_vec1 = text_vec\n",
    "            else:\n",
    "                text_vec2 = text_vec\n",
    "\n",
    "        if norm(text_vec1) == 0 or norm(text_vec2) == 0:\n",
    "            return 0\n",
    "        cos_sim = dot(text_vec1, text_vec2)/(norm(text_vec1)*norm(text_vec2))\n",
    "        return cos_sim\n",
    "\n",
    "    def __cal_tfidf_similarity(self,matched_ent,paper_id):\n",
    "        tfidf_score = 0\n",
    "        for ent in matched_ent:\n",
    "            if len([ele[1] for ele in self.inverted_index.get(ent) if ele[0] == paper_id]) != 0:\n",
    "                t_count = [ele[1] for ele in self.inverted_index.get(ent) if ele[0] == paper_id][0]\n",
    "                tf_w = 1 + math.log10(t_count)\n",
    "                N = 10000\n",
    "                df = len(self.KB['entities'][ent]['paper_lst'])\n",
    "                idf_w = math.log10((N/df))\n",
    "                tfidf_score += tf_w*idf_w\n",
    "        # doc_tfidf_norm = self.__get_doc_tfidf_norm(paper_id)\n",
    "        # tfidf_score = tfidf_score/doc_tfidf_norm\n",
    "        return tfidf_score\n",
    "\n",
    "    def __show_result(self,paper_selected):\n",
    "        for rank in range(1,len(paper_selected)+1):\n",
    "            idx = rank -1\n",
    "            snippet = self.data_df.loc[self.data_df['paper_id']==paper_selected[idx][0]]['original_abstract'].values[0]\n",
    "            title = self.data_df.loc[self.data_df['paper_id']==paper_selected[idx][0]]['title'].values[0]\n",
    "            authors = self.data_df.loc[self.data_df['paper_id']==paper_selected[idx][0]]['authors'].values[0]\n",
    "            article_identifier = self.data_df.loc[self.data_df['paper_id']==paper_selected[idx][0]]['paper_identifier'].values[0]\n",
    "            article_number = self.data_df.loc[self.data_df['paper_id']==paper_selected[idx][0]]['paper_id'].values[0]\n",
    "            score = paper_selected[idx][1]\n",
    "            if rank != 1:\n",
    "                print('\\n')\n",
    "            print(f'------------------------------ Match Ranked {rank} (similarity score: {score})------------------------------')\n",
    "            print(f'article identifier: {article_identifier},  article number: {article_number} \\n')\n",
    "            print(f'title:  {title} \\n')\n",
    "            print('Authors: ')\n",
    "            print('; '.join(authors),'\\n')\n",
    "            print('snippet: \\n')\n",
    "            print(snippet)\n",
    "\n",
    "    def retrive(self,query,show = True):\n",
    "        stops = stopwords.words('english') # english stopwords, because our data is in english\n",
    "        query = \" \".join([word for word in query.split() if word not in stops])\n",
    "        query = query.replace('[^A-Za-z0-9\\s+\\-]',' ')\n",
    "        q_doc = self.nlp(query)\n",
    "        q_doc_general = self.nlp_general(query)\n",
    "        q_entities = list(set([ent.text.strip() for ent in  q_doc.ents] + [ent.text.strip() for ent in  q_doc_general.ents]))\n",
    "        query_ent_vec_dict = self.__embed_text(q_entities)\n",
    "\n",
    "        doc_lst = []\n",
    "        matched_ent = []\n",
    "        for ent in q_entities:\n",
    "            # try hard match first\n",
    "            if ent in self.inverted_index.keys():\n",
    "                paper_lst = [ele[0] for ele in self.inverted_index.get(ent)]\n",
    "                doc_lst.extend(paper_lst)\n",
    "                matched_ent.append(ent)\n",
    "            elif ent in self.norm_dict.keys():\n",
    "                can = self.norm_dict[ent]\n",
    "                paper_lst = [ele[0] for ele in self.inverted_index.get(can)]\n",
    "                doc_lst.extend(paper_lst)\n",
    "                matched_ent.append(can)\n",
    "            # if can't hard match, use word vector to soft match them with a threshold\n",
    "            else:\n",
    "                ENT_SOFT_MATCH_THRESH = 0.7\n",
    "                can_lst = list(set(self.norm_dict.values()))\n",
    "                sim_lst = []\n",
    "                for can in can_lst:\n",
    "                    can_vec_dict = self.__embed_text([can])\n",
    "                    q_ent_vec_dict = {ent:query_ent_vec_dict[ent]}\n",
    "\n",
    "                    # if any of these two entities are completely out of vocab in GloVe, skip match them\n",
    "                    if np.all(can_vec_dict.get(can)==0) or np.all(q_ent_vec_dict.get(ent)==0):\n",
    "                        continue\n",
    "\n",
    "                    sim_lst.append(self.__cal_wv_similarity(q_ent_vec_dict,can_vec_dict))\n",
    "                if len(sim_lst) == 0:\n",
    "                    continue\n",
    "                max_sim = max(sim_lst)\n",
    "                if max_sim > ENT_SOFT_MATCH_THRESH:\n",
    "                    max_idx = sim_lst.index(max_sim)\n",
    "                    can = can_lst[max_idx]\n",
    "                    paper_lst = [ele[0] for ele in self.inverted_index.get(can)]\n",
    "                    doc_lst.extend(paper_lst)\n",
    "                    matched_ent.append(can)\n",
    "\n",
    "        doc_to_be_searched = list(set(doc_lst))\n",
    "        wv_score = []\n",
    "        tfidf_score = []\n",
    "        for paper_id in doc_to_be_searched:\n",
    "            doc_ent_lst = self.KB['paper'][paper_id]['entities'] + self.KB['paper'][paper_id]['authors']\n",
    "            doc_ent_vec_dict = self.__embed_text(doc_ent_lst)\n",
    "            wv_score.append(self.__cal_wv_similarity(doc_ent_vec_dict,query_ent_vec_dict))\n",
    "            tfidf_score.append(self.__cal_tfidf_similarity(matched_ent,paper_id))\n",
    "\n",
    "        # standardising the wv similarity score and tfidf score to 0-1 before averaging the two scores\n",
    "        if len(tfidf_score) == 0 or max(tfidf_score) == min(tfidf_score):\n",
    "            std_tfidf_score = [0]*len(tfidf_score)\n",
    "        else:\n",
    "            std_tfidf_score = [(s - min(tfidf_score))/(max(tfidf_score)-min(tfidf_score)) for s in tfidf_score]\n",
    "\n",
    "        if len(wv_score) == 0 or max(wv_score) == min(wv_score):\n",
    "            std_wv_score = [0]*len(wv_score)\n",
    "        else:\n",
    "            std_wv_score = [(s - min(wv_score))/(max(wv_score)-min(wv_score)) for s in wv_score]\n",
    "\n",
    "        # The final retrieval score is the average of the standardised tfidf and the standardised wv cos similarity\n",
    "        scores_lst = [(glove+tfidf)/2 for glove,tfidf in zip(std_wv_score,std_tfidf_score)]\n",
    "        scores_arr = np.array(scores_lst)\n",
    "        ranked_idx = np.argsort(scores_arr)[::-1]\n",
    "        paper_ranked = [(doc_to_be_searched[idx],scores_arr[idx]) for idx in ranked_idx]\n",
    "        if len(paper_ranked) == 0:\n",
    "            print('Sorry, there is no good match :(')\n",
    "        else:\n",
    "            if show == True:\n",
    "                self.__show_result(paper_ranked[:3])\n",
    "            else:\n",
    "                return paper_ranked\n",
    "\n",
    "    def eval(self,queries,labels):\n",
    "        # this function return mrr metric\n",
    "        RR_lst = []\n",
    "        for q,l in zip(queries,labels):\n",
    "            paper_ranked = self.retrive(q,show = False)\n",
    "            paper_id_ranked = [tup[0] for tup in paper_ranked]\n",
    "            if l in paper_id_ranked:\n",
    "                RR = 1/(paper_id_ranked.index(l)+1) # '+1' here is because we are using the position not the index\n",
    "            else:\n",
    "                RR = 0\n",
    "            RR_lst.append(RR)\n",
    "        return sum(RR_lst)/len(RR_lst)\n",
    "\n",
    "IR = Retriever_glove(inverted_index,glove_dict,KB,processed_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How useful NER and KB for this task?\n",
    "- NER: With the help of NER, the number of unique words are significantly reduced and thus improved the time efficiency (without big drop of retrieval performance). Because the conventional IR using inverted index method is utilising all the unique words, which is not a desired method especially when the document collection is huge. After performing NER, the IR system can focus more on the context, so even we reduce the space of inverted index, the IR system can still maintain a good performance. Furthermore, using unique words will break the entity phrases apart, and twisted the representation of the original meaning. Therefore, we need NER to maintain the integrity of the context.\n",
    "- KB: The Knowledge base enable an easy implementation of the retrieval system by collecting all the crucial information of the document collection. In the KB, each document is represented as its entities, so people do not need to go through the entire text. The most important part of KB is the storage of canonical names and the associated aliases for text normalisation. In real life, the ways of conveying the same concept in natural language could be various. And text normalisation could enable the IR system to capture the concepts correctly under these variations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = 'what are the symptoms of covid19?'\n",
    "IR.retrive(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- By reading and analysing the text snippet myself, I found these top 2 articles are highly relevant to the symptoms of COVID, the performance of retrival is really well. For example, the 1st one talks about the possible psychosis symptoms of covid, e.g.'patients with a novel corona virus had psychotic symptoms, including hallucination in different forms of modality, delusion, disorganized speech, and grossly disorganized or catatonic behaviors'. The 2nd article mainly talks about the headache symptoms of covid specifically."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarization -- Duc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class NLTK_Extractive_Summarizer:\n",
    "    \"\"\"\n",
    "    A class used to summarize texts.\n",
    "    Attributes\n",
    "    ----------\n",
    "    stop_words : set\n",
    "        a set of stopwords. These are ignored when searching for the most used\n",
    "        words in the text\n",
    "    language : str\n",
    "        the current selected language. The stop words set is language specific\n",
    "    summary_length : int\n",
    "        the default number of sentences to use for the summary.\n",
    "    balance_length : bool\n",
    "        determines if the sentence weight is weighted based on sentence length\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = {}\n",
    "    language = None\n",
    "    summary_length = 0\n",
    "    balance_length = False\n",
    "\n",
    "    def __init__(self, language='english', summary_length=3, balance_length=True):\n",
    "        \"\"\"\n",
    "        :param str language: The language to use, defaults to 'en'\n",
    "        :param int summary_length: The default number of sentences in summary, defaults to 3\n",
    "        :param bool balance_length: Balance sentences on length, default to False\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the language to use and set the stop words to the default\n",
    "        # list provided by NLTK corpus for this language\n",
    "        self.stop_words = set(stopwords.words(language))\n",
    "        self.language = language\n",
    "\n",
    "        # Set the default length for the summaries to be created\n",
    "        self.summary_length = summary_length\n",
    "\n",
    "        # Sets the switch if the sentence weights need to weighted on\n",
    "        # sentence length. This might improve performance if the text\n",
    "        # contains a variety of short and long sentences.\n",
    "        self.balance_length = balance_length\n",
    "\n",
    "    def weighted_sentence(self, text, summary_length=None):\n",
    "        \"\"\"\n",
    "        Summarize the given text based on the weight of sentence\n",
    "        The language and stop word set have been initialized and are used. If no\n",
    "        summary length is given as parameter, the default length is used.\n",
    "        :param (str or list) text: The text to summarize\n",
    "        :param int summary_length: The number of sentences in summary, optional\n",
    "        :return (str): A string with the summary of the given text\n",
    "        \"\"\"\n",
    "\n",
    "        # Length of summary to generate, if not specified use default\n",
    "        if not summary_length:\n",
    "            summary_length = self.summary_length\n",
    "\n",
    "        # Make a list of all the sentences in the given text\n",
    "        sentences = []\n",
    "        if type(text) == str:\n",
    "            sentences.extend(tokenize.sent_tokenize(text))\n",
    "        elif type(text) == list:\n",
    "            for text_part in text:\n",
    "                sentences.extend(tokenize.sent_tokenize(text_part))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "        # Determine for each word, not being a stop word, the number of occurences\n",
    "        # in the text. This word frequency determines the importance of the word.\n",
    "        word_weights={}\n",
    "        for sent in sentences:\n",
    "            for word in word_tokenize(sent):\n",
    "                word = word.lower()\n",
    "                if len(word) > 1 and word not in self.stop_words:\n",
    "                    if word in word_weights.keys():\n",
    "                        word_weights[word] += 1\n",
    "                    else:\n",
    "                        word_weights[word] = 1\n",
    "\n",
    "        # The weight of each sentence equals the sum of the word importance for\n",
    "        # each word in the sentence\n",
    "        sentence_weights = {}\n",
    "        for sent in sentences:\n",
    "            sentence_weights[sent] = 0\n",
    "            tokens = word_tokenize(sent)\n",
    "            for word in tokens:\n",
    "                word = word.lower()\n",
    "                if word in word_weights.keys():\n",
    "                    sentence_weights[sent] += word_weights[word]\n",
    "            if self.balance_length and (len(tokens) > 0):\n",
    "                sentence_weights[sent] = sentence_weights[sent] / len(tokens)\n",
    "        highest_weights = sorted(sentence_weights.values())[-summary_length:]\n",
    "\n",
    "\n",
    "        # The summary consists of the sentences with the highest sentence weight, in the\n",
    "        # same order as they occur in the original text\n",
    "        summary = \"\"\n",
    "        for sentence, strength in sentence_weights.items():\n",
    "            if strength in highest_weights:\n",
    "                summary += sentence + \" \"\n",
    "        summary = summary.replace('_', ' ').strip()\n",
    "\n",
    "        return summary\n",
    "\n",
    "\n",
    "    def text_rank(self, text, summary_length=None):\n",
    "        \"\"\"\n",
    "        Summarize the given text using text rank algorithm (based on page rank)\n",
    "        The language and stop word set have been initialized and are used. If no\n",
    "        summary length is given as parameter, the default length is used.\n",
    "        :param (str or list) text: The text to summarize\n",
    "        :param int summary_length: The number of sentences in summary, optional\n",
    "        :return (str): A string with the summary of the given text\n",
    "        \"\"\"\n",
    "\n",
    "        # Length of summary to generate, if not specified use default\n",
    "        if not summary_length:\n",
    "            summary_length = self.summary_length\n",
    "\n",
    "        # Make a list of all the sentences in the given text\n",
    "        sentences = []\n",
    "        if type(text) == str:\n",
    "            sentences.extend(tokenize.sent_tokenize(text))\n",
    "        elif type(text) == list:\n",
    "            for text_part in text:\n",
    "                sentences.extend(tokenize.sent_tokenize(text_part))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "        # remove punctuations, numbers and special characters\n",
    "        clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "        # make alphabets lowercase\n",
    "        clean_sentences = [s.lower() for s in clean_sentences]\n",
    "\n",
    "        # function to remove stopwords\n",
    "        def remove_stopwords(sen):\n",
    "            sen_new = \" \".join([i for i in sen if i not in self.stop_words])\n",
    "            return sen_new\n",
    "\n",
    "\n",
    "        # remove stopwords from the sentences\n",
    "        clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "\n",
    "        # Extract word vectors\n",
    "        word_embeddings = {}\n",
    "        with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                word_embeddings[word] = coefs\n",
    "\n",
    "\n",
    "        # Init sentence vectors\n",
    "        sentence_vectors = []\n",
    "        for sent in clean_sentences:\n",
    "            if len(sent) != 0:\n",
    "                vec = sum([word_embeddings.get(word, np.zeros((100,))) for word in sent.split()]) / (len(sent.split()) + 0.001)\n",
    "            else:\n",
    "                vec = np.zeros((100,))\n",
    "            sentence_vectors.append(vec)\n",
    "\n",
    "        # similarity matrix\n",
    "        sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "        for i in range(len(sentences)):\n",
    "            for j in range(len(sentences)):\n",
    "                if i != j:\n",
    "                    sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100),\n",
    "                                                      sentence_vectors[j].reshape(1,100))[0, 0]\n",
    "\n",
    "\n",
    "        # Compute score\n",
    "        nx_graph = nx.from_numpy_array(sim_mat)\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "        ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "        summ = []\n",
    "        # Generate summary\n",
    "        for i in range(summary_length):\n",
    "            summ.append(ranked_sentences[i][1])\n",
    "        return \" \".join(summ)\n",
    "\n",
    "\n",
    "    def summarize(self, long_text, summary_length=None, split_at=50, method=1):\n",
    "        \"\"\"\n",
    "        Summarize the long text using two method: weighted sentence and text rank.\n",
    "        The language and stop word set have been initialized and are used. If no\n",
    "        summary length is given as parameter, the default length is used.\n",
    "\n",
    "        :param (str or list) long_text: The long text to summarize\n",
    "        :param int summary_length: The number of sentences in summary, optional\n",
    "        :param int split_at: The number of sentences in each text chunk\n",
    "        :param int method: 1: weighted sentence, 2: text rank\n",
    "\n",
    "        :return (str): A string with the summary of the given text\n",
    "        \"\"\"\n",
    "\n",
    "        # Length of summary to generate, if not specified use default\n",
    "        if not summary_length:\n",
    "            summary_length = self.summary_length\n",
    "\n",
    "        # Make a list of all the sentences in the given text and split this list\n",
    "        # in chunks of n sentences, n being the split_at value\n",
    "        sentences = []\n",
    "        for sent in tokenize.sent_tokenize(long_text):\n",
    "            sentences.append(sent)\n",
    "\n",
    "        chunks = [sentences[x:x+split_at] for x in range(0, len(sentences), split_at)]\n",
    "\n",
    "        # Choose method applied to summarize\n",
    "        method_func = self.weighted_sentence if method == 1 else self.text_rank\n",
    "        summaries = []\n",
    "        for sentences in chunks:\n",
    "            summary = method_func(sentences, summary_length)\n",
    "            summaries.append(summary)\n",
    "\n",
    "        return \" \".join(summaries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len body:  50782\n",
      "len: : 728\n",
      "scores_abstractive:  [{'rouge-1': {'r': 0.5737704918032787, 'p': 0.10638297872340426, 'f': 0.17948717684825774}, 'rouge-2': {'r': 0.14634146341463414, 'p': 0.019448946515397084, 'f': 0.03433476187752391}, 'rouge-l': {'r': 0.5245901639344263, 'p': 0.0972644376899696, 'f': 0.16410256146364238}}]\n",
      "scores_extractive:  [{'rouge-1': {'r': 0.5737704918032787, 'p': 0.10638297872340426, 'f': 0.17948717684825774}, 'rouge-2': {'r': 0.14634146341463414, 'p': 0.019448946515397084, 'f': 0.03433476187752391}, 'rouge-l': {'r': 0.5245901639344263, 'p': 0.0972644376899696, 'f': 0.16410256146364238}}]\n"
     ]
    }
   ],
   "source": [
    "# ! pip install rouge\n",
    "\n",
    "extractor = NLTK_Extractive_Summarizer(summary_length = 5)\n",
    "id = 3\n",
    "text = processed_df.loc[processed_df['paper_id']==id]['original_body_text'].values[0]\n",
    "target_summ = processed_df.loc[processed_df['paper_id']==id]['abstract'].values[0]\n",
    "# print(text)\n",
    "summ = extractor.summarize(text)\n",
    "print('len body: ',len(text))\n",
    "print('len: :', len(summ.split()))\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "scores_abstractive = rouge.get_scores(summ, target_summ)\n",
    "scores_extractive = rouge.get_scores(summ, target_summ)\n",
    "print('scores_abstractive: ',scores_abstractive)\n",
    "print('scores_extractive: ',scores_extractive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame()\n",
    "dataset_df['body_text'] = processed_df['body_text']\n",
    "dataset_df['target_summary'] = processed_df['abstract']\n",
    "dataset_df.to_csv('summary_dataset.tsv', sep=\"\\t\")\n",
    "\n",
    "bert_dataset_df = pd.DataFrame()\n",
    "bert_dataset_df['body_text'] = processed_df.body_text.apply(lambda x: ' '.join(x.split()[:512]))\n",
    "bert_dataset_df['target_summary'] = processed_df.abstract.apply(lambda x: ' '.join(x.split()[:256]))\n",
    "bert_dataset_df.to_csv('bert_summary_dataset.tsv', sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def data_split(dataset_df):\n",
    "    x_train, x_test_val, y_train, y_test_val = train_test_split(dataset_df['body_text'], dataset_df['target_summary'], test_size=0.3, random_state=0)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test_val, y_test_val, test_size=0.75, random_state=0)\n",
    "\n",
    "    bert_train_df = pd.DataFrame()\n",
    "    bert_train_df['article'] = x_train\n",
    "    bert_train_df['summary'] = y_train\n",
    "\n",
    "    bert_val_df = pd.DataFrame()\n",
    "    bert_val_df['article'] = x_val\n",
    "    bert_val_df['summary'] = y_val\n",
    "\n",
    "    bert_test_df = pd.DataFrame()\n",
    "    bert_test_df['article'] = x_test\n",
    "    bert_test_df['summary'] = y_test\n",
    "    return bert_train_df, bert_val_df, bert_test_df\n",
    "\n",
    "def dataset_statistics(df):\n",
    "    article_len = df.article.str.split().str.len()\n",
    "    summary_len = df.summary.str.split().str.len()\n",
    "    # len_df = pd.DataFrame([article_len,summary_len], columns=['Col1', 'Col2'])\n",
    "    len_df = pd.DataFrame(dict(s1 = article_len, s2 = summary_len)).reset_index().drop(columns = 'index')\n",
    "    len_df.columns = ['article_len', 'summary_len']\n",
    "    boxplot = len_df.boxplot(column=['article_len', 'summary_len'])\n",
    "    boxplot.plot()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "bert_train_df, bert_val_df, bert_test_df = data_split(bert_dataset_df)\n",
    "dataset_statistics(bert_train_df)\n",
    "dataset_statistics(bert_val_df)\n",
    "dataset_statistics(bert_test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SciBERT Summarizer -- Sinuo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline: SciBERT Summarization -- off the shelf pretrained summarization model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # !pip install bert-extractive-summarizer==0.4.2\n",
    "# from summarizer import Summarizer\n",
    "#\n",
    "# import torch\n",
    "# import time\n",
    "# from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "# # assert torch.cuda.is_available()\n",
    "#\n",
    "#\n",
    "# SUMMARY_RATIO = 0.3\n",
    "# body_text = processed_df.loc[processed_df['paper_id']==id]['original_body_text'].values[0]\n",
    "#\n",
    "# BERTS = ['allenai/scibert_scivocab_uncased']\n",
    "# # Evaluate custom models.\n",
    "# for BERT_PATH in BERTS:\n",
    "#\n",
    "#   # Load model, model config and tokenizer via Transformers\n",
    "#   custom_config = AutoConfig.from_pretrained(BERT_PATH)\n",
    "#   custom_config.output_hidden_states=True\n",
    "#   print(custom_config)\n",
    "#   custom_tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)\n",
    "#   custom_model = AutoModel.from_pretrained(BERT_PATH, config=custom_config)\n",
    "#   model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)\n",
    "#\n",
    "#\n",
    "#   start = time.time()\n",
    "#   resp = model(body_text, ratio=SUMMARY_RATIO)\n",
    "#   end = time.time()\n",
    "#   print('Model type:', BERT_PATH)\n",
    "#   print(f'Response Time: {end-start}')\n",
    "#   # TODO: Split into sentences and pretty-print.\n",
    "#   print('Summary: ', resp, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  The translation sector has seen an increase in volunteer translation thanks to crowdsourcing models and collaborative platforms. New case studies using different methodologies with different sample populations and materials add nuance and depth to extant studies, thereby resulting in a more holistic understanding of volunteer translation. Recourse to a socionarrative approach (Baker 2006) is justified by the fact that most studies analyzing the motivations of volunteer translators tend to employ surveys and/or interviews. It is, however, worth signaling that the inclusion and exclusion of translation organizations in the case study corpus also intersects with narrative framing: a researcher’s narratives and the narratives they have been exposed to can influence what organizations they are aware of and have access to (this intersects with the idea of researcher subjectivity). Personal narratives are the stories we tell ourselves about the world and our own lives; public narratives are the shared stories that appear within social groupings such as families, workplaces, communities, and societies; disciplinary narratives are the theoretical concepts and historical accounts that circulate in academia and fields of knowledge; and meta-narratives are the universal stories “in which we are embedded as contemporary actors in history […] Progress, Decadence, Industrialization, Enlightenment, etc.” ( More importantly, search engine results are usually commercially driven (e.g., sponsored content or advertising), and this makes some content more salient in search results compared to other hits. The type of content also posed a limitation. Table 1 presents an overview of the data. Data from this study shows that narratives relating to this Golden Era are common. In an article published on Aljazeera.net (Mohammad 2018), the narrative of the Golden Era of Translation was employed again to legitimize AOT projects. There are some interesting aspects to note as to how temporality features were utilized to promote this narrative. First, the spatial organization of content is a key element to present the topic effectively. Time is important in this quote by presenting the positive impact of the AOT using the narrative of the Golden Era of Translation. The following quote, however, contextualizes the role of Kalima, which aims to maintain the achievements of Arabic translators:[Arab scholars contributed remarkably to the Renaissance in Europe through their translations and by preserving the classics of the Roman, the Greek, and the Persian civilizations. Masad 2007)\n",
      "This excerpt contains references to times and places that contextualize Kalima’s mission. The analysis shows, here again, implicit recourse to the narrative of the Golden Era in the way that the past and Arabic-Islamic civilization are honored:[We look forward to forming a team of Arabs who are ambitious to create a better future for education in the Arab World and to bring the Arab World closer to resuming our civilization.] ( The AOT’s “About” section illustrates this:[It is a result of what the Arab intellectuals have always called a necessary project since translation is a core activity for renaissance…. While the tone of the article is negative in general, the role of the AOT seems to be deliberately stated under the third headline, “Solutions,” that concludes the article:[but the professor of linguistics at Lebanon University disagrees with this [negative] reading [of translation status] and confirms that the movement of Arabic translation is witnessing a renaissance in terms of content, translated titles, and institutional work. He gives an example of AOT that has translated about a hundred titles over six years] (Ashqar 2009)\n",
      "Despite highlighting the contribution and translation efforts carried out by the AOT, this quote suggests that Arabic translation is recovering from a period of inactivity. In the same article, Alshamy, a language expert in the UN, states:[Greece with its population of 11 million translates annually five times more than what the Arabic region translates in all domains from all languages] (Ashqar 2009)\n",
      "Presenting statistics in a time frame, as in the quote above, strengthens the claim of the long-lasting crisis in Arabic translation. A similar narrative can be found in Kalima’s Wikipedia entry:[The Arabic translation movement declined at the beginning of the 11th century. Similarly, Alatar (2017) posted an article that begins with an appreciation of the Arabic translation movement during the Golden Era and how it contributed massively to advancing modern science in Europe and the United States. The third narrative focuses on the dearth of Arabic content online. Temporal features are once again used to construct a narrative that argues in favor of translation as the solution for the Arabic Internet and as a means to engage potential volunteers. The lack of Arabic content online is narrated as a problem that Taghreedat’s team and its volunteer translators can potentially solve. The second narrative identified in the analysis is the Bridge to Knowledge, urging governments and institutions to initiate translation projects and/or justify their investments in translation. It has led to the Bridge to Knowledge narrative finding its way into many translation publications and projects, demonstrating that a narrative can be a provoking factor regardless of accuracy and truth. In fact, he concedes that any attempt to explore contemporary translation production will be handicapped by the lack of adequate statistics and insufficient archival systems (Jalal 2010, p. 102). The key features of this chapter can be summarized in three points. Third, and most importantly, this chapter identifies the common narratives about Arabic translation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# resp = model(text, ratio=SUMMARY_RATIO)\n",
    "# print('Summary: ', resp, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from summarizer import Summarizer\n",
    "#\n",
    "# body = text\n",
    "# model = Summarizer(custom_model=model, custom_tokenizer=tokenizer)\n",
    "# model(body)\n",
    "#\n",
    "# scores_abstractive = rouge.get_scores(resp, target_summ)\n",
    "# scores_extractive = rouge.get_scores(resp, target_summ)\n",
    "# print('scores_abstractive: ',scores_abstractive)\n",
    "# print('scores_extractive: ',scores_extractive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tuning BERT2BERT Model for CORD19 Article Summarization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33msinuowang\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/crossing/Desktop/A3/wandb/run-20230409_133136-k4tdok8r</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/sinuowang/SciBERT/runs/k4tdok8r' target=\"_blank\">pretty-sea-6</a></strong> to <a href='https://wandb.ai/sinuowang/SciBERT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/sinuowang/SciBERT' target=\"_blank\">https://wandb.ai/sinuowang/SciBERT</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/sinuowang/SciBERT/runs/k4tdok8r' target=\"_blank\">https://wandb.ai/sinuowang/SciBERT/runs/k4tdok8r</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sinuowang/SciBERT/runs/k4tdok8r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fbd4b9ce4f0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project = 'SciBERT'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def load_tokenizer(args):\n",
    "    if not os.path.exists(args.tokenizer_save_path):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "        tokenizer.save_pretrained(args.tokenizer_save_path)\n",
    "        return tokenizer\n",
    "    return BertTokenizerFast.from_pretrained(args.tokenizer_save_path)\n",
    "\n",
    "\n",
    "class BERT_Dataset(Dataset):\n",
    "    # def __init__(self, data_path, data_df, tokenizer, xmax=512, ymax=48, nrows=None):\n",
    "    def __init__(self, data_df, tokenizer, input_max=512, summary_max=48):\n",
    "        self.df = data_df\n",
    "        # self.article = [art_str.split('.') for art_str in data_df['article'].tolist()]\n",
    "        # self.summary = [summ_str.split('.') for summ_str in data_df['summary'].tolist()]\n",
    "\n",
    "        self.article = data_df['article'].tolist()\n",
    "        self.summary = data_df['summary'].tolist()\n",
    "        self.xmax = input_max\n",
    "        self.ymax = summary_max\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def encode_str(self, s, lim):\n",
    "        t = self.tokenizer(s, max_length=lim, truncation=True,\n",
    "                           padding='max_length', return_tensors='pt')\n",
    "        return t.input_ids[0], t.attention_mask[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x, xmask = self.encode_str(self.df.loc[idx, self.article], self.xmax)\n",
    "        # y, ymask = self.encode_str(self.df.loc[idx, self.summary], self.ymax)\n",
    "        x, xmask = self.encode_str(self.article[idx], self.xmax)\n",
    "        y, ymask = self.encode_str(self.summary[idx], self.ymax)\n",
    "        labels = y.clone()\n",
    "        labels = torch.tensor([torch.tensor(-100) if token == self.tokenizer.pad_token_id else token for token in y])\n",
    "        return {\n",
    "            'input_ids':x.unsqueeze(0),\n",
    "            'attention_mask':xmask.unsqueeze(0),\n",
    "            'labels': labels.unsqueeze(0),\n",
    "            'decoder_input_ids':y.unsqueeze(0),\n",
    "            'decoder_attention_mask':ymask.unsqueeze(0)\n",
    "             }\n",
    "\n",
    "def create_bert_dataloader(args,data_df, tokenizer,shuffle = True):\n",
    "    data_loader = DataLoader(\n",
    "            BERT_Dataset(data_df, tokenizer, input_max=args.input_max, summary_max=args.summary_max),\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "        )\n",
    "    return data_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from transformers import EncoderDecoderModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch.optim as optim\n",
    "# from config import *\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    # labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    #\n",
    "    # rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    res = rouge.get_scores(pred_ids, labels_ids)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, args, tokenizer,train_loader=None, val_loader=None, test_loader=None):\n",
    "        self.args = args\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader= test_loader\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.__init_model()\n",
    "\n",
    "    def __init_model(self):\n",
    "        # set special tokens\n",
    "        bos_token_id = 101 #cls\n",
    "        eos_token_id = 102 #sep\n",
    "        pad_token_id =  0 #PAD\n",
    "        model = EncoderDecoderModel.from_encoder_decoder_pretrained(self.args.model_name, self.args.model_name)\n",
    "        model.config.decoder.decoder_start_token_id = bos_token_id #tokenizer.bos_token_id\n",
    "        model.config.decoder_start_token_id = bos_token_id\n",
    "        model.config.encoder.bos_token_id = bos_token_id #tokenizer.bos_token_id\n",
    "        model.config.encoder.eos_token_id = eos_token_id#tokenizer.eos_token_id\n",
    "        model.config.encoder.pad_token_id = pad_token_id#tokenizer.pad_token_id\n",
    "        model.config.pad_token_id = pad_token_id\n",
    "\n",
    "        # unfroze SciBERT encoder\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'encoder.encoder' in name or 'encoder.pooler' in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "            # print('name: ',name,'param: ',param.requires_grad)\n",
    "\n",
    "        # to device: cpu or gpu\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        t_total = len(self.train_loader) * self.args.epochs\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.lr, eps=self.args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "\n",
    "        avg_loss = 0\n",
    "        for e in range(self.args.epochs):\n",
    "            for step, batch in enumerate(self.train_loader):\n",
    "                batch = (v.to(self.device) for k, v in batch.items())\n",
    "                x, xmask, labels, y, ymask = batch\n",
    "\n",
    "                outputs = self.model(input_ids=x, attention_mask=xmask,\n",
    "                                labels=labels, decoder_attention_mask=ymask,\n",
    "                                return_dict=True)\n",
    "                loss = outputs.loss\n",
    "                avg_loss += loss.item() / len(self.train_loader)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                print(f\"epoch: {e+1}, loss: {loss.item():.3f}, avg: {avg_loss:.2f}, latest lr: {optimizer.param_groups[0]['lr']}\")\n",
    "        return\n",
    "\n",
    "    def eval(self,dataloader):\n",
    "        preds, labels = [], []\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            batch_data = batch_data.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                generated_tokens = self.model.generate(\n",
    "                    batch_data[\"input_ids\"],\n",
    "                    attention_mask=batch_data[\"attention_mask\"],\n",
    "                    max_length=self.args.summary_max,\n",
    "                    num_beams=4,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                ).cpu().numpy()\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "            decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "            preds += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "            labels += [' '.join(label.strip()) for label in decoded_labels]\n",
    "        scores = rouge.get_scores(hyps=preds, refs=labels, avg=True)\n",
    "        result = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "        result['avg'] = np.mean(list(result.values()))\n",
    "        print(f\"Rouge1: {result['rouge-1']:>0.2f} Rouge2: {result['rouge-2']:>0.2f} RougeL: {result['rouge-l']:>0.2f}\\n\")\n",
    "        return result\n",
    "\n",
    "\n",
    "        # training_args = Seq2SeqTrainingArguments(\n",
    "        #     do_train= True,\n",
    "        #     do_eval= True,\n",
    "        #     predict_with_generate=True,\n",
    "        #     per_device_train_batch_size=self.args.batch_size,\n",
    "        #     per_device_eval_batch_size=self.args.batch_size,\n",
    "        #     num_train_epochs = self.args.epochs,\n",
    "        #     learning_rate= self.args.lr,\n",
    "        #     weight_decay = self.args.weight_decay,\n",
    "        #     evaluation_strategy=\"steps\",\n",
    "        #     fp16=True,\n",
    "        #     output_dir=\"./\",\n",
    "        #     overwrite_output_dir=True,\n",
    "        #     logging_steps=500,\n",
    "        #     save_steps=500,\n",
    "        #     eval_steps=self.args.eval_steps,\n",
    "        #     report_to=\"wandb\",\n",
    "        # )\n",
    "        #\n",
    "        # trainer = Seq2SeqTrainer(\n",
    "        # model=self.model,\n",
    "        # tokenizer= self.tokenizer,\n",
    "        # args=training_args,\n",
    "        # train_dataset=self.train_loader,\n",
    "        # eval_dataset=self.val_loader,\n",
    "        # compute_metrics=compute_metrics,\n",
    "        # )\n",
    "        #\n",
    "        # trainer.train()\n",
    "        # wandb.finish()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--input_max', default = 512, type=str, help='inputs')\n",
    "    parser.add_argument('--summary_max', default = 256, type=str, help='labels')\n",
    "    parser.add_argument('--tokenizer_save_path', type=str, default='./tokenizer')\n",
    "    parser.add_argument('--model_name', type=str, default=\"allenai/scibert_scivocab_uncased\", help='model name')\n",
    "    parser.add_argument('--epochs', type=int, default=3)\n",
    "    parser.add_argument('--eval_steps', type=int, default=500)\n",
    "    parser.add_argument('--weight_decay', type=int, default=0.0)\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument('--batch_size', type=int, default=4)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('-f')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tokenizer_save_path = './bert.tokenizer'\n",
    "    tokenizer = load_tokenizer(args)\n",
    "\n",
    "    # bert_trainloader = create_bert_dataloader(args,bert_train_df, tokenizer)\n",
    "    # bert_valloader = create_bert_dataloader(args,bert_train_df, tokenizer, shuffle = True)\n",
    "    # bert_testloader = create_bert_dataloader(args,bert_train_df, tokenizer,shuffle = True)\n",
    "\n",
    "    bert_trainloader = BERT_Dataset(bert_train_df, tokenizer, input_max=args.input_max, summary_max=args.summary_max)\n",
    "    bert_valloader = BERT_Dataset(bert_train_df, tokenizer, input_max=args.input_max, summary_max=args.summary_max)\n",
    "    bert_testloader = BERT_Dataset(bert_train_df, tokenizer, input_max=args.input_max, summary_max=args.summary_max),\n",
    "\n",
    "    trainer = Trainer(args, tokenizer, train_loader=bert_trainloader, val_loader=bert_valloader, test_loader=bert_testloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 12.391, avg: 0.00, latest lr: 9.998571428571429e-05\n",
      "epoch: 1, loss: 8.970, avg: 0.00, latest lr: 9.997142857142857e-05\n",
      "epoch: 1, loss: 9.685, avg: 0.00, latest lr: 9.995714285714286e-05\n",
      "epoch: 1, loss: 9.423, avg: 0.01, latest lr: 9.994285714285715e-05\n",
      "epoch: 1, loss: 8.165, avg: 0.01, latest lr: 9.992857142857144e-05\n",
      "epoch: 1, loss: 8.608, avg: 0.01, latest lr: 9.991428571428572e-05\n",
      "epoch: 1, loss: 8.989, avg: 0.01, latest lr: 9.99e-05\n",
      "epoch: 1, loss: 8.754, avg: 0.01, latest lr: 9.98857142857143e-05\n",
      "epoch: 1, loss: 8.806, avg: 0.01, latest lr: 9.987142857142857e-05\n",
      "epoch: 1, loss: 8.322, avg: 0.01, latest lr: 9.985714285714287e-05\n",
      "epoch: 1, loss: 8.033, avg: 0.01, latest lr: 9.984285714285715e-05\n",
      "epoch: 1, loss: 7.550, avg: 0.02, latest lr: 9.982857142857143e-05\n",
      "epoch: 1, loss: 7.447, avg: 0.02, latest lr: 9.981428571428572e-05\n",
      "epoch: 1, loss: 8.021, avg: 0.02, latest lr: 9.98e-05\n",
      "epoch: 1, loss: 8.964, avg: 0.02, latest lr: 9.97857142857143e-05\n",
      "epoch: 1, loss: 9.188, avg: 0.02, latest lr: 9.977142857142857e-05\n",
      "epoch: 1, loss: 8.633, avg: 0.02, latest lr: 9.975714285714286e-05\n",
      "epoch: 1, loss: 8.170, avg: 0.02, latest lr: 9.974285714285715e-05\n",
      "epoch: 1, loss: 8.408, avg: 0.02, latest lr: 9.972857142857144e-05\n",
      "epoch: 1, loss: 8.434, avg: 0.02, latest lr: 9.971428571428571e-05\n",
      "epoch: 1, loss: 8.405, avg: 0.03, latest lr: 9.970000000000001e-05\n",
      "epoch: 1, loss: 8.076, avg: 0.03, latest lr: 9.96857142857143e-05\n",
      "epoch: 1, loss: 7.931, avg: 0.03, latest lr: 9.967142857142858e-05\n",
      "epoch: 1, loss: 8.920, avg: 0.03, latest lr: 9.965714285714286e-05\n",
      "epoch: 1, loss: 8.564, avg: 0.03, latest lr: 9.964285714285714e-05\n",
      "epoch: 1, loss: 8.740, avg: 0.03, latest lr: 9.962857142857144e-05\n",
      "epoch: 1, loss: 8.193, avg: 0.03, latest lr: 9.961428571428571e-05\n",
      "epoch: 1, loss: 9.060, avg: 0.03, latest lr: 9.960000000000001e-05\n",
      "epoch: 1, loss: 8.212, avg: 0.04, latest lr: 9.958571428571429e-05\n",
      "epoch: 1, loss: 8.762, avg: 0.04, latest lr: 9.957142857142858e-05\n",
      "epoch: 1, loss: 8.115, avg: 0.04, latest lr: 9.955714285714286e-05\n",
      "epoch: 1, loss: 8.212, avg: 0.04, latest lr: 9.954285714285714e-05\n",
      "epoch: 1, loss: 8.524, avg: 0.04, latest lr: 9.952857142857144e-05\n",
      "epoch: 1, loss: 8.184, avg: 0.04, latest lr: 9.951428571428571e-05\n",
      "epoch: 1, loss: 8.254, avg: 0.04, latest lr: 9.95e-05\n",
      "epoch: 1, loss: 7.802, avg: 0.04, latest lr: 9.948571428571429e-05\n",
      "epoch: 1, loss: 8.068, avg: 0.05, latest lr: 9.947142857142857e-05\n",
      "epoch: 1, loss: 8.384, avg: 0.05, latest lr: 9.945714285714286e-05\n",
      "epoch: 1, loss: 8.353, avg: 0.05, latest lr: 9.944285714285715e-05\n",
      "epoch: 1, loss: 8.904, avg: 0.05, latest lr: 9.942857142857144e-05\n",
      "epoch: 1, loss: 8.444, avg: 0.05, latest lr: 9.941428571428572e-05\n",
      "epoch: 1, loss: 7.909, avg: 0.05, latest lr: 9.94e-05\n",
      "epoch: 1, loss: 8.365, avg: 0.05, latest lr: 9.938571428571429e-05\n",
      "epoch: 1, loss: 7.621, avg: 0.05, latest lr: 9.937142857142857e-05\n",
      "epoch: 1, loss: 8.185, avg: 0.05, latest lr: 9.935714285714285e-05\n",
      "epoch: 1, loss: 9.122, avg: 0.06, latest lr: 9.934285714285715e-05\n",
      "epoch: 1, loss: 8.731, avg: 0.06, latest lr: 9.932857142857143e-05\n",
      "epoch: 1, loss: 8.832, avg: 0.06, latest lr: 9.931428571428572e-05\n",
      "epoch: 1, loss: 7.872, avg: 0.06, latest lr: 9.93e-05\n",
      "epoch: 1, loss: 7.827, avg: 0.06, latest lr: 9.92857142857143e-05\n",
      "epoch: 1, loss: 9.063, avg: 0.06, latest lr: 9.927142857142857e-05\n",
      "epoch: 1, loss: 7.301, avg: 0.06, latest lr: 9.925714285714287e-05\n",
      "epoch: 1, loss: 8.657, avg: 0.06, latest lr: 9.924285714285715e-05\n",
      "epoch: 1, loss: 8.278, avg: 0.07, latest lr: 9.922857142857143e-05\n",
      "epoch: 1, loss: 7.413, avg: 0.07, latest lr: 9.921428571428572e-05\n",
      "epoch: 1, loss: 7.541, avg: 0.07, latest lr: 9.92e-05\n",
      "epoch: 1, loss: 7.562, avg: 0.07, latest lr: 9.91857142857143e-05\n",
      "epoch: 1, loss: 8.734, avg: 0.07, latest lr: 9.917142857142857e-05\n",
      "epoch: 1, loss: 6.939, avg: 0.07, latest lr: 9.915714285714286e-05\n",
      "epoch: 1, loss: 7.300, avg: 0.07, latest lr: 9.914285714285715e-05\n",
      "epoch: 1, loss: 8.603, avg: 0.07, latest lr: 9.912857142857144e-05\n",
      "epoch: 1, loss: 8.360, avg: 0.07, latest lr: 9.911428571428571e-05\n",
      "epoch: 1, loss: 8.142, avg: 0.08, latest lr: 9.910000000000001e-05\n",
      "epoch: 1, loss: 7.918, avg: 0.08, latest lr: 9.90857142857143e-05\n",
      "epoch: 1, loss: 8.402, avg: 0.08, latest lr: 9.907142857142858e-05\n",
      "epoch: 1, loss: 7.970, avg: 0.08, latest lr: 9.905714285714286e-05\n",
      "epoch: 1, loss: 8.306, avg: 0.08, latest lr: 9.904285714285714e-05\n",
      "epoch: 1, loss: 8.795, avg: 0.08, latest lr: 9.902857142857144e-05\n",
      "epoch: 1, loss: 8.318, avg: 0.08, latest lr: 9.901428571428571e-05\n",
      "epoch: 1, loss: 7.975, avg: 0.08, latest lr: 9.900000000000001e-05\n",
      "epoch: 1, loss: 7.914, avg: 0.09, latest lr: 9.898571428571429e-05\n",
      "epoch: 1, loss: 8.595, avg: 0.09, latest lr: 9.897142857142859e-05\n",
      "epoch: 1, loss: 8.111, avg: 0.09, latest lr: 9.895714285714286e-05\n",
      "epoch: 1, loss: 8.309, avg: 0.09, latest lr: 9.894285714285715e-05\n",
      "epoch: 1, loss: 8.792, avg: 0.09, latest lr: 9.892857142857144e-05\n",
      "epoch: 1, loss: 6.638, avg: 0.09, latest lr: 9.891428571428571e-05\n",
      "epoch: 1, loss: 9.156, avg: 0.09, latest lr: 9.89e-05\n",
      "epoch: 1, loss: 7.518, avg: 0.09, latest lr: 9.888571428571429e-05\n",
      "epoch: 1, loss: 8.333, avg: 0.09, latest lr: 9.887142857142859e-05\n",
      "epoch: 1, loss: 8.081, avg: 0.10, latest lr: 9.885714285714286e-05\n",
      "epoch: 1, loss: 7.874, avg: 0.10, latest lr: 9.884285714285715e-05\n",
      "epoch: 1, loss: 8.079, avg: 0.10, latest lr: 9.882857142857144e-05\n",
      "epoch: 1, loss: 8.191, avg: 0.10, latest lr: 9.881428571428572e-05\n",
      "epoch: 1, loss: 9.226, avg: 0.10, latest lr: 9.88e-05\n",
      "epoch: 1, loss: 7.458, avg: 0.10, latest lr: 9.878571428571429e-05\n",
      "epoch: 1, loss: 8.475, avg: 0.10, latest lr: 9.877142857142858e-05\n",
      "epoch: 1, loss: 7.524, avg: 0.10, latest lr: 9.875714285714285e-05\n",
      "epoch: 1, loss: 8.736, avg: 0.10, latest lr: 9.874285714285715e-05\n",
      "epoch: 1, loss: 8.139, avg: 0.11, latest lr: 9.872857142857143e-05\n",
      "epoch: 1, loss: 7.063, avg: 0.11, latest lr: 9.871428571428572e-05\n",
      "epoch: 1, loss: 7.510, avg: 0.11, latest lr: 9.87e-05\n",
      "epoch: 1, loss: 8.015, avg: 0.11, latest lr: 9.86857142857143e-05\n",
      "epoch: 1, loss: 8.204, avg: 0.11, latest lr: 9.867142857142858e-05\n",
      "epoch: 1, loss: 8.974, avg: 0.11, latest lr: 9.865714285714286e-05\n",
      "epoch: 1, loss: 7.917, avg: 0.11, latest lr: 9.864285714285715e-05\n",
      "epoch: 1, loss: 8.008, avg: 0.11, latest lr: 9.862857142857143e-05\n",
      "epoch: 1, loss: 7.566, avg: 0.12, latest lr: 9.861428571428571e-05\n",
      "epoch: 1, loss: 8.239, avg: 0.12, latest lr: 9.86e-05\n",
      "epoch: 1, loss: 7.958, avg: 0.12, latest lr: 9.85857142857143e-05\n",
      "epoch: 1, loss: 7.966, avg: 0.12, latest lr: 9.857142857142858e-05\n",
      "epoch: 1, loss: 8.647, avg: 0.12, latest lr: 9.855714285714286e-05\n",
      "epoch: 1, loss: 6.823, avg: 0.12, latest lr: 9.854285714285715e-05\n",
      "epoch: 1, loss: 8.276, avg: 0.12, latest lr: 9.852857142857144e-05\n",
      "epoch: 1, loss: 7.453, avg: 0.12, latest lr: 9.851428571428571e-05\n",
      "epoch: 1, loss: 8.756, avg: 0.12, latest lr: 9.850000000000001e-05\n",
      "epoch: 1, loss: 7.815, avg: 0.13, latest lr: 9.848571428571429e-05\n",
      "epoch: 1, loss: 8.371, avg: 0.13, latest lr: 9.847142857142858e-05\n",
      "epoch: 1, loss: 8.262, avg: 0.13, latest lr: 9.845714285714286e-05\n",
      "epoch: 1, loss: 8.135, avg: 0.13, latest lr: 9.844285714285714e-05\n",
      "epoch: 1, loss: 8.048, avg: 0.13, latest lr: 9.842857142857144e-05\n",
      "epoch: 1, loss: 7.865, avg: 0.13, latest lr: 9.841428571428571e-05\n",
      "epoch: 1, loss: 8.533, avg: 0.13, latest lr: 9.84e-05\n",
      "epoch: 1, loss: 8.051, avg: 0.13, latest lr: 9.838571428571429e-05\n",
      "epoch: 1, loss: 8.895, avg: 0.13, latest lr: 9.837142857142859e-05\n",
      "epoch: 1, loss: 8.851, avg: 0.14, latest lr: 9.835714285714286e-05\n",
      "epoch: 1, loss: 7.592, avg: 0.14, latest lr: 9.834285714285715e-05\n",
      "epoch: 1, loss: 8.638, avg: 0.14, latest lr: 9.832857142857144e-05\n",
      "epoch: 1, loss: 8.264, avg: 0.14, latest lr: 9.831428571428572e-05\n",
      "epoch: 1, loss: 7.538, avg: 0.14, latest lr: 9.83e-05\n",
      "epoch: 1, loss: 7.520, avg: 0.14, latest lr: 9.828571428571429e-05\n",
      "epoch: 1, loss: 8.074, avg: 0.14, latest lr: 9.827142857142858e-05\n",
      "epoch: 1, loss: 7.358, avg: 0.14, latest lr: 9.825714285714285e-05\n",
      "epoch: 1, loss: 8.834, avg: 0.15, latest lr: 9.824285714285715e-05\n",
      "epoch: 1, loss: 7.914, avg: 0.15, latest lr: 9.822857142857143e-05\n",
      "epoch: 1, loss: 6.538, avg: 0.15, latest lr: 9.821428571428572e-05\n",
      "epoch: 1, loss: 8.234, avg: 0.15, latest lr: 9.82e-05\n",
      "epoch: 1, loss: 7.849, avg: 0.15, latest lr: 9.81857142857143e-05\n",
      "epoch: 1, loss: 7.202, avg: 0.15, latest lr: 9.817142857142858e-05\n",
      "epoch: 1, loss: 8.411, avg: 0.15, latest lr: 9.815714285714285e-05\n",
      "epoch: 1, loss: 8.375, avg: 0.15, latest lr: 9.814285714285715e-05\n",
      "epoch: 1, loss: 7.490, avg: 0.15, latest lr: 9.812857142857143e-05\n",
      "epoch: 1, loss: 7.476, avg: 0.16, latest lr: 9.811428571428572e-05\n",
      "epoch: 1, loss: 7.888, avg: 0.16, latest lr: 9.81e-05\n",
      "epoch: 1, loss: 7.169, avg: 0.16, latest lr: 9.80857142857143e-05\n",
      "epoch: 1, loss: 8.723, avg: 0.16, latest lr: 9.807142857142858e-05\n",
      "epoch: 1, loss: 7.307, avg: 0.16, latest lr: 9.805714285714286e-05\n",
      "epoch: 1, loss: 8.321, avg: 0.16, latest lr: 9.804285714285715e-05\n",
      "epoch: 1, loss: 8.579, avg: 0.16, latest lr: 9.802857142857143e-05\n",
      "epoch: 1, loss: 8.276, avg: 0.16, latest lr: 9.801428571428571e-05\n",
      "epoch: 1, loss: 8.627, avg: 0.16, latest lr: 9.8e-05\n",
      "epoch: 1, loss: 8.098, avg: 0.17, latest lr: 9.79857142857143e-05\n",
      "epoch: 1, loss: 7.641, avg: 0.17, latest lr: 9.797142857142858e-05\n",
      "epoch: 1, loss: 8.254, avg: 0.17, latest lr: 9.795714285714286e-05\n",
      "epoch: 1, loss: 8.394, avg: 0.17, latest lr: 9.794285714285714e-05\n",
      "epoch: 1, loss: 7.655, avg: 0.17, latest lr: 9.792857142857144e-05\n",
      "epoch: 1, loss: 8.855, avg: 0.17, latest lr: 9.791428571428571e-05\n",
      "epoch: 1, loss: 8.170, avg: 0.17, latest lr: 9.790000000000001e-05\n",
      "epoch: 1, loss: 7.845, avg: 0.17, latest lr: 9.788571428571429e-05\n",
      "epoch: 1, loss: 7.612, avg: 0.17, latest lr: 9.787142857142857e-05\n",
      "epoch: 1, loss: 8.084, avg: 0.18, latest lr: 9.785714285714286e-05\n",
      "epoch: 1, loss: 7.443, avg: 0.18, latest lr: 9.784285714285714e-05\n",
      "epoch: 1, loss: 8.487, avg: 0.18, latest lr: 9.782857142857144e-05\n",
      "epoch: 1, loss: 8.054, avg: 0.18, latest lr: 9.781428571428571e-05\n",
      "epoch: 1, loss: 8.452, avg: 0.18, latest lr: 9.78e-05\n",
      "epoch: 1, loss: 7.671, avg: 0.18, latest lr: 9.778571428571429e-05\n",
      "epoch: 1, loss: 7.895, avg: 0.18, latest lr: 9.777142857142859e-05\n",
      "epoch: 1, loss: 8.696, avg: 0.18, latest lr: 9.775714285714286e-05\n",
      "epoch: 1, loss: 8.228, avg: 0.19, latest lr: 9.774285714285715e-05\n",
      "epoch: 1, loss: 7.781, avg: 0.19, latest lr: 9.772857142857144e-05\n",
      "epoch: 1, loss: 7.576, avg: 0.19, latest lr: 9.771428571428572e-05\n",
      "epoch: 1, loss: 7.955, avg: 0.19, latest lr: 9.77e-05\n",
      "epoch: 1, loss: 8.322, avg: 0.19, latest lr: 9.768571428571429e-05\n",
      "epoch: 1, loss: 8.466, avg: 0.19, latest lr: 9.767142857142858e-05\n",
      "epoch: 1, loss: 7.145, avg: 0.19, latest lr: 9.765714285714285e-05\n",
      "epoch: 1, loss: 7.487, avg: 0.19, latest lr: 9.764285714285715e-05\n",
      "epoch: 1, loss: 7.862, avg: 0.19, latest lr: 9.762857142857143e-05\n",
      "epoch: 1, loss: 8.607, avg: 0.20, latest lr: 9.761428571428572e-05\n",
      "epoch: 1, loss: 8.495, avg: 0.20, latest lr: 9.76e-05\n",
      "epoch: 1, loss: 8.338, avg: 0.20, latest lr: 9.75857142857143e-05\n",
      "epoch: 1, loss: 8.321, avg: 0.20, latest lr: 9.757142857142858e-05\n",
      "epoch: 1, loss: 8.550, avg: 0.20, latest lr: 9.755714285714286e-05\n",
      "epoch: 1, loss: 8.476, avg: 0.20, latest lr: 9.754285714285715e-05\n",
      "epoch: 1, loss: 8.180, avg: 0.20, latest lr: 9.752857142857143e-05\n",
      "epoch: 1, loss: 8.429, avg: 0.20, latest lr: 9.751428571428571e-05\n",
      "epoch: 1, loss: 8.331, avg: 0.20, latest lr: 9.75e-05\n",
      "epoch: 1, loss: 8.769, avg: 0.21, latest lr: 9.74857142857143e-05\n",
      "epoch: 1, loss: 7.527, avg: 0.21, latest lr: 9.747142857142858e-05\n",
      "epoch: 1, loss: 7.657, avg: 0.21, latest lr: 9.745714285714286e-05\n",
      "epoch: 1, loss: 7.611, avg: 0.21, latest lr: 9.744285714285715e-05\n",
      "epoch: 1, loss: 8.516, avg: 0.21, latest lr: 9.742857142857143e-05\n",
      "epoch: 1, loss: 8.268, avg: 0.21, latest lr: 9.741428571428571e-05\n",
      "epoch: 1, loss: 7.862, avg: 0.21, latest lr: 9.74e-05\n",
      "epoch: 1, loss: 8.282, avg: 0.21, latest lr: 9.738571428571429e-05\n",
      "epoch: 1, loss: 8.082, avg: 0.22, latest lr: 9.737142857142858e-05\n",
      "epoch: 1, loss: 8.291, avg: 0.22, latest lr: 9.735714285714286e-05\n",
      "epoch: 1, loss: 7.448, avg: 0.22, latest lr: 9.734285714285714e-05\n",
      "epoch: 1, loss: 6.725, avg: 0.22, latest lr: 9.732857142857144e-05\n",
      "epoch: 1, loss: 8.334, avg: 0.22, latest lr: 9.731428571428572e-05\n",
      "epoch: 1, loss: 6.859, avg: 0.22, latest lr: 9.730000000000001e-05\n",
      "epoch: 1, loss: 7.215, avg: 0.22, latest lr: 9.728571428571429e-05\n",
      "epoch: 1, loss: 8.349, avg: 0.22, latest lr: 9.727142857142857e-05\n",
      "epoch: 1, loss: 7.525, avg: 0.22, latest lr: 9.725714285714286e-05\n",
      "epoch: 1, loss: 7.529, avg: 0.23, latest lr: 9.724285714285714e-05\n",
      "epoch: 1, loss: 8.587, avg: 0.23, latest lr: 9.722857142857144e-05\n",
      "epoch: 1, loss: 8.716, avg: 0.23, latest lr: 9.721428571428572e-05\n",
      "epoch: 1, loss: 7.156, avg: 0.23, latest lr: 9.72e-05\n",
      "epoch: 1, loss: 8.193, avg: 0.23, latest lr: 9.718571428571429e-05\n",
      "epoch: 1, loss: 7.539, avg: 0.23, latest lr: 9.717142857142858e-05\n",
      "epoch: 1, loss: 7.975, avg: 0.23, latest lr: 9.715714285714285e-05\n",
      "epoch: 1, loss: 7.956, avg: 0.23, latest lr: 9.714285714285715e-05\n",
      "epoch: 1, loss: 8.690, avg: 0.23, latest lr: 9.712857142857144e-05\n",
      "epoch: 1, loss: 8.084, avg: 0.24, latest lr: 9.711428571428572e-05\n",
      "epoch: 1, loss: 8.553, avg: 0.24, latest lr: 9.71e-05\n",
      "epoch: 1, loss: 7.817, avg: 0.24, latest lr: 9.708571428571429e-05\n",
      "epoch: 1, loss: 7.609, avg: 0.24, latest lr: 9.707142857142858e-05\n",
      "epoch: 1, loss: 8.318, avg: 0.24, latest lr: 9.705714285714285e-05\n",
      "epoch: 1, loss: 7.136, avg: 0.24, latest lr: 9.704285714285715e-05\n",
      "epoch: 1, loss: 8.490, avg: 0.24, latest lr: 9.702857142857143e-05\n",
      "epoch: 1, loss: 7.846, avg: 0.24, latest lr: 9.701428571428573e-05\n",
      "epoch: 1, loss: 8.710, avg: 0.24, latest lr: 9.7e-05\n",
      "epoch: 1, loss: 8.110, avg: 0.25, latest lr: 9.69857142857143e-05\n",
      "epoch: 1, loss: 8.537, avg: 0.25, latest lr: 9.697142857142858e-05\n",
      "epoch: 1, loss: 8.029, avg: 0.25, latest lr: 9.695714285714286e-05\n",
      "epoch: 1, loss: 8.581, avg: 0.25, latest lr: 9.694285714285715e-05\n",
      "epoch: 1, loss: 8.168, avg: 0.25, latest lr: 9.692857142857143e-05\n",
      "epoch: 1, loss: 8.555, avg: 0.25, latest lr: 9.691428571428573e-05\n",
      "epoch: 1, loss: 8.413, avg: 0.25, latest lr: 9.69e-05\n",
      "epoch: 1, loss: 8.256, avg: 0.25, latest lr: 9.68857142857143e-05\n",
      "epoch: 1, loss: 8.503, avg: 0.26, latest lr: 9.687142857142858e-05\n",
      "epoch: 1, loss: 7.853, avg: 0.26, latest lr: 9.685714285714286e-05\n",
      "epoch: 1, loss: 7.892, avg: 0.26, latest lr: 9.684285714285714e-05\n",
      "epoch: 1, loss: 8.104, avg: 0.26, latest lr: 9.682857142857144e-05\n",
      "epoch: 1, loss: 7.830, avg: 0.26, latest lr: 9.681428571428572e-05\n",
      "epoch: 1, loss: 8.077, avg: 0.26, latest lr: 9.680000000000001e-05\n",
      "epoch: 1, loss: 7.292, avg: 0.26, latest lr: 9.678571428571429e-05\n",
      "epoch: 1, loss: 7.948, avg: 0.26, latest lr: 9.677142857142858e-05\n",
      "epoch: 1, loss: 7.625, avg: 0.26, latest lr: 9.675714285714286e-05\n",
      "epoch: 1, loss: 8.081, avg: 0.27, latest lr: 9.674285714285714e-05\n",
      "epoch: 1, loss: 8.283, avg: 0.27, latest lr: 9.672857142857144e-05\n",
      "epoch: 1, loss: 8.253, avg: 0.27, latest lr: 9.671428571428572e-05\n",
      "epoch: 1, loss: 8.357, avg: 0.27, latest lr: 9.67e-05\n",
      "epoch: 1, loss: 7.036, avg: 0.27, latest lr: 9.668571428571429e-05\n",
      "epoch: 1, loss: 7.867, avg: 0.27, latest lr: 9.667142857142857e-05\n",
      "epoch: 1, loss: 8.687, avg: 0.27, latest lr: 9.665714285714286e-05\n",
      "epoch: 1, loss: 8.161, avg: 0.27, latest lr: 9.664285714285714e-05\n",
      "epoch: 1, loss: 7.762, avg: 0.27, latest lr: 9.662857142857144e-05\n",
      "epoch: 1, loss: 8.288, avg: 0.28, latest lr: 9.661428571428572e-05\n",
      "epoch: 1, loss: 8.391, avg: 0.28, latest lr: 9.66e-05\n",
      "epoch: 1, loss: 8.459, avg: 0.28, latest lr: 9.658571428571429e-05\n",
      "epoch: 1, loss: 8.488, avg: 0.28, latest lr: 9.657142857142858e-05\n",
      "epoch: 1, loss: 8.276, avg: 0.28, latest lr: 9.655714285714285e-05\n",
      "epoch: 1, loss: 8.454, avg: 0.28, latest lr: 9.654285714285715e-05\n",
      "epoch: 1, loss: 7.323, avg: 0.28, latest lr: 9.652857142857143e-05\n",
      "epoch: 1, loss: 7.201, avg: 0.28, latest lr: 9.651428571428572e-05\n",
      "epoch: 1, loss: 7.337, avg: 0.29, latest lr: 9.65e-05\n",
      "epoch: 1, loss: 8.729, avg: 0.29, latest lr: 9.648571428571428e-05\n",
      "epoch: 1, loss: 7.570, avg: 0.29, latest lr: 9.647142857142858e-05\n",
      "epoch: 1, loss: 7.414, avg: 0.29, latest lr: 9.645714285714285e-05\n",
      "epoch: 1, loss: 8.865, avg: 0.29, latest lr: 9.644285714285715e-05\n",
      "epoch: 1, loss: 7.785, avg: 0.29, latest lr: 9.642857142857143e-05\n",
      "epoch: 1, loss: 8.402, avg: 0.29, latest lr: 9.641428571428573e-05\n",
      "epoch: 1, loss: 7.747, avg: 0.29, latest lr: 9.64e-05\n",
      "epoch: 1, loss: 7.885, avg: 0.29, latest lr: 9.63857142857143e-05\n",
      "epoch: 1, loss: 7.164, avg: 0.30, latest lr: 9.637142857142858e-05\n",
      "epoch: 1, loss: 7.864, avg: 0.30, latest lr: 9.635714285714286e-05\n",
      "epoch: 1, loss: 7.623, avg: 0.30, latest lr: 9.634285714285715e-05\n",
      "epoch: 1, loss: 7.938, avg: 0.30, latest lr: 9.632857142857143e-05\n",
      "epoch: 1, loss: 7.908, avg: 0.30, latest lr: 9.631428571428573e-05\n",
      "epoch: 1, loss: 6.969, avg: 0.30, latest lr: 9.63e-05\n",
      "epoch: 1, loss: 7.781, avg: 0.30, latest lr: 9.628571428571429e-05\n",
      "epoch: 1, loss: 7.666, avg: 0.30, latest lr: 9.627142857142858e-05\n",
      "epoch: 1, loss: 7.598, avg: 0.30, latest lr: 9.625714285714286e-05\n",
      "epoch: 1, loss: 8.117, avg: 0.31, latest lr: 9.624285714285714e-05\n",
      "epoch: 1, loss: 7.470, avg: 0.31, latest lr: 9.622857142857144e-05\n",
      "epoch: 1, loss: 7.463, avg: 0.31, latest lr: 9.621428571428572e-05\n",
      "epoch: 1, loss: 7.345, avg: 0.31, latest lr: 9.620000000000001e-05\n",
      "epoch: 1, loss: 7.585, avg: 0.31, latest lr: 9.618571428571429e-05\n",
      "epoch: 1, loss: 7.831, avg: 0.31, latest lr: 9.617142857142857e-05\n",
      "epoch: 1, loss: 7.761, avg: 0.31, latest lr: 9.615714285714286e-05\n",
      "epoch: 1, loss: 7.541, avg: 0.31, latest lr: 9.614285714285714e-05\n",
      "epoch: 1, loss: 7.748, avg: 0.31, latest lr: 9.612857142857144e-05\n",
      "epoch: 1, loss: 7.280, avg: 0.31, latest lr: 9.611428571428572e-05\n",
      "epoch: 1, loss: 7.995, avg: 0.32, latest lr: 9.61e-05\n",
      "epoch: 1, loss: 7.468, avg: 0.32, latest lr: 9.608571428571429e-05\n",
      "epoch: 1, loss: 8.305, avg: 0.32, latest lr: 9.607142857142859e-05\n",
      "epoch: 1, loss: 8.823, avg: 0.32, latest lr: 9.605714285714286e-05\n",
      "epoch: 1, loss: 7.242, avg: 0.32, latest lr: 9.604285714285715e-05\n",
      "epoch: 1, loss: 8.622, avg: 0.32, latest lr: 9.602857142857144e-05\n",
      "epoch: 1, loss: 8.061, avg: 0.32, latest lr: 9.601428571428572e-05\n",
      "epoch: 1, loss: 7.720, avg: 0.32, latest lr: 9.6e-05\n",
      "epoch: 1, loss: 8.067, avg: 0.33, latest lr: 9.598571428571429e-05\n",
      "epoch: 1, loss: 7.939, avg: 0.33, latest lr: 9.597142857142858e-05\n",
      "epoch: 1, loss: 7.342, avg: 0.33, latest lr: 9.595714285714285e-05\n",
      "epoch: 1, loss: 7.941, avg: 0.33, latest lr: 9.594285714285715e-05\n",
      "epoch: 1, loss: 8.637, avg: 0.33, latest lr: 9.592857142857143e-05\n",
      "epoch: 1, loss: 7.451, avg: 0.33, latest lr: 9.591428571428572e-05\n",
      "epoch: 1, loss: 7.017, avg: 0.33, latest lr: 9.59e-05\n",
      "epoch: 1, loss: 8.834, avg: 0.33, latest lr: 9.588571428571428e-05\n",
      "epoch: 1, loss: 8.717, avg: 0.33, latest lr: 9.587142857142858e-05\n",
      "epoch: 1, loss: 8.415, avg: 0.34, latest lr: 9.585714285714285e-05\n",
      "epoch: 1, loss: 7.843, avg: 0.34, latest lr: 9.584285714285715e-05\n",
      "epoch: 1, loss: 8.418, avg: 0.34, latest lr: 9.582857142857143e-05\n",
      "epoch: 1, loss: 6.777, avg: 0.34, latest lr: 9.581428571428573e-05\n",
      "epoch: 1, loss: 8.093, avg: 0.34, latest lr: 9.58e-05\n",
      "epoch: 1, loss: 7.854, avg: 0.34, latest lr: 9.57857142857143e-05\n",
      "epoch: 1, loss: 7.799, avg: 0.34, latest lr: 9.577142857142858e-05\n",
      "epoch: 1, loss: 7.218, avg: 0.34, latest lr: 9.575714285714286e-05\n",
      "epoch: 1, loss: 7.482, avg: 0.34, latest lr: 9.574285714285714e-05\n",
      "epoch: 1, loss: 7.718, avg: 0.35, latest lr: 9.572857142857143e-05\n",
      "epoch: 1, loss: 8.148, avg: 0.35, latest lr: 9.571428571428573e-05\n",
      "epoch: 1, loss: 6.963, avg: 0.35, latest lr: 9.57e-05\n",
      "epoch: 1, loss: 7.308, avg: 0.35, latest lr: 9.568571428571429e-05\n",
      "epoch: 1, loss: 7.577, avg: 0.35, latest lr: 9.567142857142858e-05\n",
      "epoch: 1, loss: 6.992, avg: 0.35, latest lr: 9.565714285714286e-05\n",
      "epoch: 1, loss: 8.337, avg: 0.35, latest lr: 9.564285714285714e-05\n",
      "epoch: 1, loss: 8.387, avg: 0.35, latest lr: 9.562857142857144e-05\n",
      "epoch: 1, loss: 7.575, avg: 0.35, latest lr: 9.561428571428572e-05\n",
      "epoch: 1, loss: 7.636, avg: 0.36, latest lr: 9.56e-05\n",
      "epoch: 1, loss: 7.243, avg: 0.36, latest lr: 9.558571428571429e-05\n",
      "epoch: 1, loss: 7.716, avg: 0.36, latest lr: 9.557142857142857e-05\n",
      "epoch: 1, loss: 7.937, avg: 0.36, latest lr: 9.555714285714286e-05\n",
      "epoch: 1, loss: 8.139, avg: 0.36, latest lr: 9.554285714285714e-05\n",
      "epoch: 1, loss: 7.862, avg: 0.36, latest lr: 9.552857142857144e-05\n",
      "epoch: 1, loss: 8.442, avg: 0.36, latest lr: 9.551428571428572e-05\n",
      "epoch: 1, loss: 7.052, avg: 0.36, latest lr: 9.55e-05\n",
      "epoch: 1, loss: 7.628, avg: 0.36, latest lr: 9.548571428571429e-05\n",
      "epoch: 1, loss: 7.595, avg: 0.37, latest lr: 9.547142857142858e-05\n",
      "epoch: 1, loss: 7.668, avg: 0.37, latest lr: 9.545714285714287e-05\n",
      "epoch: 1, loss: 8.386, avg: 0.37, latest lr: 9.544285714285715e-05\n",
      "epoch: 1, loss: 8.104, avg: 0.37, latest lr: 9.542857142857143e-05\n",
      "epoch: 1, loss: 7.730, avg: 0.37, latest lr: 9.541428571428572e-05\n",
      "epoch: 1, loss: 8.036, avg: 0.37, latest lr: 9.54e-05\n",
      "epoch: 1, loss: 7.515, avg: 0.37, latest lr: 9.538571428571428e-05\n",
      "epoch: 1, loss: 6.610, avg: 0.37, latest lr: 9.537142857142858e-05\n",
      "epoch: 1, loss: 8.723, avg: 0.37, latest lr: 9.535714285714287e-05\n",
      "epoch: 1, loss: 8.221, avg: 0.38, latest lr: 9.534285714285715e-05\n",
      "epoch: 1, loss: 7.972, avg: 0.38, latest lr: 9.532857142857143e-05\n",
      "epoch: 1, loss: 6.917, avg: 0.38, latest lr: 9.531428571428573e-05\n",
      "epoch: 1, loss: 6.777, avg: 0.38, latest lr: 9.53e-05\n",
      "epoch: 1, loss: 7.113, avg: 0.38, latest lr: 9.52857142857143e-05\n",
      "epoch: 1, loss: 8.386, avg: 0.38, latest lr: 9.527142857142858e-05\n",
      "epoch: 1, loss: 8.761, avg: 0.38, latest lr: 9.525714285714286e-05\n",
      "epoch: 1, loss: 7.168, avg: 0.38, latest lr: 9.524285714285715e-05\n",
      "epoch: 1, loss: 10.936, avg: 0.38, latest lr: 9.522857142857143e-05\n",
      "epoch: 1, loss: 7.403, avg: 0.39, latest lr: 9.521428571428573e-05\n",
      "epoch: 1, loss: 8.172, avg: 0.39, latest lr: 9.52e-05\n",
      "epoch: 1, loss: 7.843, avg: 0.39, latest lr: 9.51857142857143e-05\n",
      "epoch: 1, loss: 6.825, avg: 0.39, latest lr: 9.517142857142858e-05\n",
      "epoch: 1, loss: 7.620, avg: 0.39, latest lr: 9.515714285714286e-05\n",
      "epoch: 1, loss: 8.239, avg: 0.39, latest lr: 9.514285714285714e-05\n",
      "epoch: 1, loss: 8.380, avg: 0.39, latest lr: 9.512857142857143e-05\n",
      "epoch: 1, loss: 8.341, avg: 0.39, latest lr: 9.511428571428572e-05\n",
      "epoch: 1, loss: 7.569, avg: 0.39, latest lr: 9.51e-05\n",
      "epoch: 1, loss: 8.756, avg: 0.40, latest lr: 9.508571428571429e-05\n",
      "epoch: 1, loss: 8.653, avg: 0.40, latest lr: 9.507142857142857e-05\n",
      "epoch: 1, loss: 7.047, avg: 0.40, latest lr: 9.505714285714287e-05\n",
      "epoch: 1, loss: 6.819, avg: 0.40, latest lr: 9.504285714285714e-05\n",
      "epoch: 1, loss: 7.812, avg: 0.40, latest lr: 9.502857142857144e-05\n",
      "epoch: 1, loss: 7.374, avg: 0.40, latest lr: 9.501428571428572e-05\n",
      "epoch: 1, loss: 8.221, avg: 0.40, latest lr: 9.5e-05\n",
      "epoch: 1, loss: 8.548, avg: 0.40, latest lr: 9.498571428571429e-05\n",
      "epoch: 1, loss: 8.166, avg: 0.40, latest lr: 9.497142857142857e-05\n",
      "epoch: 1, loss: 6.964, avg: 0.41, latest lr: 9.495714285714287e-05\n",
      "epoch: 1, loss: 8.039, avg: 0.41, latest lr: 9.494285714285714e-05\n",
      "epoch: 1, loss: 7.710, avg: 0.41, latest lr: 9.492857142857144e-05\n",
      "epoch: 1, loss: 7.626, avg: 0.41, latest lr: 9.491428571428572e-05\n",
      "epoch: 1, loss: 8.132, avg: 0.41, latest lr: 9.49e-05\n",
      "epoch: 1, loss: 6.764, avg: 0.41, latest lr: 9.488571428571429e-05\n",
      "epoch: 1, loss: 7.000, avg: 0.41, latest lr: 9.487142857142858e-05\n",
      "epoch: 1, loss: 7.876, avg: 0.41, latest lr: 9.485714285714287e-05\n",
      "epoch: 1, loss: 8.286, avg: 0.41, latest lr: 9.484285714285715e-05\n",
      "epoch: 1, loss: 6.742, avg: 0.42, latest lr: 9.482857142857143e-05\n",
      "epoch: 1, loss: 7.785, avg: 0.42, latest lr: 9.481428571428572e-05\n",
      "epoch: 1, loss: 8.002, avg: 0.42, latest lr: 9.48e-05\n",
      "epoch: 1, loss: 7.972, avg: 0.42, latest lr: 9.478571428571428e-05\n",
      "epoch: 1, loss: 7.903, avg: 0.42, latest lr: 9.477142857142858e-05\n",
      "epoch: 1, loss: 8.688, avg: 0.42, latest lr: 9.475714285714286e-05\n",
      "epoch: 1, loss: 8.015, avg: 0.42, latest lr: 9.474285714285715e-05\n",
      "epoch: 1, loss: 8.209, avg: 0.42, latest lr: 9.472857142857143e-05\n",
      "epoch: 1, loss: 7.940, avg: 0.42, latest lr: 9.471428571428573e-05\n",
      "epoch: 1, loss: 7.460, avg: 0.43, latest lr: 9.47e-05\n",
      "epoch: 1, loss: 8.082, avg: 0.43, latest lr: 9.46857142857143e-05\n",
      "epoch: 1, loss: 10.108, avg: 0.43, latest lr: 9.467142857142858e-05\n",
      "epoch: 1, loss: 7.101, avg: 0.43, latest lr: 9.465714285714286e-05\n",
      "epoch: 1, loss: 7.660, avg: 0.43, latest lr: 9.464285714285715e-05\n",
      "epoch: 1, loss: 7.687, avg: 0.43, latest lr: 9.462857142857143e-05\n",
      "epoch: 1, loss: 8.025, avg: 0.43, latest lr: 9.461428571428573e-05\n",
      "epoch: 1, loss: 8.440, avg: 0.43, latest lr: 9.46e-05\n",
      "epoch: 1, loss: 7.307, avg: 0.43, latest lr: 9.458571428571429e-05\n",
      "epoch: 1, loss: 8.497, avg: 0.44, latest lr: 9.457142857142858e-05\n",
      "epoch: 1, loss: 7.925, avg: 0.44, latest lr: 9.455714285714287e-05\n",
      "epoch: 1, loss: 7.339, avg: 0.44, latest lr: 9.454285714285714e-05\n",
      "epoch: 1, loss: 7.708, avg: 0.44, latest lr: 9.452857142857144e-05\n",
      "epoch: 1, loss: 7.301, avg: 0.44, latest lr: 9.451428571428572e-05\n",
      "epoch: 1, loss: 7.225, avg: 0.44, latest lr: 9.449999999999999e-05\n",
      "epoch: 1, loss: 7.745, avg: 0.44, latest lr: 9.448571428571429e-05\n",
      "epoch: 1, loss: 7.470, avg: 0.44, latest lr: 9.447142857142857e-05\n",
      "epoch: 1, loss: 7.299, avg: 0.44, latest lr: 9.445714285714287e-05\n",
      "epoch: 1, loss: 8.170, avg: 0.45, latest lr: 9.444285714285714e-05\n",
      "epoch: 1, loss: 7.571, avg: 0.45, latest lr: 9.442857142857144e-05\n",
      "epoch: 1, loss: 8.157, avg: 0.45, latest lr: 9.441428571428572e-05\n",
      "epoch: 1, loss: 7.671, avg: 0.45, latest lr: 9.44e-05\n",
      "epoch: 1, loss: 7.569, avg: 0.45, latest lr: 9.438571428571429e-05\n",
      "epoch: 1, loss: 6.761, avg: 0.45, latest lr: 9.437142857142857e-05\n",
      "epoch: 1, loss: 7.091, avg: 0.45, latest lr: 9.435714285714287e-05\n",
      "epoch: 1, loss: 8.480, avg: 0.45, latest lr: 9.434285714285714e-05\n",
      "epoch: 1, loss: 7.902, avg: 0.45, latest lr: 9.432857142857143e-05\n",
      "epoch: 1, loss: 6.493, avg: 0.46, latest lr: 9.431428571428572e-05\n",
      "epoch: 1, loss: 8.711, avg: 0.46, latest lr: 9.43e-05\n",
      "epoch: 1, loss: 6.203, avg: 0.46, latest lr: 9.428571428571429e-05\n",
      "epoch: 1, loss: 7.069, avg: 0.46, latest lr: 9.427142857142858e-05\n",
      "epoch: 1, loss: 8.191, avg: 0.46, latest lr: 9.425714285714287e-05\n",
      "epoch: 1, loss: 7.710, avg: 0.46, latest lr: 9.424285714285715e-05\n",
      "epoch: 1, loss: 7.360, avg: 0.46, latest lr: 9.422857142857143e-05\n",
      "epoch: 1, loss: 7.127, avg: 0.46, latest lr: 9.421428571428572e-05\n",
      "epoch: 1, loss: 7.357, avg: 0.46, latest lr: 9.42e-05\n",
      "epoch: 1, loss: 7.616, avg: 0.47, latest lr: 9.418571428571428e-05\n",
      "epoch: 1, loss: 7.559, avg: 0.47, latest lr: 9.417142857142858e-05\n",
      "epoch: 1, loss: 6.822, avg: 0.47, latest lr: 9.415714285714286e-05\n",
      "epoch: 1, loss: 7.712, avg: 0.47, latest lr: 9.414285714285715e-05\n",
      "epoch: 1, loss: 7.957, avg: 0.47, latest lr: 9.412857142857143e-05\n",
      "epoch: 1, loss: 6.690, avg: 0.47, latest lr: 9.411428571428573e-05\n",
      "epoch: 1, loss: 7.111, avg: 0.47, latest lr: 9.41e-05\n",
      "epoch: 1, loss: 6.687, avg: 0.47, latest lr: 9.40857142857143e-05\n",
      "epoch: 1, loss: 7.895, avg: 0.47, latest lr: 9.407142857142858e-05\n",
      "epoch: 1, loss: 8.272, avg: 0.47, latest lr: 9.405714285714286e-05\n",
      "epoch: 1, loss: 7.813, avg: 0.48, latest lr: 9.404285714285714e-05\n",
      "epoch: 1, loss: 7.394, avg: 0.48, latest lr: 9.402857142857143e-05\n",
      "epoch: 1, loss: 5.846, avg: 0.48, latest lr: 9.401428571428572e-05\n",
      "epoch: 1, loss: 6.638, avg: 0.48, latest lr: 9.4e-05\n",
      "epoch: 1, loss: 7.319, avg: 0.48, latest lr: 9.398571428571429e-05\n",
      "epoch: 1, loss: 6.315, avg: 0.48, latest lr: 9.397142857142857e-05\n",
      "epoch: 1, loss: 7.201, avg: 0.48, latest lr: 9.395714285714287e-05\n",
      "epoch: 1, loss: 8.279, avg: 0.48, latest lr: 9.394285714285714e-05\n",
      "epoch: 1, loss: 7.229, avg: 0.48, latest lr: 9.392857142857144e-05\n",
      "epoch: 1, loss: 7.904, avg: 0.49, latest lr: 9.391428571428572e-05\n",
      "epoch: 1, loss: 7.064, avg: 0.49, latest lr: 9.39e-05\n",
      "epoch: 1, loss: 6.750, avg: 0.49, latest lr: 9.388571428571429e-05\n",
      "epoch: 1, loss: 6.218, avg: 0.49, latest lr: 9.387142857142857e-05\n",
      "epoch: 1, loss: 6.546, avg: 0.49, latest lr: 9.385714285714287e-05\n",
      "epoch: 1, loss: 5.677, avg: 0.49, latest lr: 9.384285714285714e-05\n",
      "epoch: 1, loss: 9.475, avg: 0.49, latest lr: 9.382857142857144e-05\n",
      "epoch: 1, loss: 7.609, avg: 0.49, latest lr: 9.381428571428572e-05\n",
      "epoch: 1, loss: 8.097, avg: 0.49, latest lr: 9.38e-05\n",
      "epoch: 1, loss: 7.679, avg: 0.49, latest lr: 9.378571428571429e-05\n",
      "epoch: 1, loss: 6.692, avg: 0.50, latest lr: 9.377142857142857e-05\n",
      "epoch: 1, loss: 7.709, avg: 0.50, latest lr: 9.375714285714287e-05\n",
      "epoch: 1, loss: 7.540, avg: 0.50, latest lr: 9.374285714285714e-05\n",
      "epoch: 1, loss: 7.313, avg: 0.50, latest lr: 9.372857142857143e-05\n",
      "epoch: 1, loss: 7.532, avg: 0.50, latest lr: 9.371428571428572e-05\n",
      "epoch: 1, loss: 6.169, avg: 0.50, latest lr: 9.370000000000001e-05\n",
      "epoch: 1, loss: 8.353, avg: 0.50, latest lr: 9.368571428571428e-05\n",
      "epoch: 1, loss: 6.724, avg: 0.50, latest lr: 9.367142857142858e-05\n",
      "epoch: 1, loss: 7.434, avg: 0.50, latest lr: 9.365714285714286e-05\n",
      "epoch: 1, loss: 6.960, avg: 0.50, latest lr: 9.364285714285715e-05\n",
      "epoch: 1, loss: 7.198, avg: 0.51, latest lr: 9.362857142857143e-05\n",
      "epoch: 1, loss: 8.097, avg: 0.51, latest lr: 9.361428571428571e-05\n",
      "epoch: 1, loss: 7.338, avg: 0.51, latest lr: 9.360000000000001e-05\n",
      "epoch: 1, loss: 8.004, avg: 0.51, latest lr: 9.358571428571428e-05\n",
      "epoch: 1, loss: 7.138, avg: 0.51, latest lr: 9.357142857142858e-05\n",
      "epoch: 1, loss: 6.278, avg: 0.51, latest lr: 9.355714285714286e-05\n",
      "epoch: 1, loss: 7.492, avg: 0.51, latest lr: 9.354285714285715e-05\n",
      "epoch: 1, loss: 7.391, avg: 0.51, latest lr: 9.352857142857143e-05\n",
      "epoch: 1, loss: 6.234, avg: 0.51, latest lr: 9.351428571428573e-05\n",
      "epoch: 1, loss: 7.259, avg: 0.52, latest lr: 9.350000000000001e-05\n",
      "epoch: 1, loss: 7.210, avg: 0.52, latest lr: 9.348571428571429e-05\n",
      "epoch: 1, loss: 6.843, avg: 0.52, latest lr: 9.347142857142858e-05\n",
      "epoch: 1, loss: 6.639, avg: 0.52, latest lr: 9.345714285714286e-05\n",
      "epoch: 1, loss: 6.968, avg: 0.52, latest lr: 9.344285714285714e-05\n",
      "epoch: 1, loss: 7.604, avg: 0.52, latest lr: 9.342857142857143e-05\n",
      "epoch: 1, loss: 6.660, avg: 0.52, latest lr: 9.341428571428572e-05\n",
      "epoch: 1, loss: 7.489, avg: 0.52, latest lr: 9.340000000000001e-05\n",
      "epoch: 1, loss: 7.646, avg: 0.52, latest lr: 9.338571428571429e-05\n",
      "epoch: 1, loss: 6.612, avg: 0.52, latest lr: 9.337142857142857e-05\n",
      "epoch: 1, loss: 7.559, avg: 0.53, latest lr: 9.335714285714287e-05\n",
      "epoch: 1, loss: 7.712, avg: 0.53, latest lr: 9.334285714285714e-05\n",
      "epoch: 1, loss: 7.532, avg: 0.53, latest lr: 9.332857142857144e-05\n",
      "epoch: 1, loss: 7.817, avg: 0.53, latest lr: 9.331428571428572e-05\n",
      "epoch: 1, loss: 7.638, avg: 0.53, latest lr: 9.33e-05\n",
      "epoch: 1, loss: 7.410, avg: 0.53, latest lr: 9.328571428571429e-05\n",
      "epoch: 1, loss: 6.915, avg: 0.53, latest lr: 9.327142857142857e-05\n",
      "epoch: 1, loss: 7.004, avg: 0.53, latest lr: 9.325714285714287e-05\n",
      "epoch: 1, loss: 7.277, avg: 0.53, latest lr: 9.324285714285714e-05\n",
      "epoch: 1, loss: 7.620, avg: 0.53, latest lr: 9.322857142857144e-05\n",
      "epoch: 1, loss: 6.205, avg: 0.54, latest lr: 9.321428571428572e-05\n",
      "epoch: 1, loss: 7.529, avg: 0.54, latest lr: 9.320000000000002e-05\n",
      "epoch: 1, loss: 7.257, avg: 0.54, latest lr: 9.318571428571429e-05\n",
      "epoch: 1, loss: 5.953, avg: 0.54, latest lr: 9.317142857142858e-05\n",
      "epoch: 1, loss: 5.865, avg: 0.54, latest lr: 9.315714285714287e-05\n",
      "epoch: 1, loss: 6.160, avg: 0.54, latest lr: 9.314285714285715e-05\n",
      "epoch: 1, loss: 7.383, avg: 0.54, latest lr: 9.312857142857143e-05\n",
      "epoch: 1, loss: 6.464, avg: 0.54, latest lr: 9.311428571428572e-05\n",
      "epoch: 1, loss: 5.946, avg: 0.54, latest lr: 9.310000000000001e-05\n",
      "epoch: 1, loss: 6.643, avg: 0.54, latest lr: 9.308571428571428e-05\n",
      "epoch: 1, loss: 6.014, avg: 0.54, latest lr: 9.307142857142858e-05\n",
      "epoch: 1, loss: 5.380, avg: 0.55, latest lr: 9.305714285714286e-05\n",
      "epoch: 1, loss: 7.416, avg: 0.55, latest lr: 9.304285714285715e-05\n",
      "epoch: 1, loss: 6.819, avg: 0.55, latest lr: 9.302857142857143e-05\n",
      "epoch: 1, loss: 7.714, avg: 0.55, latest lr: 9.301428571428571e-05\n",
      "epoch: 1, loss: 6.934, avg: 0.55, latest lr: 9.300000000000001e-05\n",
      "epoch: 1, loss: 7.786, avg: 0.55, latest lr: 9.298571428571428e-05\n",
      "epoch: 1, loss: 6.811, avg: 0.55, latest lr: 9.297142857142858e-05\n",
      "epoch: 1, loss: 6.706, avg: 0.55, latest lr: 9.295714285714286e-05\n",
      "epoch: 1, loss: 6.243, avg: 0.55, latest lr: 9.294285714285714e-05\n",
      "epoch: 1, loss: 6.951, avg: 0.55, latest lr: 9.292857142857143e-05\n",
      "epoch: 1, loss: 5.003, avg: 0.56, latest lr: 9.291428571428572e-05\n",
      "epoch: 1, loss: 6.598, avg: 0.56, latest lr: 9.290000000000001e-05\n",
      "epoch: 1, loss: 7.173, avg: 0.56, latest lr: 9.288571428571429e-05\n",
      "epoch: 1, loss: 6.215, avg: 0.56, latest lr: 9.287142857142858e-05\n",
      "epoch: 1, loss: 6.383, avg: 0.56, latest lr: 9.285714285714286e-05\n",
      "epoch: 1, loss: 6.225, avg: 0.56, latest lr: 9.284285714285714e-05\n",
      "epoch: 1, loss: 7.423, avg: 0.56, latest lr: 9.282857142857143e-05\n",
      "epoch: 1, loss: 6.393, avg: 0.56, latest lr: 9.281428571428572e-05\n",
      "epoch: 1, loss: 7.288, avg: 0.56, latest lr: 9.28e-05\n",
      "epoch: 1, loss: 7.649, avg: 0.56, latest lr: 9.278571428571429e-05\n",
      "epoch: 1, loss: 6.814, avg: 0.57, latest lr: 9.277142857142857e-05\n",
      "epoch: 1, loss: 7.724, avg: 0.57, latest lr: 9.275714285714287e-05\n",
      "epoch: 1, loss: 8.052, avg: 0.57, latest lr: 9.274285714285714e-05\n",
      "epoch: 1, loss: 6.387, avg: 0.57, latest lr: 9.272857142857144e-05\n",
      "epoch: 1, loss: 7.092, avg: 0.57, latest lr: 9.271428571428572e-05\n",
      "epoch: 1, loss: 7.393, avg: 0.57, latest lr: 9.27e-05\n",
      "epoch: 1, loss: 5.831, avg: 0.57, latest lr: 9.268571428571429e-05\n",
      "epoch: 1, loss: 7.079, avg: 0.57, latest lr: 9.267142857142857e-05\n",
      "epoch: 1, loss: 5.521, avg: 0.57, latest lr: 9.265714285714287e-05\n",
      "epoch: 1, loss: 7.513, avg: 0.57, latest lr: 9.264285714285714e-05\n",
      "epoch: 1, loss: 7.228, avg: 0.58, latest lr: 9.262857142857143e-05\n",
      "epoch: 1, loss: 6.381, avg: 0.58, latest lr: 9.261428571428572e-05\n",
      "epoch: 1, loss: 6.691, avg: 0.58, latest lr: 9.260000000000001e-05\n",
      "epoch: 1, loss: 7.223, avg: 0.58, latest lr: 9.258571428571428e-05\n",
      "epoch: 1, loss: 6.867, avg: 0.58, latest lr: 9.257142857142858e-05\n",
      "epoch: 1, loss: 6.002, avg: 0.58, latest lr: 9.255714285714286e-05\n",
      "epoch: 1, loss: 7.007, avg: 0.58, latest lr: 9.254285714285715e-05\n",
      "epoch: 1, loss: 7.359, avg: 0.58, latest lr: 9.252857142857143e-05\n",
      "epoch: 1, loss: 6.943, avg: 0.58, latest lr: 9.251428571428572e-05\n",
      "epoch: 1, loss: 8.086, avg: 0.58, latest lr: 9.250000000000001e-05\n",
      "epoch: 1, loss: 7.253, avg: 0.59, latest lr: 9.248571428571428e-05\n",
      "epoch: 1, loss: 7.151, avg: 0.59, latest lr: 9.247142857142858e-05\n",
      "epoch: 1, loss: 7.004, avg: 0.59, latest lr: 9.245714285714286e-05\n",
      "epoch: 1, loss: 5.545, avg: 0.59, latest lr: 9.244285714285715e-05\n",
      "epoch: 1, loss: 7.626, avg: 0.59, latest lr: 9.242857142857143e-05\n",
      "epoch: 1, loss: 6.422, avg: 0.59, latest lr: 9.241428571428573e-05\n",
      "epoch: 1, loss: 6.842, avg: 0.59, latest lr: 9.240000000000001e-05\n",
      "epoch: 1, loss: 6.585, avg: 0.59, latest lr: 9.23857142857143e-05\n",
      "epoch: 1, loss: 6.750, avg: 0.59, latest lr: 9.237142857142858e-05\n",
      "epoch: 1, loss: 7.968, avg: 0.59, latest lr: 9.235714285714286e-05\n",
      "epoch: 1, loss: 7.026, avg: 0.60, latest lr: 9.234285714285714e-05\n",
      "epoch: 1, loss: 7.478, avg: 0.60, latest lr: 9.232857142857143e-05\n",
      "epoch: 1, loss: 7.739, avg: 0.60, latest lr: 9.231428571428572e-05\n",
      "epoch: 1, loss: 7.240, avg: 0.60, latest lr: 9.230000000000001e-05\n",
      "epoch: 1, loss: 6.505, avg: 0.60, latest lr: 9.228571428571429e-05\n",
      "epoch: 1, loss: 6.258, avg: 0.60, latest lr: 9.227142857142857e-05\n",
      "epoch: 1, loss: 6.927, avg: 0.60, latest lr: 9.225714285714286e-05\n",
      "epoch: 1, loss: 7.221, avg: 0.60, latest lr: 9.224285714285714e-05\n",
      "epoch: 1, loss: 6.122, avg: 0.60, latest lr: 9.222857142857142e-05\n",
      "epoch: 1, loss: 6.507, avg: 0.60, latest lr: 9.221428571428572e-05\n",
      "epoch: 1, loss: 7.031, avg: 0.60, latest lr: 9.22e-05\n",
      "epoch: 1, loss: 7.815, avg: 0.61, latest lr: 9.218571428571429e-05\n",
      "epoch: 1, loss: 6.993, avg: 0.61, latest lr: 9.217142857142857e-05\n",
      "epoch: 1, loss: 6.877, avg: 0.61, latest lr: 9.215714285714287e-05\n",
      "epoch: 1, loss: 7.304, avg: 0.61, latest lr: 9.214285714285714e-05\n",
      "epoch: 1, loss: 6.944, avg: 0.61, latest lr: 9.212857142857144e-05\n",
      "epoch: 1, loss: 6.051, avg: 0.61, latest lr: 9.211428571428572e-05\n",
      "epoch: 1, loss: 6.144, avg: 0.61, latest lr: 9.21e-05\n",
      "epoch: 1, loss: 5.602, avg: 0.61, latest lr: 9.208571428571429e-05\n",
      "epoch: 1, loss: 6.779, avg: 0.61, latest lr: 9.207142857142857e-05\n",
      "epoch: 1, loss: 6.588, avg: 0.61, latest lr: 9.205714285714287e-05\n",
      "epoch: 1, loss: 6.489, avg: 0.62, latest lr: 9.204285714285714e-05\n",
      "epoch: 1, loss: 6.937, avg: 0.62, latest lr: 9.202857142857143e-05\n",
      "epoch: 1, loss: 7.170, avg: 0.62, latest lr: 9.201428571428572e-05\n",
      "epoch: 1, loss: 6.427, avg: 0.62, latest lr: 9.200000000000001e-05\n",
      "epoch: 1, loss: 7.219, avg: 0.62, latest lr: 9.198571428571428e-05\n",
      "epoch: 1, loss: 7.053, avg: 0.62, latest lr: 9.197142857142858e-05\n",
      "epoch: 1, loss: 5.818, avg: 0.62, latest lr: 9.195714285714286e-05\n",
      "epoch: 1, loss: 5.556, avg: 0.62, latest lr: 9.194285714285715e-05\n",
      "epoch: 1, loss: 7.471, avg: 0.62, latest lr: 9.192857142857143e-05\n",
      "epoch: 1, loss: 6.806, avg: 0.62, latest lr: 9.191428571428571e-05\n",
      "epoch: 1, loss: 5.976, avg: 0.62, latest lr: 9.190000000000001e-05\n",
      "epoch: 1, loss: 6.478, avg: 0.63, latest lr: 9.188571428571428e-05\n",
      "epoch: 1, loss: 6.532, avg: 0.63, latest lr: 9.187142857142858e-05\n",
      "epoch: 1, loss: 5.486, avg: 0.63, latest lr: 9.185714285714286e-05\n",
      "epoch: 1, loss: 7.430, avg: 0.63, latest lr: 9.184285714285716e-05\n",
      "epoch: 1, loss: 6.509, avg: 0.63, latest lr: 9.182857142857143e-05\n",
      "epoch: 1, loss: 7.542, avg: 0.63, latest lr: 9.181428571428573e-05\n",
      "epoch: 1, loss: 7.419, avg: 0.63, latest lr: 9.180000000000001e-05\n",
      "epoch: 1, loss: 6.382, avg: 0.63, latest lr: 9.178571428571429e-05\n",
      "epoch: 1, loss: 6.329, avg: 0.63, latest lr: 9.177142857142858e-05\n",
      "epoch: 1, loss: 6.054, avg: 0.63, latest lr: 9.175714285714286e-05\n",
      "epoch: 1, loss: 6.111, avg: 0.64, latest lr: 9.174285714285716e-05\n",
      "epoch: 1, loss: 6.429, avg: 0.64, latest lr: 9.172857142857143e-05\n",
      "epoch: 1, loss: 6.900, avg: 0.64, latest lr: 9.171428571428572e-05\n",
      "epoch: 1, loss: 6.265, avg: 0.64, latest lr: 9.17e-05\n",
      "epoch: 1, loss: 5.940, avg: 0.64, latest lr: 9.168571428571429e-05\n",
      "epoch: 1, loss: 6.387, avg: 0.64, latest lr: 9.167142857142857e-05\n",
      "epoch: 1, loss: 6.881, avg: 0.64, latest lr: 9.165714285714287e-05\n",
      "epoch: 1, loss: 6.279, avg: 0.64, latest lr: 9.164285714285715e-05\n",
      "epoch: 1, loss: 6.650, avg: 0.64, latest lr: 9.162857142857144e-05\n",
      "epoch: 1, loss: 6.030, avg: 0.64, latest lr: 9.161428571428572e-05\n",
      "epoch: 1, loss: 7.006, avg: 0.64, latest lr: 9.16e-05\n",
      "epoch: 1, loss: 6.986, avg: 0.65, latest lr: 9.158571428571429e-05\n",
      "epoch: 1, loss: 6.731, avg: 0.65, latest lr: 9.157142857142857e-05\n",
      "epoch: 1, loss: 7.352, avg: 0.65, latest lr: 9.155714285714287e-05\n",
      "epoch: 1, loss: 6.771, avg: 0.65, latest lr: 9.154285714285715e-05\n",
      "epoch: 1, loss: 6.300, avg: 0.65, latest lr: 9.152857142857143e-05\n",
      "epoch: 1, loss: 6.147, avg: 0.65, latest lr: 9.151428571428572e-05\n",
      "epoch: 1, loss: 6.466, avg: 0.65, latest lr: 9.15e-05\n",
      "epoch: 1, loss: 6.592, avg: 0.65, latest lr: 9.148571428571428e-05\n",
      "epoch: 1, loss: 8.002, avg: 0.65, latest lr: 9.147142857142857e-05\n",
      "epoch: 1, loss: 6.174, avg: 0.65, latest lr: 9.145714285714287e-05\n",
      "epoch: 1, loss: 5.808, avg: 0.65, latest lr: 9.144285714285715e-05\n",
      "epoch: 1, loss: 6.572, avg: 0.66, latest lr: 9.142857142857143e-05\n",
      "epoch: 1, loss: 5.694, avg: 0.66, latest lr: 9.141428571428572e-05\n",
      "epoch: 1, loss: 7.489, avg: 0.66, latest lr: 9.140000000000001e-05\n",
      "epoch: 1, loss: 7.582, avg: 0.66, latest lr: 9.138571428571428e-05\n",
      "epoch: 1, loss: 6.457, avg: 0.66, latest lr: 9.137142857142858e-05\n",
      "epoch: 1, loss: 5.613, avg: 0.66, latest lr: 9.135714285714286e-05\n",
      "epoch: 1, loss: 5.769, avg: 0.66, latest lr: 9.134285714285715e-05\n",
      "epoch: 1, loss: 6.505, avg: 0.66, latest lr: 9.132857142857143e-05\n",
      "epoch: 1, loss: 6.862, avg: 0.66, latest lr: 9.131428571428571e-05\n",
      "epoch: 1, loss: 6.672, avg: 0.66, latest lr: 9.130000000000001e-05\n",
      "epoch: 1, loss: 5.371, avg: 0.67, latest lr: 9.128571428571428e-05\n",
      "epoch: 1, loss: 6.959, avg: 0.67, latest lr: 9.127142857142858e-05\n",
      "epoch: 1, loss: 6.628, avg: 0.67, latest lr: 9.125714285714286e-05\n",
      "epoch: 1, loss: 5.372, avg: 0.67, latest lr: 9.124285714285716e-05\n",
      "epoch: 1, loss: 6.719, avg: 0.67, latest lr: 9.122857142857143e-05\n",
      "epoch: 1, loss: 6.017, avg: 0.67, latest lr: 9.121428571428572e-05\n",
      "epoch: 1, loss: 6.515, avg: 0.67, latest lr: 9.120000000000001e-05\n",
      "epoch: 1, loss: 6.404, avg: 0.67, latest lr: 9.118571428571429e-05\n",
      "epoch: 1, loss: 6.870, avg: 0.67, latest lr: 9.117142857142857e-05\n",
      "epoch: 1, loss: 6.706, avg: 0.67, latest lr: 9.115714285714286e-05\n",
      "epoch: 1, loss: 6.390, avg: 0.67, latest lr: 9.114285714285716e-05\n",
      "epoch: 1, loss: 6.159, avg: 0.68, latest lr: 9.112857142857142e-05\n",
      "epoch: 1, loss: 5.726, avg: 0.68, latest lr: 9.111428571428572e-05\n",
      "epoch: 1, loss: 6.900, avg: 0.68, latest lr: 9.11e-05\n",
      "epoch: 1, loss: 6.698, avg: 0.68, latest lr: 9.108571428571429e-05\n",
      "epoch: 1, loss: 7.646, avg: 0.68, latest lr: 9.107142857142857e-05\n",
      "epoch: 1, loss: 6.723, avg: 0.68, latest lr: 9.105714285714287e-05\n",
      "epoch: 1, loss: 6.635, avg: 0.68, latest lr: 9.104285714285715e-05\n",
      "epoch: 1, loss: 6.777, avg: 0.68, latest lr: 9.102857142857144e-05\n",
      "epoch: 1, loss: 5.943, avg: 0.68, latest lr: 9.101428571428572e-05\n",
      "epoch: 1, loss: 7.038, avg: 0.68, latest lr: 9.1e-05\n",
      "epoch: 1, loss: 6.047, avg: 0.68, latest lr: 9.098571428571429e-05\n",
      "epoch: 1, loss: 5.895, avg: 0.69, latest lr: 9.097142857142857e-05\n",
      "epoch: 1, loss: 7.512, avg: 0.69, latest lr: 9.095714285714287e-05\n",
      "epoch: 1, loss: 6.481, avg: 0.69, latest lr: 9.094285714285715e-05\n",
      "epoch: 1, loss: 7.464, avg: 0.69, latest lr: 9.092857142857143e-05\n",
      "epoch: 1, loss: 7.008, avg: 0.69, latest lr: 9.091428571428572e-05\n",
      "epoch: 1, loss: 6.692, avg: 0.69, latest lr: 9.090000000000001e-05\n",
      "epoch: 1, loss: 6.485, avg: 0.69, latest lr: 9.088571428571428e-05\n",
      "epoch: 1, loss: 9.251, avg: 0.69, latest lr: 9.087142857142857e-05\n",
      "epoch: 1, loss: 5.718, avg: 0.69, latest lr: 9.085714285714286e-05\n",
      "epoch: 1, loss: 6.489, avg: 0.69, latest lr: 9.084285714285715e-05\n",
      "epoch: 1, loss: 5.179, avg: 0.70, latest lr: 9.082857142857143e-05\n",
      "epoch: 1, loss: 6.963, avg: 0.70, latest lr: 9.081428571428571e-05\n",
      "epoch: 1, loss: 6.161, avg: 0.70, latest lr: 9.080000000000001e-05\n",
      "epoch: 1, loss: 6.911, avg: 0.70, latest lr: 9.078571428571428e-05\n",
      "epoch: 1, loss: 5.700, avg: 0.70, latest lr: 9.077142857142858e-05\n",
      "epoch: 1, loss: 6.825, avg: 0.70, latest lr: 9.075714285714286e-05\n",
      "epoch: 1, loss: 4.745, avg: 0.70, latest lr: 9.074285714285715e-05\n",
      "epoch: 1, loss: 7.053, avg: 0.70, latest lr: 9.072857142857143e-05\n",
      "epoch: 1, loss: 6.258, avg: 0.70, latest lr: 9.071428571428571e-05\n",
      "epoch: 1, loss: 6.672, avg: 0.70, latest lr: 9.070000000000001e-05\n",
      "epoch: 1, loss: 6.882, avg: 0.70, latest lr: 9.068571428571428e-05\n",
      "epoch: 1, loss: 6.386, avg: 0.71, latest lr: 9.067142857142858e-05\n",
      "epoch: 1, loss: 6.865, avg: 0.71, latest lr: 9.065714285714286e-05\n",
      "epoch: 1, loss: 7.157, avg: 0.71, latest lr: 9.064285714285716e-05\n",
      "epoch: 1, loss: 6.427, avg: 0.71, latest lr: 9.062857142857143e-05\n",
      "epoch: 1, loss: 6.826, avg: 0.71, latest lr: 9.061428571428572e-05\n",
      "epoch: 1, loss: 5.804, avg: 0.71, latest lr: 9.06e-05\n",
      "epoch: 1, loss: 6.995, avg: 0.71, latest lr: 9.058571428571429e-05\n",
      "epoch: 1, loss: 5.815, avg: 0.71, latest lr: 9.057142857142857e-05\n",
      "epoch: 1, loss: 7.431, avg: 0.71, latest lr: 9.055714285714286e-05\n",
      "epoch: 1, loss: 6.798, avg: 0.71, latest lr: 9.054285714285715e-05\n",
      "epoch: 1, loss: 5.481, avg: 0.71, latest lr: 9.052857142857142e-05\n",
      "epoch: 1, loss: 5.857, avg: 0.72, latest lr: 9.051428571428572e-05\n",
      "epoch: 1, loss: 5.851, avg: 0.72, latest lr: 9.05e-05\n",
      "epoch: 1, loss: 6.740, avg: 0.72, latest lr: 9.048571428571429e-05\n",
      "epoch: 1, loss: 6.617, avg: 0.72, latest lr: 9.047142857142857e-05\n",
      "epoch: 1, loss: 6.687, avg: 0.72, latest lr: 9.045714285714287e-05\n",
      "epoch: 1, loss: 6.408, avg: 0.72, latest lr: 9.044285714285715e-05\n",
      "epoch: 1, loss: 6.496, avg: 0.72, latest lr: 9.042857142857143e-05\n",
      "epoch: 1, loss: 6.678, avg: 0.72, latest lr: 9.041428571428572e-05\n",
      "epoch: 1, loss: 6.410, avg: 0.72, latest lr: 9.04e-05\n",
      "epoch: 1, loss: 6.288, avg: 0.72, latest lr: 9.038571428571429e-05\n",
      "epoch: 1, loss: 5.647, avg: 0.72, latest lr: 9.037142857142857e-05\n",
      "epoch: 1, loss: 5.227, avg: 0.73, latest lr: 9.035714285714287e-05\n",
      "epoch: 1, loss: 5.538, avg: 0.73, latest lr: 9.034285714285715e-05\n",
      "epoch: 1, loss: 4.928, avg: 0.73, latest lr: 9.032857142857143e-05\n",
      "epoch: 1, loss: 6.147, avg: 0.73, latest lr: 9.031428571428572e-05\n",
      "epoch: 1, loss: 5.301, avg: 0.73, latest lr: 9.030000000000001e-05\n",
      "epoch: 1, loss: 6.583, avg: 0.73, latest lr: 9.028571428571428e-05\n",
      "epoch: 1, loss: 6.067, avg: 0.73, latest lr: 9.027142857142858e-05\n",
      "epoch: 1, loss: 6.790, avg: 0.73, latest lr: 9.025714285714286e-05\n",
      "epoch: 1, loss: 4.998, avg: 0.73, latest lr: 9.024285714285715e-05\n",
      "epoch: 1, loss: 6.231, avg: 0.73, latest lr: 9.022857142857143e-05\n",
      "epoch: 1, loss: 5.729, avg: 0.73, latest lr: 9.021428571428571e-05\n",
      "epoch: 1, loss: 5.325, avg: 0.73, latest lr: 9.020000000000001e-05\n",
      "epoch: 1, loss: 5.770, avg: 0.74, latest lr: 9.018571428571428e-05\n",
      "epoch: 1, loss: 5.723, avg: 0.74, latest lr: 9.017142857142858e-05\n",
      "epoch: 1, loss: 4.892, avg: 0.74, latest lr: 9.015714285714286e-05\n",
      "epoch: 1, loss: 6.313, avg: 0.74, latest lr: 9.014285714285716e-05\n",
      "epoch: 1, loss: 5.071, avg: 0.74, latest lr: 9.012857142857143e-05\n",
      "epoch: 1, loss: 6.068, avg: 0.74, latest lr: 9.011428571428571e-05\n",
      "epoch: 1, loss: 6.254, avg: 0.74, latest lr: 9.010000000000001e-05\n",
      "epoch: 1, loss: 6.370, avg: 0.74, latest lr: 9.008571428571429e-05\n",
      "epoch: 1, loss: 5.806, avg: 0.74, latest lr: 9.007142857142857e-05\n",
      "epoch: 1, loss: 7.571, avg: 0.74, latest lr: 9.005714285714286e-05\n",
      "epoch: 1, loss: 5.613, avg: 0.74, latest lr: 9.004285714285716e-05\n",
      "epoch: 1, loss: 4.880, avg: 0.74, latest lr: 9.002857142857143e-05\n",
      "epoch: 1, loss: 6.311, avg: 0.75, latest lr: 9.001428571428572e-05\n",
      "epoch: 1, loss: 6.931, avg: 0.75, latest lr: 9e-05\n",
      "epoch: 1, loss: 5.931, avg: 0.75, latest lr: 8.998571428571429e-05\n",
      "epoch: 1, loss: 6.000, avg: 0.75, latest lr: 8.997142857142857e-05\n",
      "epoch: 1, loss: 6.157, avg: 0.75, latest lr: 8.995714285714286e-05\n",
      "epoch: 1, loss: 6.125, avg: 0.75, latest lr: 8.994285714285715e-05\n",
      "epoch: 1, loss: 7.485, avg: 0.75, latest lr: 8.992857142857142e-05\n",
      "epoch: 1, loss: 4.656, avg: 0.75, latest lr: 8.991428571428572e-05\n",
      "epoch: 1, loss: 5.473, avg: 0.75, latest lr: 8.99e-05\n",
      "epoch: 1, loss: 6.356, avg: 0.75, latest lr: 8.98857142857143e-05\n",
      "epoch: 1, loss: 5.209, avg: 0.75, latest lr: 8.987142857142857e-05\n",
      "epoch: 1, loss: 6.676, avg: 0.75, latest lr: 8.985714285714287e-05\n",
      "epoch: 1, loss: 7.525, avg: 0.76, latest lr: 8.984285714285715e-05\n",
      "epoch: 1, loss: 6.994, avg: 0.76, latest lr: 8.982857142857143e-05\n",
      "epoch: 1, loss: 6.850, avg: 0.76, latest lr: 8.981428571428572e-05\n",
      "epoch: 1, loss: 6.021, avg: 0.76, latest lr: 8.98e-05\n",
      "epoch: 1, loss: 5.490, avg: 0.76, latest lr: 8.97857142857143e-05\n",
      "epoch: 1, loss: 5.191, avg: 0.76, latest lr: 8.977142857142857e-05\n",
      "epoch: 1, loss: 5.555, avg: 0.76, latest lr: 8.975714285714286e-05\n",
      "epoch: 1, loss: 8.227, avg: 0.76, latest lr: 8.974285714285715e-05\n",
      "epoch: 1, loss: 6.161, avg: 0.76, latest lr: 8.972857142857143e-05\n",
      "epoch: 1, loss: 4.855, avg: 0.76, latest lr: 8.971428571428571e-05\n",
      "epoch: 1, loss: 5.014, avg: 0.76, latest lr: 8.970000000000001e-05\n",
      "epoch: 1, loss: 6.597, avg: 0.77, latest lr: 8.96857142857143e-05\n",
      "epoch: 1, loss: 6.338, avg: 0.77, latest lr: 8.967142857142858e-05\n",
      "epoch: 1, loss: 5.517, avg: 0.77, latest lr: 8.965714285714286e-05\n",
      "epoch: 1, loss: 5.374, avg: 0.77, latest lr: 8.964285714285715e-05\n",
      "epoch: 1, loss: 6.279, avg: 0.77, latest lr: 8.962857142857143e-05\n",
      "epoch: 1, loss: 6.862, avg: 0.77, latest lr: 8.961428571428571e-05\n",
      "epoch: 1, loss: 6.636, avg: 0.77, latest lr: 8.960000000000001e-05\n",
      "epoch: 1, loss: 5.204, avg: 0.77, latest lr: 8.958571428571429e-05\n",
      "epoch: 1, loss: 5.117, avg: 0.77, latest lr: 8.957142857142858e-05\n",
      "epoch: 1, loss: 4.833, avg: 0.77, latest lr: 8.955714285714286e-05\n",
      "epoch: 1, loss: 7.276, avg: 0.77, latest lr: 8.954285714285716e-05\n",
      "epoch: 1, loss: 6.627, avg: 0.78, latest lr: 8.952857142857143e-05\n",
      "epoch: 1, loss: 5.434, avg: 0.78, latest lr: 8.951428571428572e-05\n",
      "epoch: 1, loss: 6.795, avg: 0.78, latest lr: 8.950000000000001e-05\n",
      "epoch: 1, loss: 4.558, avg: 0.78, latest lr: 8.948571428571429e-05\n",
      "epoch: 1, loss: 6.943, avg: 0.78, latest lr: 8.947142857142857e-05\n",
      "epoch: 1, loss: 5.248, avg: 0.78, latest lr: 8.945714285714286e-05\n",
      "epoch: 1, loss: 6.346, avg: 0.78, latest lr: 8.944285714285715e-05\n",
      "epoch: 1, loss: 5.667, avg: 0.78, latest lr: 8.942857142857142e-05\n",
      "epoch: 1, loss: 6.150, avg: 0.78, latest lr: 8.941428571428572e-05\n",
      "epoch: 1, loss: 6.329, avg: 0.78, latest lr: 8.94e-05\n",
      "epoch: 1, loss: 6.884, avg: 0.78, latest lr: 8.93857142857143e-05\n",
      "epoch: 1, loss: 6.235, avg: 0.78, latest lr: 8.937142857142857e-05\n",
      "epoch: 1, loss: 4.042, avg: 0.79, latest lr: 8.935714285714285e-05\n",
      "epoch: 1, loss: 6.184, avg: 0.79, latest lr: 8.934285714285715e-05\n",
      "epoch: 1, loss: 4.771, avg: 0.79, latest lr: 8.932857142857142e-05\n",
      "epoch: 1, loss: 6.169, avg: 0.79, latest lr: 8.931428571428572e-05\n",
      "epoch: 1, loss: 5.902, avg: 0.79, latest lr: 8.93e-05\n",
      "epoch: 1, loss: 6.112, avg: 0.79, latest lr: 8.92857142857143e-05\n",
      "epoch: 1, loss: 5.520, avg: 0.79, latest lr: 8.927142857142857e-05\n",
      "epoch: 1, loss: 5.871, avg: 0.79, latest lr: 8.925714285714287e-05\n",
      "epoch: 1, loss: 5.622, avg: 0.79, latest lr: 8.924285714285715e-05\n",
      "epoch: 1, loss: 5.536, avg: 0.79, latest lr: 8.922857142857143e-05\n",
      "epoch: 1, loss: 5.302, avg: 0.79, latest lr: 8.921428571428572e-05\n",
      "epoch: 1, loss: 6.264, avg: 0.79, latest lr: 8.92e-05\n",
      "epoch: 1, loss: 5.137, avg: 0.79, latest lr: 8.91857142857143e-05\n",
      "epoch: 1, loss: 6.694, avg: 0.80, latest lr: 8.917142857142857e-05\n",
      "epoch: 1, loss: 4.881, avg: 0.80, latest lr: 8.915714285714286e-05\n",
      "epoch: 1, loss: 6.346, avg: 0.80, latest lr: 8.914285714285715e-05\n",
      "epoch: 1, loss: 6.682, avg: 0.80, latest lr: 8.912857142857143e-05\n",
      "epoch: 1, loss: 6.448, avg: 0.80, latest lr: 8.911428571428571e-05\n",
      "epoch: 1, loss: 5.486, avg: 0.80, latest lr: 8.910000000000001e-05\n",
      "epoch: 1, loss: 6.631, avg: 0.80, latest lr: 8.90857142857143e-05\n",
      "epoch: 1, loss: 4.674, avg: 0.80, latest lr: 8.907142857142858e-05\n",
      "epoch: 1, loss: 6.574, avg: 0.80, latest lr: 8.905714285714286e-05\n",
      "epoch: 1, loss: 6.894, avg: 0.80, latest lr: 8.904285714285714e-05\n",
      "epoch: 1, loss: 6.378, avg: 0.80, latest lr: 8.902857142857143e-05\n",
      "epoch: 1, loss: 6.185, avg: 0.81, latest lr: 8.901428571428571e-05\n",
      "epoch: 1, loss: 5.018, avg: 0.81, latest lr: 8.900000000000001e-05\n",
      "epoch: 1, loss: 6.115, avg: 0.81, latest lr: 8.898571428571429e-05\n",
      "epoch: 1, loss: 6.455, avg: 0.81, latest lr: 8.897142857142858e-05\n",
      "epoch: 1, loss: 5.939, avg: 0.81, latest lr: 8.895714285714286e-05\n",
      "epoch: 1, loss: 6.100, avg: 0.81, latest lr: 8.894285714285716e-05\n",
      "epoch: 1, loss: 6.064, avg: 0.81, latest lr: 8.892857142857143e-05\n",
      "epoch: 1, loss: 6.829, avg: 0.81, latest lr: 8.891428571428572e-05\n",
      "epoch: 1, loss: 6.417, avg: 0.81, latest lr: 8.89e-05\n",
      "epoch: 1, loss: 6.155, avg: 0.81, latest lr: 8.888571428571429e-05\n",
      "epoch: 1, loss: 4.574, avg: 0.81, latest lr: 8.887142857142857e-05\n",
      "epoch: 1, loss: 6.579, avg: 0.81, latest lr: 8.885714285714286e-05\n",
      "epoch: 1, loss: 5.761, avg: 0.82, latest lr: 8.884285714285715e-05\n",
      "epoch: 1, loss: 6.042, avg: 0.82, latest lr: 8.882857142857142e-05\n",
      "epoch: 1, loss: 6.169, avg: 0.82, latest lr: 8.881428571428572e-05\n",
      "epoch: 1, loss: 5.394, avg: 0.82, latest lr: 8.88e-05\n",
      "epoch: 1, loss: 6.411, avg: 0.82, latest lr: 8.87857142857143e-05\n",
      "epoch: 1, loss: 5.858, avg: 0.82, latest lr: 8.877142857142857e-05\n",
      "epoch: 1, loss: 7.211, avg: 0.82, latest lr: 8.875714285714287e-05\n",
      "epoch: 1, loss: 5.326, avg: 0.82, latest lr: 8.874285714285715e-05\n",
      "epoch: 1, loss: 5.902, avg: 0.82, latest lr: 8.872857142857143e-05\n",
      "epoch: 1, loss: 5.665, avg: 0.82, latest lr: 8.871428571428572e-05\n",
      "epoch: 1, loss: 5.239, avg: 0.82, latest lr: 8.87e-05\n",
      "epoch: 1, loss: 6.461, avg: 0.83, latest lr: 8.86857142857143e-05\n",
      "epoch: 1, loss: 5.207, avg: 0.83, latest lr: 8.867142857142857e-05\n",
      "epoch: 1, loss: 6.396, avg: 0.83, latest lr: 8.865714285714287e-05\n",
      "epoch: 1, loss: 6.029, avg: 0.83, latest lr: 8.864285714285715e-05\n",
      "epoch: 1, loss: 7.014, avg: 0.83, latest lr: 8.862857142857143e-05\n",
      "epoch: 1, loss: 6.406, avg: 0.83, latest lr: 8.861428571428572e-05\n",
      "epoch: 1, loss: 6.637, avg: 0.83, latest lr: 8.86e-05\n",
      "epoch: 1, loss: 7.182, avg: 0.83, latest lr: 8.85857142857143e-05\n",
      "epoch: 1, loss: 6.058, avg: 0.83, latest lr: 8.857142857142857e-05\n",
      "epoch: 1, loss: 6.890, avg: 0.83, latest lr: 8.855714285714286e-05\n",
      "epoch: 1, loss: 6.290, avg: 0.83, latest lr: 8.854285714285715e-05\n",
      "epoch: 1, loss: 5.923, avg: 0.84, latest lr: 8.852857142857143e-05\n",
      "epoch: 1, loss: 5.676, avg: 0.84, latest lr: 8.851428571428571e-05\n",
      "epoch: 1, loss: 5.221, avg: 0.84, latest lr: 8.850000000000001e-05\n",
      "epoch: 1, loss: 3.699, avg: 0.84, latest lr: 8.84857142857143e-05\n",
      "epoch: 1, loss: 5.637, avg: 0.84, latest lr: 8.847142857142858e-05\n",
      "epoch: 1, loss: 5.888, avg: 0.84, latest lr: 8.845714285714286e-05\n",
      "epoch: 1, loss: 5.587, avg: 0.84, latest lr: 8.844285714285714e-05\n",
      "epoch: 1, loss: 6.213, avg: 0.84, latest lr: 8.842857142857143e-05\n",
      "epoch: 1, loss: 6.881, avg: 0.84, latest lr: 8.841428571428571e-05\n",
      "epoch: 1, loss: 6.884, avg: 0.84, latest lr: 8.840000000000001e-05\n",
      "epoch: 1, loss: 5.461, avg: 0.84, latest lr: 8.838571428571429e-05\n",
      "epoch: 1, loss: 6.434, avg: 0.84, latest lr: 8.837142857142857e-05\n",
      "epoch: 1, loss: 6.764, avg: 0.85, latest lr: 8.835714285714286e-05\n",
      "epoch: 1, loss: 6.281, avg: 0.85, latest lr: 8.834285714285715e-05\n",
      "epoch: 1, loss: 5.721, avg: 0.85, latest lr: 8.832857142857144e-05\n",
      "epoch: 1, loss: 5.303, avg: 0.85, latest lr: 8.831428571428572e-05\n",
      "epoch: 1, loss: 6.123, avg: 0.85, latest lr: 8.83e-05\n",
      "epoch: 1, loss: 5.751, avg: 0.85, latest lr: 8.828571428571429e-05\n",
      "epoch: 1, loss: 6.431, avg: 0.85, latest lr: 8.827142857142857e-05\n",
      "epoch: 1, loss: 7.107, avg: 0.85, latest lr: 8.825714285714286e-05\n",
      "epoch: 1, loss: 5.149, avg: 0.85, latest lr: 8.824285714285715e-05\n",
      "epoch: 1, loss: 5.271, avg: 0.85, latest lr: 8.822857142857144e-05\n",
      "epoch: 1, loss: 5.705, avg: 0.85, latest lr: 8.821428571428572e-05\n",
      "epoch: 1, loss: 6.130, avg: 0.85, latest lr: 8.82e-05\n",
      "epoch: 1, loss: 6.589, avg: 0.86, latest lr: 8.81857142857143e-05\n",
      "epoch: 1, loss: 6.441, avg: 0.86, latest lr: 8.817142857142857e-05\n",
      "epoch: 1, loss: 5.847, avg: 0.86, latest lr: 8.815714285714287e-05\n",
      "epoch: 1, loss: 4.563, avg: 0.86, latest lr: 8.814285714285715e-05\n",
      "epoch: 1, loss: 6.303, avg: 0.86, latest lr: 8.812857142857143e-05\n",
      "epoch: 1, loss: 5.889, avg: 0.86, latest lr: 8.811428571428572e-05\n",
      "epoch: 1, loss: 5.956, avg: 0.86, latest lr: 8.81e-05\n",
      "epoch: 1, loss: 4.633, avg: 0.86, latest lr: 8.80857142857143e-05\n",
      "epoch: 1, loss: 6.211, avg: 0.86, latest lr: 8.807142857142857e-05\n",
      "epoch: 1, loss: 5.593, avg: 0.86, latest lr: 8.805714285714286e-05\n",
      "epoch: 1, loss: 5.876, avg: 0.86, latest lr: 8.804285714285715e-05\n",
      "epoch: 1, loss: 6.090, avg: 0.86, latest lr: 8.802857142857144e-05\n",
      "epoch: 1, loss: 4.450, avg: 0.87, latest lr: 8.801428571428571e-05\n",
      "epoch: 1, loss: 5.128, avg: 0.87, latest lr: 8.800000000000001e-05\n",
      "epoch: 1, loss: 5.959, avg: 0.87, latest lr: 8.79857142857143e-05\n",
      "epoch: 1, loss: 6.549, avg: 0.87, latest lr: 8.797142857142856e-05\n",
      "epoch: 1, loss: 5.734, avg: 0.87, latest lr: 8.795714285714286e-05\n",
      "epoch: 1, loss: 5.805, avg: 0.87, latest lr: 8.794285714285714e-05\n",
      "epoch: 1, loss: 6.228, avg: 0.87, latest lr: 8.792857142857144e-05\n",
      "epoch: 1, loss: 5.058, avg: 0.87, latest lr: 8.791428571428571e-05\n",
      "epoch: 1, loss: 5.848, avg: 0.87, latest lr: 8.790000000000001e-05\n",
      "epoch: 1, loss: 6.207, avg: 0.87, latest lr: 8.788571428571429e-05\n",
      "epoch: 1, loss: 5.386, avg: 0.87, latest lr: 8.787142857142858e-05\n",
      "epoch: 1, loss: 5.273, avg: 0.87, latest lr: 8.785714285714286e-05\n",
      "epoch: 1, loss: 5.887, avg: 0.87, latest lr: 8.784285714285714e-05\n",
      "epoch: 1, loss: 5.393, avg: 0.88, latest lr: 8.782857142857144e-05\n",
      "epoch: 1, loss: 7.145, avg: 0.88, latest lr: 8.781428571428571e-05\n",
      "epoch: 1, loss: 5.469, avg: 0.88, latest lr: 8.78e-05\n",
      "epoch: 1, loss: 5.578, avg: 0.88, latest lr: 8.778571428571429e-05\n",
      "epoch: 1, loss: 6.474, avg: 0.88, latest lr: 8.777142857142857e-05\n",
      "epoch: 1, loss: 5.318, avg: 0.88, latest lr: 8.775714285714286e-05\n",
      "epoch: 1, loss: 6.021, avg: 0.88, latest lr: 8.774285714285715e-05\n",
      "epoch: 1, loss: 5.204, avg: 0.88, latest lr: 8.772857142857144e-05\n",
      "epoch: 1, loss: 5.960, avg: 0.88, latest lr: 8.771428571428572e-05\n",
      "epoch: 1, loss: 5.546, avg: 0.88, latest lr: 8.77e-05\n",
      "epoch: 1, loss: 6.701, avg: 0.88, latest lr: 8.768571428571429e-05\n",
      "epoch: 1, loss: 6.063, avg: 0.89, latest lr: 8.767142857142857e-05\n",
      "epoch: 1, loss: 5.281, avg: 0.89, latest lr: 8.765714285714285e-05\n",
      "epoch: 1, loss: 6.669, avg: 0.89, latest lr: 8.764285714285715e-05\n",
      "epoch: 1, loss: 5.523, avg: 0.89, latest lr: 8.762857142857143e-05\n",
      "epoch: 1, loss: 5.793, avg: 0.89, latest lr: 8.761428571428572e-05\n",
      "epoch: 1, loss: 6.345, avg: 0.89, latest lr: 8.76e-05\n",
      "epoch: 1, loss: 4.910, avg: 0.89, latest lr: 8.75857142857143e-05\n",
      "epoch: 1, loss: 5.518, avg: 0.89, latest lr: 8.757142857142857e-05\n",
      "epoch: 1, loss: 6.165, avg: 0.89, latest lr: 8.755714285714287e-05\n",
      "epoch: 1, loss: 6.358, avg: 0.89, latest lr: 8.754285714285715e-05\n",
      "epoch: 1, loss: 6.647, avg: 0.89, latest lr: 8.752857142857143e-05\n",
      "epoch: 1, loss: 6.501, avg: 0.89, latest lr: 8.751428571428572e-05\n",
      "epoch: 1, loss: 6.515, avg: 0.90, latest lr: 8.75e-05\n",
      "epoch: 1, loss: 6.279, avg: 0.90, latest lr: 8.74857142857143e-05\n",
      "epoch: 1, loss: 5.687, avg: 0.90, latest lr: 8.747142857142857e-05\n",
      "epoch: 1, loss: 6.473, avg: 0.90, latest lr: 8.745714285714286e-05\n",
      "epoch: 1, loss: 6.273, avg: 0.90, latest lr: 8.744285714285715e-05\n",
      "epoch: 1, loss: 4.777, avg: 0.90, latest lr: 8.742857142857144e-05\n",
      "epoch: 1, loss: 5.975, avg: 0.90, latest lr: 8.741428571428571e-05\n",
      "epoch: 1, loss: 6.277, avg: 0.90, latest lr: 8.740000000000001e-05\n",
      "epoch: 1, loss: 6.155, avg: 0.90, latest lr: 8.73857142857143e-05\n",
      "epoch: 1, loss: 6.147, avg: 0.90, latest lr: 8.737142857142858e-05\n",
      "epoch: 1, loss: 6.216, avg: 0.90, latest lr: 8.735714285714286e-05\n",
      "epoch: 1, loss: 7.215, avg: 0.91, latest lr: 8.734285714285714e-05\n",
      "epoch: 1, loss: 4.806, avg: 0.91, latest lr: 8.732857142857144e-05\n",
      "epoch: 1, loss: 5.045, avg: 0.91, latest lr: 8.731428571428571e-05\n",
      "epoch: 1, loss: 6.647, avg: 0.91, latest lr: 8.730000000000001e-05\n",
      "epoch: 1, loss: 6.731, avg: 0.91, latest lr: 8.728571428571429e-05\n",
      "epoch: 1, loss: 5.127, avg: 0.91, latest lr: 8.727142857142857e-05\n",
      "epoch: 1, loss: 6.716, avg: 0.91, latest lr: 8.725714285714286e-05\n",
      "epoch: 1, loss: 6.595, avg: 0.91, latest lr: 8.724285714285716e-05\n",
      "epoch: 1, loss: 5.824, avg: 0.91, latest lr: 8.722857142857144e-05\n",
      "epoch: 1, loss: 5.717, avg: 0.91, latest lr: 8.721428571428571e-05\n",
      "epoch: 1, loss: 6.289, avg: 0.91, latest lr: 8.72e-05\n",
      "epoch: 1, loss: 4.625, avg: 0.91, latest lr: 8.718571428571429e-05\n",
      "epoch: 1, loss: 5.862, avg: 0.92, latest lr: 8.717142857142857e-05\n",
      "epoch: 1, loss: 6.233, avg: 0.92, latest lr: 8.715714285714286e-05\n",
      "epoch: 1, loss: 6.432, avg: 0.92, latest lr: 8.714285714285715e-05\n",
      "epoch: 1, loss: 6.294, avg: 0.92, latest lr: 8.712857142857144e-05\n",
      "epoch: 1, loss: 4.746, avg: 0.92, latest lr: 8.711428571428572e-05\n",
      "epoch: 1, loss: 6.286, avg: 0.92, latest lr: 8.71e-05\n",
      "epoch: 1, loss: 6.170, avg: 0.92, latest lr: 8.708571428571429e-05\n",
      "epoch: 1, loss: 5.979, avg: 0.92, latest lr: 8.707142857142857e-05\n",
      "epoch: 1, loss: 5.963, avg: 0.92, latest lr: 8.705714285714285e-05\n",
      "epoch: 1, loss: 5.562, avg: 0.92, latest lr: 8.704285714285715e-05\n",
      "epoch: 1, loss: 5.747, avg: 0.92, latest lr: 8.702857142857143e-05\n",
      "epoch: 1, loss: 6.370, avg: 0.92, latest lr: 8.701428571428572e-05\n",
      "epoch: 1, loss: 5.966, avg: 0.93, latest lr: 8.7e-05\n",
      "epoch: 1, loss: 6.118, avg: 0.93, latest lr: 8.69857142857143e-05\n",
      "epoch: 1, loss: 6.269, avg: 0.93, latest lr: 8.697142857142857e-05\n",
      "epoch: 1, loss: 4.362, avg: 0.93, latest lr: 8.695714285714286e-05\n",
      "epoch: 1, loss: 6.291, avg: 0.93, latest lr: 8.694285714285715e-05\n",
      "epoch: 1, loss: 4.347, avg: 0.93, latest lr: 8.692857142857143e-05\n",
      "epoch: 1, loss: 5.388, avg: 0.93, latest lr: 8.691428571428571e-05\n",
      "epoch: 1, loss: 5.966, avg: 0.93, latest lr: 8.69e-05\n",
      "epoch: 1, loss: 6.259, avg: 0.93, latest lr: 8.68857142857143e-05\n",
      "epoch: 1, loss: 5.553, avg: 0.93, latest lr: 8.687142857142856e-05\n",
      "epoch: 1, loss: 6.036, avg: 0.93, latest lr: 8.685714285714286e-05\n",
      "epoch: 1, loss: 7.557, avg: 0.93, latest lr: 8.684285714285715e-05\n",
      "epoch: 1, loss: 5.818, avg: 0.94, latest lr: 8.682857142857144e-05\n",
      "epoch: 1, loss: 4.991, avg: 0.94, latest lr: 8.681428571428571e-05\n",
      "epoch: 1, loss: 5.893, avg: 0.94, latest lr: 8.680000000000001e-05\n",
      "epoch: 1, loss: 5.670, avg: 0.94, latest lr: 8.678571428571429e-05\n",
      "epoch: 1, loss: 6.199, avg: 0.94, latest lr: 8.677142857142858e-05\n",
      "epoch: 1, loss: 6.344, avg: 0.94, latest lr: 8.675714285714286e-05\n",
      "epoch: 1, loss: 5.009, avg: 0.94, latest lr: 8.674285714285714e-05\n",
      "epoch: 1, loss: 5.645, avg: 0.94, latest lr: 8.672857142857144e-05\n",
      "epoch: 1, loss: 7.040, avg: 0.94, latest lr: 8.671428571428571e-05\n",
      "epoch: 1, loss: 5.216, avg: 0.94, latest lr: 8.67e-05\n",
      "epoch: 1, loss: 5.249, avg: 0.94, latest lr: 8.668571428571429e-05\n",
      "epoch: 1, loss: 5.927, avg: 0.94, latest lr: 8.667142857142857e-05\n",
      "epoch: 1, loss: 6.769, avg: 0.95, latest lr: 8.665714285714286e-05\n",
      "epoch: 1, loss: 6.542, avg: 0.95, latest lr: 8.664285714285715e-05\n",
      "epoch: 1, loss: 6.026, avg: 0.95, latest lr: 8.662857142857144e-05\n",
      "epoch: 1, loss: 5.129, avg: 0.95, latest lr: 8.661428571428572e-05\n",
      "epoch: 1, loss: 6.539, avg: 0.95, latest lr: 8.66e-05\n",
      "epoch: 1, loss: 5.007, avg: 0.95, latest lr: 8.658571428571429e-05\n",
      "epoch: 1, loss: 5.426, avg: 0.95, latest lr: 8.657142857142858e-05\n",
      "epoch: 1, loss: 4.917, avg: 0.95, latest lr: 8.655714285714285e-05\n",
      "epoch: 1, loss: 7.115, avg: 0.95, latest lr: 8.654285714285715e-05\n",
      "epoch: 1, loss: 5.293, avg: 0.95, latest lr: 8.652857142857144e-05\n",
      "epoch: 1, loss: 6.945, avg: 0.95, latest lr: 8.651428571428572e-05\n",
      "epoch: 1, loss: 6.050, avg: 0.95, latest lr: 8.65e-05\n",
      "epoch: 1, loss: 5.548, avg: 0.96, latest lr: 8.64857142857143e-05\n",
      "epoch: 1, loss: 6.221, avg: 0.96, latest lr: 8.647142857142858e-05\n",
      "epoch: 1, loss: 6.088, avg: 0.96, latest lr: 8.645714285714285e-05\n",
      "epoch: 1, loss: 5.298, avg: 0.96, latest lr: 8.644285714285715e-05\n",
      "epoch: 1, loss: 4.717, avg: 0.96, latest lr: 8.642857142857143e-05\n",
      "epoch: 1, loss: 5.385, avg: 0.96, latest lr: 8.641428571428572e-05\n",
      "epoch: 1, loss: 5.833, avg: 0.96, latest lr: 8.64e-05\n",
      "epoch: 1, loss: 7.288, avg: 0.96, latest lr: 8.63857142857143e-05\n",
      "epoch: 1, loss: 4.918, avg: 0.96, latest lr: 8.637142857142858e-05\n",
      "epoch: 1, loss: 6.802, avg: 0.96, latest lr: 8.635714285714286e-05\n",
      "epoch: 1, loss: 6.303, avg: 0.96, latest lr: 8.634285714285715e-05\n",
      "epoch: 1, loss: 6.389, avg: 0.96, latest lr: 8.632857142857143e-05\n",
      "epoch: 1, loss: 5.260, avg: 0.97, latest lr: 8.631428571428571e-05\n",
      "epoch: 1, loss: 5.742, avg: 0.97, latest lr: 8.63e-05\n",
      "epoch: 1, loss: 5.398, avg: 0.97, latest lr: 8.62857142857143e-05\n",
      "epoch: 1, loss: 6.363, avg: 0.97, latest lr: 8.627142857142858e-05\n",
      "epoch: 1, loss: 5.824, avg: 0.97, latest lr: 8.625714285714286e-05\n",
      "epoch: 1, loss: 6.417, avg: 0.97, latest lr: 8.624285714285714e-05\n",
      "epoch: 1, loss: 6.480, avg: 0.97, latest lr: 8.622857142857144e-05\n",
      "epoch: 1, loss: 6.666, avg: 0.97, latest lr: 8.621428571428571e-05\n",
      "epoch: 1, loss: 4.723, avg: 0.97, latest lr: 8.620000000000001e-05\n",
      "epoch: 1, loss: 5.892, avg: 0.97, latest lr: 8.618571428571429e-05\n",
      "epoch: 1, loss: 5.461, avg: 0.97, latest lr: 8.617142857142858e-05\n",
      "epoch: 1, loss: 6.256, avg: 0.97, latest lr: 8.615714285714286e-05\n",
      "epoch: 1, loss: 7.082, avg: 0.98, latest lr: 8.614285714285714e-05\n",
      "epoch: 1, loss: 6.362, avg: 0.98, latest lr: 8.612857142857144e-05\n",
      "epoch: 1, loss: 5.132, avg: 0.98, latest lr: 8.611428571428571e-05\n",
      "epoch: 1, loss: 5.436, avg: 0.98, latest lr: 8.61e-05\n",
      "epoch: 1, loss: 5.545, avg: 0.98, latest lr: 8.608571428571429e-05\n",
      "epoch: 1, loss: 6.288, avg: 0.98, latest lr: 8.607142857142859e-05\n",
      "epoch: 1, loss: 6.783, avg: 0.98, latest lr: 8.605714285714286e-05\n",
      "epoch: 1, loss: 5.239, avg: 0.98, latest lr: 8.604285714285715e-05\n",
      "epoch: 1, loss: 6.886, avg: 0.98, latest lr: 8.602857142857144e-05\n",
      "epoch: 1, loss: 5.314, avg: 0.98, latest lr: 8.601428571428572e-05\n",
      "epoch: 1, loss: 5.834, avg: 0.98, latest lr: 8.6e-05\n",
      "epoch: 1, loss: 6.119, avg: 0.99, latest lr: 8.598571428571429e-05\n",
      "epoch: 1, loss: 5.868, avg: 0.99, latest lr: 8.597142857142858e-05\n",
      "epoch: 1, loss: 5.291, avg: 0.99, latest lr: 8.595714285714285e-05\n",
      "epoch: 1, loss: 5.408, avg: 0.99, latest lr: 8.594285714285715e-05\n",
      "epoch: 1, loss: 5.705, avg: 0.99, latest lr: 8.592857142857143e-05\n",
      "epoch: 1, loss: 3.897, avg: 0.99, latest lr: 8.591428571428572e-05\n",
      "epoch: 1, loss: 5.513, avg: 0.99, latest lr: 8.59e-05\n",
      "epoch: 1, loss: 4.844, avg: 0.99, latest lr: 8.58857142857143e-05\n",
      "epoch: 1, loss: 5.018, avg: 0.99, latest lr: 8.587142857142858e-05\n",
      "epoch: 1, loss: 5.969, avg: 0.99, latest lr: 8.585714285714286e-05\n",
      "epoch: 1, loss: 6.042, avg: 0.99, latest lr: 8.584285714285715e-05\n",
      "epoch: 1, loss: 6.359, avg: 0.99, latest lr: 8.582857142857143e-05\n",
      "epoch: 1, loss: 4.753, avg: 0.99, latest lr: 8.581428571428572e-05\n",
      "epoch: 1, loss: 5.800, avg: 1.00, latest lr: 8.58e-05\n",
      "epoch: 1, loss: 5.875, avg: 1.00, latest lr: 8.57857142857143e-05\n",
      "epoch: 1, loss: 6.319, avg: 1.00, latest lr: 8.577142857142858e-05\n",
      "epoch: 1, loss: 6.326, avg: 1.00, latest lr: 8.575714285714286e-05\n",
      "epoch: 1, loss: 6.210, avg: 1.00, latest lr: 8.574285714285715e-05\n",
      "epoch: 1, loss: 6.051, avg: 1.00, latest lr: 8.572857142857143e-05\n",
      "epoch: 1, loss: 5.883, avg: 1.00, latest lr: 8.571428571428571e-05\n",
      "epoch: 1, loss: 5.195, avg: 1.00, latest lr: 8.57e-05\n",
      "epoch: 1, loss: 5.955, avg: 1.00, latest lr: 8.568571428571429e-05\n",
      "epoch: 1, loss: 5.989, avg: 1.00, latest lr: 8.567142857142858e-05\n",
      "epoch: 1, loss: 5.605, avg: 1.00, latest lr: 8.565714285714286e-05\n",
      "epoch: 1, loss: 4.763, avg: 1.00, latest lr: 8.564285714285714e-05\n",
      "epoch: 1, loss: 5.844, avg: 1.01, latest lr: 8.562857142857144e-05\n",
      "epoch: 1, loss: 5.367, avg: 1.01, latest lr: 8.561428571428571e-05\n",
      "epoch: 1, loss: 6.642, avg: 1.01, latest lr: 8.560000000000001e-05\n",
      "epoch: 1, loss: 6.213, avg: 1.01, latest lr: 8.558571428571429e-05\n",
      "epoch: 1, loss: 5.971, avg: 1.01, latest lr: 8.557142857142857e-05\n",
      "epoch: 1, loss: 6.417, avg: 1.01, latest lr: 8.555714285714286e-05\n",
      "epoch: 1, loss: 6.470, avg: 1.01, latest lr: 8.554285714285714e-05\n",
      "epoch: 1, loss: 5.935, avg: 1.01, latest lr: 8.552857142857144e-05\n",
      "epoch: 1, loss: 5.701, avg: 1.01, latest lr: 8.551428571428571e-05\n",
      "epoch: 1, loss: 6.165, avg: 1.01, latest lr: 8.55e-05\n",
      "epoch: 1, loss: 6.827, avg: 1.01, latest lr: 8.548571428571429e-05\n",
      "epoch: 1, loss: 6.127, avg: 1.01, latest lr: 8.547142857142859e-05\n",
      "epoch: 1, loss: 5.787, avg: 1.02, latest lr: 8.545714285714286e-05\n",
      "epoch: 1, loss: 5.248, avg: 1.02, latest lr: 8.544285714285715e-05\n",
      "epoch: 1, loss: 4.183, avg: 1.02, latest lr: 8.542857142857144e-05\n",
      "epoch: 1, loss: 6.424, avg: 1.02, latest lr: 8.541428571428572e-05\n",
      "epoch: 1, loss: 5.859, avg: 1.02, latest lr: 8.54e-05\n",
      "epoch: 1, loss: 4.676, avg: 1.02, latest lr: 8.538571428571429e-05\n",
      "epoch: 1, loss: 7.051, avg: 1.02, latest lr: 8.537142857142858e-05\n",
      "epoch: 1, loss: 4.496, avg: 1.02, latest lr: 8.535714285714285e-05\n",
      "epoch: 1, loss: 5.887, avg: 1.02, latest lr: 8.534285714285715e-05\n",
      "epoch: 1, loss: 5.598, avg: 1.02, latest lr: 8.532857142857143e-05\n",
      "epoch: 1, loss: 5.473, avg: 1.02, latest lr: 8.531428571428572e-05\n",
      "epoch: 1, loss: 6.605, avg: 1.02, latest lr: 8.53e-05\n",
      "epoch: 1, loss: 5.228, avg: 1.03, latest lr: 8.52857142857143e-05\n",
      "epoch: 1, loss: 5.141, avg: 1.03, latest lr: 8.527142857142858e-05\n",
      "epoch: 1, loss: 6.051, avg: 1.03, latest lr: 8.525714285714286e-05\n",
      "epoch: 1, loss: 6.981, avg: 1.03, latest lr: 8.524285714285715e-05\n",
      "epoch: 1, loss: 5.596, avg: 1.03, latest lr: 8.522857142857143e-05\n",
      "epoch: 1, loss: 6.129, avg: 1.03, latest lr: 8.521428571428571e-05\n",
      "epoch: 1, loss: 4.211, avg: 1.03, latest lr: 8.52e-05\n",
      "epoch: 1, loss: 5.280, avg: 1.03, latest lr: 8.51857142857143e-05\n",
      "epoch: 1, loss: 4.897, avg: 1.03, latest lr: 8.517142857142858e-05\n",
      "epoch: 1, loss: 5.480, avg: 1.03, latest lr: 8.515714285714286e-05\n",
      "epoch: 1, loss: 6.199, avg: 1.03, latest lr: 8.514285714285714e-05\n",
      "epoch: 1, loss: 6.528, avg: 1.03, latest lr: 8.512857142857144e-05\n",
      "epoch: 1, loss: 4.273, avg: 1.03, latest lr: 8.511428571428571e-05\n",
      "epoch: 1, loss: 3.743, avg: 1.04, latest lr: 8.510000000000001e-05\n",
      "epoch: 1, loss: 5.889, avg: 1.04, latest lr: 8.508571428571429e-05\n",
      "epoch: 1, loss: 6.136, avg: 1.04, latest lr: 8.507142857142858e-05\n",
      "epoch: 1, loss: 6.200, avg: 1.04, latest lr: 8.505714285714286e-05\n",
      "epoch: 1, loss: 4.274, avg: 1.04, latest lr: 8.504285714285714e-05\n",
      "epoch: 1, loss: 5.518, avg: 1.04, latest lr: 8.502857142857144e-05\n",
      "epoch: 1, loss: 6.368, avg: 1.04, latest lr: 8.501428571428571e-05\n",
      "epoch: 1, loss: 5.827, avg: 1.04, latest lr: 8.5e-05\n",
      "epoch: 1, loss: 5.795, avg: 1.04, latest lr: 8.498571428571429e-05\n",
      "epoch: 1, loss: 4.706, avg: 1.04, latest lr: 8.497142857142857e-05\n",
      "epoch: 1, loss: 4.837, avg: 1.04, latest lr: 8.495714285714286e-05\n",
      "epoch: 1, loss: 5.137, avg: 1.04, latest lr: 8.494285714285714e-05\n",
      "epoch: 1, loss: 5.759, avg: 1.04, latest lr: 8.492857142857144e-05\n",
      "epoch: 1, loss: 7.172, avg: 1.05, latest lr: 8.49142857142857e-05\n",
      "epoch: 1, loss: 6.118, avg: 1.05, latest lr: 8.49e-05\n",
      "epoch: 1, loss: 6.209, avg: 1.05, latest lr: 8.488571428571429e-05\n",
      "epoch: 1, loss: 5.706, avg: 1.05, latest lr: 8.487142857142858e-05\n",
      "epoch: 1, loss: 5.333, avg: 1.05, latest lr: 8.485714285714285e-05\n",
      "epoch: 1, loss: 6.250, avg: 1.05, latest lr: 8.484285714285715e-05\n",
      "epoch: 1, loss: 4.415, avg: 1.05, latest lr: 8.482857142857143e-05\n",
      "epoch: 1, loss: 5.436, avg: 1.05, latest lr: 8.481428571428572e-05\n",
      "epoch: 1, loss: 6.129, avg: 1.05, latest lr: 8.48e-05\n",
      "epoch: 1, loss: 6.157, avg: 1.05, latest lr: 8.478571428571428e-05\n",
      "epoch: 1, loss: 5.816, avg: 1.05, latest lr: 8.477142857142858e-05\n",
      "epoch: 1, loss: 6.694, avg: 1.05, latest lr: 8.475714285714285e-05\n",
      "epoch: 1, loss: 4.975, avg: 1.06, latest lr: 8.474285714285715e-05\n",
      "epoch: 1, loss: 6.403, avg: 1.06, latest lr: 8.472857142857143e-05\n",
      "epoch: 1, loss: 6.805, avg: 1.06, latest lr: 8.471428571428573e-05\n",
      "epoch: 1, loss: 6.700, avg: 1.06, latest lr: 8.47e-05\n",
      "epoch: 1, loss: 6.472, avg: 1.06, latest lr: 8.46857142857143e-05\n",
      "epoch: 1, loss: 5.865, avg: 1.06, latest lr: 8.467142857142858e-05\n",
      "epoch: 1, loss: 5.545, avg: 1.06, latest lr: 8.465714285714286e-05\n",
      "epoch: 1, loss: 6.027, avg: 1.06, latest lr: 8.464285714285715e-05\n",
      "epoch: 1, loss: 5.948, avg: 1.06, latest lr: 8.462857142857143e-05\n",
      "epoch: 1, loss: 6.159, avg: 1.06, latest lr: 8.461428571428573e-05\n",
      "epoch: 1, loss: 5.548, avg: 1.06, latest lr: 8.46e-05\n",
      "epoch: 1, loss: 5.741, avg: 1.07, latest lr: 8.45857142857143e-05\n",
      "epoch: 1, loss: 6.395, avg: 1.07, latest lr: 8.457142857142858e-05\n",
      "epoch: 1, loss: 5.858, avg: 1.07, latest lr: 8.455714285714286e-05\n",
      "epoch: 1, loss: 5.643, avg: 1.07, latest lr: 8.454285714285714e-05\n",
      "epoch: 1, loss: 5.302, avg: 1.07, latest lr: 8.452857142857144e-05\n",
      "epoch: 1, loss: 5.996, avg: 1.07, latest lr: 8.451428571428572e-05\n",
      "epoch: 1, loss: 3.875, avg: 1.07, latest lr: 8.450000000000001e-05\n",
      "epoch: 1, loss: 5.466, avg: 1.07, latest lr: 8.448571428571429e-05\n",
      "epoch: 1, loss: 6.948, avg: 1.07, latest lr: 8.447142857142857e-05\n",
      "epoch: 1, loss: 6.378, avg: 1.07, latest lr: 8.445714285714286e-05\n",
      "epoch: 1, loss: 6.147, avg: 1.07, latest lr: 8.444285714285714e-05\n",
      "epoch: 1, loss: 6.076, avg: 1.07, latest lr: 8.442857142857144e-05\n",
      "epoch: 1, loss: 5.173, avg: 1.08, latest lr: 8.441428571428572e-05\n",
      "epoch: 1, loss: 5.607, avg: 1.08, latest lr: 8.44e-05\n",
      "epoch: 1, loss: 6.152, avg: 1.08, latest lr: 8.438571428571429e-05\n",
      "epoch: 1, loss: 4.573, avg: 1.08, latest lr: 8.437142857142859e-05\n",
      "epoch: 1, loss: 5.827, avg: 1.08, latest lr: 8.435714285714286e-05\n",
      "epoch: 1, loss: 5.558, avg: 1.08, latest lr: 8.434285714285715e-05\n",
      "epoch: 1, loss: 4.617, avg: 1.08, latest lr: 8.432857142857144e-05\n",
      "epoch: 1, loss: 5.470, avg: 1.08, latest lr: 8.431428571428572e-05\n",
      "epoch: 1, loss: 6.035, avg: 1.08, latest lr: 8.43e-05\n",
      "epoch: 1, loss: 4.852, avg: 1.08, latest lr: 8.428571428571429e-05\n",
      "epoch: 1, loss: 5.468, avg: 1.08, latest lr: 8.427142857142858e-05\n",
      "epoch: 1, loss: 6.459, avg: 1.08, latest lr: 8.425714285714285e-05\n",
      "epoch: 1, loss: 5.223, avg: 1.08, latest lr: 8.424285714285715e-05\n",
      "epoch: 1, loss: 5.706, avg: 1.09, latest lr: 8.422857142857143e-05\n",
      "epoch: 1, loss: 5.001, avg: 1.09, latest lr: 8.421428571428572e-05\n",
      "epoch: 1, loss: 5.546, avg: 1.09, latest lr: 8.42e-05\n",
      "epoch: 1, loss: 4.568, avg: 1.09, latest lr: 8.418571428571428e-05\n",
      "epoch: 1, loss: 6.597, avg: 1.09, latest lr: 8.417142857142858e-05\n",
      "epoch: 1, loss: 4.673, avg: 1.09, latest lr: 8.415714285714285e-05\n",
      "epoch: 1, loss: 5.161, avg: 1.09, latest lr: 8.414285714285715e-05\n",
      "epoch: 1, loss: 6.289, avg: 1.09, latest lr: 8.412857142857143e-05\n",
      "epoch: 1, loss: 5.521, avg: 1.09, latest lr: 8.411428571428573e-05\n",
      "epoch: 1, loss: 5.326, avg: 1.09, latest lr: 8.41e-05\n",
      "epoch: 1, loss: 6.821, avg: 1.09, latest lr: 8.40857142857143e-05\n",
      "epoch: 1, loss: 5.869, avg: 1.09, latest lr: 8.407142857142858e-05\n",
      "epoch: 1, loss: 6.528, avg: 1.10, latest lr: 8.405714285714286e-05\n",
      "epoch: 1, loss: 6.216, avg: 1.10, latest lr: 8.404285714285715e-05\n",
      "epoch: 1, loss: 6.132, avg: 1.10, latest lr: 8.402857142857143e-05\n",
      "epoch: 1, loss: 5.182, avg: 1.10, latest lr: 8.401428571428573e-05\n",
      "epoch: 1, loss: 8.216, avg: 1.10, latest lr: 8.4e-05\n",
      "epoch: 1, loss: 5.877, avg: 1.10, latest lr: 8.398571428571429e-05\n",
      "epoch: 1, loss: 6.175, avg: 1.10, latest lr: 8.397142857142858e-05\n",
      "epoch: 1, loss: 6.150, avg: 1.10, latest lr: 8.395714285714286e-05\n",
      "epoch: 1, loss: 6.592, avg: 1.10, latest lr: 8.394285714285714e-05\n",
      "epoch: 1, loss: 6.485, avg: 1.10, latest lr: 8.392857142857144e-05\n",
      "epoch: 1, loss: 5.514, avg: 1.10, latest lr: 8.391428571428572e-05\n",
      "epoch: 1, loss: 5.376, avg: 1.10, latest lr: 8.39e-05\n",
      "epoch: 1, loss: 5.411, avg: 1.11, latest lr: 8.388571428571429e-05\n",
      "epoch: 1, loss: 5.718, avg: 1.11, latest lr: 8.387142857142857e-05\n",
      "epoch: 1, loss: 4.324, avg: 1.11, latest lr: 8.385714285714286e-05\n",
      "epoch: 1, loss: 5.993, avg: 1.11, latest lr: 8.384285714285714e-05\n",
      "epoch: 1, loss: 6.384, avg: 1.11, latest lr: 8.382857142857144e-05\n",
      "epoch: 1, loss: 6.279, avg: 1.11, latest lr: 8.381428571428572e-05\n",
      "epoch: 1, loss: 5.556, avg: 1.11, latest lr: 8.38e-05\n",
      "epoch: 1, loss: 3.962, avg: 1.11, latest lr: 8.378571428571429e-05\n",
      "epoch: 1, loss: 4.697, avg: 1.11, latest lr: 8.377142857142858e-05\n",
      "epoch: 1, loss: 5.810, avg: 1.11, latest lr: 8.375714285714285e-05\n",
      "epoch: 1, loss: 5.810, avg: 1.11, latest lr: 8.374285714285715e-05\n",
      "epoch: 1, loss: 6.222, avg: 1.11, latest lr: 8.372857142857143e-05\n",
      "epoch: 1, loss: 6.590, avg: 1.12, latest lr: 8.371428571428572e-05\n",
      "epoch: 1, loss: 5.962, avg: 1.12, latest lr: 8.37e-05\n",
      "epoch: 1, loss: 5.314, avg: 1.12, latest lr: 8.368571428571429e-05\n",
      "epoch: 1, loss: 5.961, avg: 1.12, latest lr: 8.367142857142858e-05\n",
      "epoch: 1, loss: 6.263, avg: 1.12, latest lr: 8.365714285714285e-05\n",
      "epoch: 1, loss: 6.079, avg: 1.12, latest lr: 8.364285714285715e-05\n",
      "epoch: 1, loss: 5.368, avg: 1.12, latest lr: 8.362857142857143e-05\n",
      "epoch: 1, loss: 4.775, avg: 1.12, latest lr: 8.361428571428573e-05\n",
      "epoch: 1, loss: 5.570, avg: 1.12, latest lr: 8.36e-05\n",
      "epoch: 1, loss: 5.903, avg: 1.12, latest lr: 8.35857142857143e-05\n",
      "epoch: 1, loss: 5.700, avg: 1.12, latest lr: 8.357142857142858e-05\n",
      "epoch: 1, loss: 6.405, avg: 1.12, latest lr: 8.355714285714285e-05\n",
      "epoch: 1, loss: 5.557, avg: 1.12, latest lr: 8.354285714285715e-05\n",
      "epoch: 1, loss: 4.946, avg: 1.13, latest lr: 8.352857142857143e-05\n",
      "epoch: 1, loss: 6.996, avg: 1.13, latest lr: 8.351428571428573e-05\n",
      "epoch: 1, loss: 4.783, avg: 1.13, latest lr: 8.35e-05\n",
      "epoch: 1, loss: 6.595, avg: 1.13, latest lr: 8.34857142857143e-05\n",
      "epoch: 1, loss: 6.283, avg: 1.13, latest lr: 8.347142857142858e-05\n",
      "epoch: 1, loss: 4.687, avg: 1.13, latest lr: 8.345714285714286e-05\n",
      "epoch: 1, loss: 6.368, avg: 1.13, latest lr: 8.344285714285714e-05\n",
      "epoch: 1, loss: 5.392, avg: 1.13, latest lr: 8.342857142857143e-05\n",
      "epoch: 1, loss: 6.640, avg: 1.13, latest lr: 8.341428571428572e-05\n",
      "epoch: 1, loss: 4.370, avg: 1.13, latest lr: 8.34e-05\n",
      "epoch: 1, loss: 5.830, avg: 1.13, latest lr: 8.338571428571429e-05\n",
      "epoch: 1, loss: 5.380, avg: 1.13, latest lr: 8.337142857142857e-05\n",
      "epoch: 1, loss: 5.675, avg: 1.14, latest lr: 8.335714285714286e-05\n",
      "epoch: 1, loss: 4.828, avg: 1.14, latest lr: 8.334285714285714e-05\n",
      "epoch: 1, loss: 7.172, avg: 1.14, latest lr: 8.332857142857144e-05\n",
      "epoch: 1, loss: 4.435, avg: 1.14, latest lr: 8.331428571428572e-05\n",
      "epoch: 1, loss: 6.807, avg: 1.14, latest lr: 8.33e-05\n",
      "epoch: 1, loss: 5.090, avg: 1.14, latest lr: 8.328571428571429e-05\n",
      "epoch: 1, loss: 4.916, avg: 1.14, latest lr: 8.327142857142857e-05\n",
      "epoch: 1, loss: 5.504, avg: 1.14, latest lr: 8.325714285714286e-05\n",
      "epoch: 1, loss: 6.458, avg: 1.14, latest lr: 8.324285714285714e-05\n",
      "epoch: 1, loss: 6.653, avg: 1.14, latest lr: 8.322857142857144e-05\n",
      "epoch: 1, loss: 4.402, avg: 1.14, latest lr: 8.321428571428572e-05\n",
      "epoch: 1, loss: 5.867, avg: 1.14, latest lr: 8.32e-05\n",
      "epoch: 1, loss: 6.591, avg: 1.15, latest lr: 8.318571428571429e-05\n",
      "epoch: 1, loss: 6.093, avg: 1.15, latest lr: 8.317142857142858e-05\n",
      "epoch: 1, loss: 6.404, avg: 1.15, latest lr: 8.315714285714285e-05\n",
      "epoch: 1, loss: 4.892, avg: 1.15, latest lr: 8.314285714285715e-05\n",
      "epoch: 1, loss: 4.944, avg: 1.15, latest lr: 8.312857142857143e-05\n",
      "epoch: 1, loss: 4.294, avg: 1.15, latest lr: 8.311428571428572e-05\n",
      "epoch: 1, loss: 5.530, avg: 1.15, latest lr: 8.31e-05\n",
      "epoch: 1, loss: 5.959, avg: 1.15, latest lr: 8.308571428571428e-05\n",
      "epoch: 1, loss: 5.944, avg: 1.15, latest lr: 8.307142857142858e-05\n",
      "epoch: 1, loss: 5.573, avg: 1.15, latest lr: 8.305714285714285e-05\n",
      "epoch: 1, loss: 5.786, avg: 1.15, latest lr: 8.304285714285715e-05\n",
      "epoch: 1, loss: 6.117, avg: 1.15, latest lr: 8.302857142857143e-05\n",
      "epoch: 1, loss: 4.689, avg: 1.15, latest lr: 8.301428571428573e-05\n",
      "epoch: 1, loss: 5.499, avg: 1.16, latest lr: 8.3e-05\n",
      "epoch: 1, loss: 6.099, avg: 1.16, latest lr: 8.29857142857143e-05\n",
      "epoch: 1, loss: 5.014, avg: 1.16, latest lr: 8.297142857142858e-05\n",
      "epoch: 1, loss: 4.087, avg: 1.16, latest lr: 8.295714285714286e-05\n",
      "epoch: 1, loss: 4.858, avg: 1.16, latest lr: 8.294285714285715e-05\n",
      "epoch: 1, loss: 6.431, avg: 1.16, latest lr: 8.292857142857143e-05\n",
      "epoch: 1, loss: 4.593, avg: 1.16, latest lr: 8.291428571428573e-05\n",
      "epoch: 1, loss: 6.436, avg: 1.16, latest lr: 8.29e-05\n",
      "epoch: 1, loss: 6.107, avg: 1.16, latest lr: 8.288571428571429e-05\n",
      "epoch: 1, loss: 5.902, avg: 1.16, latest lr: 8.287142857142858e-05\n",
      "epoch: 1, loss: 6.073, avg: 1.16, latest lr: 8.285714285714287e-05\n",
      "epoch: 1, loss: 5.988, avg: 1.16, latest lr: 8.284285714285714e-05\n",
      "epoch: 1, loss: 6.017, avg: 1.17, latest lr: 8.282857142857143e-05\n",
      "epoch: 1, loss: 5.928, avg: 1.17, latest lr: 8.281428571428572e-05\n",
      "epoch: 1, loss: 5.491, avg: 1.17, latest lr: 8.28e-05\n",
      "epoch: 1, loss: 4.793, avg: 1.17, latest lr: 8.278571428571429e-05\n",
      "epoch: 1, loss: 5.605, avg: 1.17, latest lr: 8.277142857142857e-05\n",
      "epoch: 1, loss: 5.874, avg: 1.17, latest lr: 8.275714285714287e-05\n",
      "epoch: 1, loss: 6.198, avg: 1.17, latest lr: 8.274285714285714e-05\n",
      "epoch: 1, loss: 4.956, avg: 1.17, latest lr: 8.272857142857144e-05\n",
      "epoch: 1, loss: 5.847, avg: 1.17, latest lr: 8.271428571428572e-05\n",
      "epoch: 1, loss: 6.064, avg: 1.17, latest lr: 8.27e-05\n",
      "epoch: 1, loss: 6.108, avg: 1.17, latest lr: 8.268571428571429e-05\n",
      "epoch: 1, loss: 5.406, avg: 1.17, latest lr: 8.267142857142857e-05\n",
      "epoch: 1, loss: 5.062, avg: 1.17, latest lr: 8.265714285714287e-05\n",
      "epoch: 1, loss: 5.817, avg: 1.18, latest lr: 8.264285714285714e-05\n",
      "epoch: 1, loss: 5.146, avg: 1.18, latest lr: 8.262857142857144e-05\n",
      "epoch: 1, loss: 4.064, avg: 1.18, latest lr: 8.261428571428572e-05\n",
      "epoch: 1, loss: 6.051, avg: 1.18, latest lr: 8.26e-05\n",
      "epoch: 1, loss: 5.813, avg: 1.18, latest lr: 8.258571428571429e-05\n",
      "epoch: 1, loss: 4.727, avg: 1.18, latest lr: 8.257142857142858e-05\n",
      "epoch: 1, loss: 4.918, avg: 1.18, latest lr: 8.255714285714287e-05\n",
      "epoch: 1, loss: 4.431, avg: 1.18, latest lr: 8.254285714285715e-05\n",
      "epoch: 1, loss: 4.919, avg: 1.18, latest lr: 8.252857142857143e-05\n",
      "epoch: 1, loss: 6.639, avg: 1.18, latest lr: 8.251428571428572e-05\n",
      "epoch: 1, loss: 5.695, avg: 1.18, latest lr: 8.25e-05\n",
      "epoch: 1, loss: 4.713, avg: 1.18, latest lr: 8.248571428571428e-05\n",
      "epoch: 1, loss: 4.316, avg: 1.18, latest lr: 8.247142857142858e-05\n",
      "epoch: 1, loss: 5.844, avg: 1.19, latest lr: 8.245714285714286e-05\n",
      "epoch: 1, loss: 6.654, avg: 1.19, latest lr: 8.244285714285715e-05\n",
      "epoch: 1, loss: 5.728, avg: 1.19, latest lr: 8.242857142857143e-05\n",
      "epoch: 1, loss: 5.100, avg: 1.19, latest lr: 8.241428571428573e-05\n",
      "epoch: 1, loss: 5.203, avg: 1.19, latest lr: 8.24e-05\n",
      "epoch: 1, loss: 4.901, avg: 1.19, latest lr: 8.23857142857143e-05\n",
      "epoch: 1, loss: 4.635, avg: 1.19, latest lr: 8.237142857142858e-05\n",
      "epoch: 1, loss: 5.165, avg: 1.19, latest lr: 8.235714285714286e-05\n",
      "epoch: 1, loss: 6.654, avg: 1.19, latest lr: 8.234285714285714e-05\n",
      "epoch: 1, loss: 4.477, avg: 1.19, latest lr: 8.232857142857143e-05\n",
      "epoch: 1, loss: 6.027, avg: 1.19, latest lr: 8.231428571428572e-05\n",
      "epoch: 1, loss: 5.947, avg: 1.19, latest lr: 8.23e-05\n",
      "epoch: 1, loss: 3.753, avg: 1.19, latest lr: 8.228571428571429e-05\n",
      "epoch: 1, loss: 7.007, avg: 1.20, latest lr: 8.227142857142858e-05\n",
      "epoch: 1, loss: 5.139, avg: 1.20, latest lr: 8.225714285714287e-05\n",
      "epoch: 1, loss: 5.904, avg: 1.20, latest lr: 8.224285714285714e-05\n",
      "epoch: 1, loss: 5.299, avg: 1.20, latest lr: 8.222857142857144e-05\n",
      "epoch: 1, loss: 4.226, avg: 1.20, latest lr: 8.221428571428572e-05\n",
      "epoch: 1, loss: 5.439, avg: 1.20, latest lr: 8.22e-05\n",
      "epoch: 1, loss: 5.576, avg: 1.20, latest lr: 8.218571428571429e-05\n",
      "epoch: 1, loss: 4.643, avg: 1.20, latest lr: 8.217142857142857e-05\n",
      "epoch: 1, loss: 5.672, avg: 1.20, latest lr: 8.215714285714287e-05\n",
      "epoch: 1, loss: 5.314, avg: 1.20, latest lr: 8.214285714285714e-05\n",
      "epoch: 1, loss: 5.380, avg: 1.20, latest lr: 8.212857142857144e-05\n",
      "epoch: 1, loss: 6.073, avg: 1.20, latest lr: 8.211428571428572e-05\n",
      "epoch: 1, loss: 4.806, avg: 1.20, latest lr: 8.21e-05\n",
      "epoch: 1, loss: 6.656, avg: 1.21, latest lr: 8.208571428571429e-05\n",
      "epoch: 1, loss: 4.921, avg: 1.21, latest lr: 8.207142857142857e-05\n",
      "epoch: 1, loss: 5.112, avg: 1.21, latest lr: 8.205714285714287e-05\n",
      "epoch: 1, loss: 5.507, avg: 1.21, latest lr: 8.204285714285714e-05\n",
      "epoch: 1, loss: 5.756, avg: 1.21, latest lr: 8.202857142857143e-05\n",
      "epoch: 1, loss: 4.922, avg: 1.21, latest lr: 8.201428571428572e-05\n",
      "epoch: 1, loss: 5.589, avg: 1.21, latest lr: 8.2e-05\n",
      "epoch: 1, loss: 6.689, avg: 1.21, latest lr: 8.198571428571428e-05\n",
      "epoch: 1, loss: 6.211, avg: 1.21, latest lr: 8.197142857142858e-05\n",
      "epoch: 1, loss: 4.593, avg: 1.21, latest lr: 8.195714285714286e-05\n",
      "epoch: 1, loss: 5.931, avg: 1.21, latest lr: 8.194285714285715e-05\n",
      "epoch: 1, loss: 5.216, avg: 1.21, latest lr: 8.192857142857143e-05\n",
      "epoch: 1, loss: 5.167, avg: 1.21, latest lr: 8.191428571428572e-05\n",
      "epoch: 1, loss: 5.427, avg: 1.22, latest lr: 8.19e-05\n",
      "epoch: 1, loss: 5.127, avg: 1.22, latest lr: 8.188571428571428e-05\n",
      "epoch: 1, loss: 5.223, avg: 1.22, latest lr: 8.187142857142858e-05\n",
      "epoch: 1, loss: 5.720, avg: 1.22, latest lr: 8.185714285714286e-05\n",
      "epoch: 1, loss: 6.023, avg: 1.22, latest lr: 8.184285714285715e-05\n",
      "epoch: 1, loss: 6.659, avg: 1.22, latest lr: 8.182857142857143e-05\n",
      "epoch: 1, loss: 5.215, avg: 1.22, latest lr: 8.181428571428573e-05\n",
      "epoch: 1, loss: 6.088, avg: 1.22, latest lr: 8.18e-05\n",
      "epoch: 1, loss: 5.386, avg: 1.22, latest lr: 8.178571428571429e-05\n",
      "epoch: 1, loss: 6.078, avg: 1.22, latest lr: 8.177142857142858e-05\n",
      "epoch: 1, loss: 5.772, avg: 1.22, latest lr: 8.175714285714286e-05\n",
      "epoch: 1, loss: 6.097, avg: 1.22, latest lr: 8.174285714285714e-05\n",
      "epoch: 1, loss: 5.762, avg: 1.23, latest lr: 8.172857142857143e-05\n",
      "epoch: 1, loss: 5.310, avg: 1.23, latest lr: 8.171428571428572e-05\n",
      "epoch: 1, loss: 6.230, avg: 1.23, latest lr: 8.17e-05\n",
      "epoch: 1, loss: 5.790, avg: 1.23, latest lr: 8.168571428571429e-05\n",
      "epoch: 1, loss: 6.355, avg: 1.23, latest lr: 8.167142857142857e-05\n",
      "epoch: 1, loss: 5.277, avg: 1.23, latest lr: 8.165714285714287e-05\n",
      "epoch: 1, loss: 5.198, avg: 1.23, latest lr: 8.164285714285714e-05\n",
      "epoch: 1, loss: 6.298, avg: 1.23, latest lr: 8.162857142857144e-05\n",
      "epoch: 1, loss: 6.199, avg: 1.23, latest lr: 8.161428571428572e-05\n",
      "epoch: 1, loss: 5.997, avg: 1.23, latest lr: 8.16e-05\n",
      "epoch: 1, loss: 5.588, avg: 1.23, latest lr: 8.158571428571429e-05\n",
      "epoch: 1, loss: 5.471, avg: 1.23, latest lr: 8.157142857142857e-05\n",
      "epoch: 1, loss: 5.810, avg: 1.24, latest lr: 8.155714285714287e-05\n",
      "epoch: 1, loss: 3.858, avg: 1.24, latest lr: 8.154285714285714e-05\n",
      "epoch: 1, loss: 4.882, avg: 1.24, latest lr: 8.152857142857144e-05\n",
      "epoch: 1, loss: 4.757, avg: 1.24, latest lr: 8.151428571428572e-05\n",
      "epoch: 1, loss: 5.417, avg: 1.24, latest lr: 8.15e-05\n",
      "epoch: 1, loss: 5.460, avg: 1.24, latest lr: 8.148571428571429e-05\n",
      "epoch: 1, loss: 6.115, avg: 1.24, latest lr: 8.147142857142858e-05\n",
      "epoch: 1, loss: 4.451, avg: 1.24, latest lr: 8.145714285714287e-05\n",
      "epoch: 1, loss: 4.584, avg: 1.24, latest lr: 8.144285714285715e-05\n",
      "epoch: 1, loss: 5.825, avg: 1.24, latest lr: 8.142857142857143e-05\n",
      "epoch: 1, loss: 4.753, avg: 1.24, latest lr: 8.141428571428572e-05\n",
      "epoch: 1, loss: 6.148, avg: 1.24, latest lr: 8.14e-05\n",
      "epoch: 1, loss: 6.190, avg: 1.24, latest lr: 8.138571428571428e-05\n",
      "epoch: 1, loss: 5.603, avg: 1.25, latest lr: 8.137142857142858e-05\n",
      "epoch: 1, loss: 7.333, avg: 1.25, latest lr: 8.135714285714286e-05\n",
      "epoch: 1, loss: 6.265, avg: 1.25, latest lr: 8.134285714285715e-05\n",
      "epoch: 1, loss: 4.883, avg: 1.25, latest lr: 8.132857142857143e-05\n",
      "epoch: 1, loss: 5.085, avg: 1.25, latest lr: 8.131428571428571e-05\n",
      "epoch: 1, loss: 5.837, avg: 1.25, latest lr: 8.13e-05\n",
      "epoch: 1, loss: 6.054, avg: 1.25, latest lr: 8.128571428571428e-05\n",
      "epoch: 1, loss: 5.814, avg: 1.25, latest lr: 8.127142857142858e-05\n",
      "epoch: 1, loss: 4.735, avg: 1.25, latest lr: 8.125714285714286e-05\n",
      "epoch: 1, loss: 4.821, avg: 1.25, latest lr: 8.124285714285714e-05\n",
      "epoch: 1, loss: 4.448, avg: 1.25, latest lr: 8.122857142857143e-05\n",
      "epoch: 1, loss: 5.617, avg: 1.25, latest lr: 8.121428571428573e-05\n",
      "epoch: 1, loss: 6.263, avg: 1.25, latest lr: 8.120000000000001e-05\n",
      "epoch: 1, loss: 5.701, avg: 1.26, latest lr: 8.118571428571429e-05\n",
      "epoch: 1, loss: 5.145, avg: 1.26, latest lr: 8.117142857142858e-05\n",
      "epoch: 1, loss: 6.919, avg: 1.26, latest lr: 8.115714285714286e-05\n",
      "epoch: 1, loss: 6.003, avg: 1.26, latest lr: 8.114285714285714e-05\n",
      "epoch: 1, loss: 4.616, avg: 1.26, latest lr: 8.112857142857143e-05\n",
      "epoch: 1, loss: 4.617, avg: 1.26, latest lr: 8.111428571428572e-05\n",
      "epoch: 1, loss: 5.843, avg: 1.26, latest lr: 8.11e-05\n",
      "epoch: 1, loss: 5.488, avg: 1.26, latest lr: 8.108571428571429e-05\n",
      "epoch: 1, loss: 5.270, avg: 1.26, latest lr: 8.107142857142857e-05\n",
      "epoch: 1, loss: 7.090, avg: 1.26, latest lr: 8.105714285714287e-05\n",
      "epoch: 1, loss: 4.838, avg: 1.26, latest lr: 8.104285714285714e-05\n",
      "epoch: 1, loss: 5.188, avg: 1.26, latest lr: 8.102857142857144e-05\n",
      "epoch: 1, loss: 5.159, avg: 1.27, latest lr: 8.101428571428572e-05\n",
      "epoch: 1, loss: 5.775, avg: 1.27, latest lr: 8.1e-05\n",
      "epoch: 1, loss: 4.980, avg: 1.27, latest lr: 8.098571428571429e-05\n",
      "epoch: 1, loss: 6.334, avg: 1.27, latest lr: 8.097142857142857e-05\n",
      "epoch: 1, loss: 6.316, avg: 1.27, latest lr: 8.095714285714287e-05\n",
      "epoch: 1, loss: 4.785, avg: 1.27, latest lr: 8.094285714285714e-05\n",
      "epoch: 1, loss: 6.600, avg: 1.27, latest lr: 8.092857142857143e-05\n",
      "epoch: 1, loss: 7.395, avg: 1.27, latest lr: 8.091428571428572e-05\n",
      "epoch: 1, loss: 3.960, avg: 1.27, latest lr: 8.090000000000001e-05\n",
      "epoch: 1, loss: 5.509, avg: 1.27, latest lr: 8.088571428571428e-05\n",
      "epoch: 1, loss: 6.063, avg: 1.27, latest lr: 8.087142857142858e-05\n",
      "epoch: 1, loss: 4.831, avg: 1.27, latest lr: 8.085714285714287e-05\n",
      "epoch: 1, loss: 4.217, avg: 1.27, latest lr: 8.084285714285715e-05\n",
      "epoch: 1, loss: 5.212, avg: 1.28, latest lr: 8.082857142857143e-05\n",
      "epoch: 1, loss: 5.462, avg: 1.28, latest lr: 8.081428571428572e-05\n",
      "epoch: 1, loss: 6.343, avg: 1.28, latest lr: 8.080000000000001e-05\n",
      "epoch: 1, loss: 5.902, avg: 1.28, latest lr: 8.078571428571428e-05\n",
      "epoch: 1, loss: 5.576, avg: 1.28, latest lr: 8.077142857142858e-05\n",
      "epoch: 1, loss: 5.680, avg: 1.28, latest lr: 8.075714285714286e-05\n",
      "epoch: 1, loss: 5.290, avg: 1.28, latest lr: 8.074285714285715e-05\n",
      "epoch: 1, loss: 5.782, avg: 1.28, latest lr: 8.072857142857143e-05\n",
      "epoch: 1, loss: 5.568, avg: 1.28, latest lr: 8.071428571428573e-05\n",
      "epoch: 1, loss: 4.864, avg: 1.28, latest lr: 8.070000000000001e-05\n",
      "epoch: 1, loss: 5.283, avg: 1.28, latest lr: 8.06857142857143e-05\n",
      "epoch: 1, loss: 6.783, avg: 1.28, latest lr: 8.067142857142858e-05\n",
      "epoch: 1, loss: 5.620, avg: 1.29, latest lr: 8.065714285714286e-05\n",
      "epoch: 1, loss: 5.776, avg: 1.29, latest lr: 8.064285714285714e-05\n",
      "epoch: 1, loss: 5.757, avg: 1.29, latest lr: 8.062857142857143e-05\n",
      "epoch: 1, loss: 5.858, avg: 1.29, latest lr: 8.061428571428572e-05\n",
      "epoch: 1, loss: 4.658, avg: 1.29, latest lr: 8.060000000000001e-05\n",
      "epoch: 1, loss: 5.811, avg: 1.29, latest lr: 8.058571428571429e-05\n",
      "epoch: 1, loss: 3.936, avg: 1.29, latest lr: 8.057142857142857e-05\n",
      "epoch: 1, loss: 6.202, avg: 1.29, latest lr: 8.055714285714286e-05\n",
      "epoch: 1, loss: 6.496, avg: 1.29, latest lr: 8.054285714285714e-05\n",
      "epoch: 1, loss: 6.625, avg: 1.29, latest lr: 8.052857142857142e-05\n",
      "epoch: 1, loss: 4.417, avg: 1.29, latest lr: 8.051428571428572e-05\n",
      "epoch: 1, loss: 5.208, avg: 1.29, latest lr: 8.05e-05\n",
      "epoch: 1, loss: 4.084, avg: 1.29, latest lr: 8.048571428571429e-05\n",
      "epoch: 1, loss: 4.997, avg: 1.30, latest lr: 8.047142857142857e-05\n",
      "epoch: 1, loss: 6.261, avg: 1.30, latest lr: 8.045714285714287e-05\n",
      "epoch: 1, loss: 5.366, avg: 1.30, latest lr: 8.044285714285714e-05\n",
      "epoch: 1, loss: 4.548, avg: 1.30, latest lr: 8.042857142857144e-05\n",
      "epoch: 1, loss: 4.341, avg: 1.30, latest lr: 8.041428571428572e-05\n",
      "epoch: 1, loss: 4.847, avg: 1.30, latest lr: 8.04e-05\n",
      "epoch: 1, loss: 5.188, avg: 1.30, latest lr: 8.038571428571429e-05\n",
      "epoch: 1, loss: 5.000, avg: 1.30, latest lr: 8.037142857142857e-05\n",
      "epoch: 1, loss: 5.726, avg: 1.30, latest lr: 8.035714285714287e-05\n",
      "epoch: 1, loss: 3.744, avg: 1.30, latest lr: 8.034285714285714e-05\n",
      "epoch: 1, loss: 7.091, avg: 1.30, latest lr: 8.032857142857143e-05\n",
      "epoch: 1, loss: 6.231, avg: 1.30, latest lr: 8.031428571428572e-05\n",
      "epoch: 1, loss: 5.896, avg: 1.30, latest lr: 8.030000000000001e-05\n",
      "epoch: 1, loss: 6.054, avg: 1.31, latest lr: 8.028571428571428e-05\n",
      "epoch: 1, loss: 4.902, avg: 1.31, latest lr: 8.027142857142858e-05\n",
      "epoch: 1, loss: 5.587, avg: 1.31, latest lr: 8.025714285714286e-05\n",
      "epoch: 1, loss: 5.059, avg: 1.31, latest lr: 8.024285714285715e-05\n",
      "epoch: 1, loss: 4.863, avg: 1.31, latest lr: 8.022857142857143e-05\n",
      "epoch: 1, loss: 5.114, avg: 1.31, latest lr: 8.021428571428571e-05\n",
      "epoch: 1, loss: 5.523, avg: 1.31, latest lr: 8.020000000000001e-05\n",
      "epoch: 1, loss: 5.431, avg: 1.31, latest lr: 8.018571428571428e-05\n",
      "epoch: 1, loss: 5.939, avg: 1.31, latest lr: 8.017142857142858e-05\n",
      "epoch: 1, loss: 5.748, avg: 1.31, latest lr: 8.015714285714286e-05\n",
      "epoch: 1, loss: 5.109, avg: 1.31, latest lr: 8.014285714285715e-05\n",
      "epoch: 1, loss: 6.424, avg: 1.31, latest lr: 8.012857142857143e-05\n",
      "epoch: 1, loss: 5.096, avg: 1.31, latest lr: 8.011428571428573e-05\n",
      "epoch: 1, loss: 6.099, avg: 1.32, latest lr: 8.010000000000001e-05\n",
      "epoch: 1, loss: 5.826, avg: 1.32, latest lr: 8.008571428571429e-05\n",
      "epoch: 1, loss: 5.901, avg: 1.32, latest lr: 8.007142857142858e-05\n",
      "epoch: 1, loss: 4.402, avg: 1.32, latest lr: 8.005714285714286e-05\n",
      "epoch: 1, loss: 5.129, avg: 1.32, latest lr: 8.004285714285714e-05\n",
      "epoch: 1, loss: 5.616, avg: 1.32, latest lr: 8.002857142857143e-05\n",
      "epoch: 1, loss: 6.623, avg: 1.32, latest lr: 8.001428571428572e-05\n",
      "epoch: 1, loss: 5.697, avg: 1.32, latest lr: 8e-05\n",
      "epoch: 1, loss: 5.326, avg: 1.32, latest lr: 7.998571428571429e-05\n",
      "epoch: 1, loss: 5.637, avg: 1.32, latest lr: 7.997142857142857e-05\n",
      "epoch: 1, loss: 4.883, avg: 1.32, latest lr: 7.995714285714287e-05\n",
      "epoch: 1, loss: 4.577, avg: 1.32, latest lr: 7.994285714285714e-05\n",
      "epoch: 1, loss: 5.304, avg: 1.32, latest lr: 7.992857142857142e-05\n",
      "epoch: 1, loss: 5.633, avg: 1.33, latest lr: 7.991428571428572e-05\n",
      "epoch: 1, loss: 5.429, avg: 1.33, latest lr: 7.99e-05\n",
      "epoch: 1, loss: 5.504, avg: 1.33, latest lr: 7.988571428571429e-05\n",
      "epoch: 1, loss: 5.801, avg: 1.33, latest lr: 7.987142857142857e-05\n",
      "epoch: 1, loss: 5.954, avg: 1.33, latest lr: 7.985714285714287e-05\n",
      "epoch: 1, loss: 5.574, avg: 1.33, latest lr: 7.984285714285714e-05\n",
      "epoch: 1, loss: 5.663, avg: 1.33, latest lr: 7.982857142857143e-05\n",
      "epoch: 1, loss: 5.823, avg: 1.33, latest lr: 7.981428571428572e-05\n",
      "epoch: 1, loss: 5.222, avg: 1.33, latest lr: 7.98e-05\n",
      "epoch: 1, loss: 5.358, avg: 1.33, latest lr: 7.978571428571429e-05\n",
      "epoch: 1, loss: 5.022, avg: 1.33, latest lr: 7.977142857142857e-05\n",
      "epoch: 1, loss: 4.438, avg: 1.33, latest lr: 7.975714285714287e-05\n",
      "epoch: 1, loss: 4.865, avg: 1.33, latest lr: 7.974285714285714e-05\n",
      "epoch: 1, loss: 4.951, avg: 1.34, latest lr: 7.972857142857143e-05\n",
      "epoch: 1, loss: 5.541, avg: 1.34, latest lr: 7.971428571428572e-05\n",
      "epoch: 1, loss: 6.006, avg: 1.34, latest lr: 7.970000000000001e-05\n",
      "epoch: 1, loss: 5.590, avg: 1.34, latest lr: 7.968571428571428e-05\n",
      "epoch: 1, loss: 6.283, avg: 1.34, latest lr: 7.967142857142858e-05\n",
      "epoch: 1, loss: 6.355, avg: 1.34, latest lr: 7.965714285714286e-05\n",
      "epoch: 1, loss: 5.426, avg: 1.34, latest lr: 7.964285714285715e-05\n",
      "epoch: 1, loss: 5.120, avg: 1.34, latest lr: 7.962857142857143e-05\n",
      "epoch: 1, loss: 4.355, avg: 1.34, latest lr: 7.961428571428571e-05\n",
      "epoch: 1, loss: 5.179, avg: 1.34, latest lr: 7.960000000000001e-05\n",
      "epoch: 1, loss: 5.192, avg: 1.34, latest lr: 7.958571428571428e-05\n",
      "epoch: 1, loss: 6.520, avg: 1.34, latest lr: 7.957142857142858e-05\n",
      "epoch: 1, loss: 4.107, avg: 1.34, latest lr: 7.955714285714286e-05\n",
      "epoch: 1, loss: 6.834, avg: 1.35, latest lr: 7.954285714285714e-05\n",
      "epoch: 1, loss: 4.669, avg: 1.35, latest lr: 7.952857142857143e-05\n",
      "epoch: 1, loss: 4.424, avg: 1.35, latest lr: 7.951428571428572e-05\n",
      "epoch: 1, loss: 6.261, avg: 1.35, latest lr: 7.950000000000001e-05\n",
      "epoch: 1, loss: 6.025, avg: 1.35, latest lr: 7.948571428571429e-05\n",
      "epoch: 1, loss: 5.809, avg: 1.35, latest lr: 7.947142857142857e-05\n",
      "epoch: 1, loss: 5.813, avg: 1.35, latest lr: 7.945714285714286e-05\n",
      "epoch: 1, loss: 5.018, avg: 1.35, latest lr: 7.944285714285716e-05\n",
      "epoch: 1, loss: 6.805, avg: 1.35, latest lr: 7.942857142857143e-05\n",
      "epoch: 1, loss: 6.134, avg: 1.35, latest lr: 7.941428571428572e-05\n",
      "epoch: 1, loss: 5.831, avg: 1.35, latest lr: 7.94e-05\n",
      "epoch: 1, loss: 5.474, avg: 1.35, latest lr: 7.938571428571429e-05\n",
      "epoch: 1, loss: 4.902, avg: 1.36, latest lr: 7.937142857142857e-05\n",
      "epoch: 1, loss: 5.608, avg: 1.36, latest lr: 7.935714285714287e-05\n",
      "epoch: 1, loss: 6.143, avg: 1.36, latest lr: 7.934285714285715e-05\n",
      "epoch: 1, loss: 4.451, avg: 1.36, latest lr: 7.932857142857144e-05\n",
      "epoch: 1, loss: 5.083, avg: 1.36, latest lr: 7.931428571428572e-05\n",
      "epoch: 1, loss: 5.927, avg: 1.36, latest lr: 7.93e-05\n",
      "epoch: 1, loss: 5.202, avg: 1.36, latest lr: 7.928571428571429e-05\n",
      "epoch: 1, loss: 6.297, avg: 1.36, latest lr: 7.927142857142857e-05\n",
      "epoch: 1, loss: 5.520, avg: 1.36, latest lr: 7.925714285714287e-05\n",
      "epoch: 1, loss: 4.885, avg: 1.36, latest lr: 7.924285714285715e-05\n",
      "epoch: 1, loss: 5.100, avg: 1.36, latest lr: 7.922857142857143e-05\n",
      "epoch: 1, loss: 5.159, avg: 1.36, latest lr: 7.921428571428572e-05\n",
      "epoch: 1, loss: 5.196, avg: 1.36, latest lr: 7.920000000000001e-05\n",
      "epoch: 1, loss: 5.380, avg: 1.37, latest lr: 7.918571428571428e-05\n",
      "epoch: 1, loss: 4.215, avg: 1.37, latest lr: 7.917142857142857e-05\n",
      "epoch: 1, loss: 4.573, avg: 1.37, latest lr: 7.915714285714286e-05\n",
      "epoch: 1, loss: 5.209, avg: 1.37, latest lr: 7.914285714285715e-05\n",
      "epoch: 1, loss: 5.487, avg: 1.37, latest lr: 7.912857142857143e-05\n",
      "epoch: 1, loss: 6.197, avg: 1.37, latest lr: 7.911428571428571e-05\n",
      "epoch: 1, loss: 4.105, avg: 1.37, latest lr: 7.910000000000001e-05\n",
      "epoch: 1, loss: 7.114, avg: 1.37, latest lr: 7.908571428571428e-05\n",
      "epoch: 1, loss: 5.299, avg: 1.37, latest lr: 7.907142857142858e-05\n",
      "epoch: 1, loss: 5.468, avg: 1.37, latest lr: 7.905714285714286e-05\n",
      "epoch: 1, loss: 5.884, avg: 1.37, latest lr: 7.904285714285715e-05\n",
      "epoch: 1, loss: 5.085, avg: 1.37, latest lr: 7.902857142857143e-05\n",
      "epoch: 1, loss: 6.063, avg: 1.37, latest lr: 7.901428571428571e-05\n",
      "epoch: 1, loss: 5.727, avg: 1.38, latest lr: 7.900000000000001e-05\n",
      "epoch: 1, loss: 6.592, avg: 1.38, latest lr: 7.898571428571428e-05\n",
      "epoch: 1, loss: 5.553, avg: 1.38, latest lr: 7.897142857142858e-05\n",
      "epoch: 1, loss: 4.901, avg: 1.38, latest lr: 7.895714285714286e-05\n",
      "epoch: 1, loss: 5.785, avg: 1.38, latest lr: 7.894285714285716e-05\n",
      "epoch: 1, loss: 4.479, avg: 1.38, latest lr: 7.892857142857143e-05\n",
      "epoch: 1, loss: 5.757, avg: 1.38, latest lr: 7.891428571428572e-05\n",
      "epoch: 1, loss: 5.541, avg: 1.38, latest lr: 7.890000000000001e-05\n",
      "epoch: 1, loss: 4.697, avg: 1.38, latest lr: 7.888571428571429e-05\n",
      "epoch: 1, loss: 5.792, avg: 1.38, latest lr: 7.887142857142857e-05\n",
      "epoch: 1, loss: 5.691, avg: 1.38, latest lr: 7.885714285714286e-05\n",
      "epoch: 1, loss: 4.011, avg: 1.38, latest lr: 7.884285714285715e-05\n",
      "epoch: 1, loss: 5.340, avg: 1.38, latest lr: 7.882857142857142e-05\n",
      "epoch: 1, loss: 6.420, avg: 1.39, latest lr: 7.881428571428572e-05\n",
      "epoch: 1, loss: 5.512, avg: 1.39, latest lr: 7.88e-05\n",
      "epoch: 1, loss: 6.048, avg: 1.39, latest lr: 7.878571428571429e-05\n",
      "epoch: 1, loss: 6.084, avg: 1.39, latest lr: 7.877142857142857e-05\n",
      "epoch: 1, loss: 6.055, avg: 1.39, latest lr: 7.875714285714287e-05\n",
      "epoch: 1, loss: 5.122, avg: 1.39, latest lr: 7.874285714285715e-05\n",
      "epoch: 1, loss: 3.951, avg: 1.39, latest lr: 7.872857142857144e-05\n",
      "epoch: 1, loss: 5.465, avg: 1.39, latest lr: 7.871428571428572e-05\n",
      "epoch: 1, loss: 5.358, avg: 1.39, latest lr: 7.87e-05\n",
      "epoch: 1, loss: 5.452, avg: 1.39, latest lr: 7.868571428571429e-05\n",
      "epoch: 1, loss: 5.073, avg: 1.39, latest lr: 7.867142857142857e-05\n",
      "epoch: 1, loss: 5.102, avg: 1.39, latest lr: 7.865714285714287e-05\n",
      "epoch: 1, loss: 6.091, avg: 1.39, latest lr: 7.864285714285715e-05\n",
      "epoch: 1, loss: 6.255, avg: 1.40, latest lr: 7.862857142857143e-05\n",
      "epoch: 1, loss: 5.868, avg: 1.40, latest lr: 7.861428571428572e-05\n",
      "epoch: 1, loss: 5.223, avg: 1.40, latest lr: 7.860000000000001e-05\n",
      "epoch: 1, loss: 4.244, avg: 1.40, latest lr: 7.858571428571428e-05\n",
      "epoch: 1, loss: 5.436, avg: 1.40, latest lr: 7.857142857142858e-05\n",
      "epoch: 1, loss: 4.479, avg: 1.40, latest lr: 7.855714285714286e-05\n",
      "epoch: 1, loss: 4.469, avg: 1.40, latest lr: 7.854285714285715e-05\n",
      "epoch: 1, loss: 7.831, avg: 1.40, latest lr: 7.852857142857143e-05\n",
      "epoch: 1, loss: 4.865, avg: 1.40, latest lr: 7.851428571428571e-05\n",
      "epoch: 1, loss: 4.225, avg: 1.40, latest lr: 7.850000000000001e-05\n",
      "epoch: 1, loss: 6.503, avg: 1.40, latest lr: 7.848571428571428e-05\n",
      "epoch: 1, loss: 6.105, avg: 1.40, latest lr: 7.847142857142858e-05\n",
      "epoch: 1, loss: 5.686, avg: 1.40, latest lr: 7.845714285714286e-05\n",
      "epoch: 1, loss: 4.732, avg: 1.41, latest lr: 7.844285714285716e-05\n",
      "epoch: 1, loss: 4.597, avg: 1.41, latest lr: 7.842857142857143e-05\n",
      "epoch: 1, loss: 5.062, avg: 1.41, latest lr: 7.841428571428571e-05\n",
      "epoch: 1, loss: 6.109, avg: 1.41, latest lr: 7.840000000000001e-05\n",
      "epoch: 1, loss: 5.778, avg: 1.41, latest lr: 7.838571428571428e-05\n",
      "epoch: 1, loss: 4.627, avg: 1.41, latest lr: 7.837142857142858e-05\n",
      "epoch: 1, loss: 5.233, avg: 1.41, latest lr: 7.835714285714286e-05\n",
      "epoch: 1, loss: 4.884, avg: 1.41, latest lr: 7.834285714285716e-05\n",
      "epoch: 1, loss: 5.852, avg: 1.41, latest lr: 7.832857142857143e-05\n",
      "epoch: 1, loss: 5.354, avg: 1.41, latest lr: 7.831428571428572e-05\n",
      "epoch: 1, loss: 6.068, avg: 1.41, latest lr: 7.83e-05\n",
      "epoch: 1, loss: 6.332, avg: 1.41, latest lr: 7.828571428571429e-05\n",
      "epoch: 1, loss: 4.477, avg: 1.41, latest lr: 7.827142857142857e-05\n",
      "epoch: 1, loss: 5.977, avg: 1.42, latest lr: 7.825714285714286e-05\n",
      "epoch: 1, loss: 6.794, avg: 1.42, latest lr: 7.824285714285715e-05\n",
      "epoch: 1, loss: 4.849, avg: 1.42, latest lr: 7.822857142857142e-05\n",
      "epoch: 1, loss: 6.177, avg: 1.42, latest lr: 7.821428571428572e-05\n",
      "epoch: 1, loss: 5.056, avg: 1.42, latest lr: 7.82e-05\n",
      "epoch: 1, loss: 5.203, avg: 1.42, latest lr: 7.818571428571429e-05\n",
      "epoch: 1, loss: 4.939, avg: 1.42, latest lr: 7.817142857142857e-05\n",
      "epoch: 1, loss: 5.477, avg: 1.42, latest lr: 7.815714285714287e-05\n",
      "epoch: 1, loss: 6.502, avg: 1.42, latest lr: 7.814285714285715e-05\n",
      "epoch: 1, loss: 6.301, avg: 1.42, latest lr: 7.812857142857143e-05\n",
      "epoch: 1, loss: 5.474, avg: 1.42, latest lr: 7.811428571428572e-05\n",
      "epoch: 1, loss: 6.525, avg: 1.42, latest lr: 7.81e-05\n",
      "epoch: 1, loss: 5.884, avg: 1.43, latest lr: 7.808571428571428e-05\n",
      "epoch: 1, loss: 4.914, avg: 1.43, latest lr: 7.807142857142857e-05\n",
      "epoch: 1, loss: 6.961, avg: 1.43, latest lr: 7.805714285714286e-05\n",
      "epoch: 1, loss: 5.509, avg: 1.43, latest lr: 7.804285714285715e-05\n",
      "epoch: 1, loss: 6.147, avg: 1.43, latest lr: 7.802857142857143e-05\n",
      "epoch: 1, loss: 4.422, avg: 1.43, latest lr: 7.801428571428572e-05\n",
      "epoch: 1, loss: 4.092, avg: 1.43, latest lr: 7.800000000000001e-05\n",
      "epoch: 1, loss: 5.519, avg: 1.43, latest lr: 7.798571428571428e-05\n",
      "epoch: 1, loss: 5.797, avg: 1.43, latest lr: 7.797142857142858e-05\n",
      "epoch: 1, loss: 3.707, avg: 1.43, latest lr: 7.795714285714286e-05\n",
      "epoch: 1, loss: 4.139, avg: 1.43, latest lr: 7.794285714285715e-05\n",
      "epoch: 1, loss: 5.835, avg: 1.43, latest lr: 7.792857142857143e-05\n",
      "epoch: 1, loss: 6.424, avg: 1.43, latest lr: 7.791428571428571e-05\n",
      "epoch: 1, loss: 5.666, avg: 1.44, latest lr: 7.790000000000001e-05\n",
      "epoch: 1, loss: 4.696, avg: 1.44, latest lr: 7.788571428571428e-05\n",
      "epoch: 1, loss: 5.915, avg: 1.44, latest lr: 7.787142857142858e-05\n",
      "epoch: 1, loss: 5.332, avg: 1.44, latest lr: 7.785714285714286e-05\n",
      "epoch: 1, loss: 5.608, avg: 1.44, latest lr: 7.784285714285716e-05\n",
      "epoch: 1, loss: 5.819, avg: 1.44, latest lr: 7.782857142857143e-05\n",
      "epoch: 1, loss: 4.536, avg: 1.44, latest lr: 7.781428571428572e-05\n",
      "epoch: 1, loss: 5.129, avg: 1.44, latest lr: 7.780000000000001e-05\n",
      "epoch: 1, loss: 4.198, avg: 1.44, latest lr: 7.778571428571429e-05\n",
      "epoch: 1, loss: 6.580, avg: 1.44, latest lr: 7.777142857142857e-05\n",
      "epoch: 1, loss: 5.697, avg: 1.44, latest lr: 7.775714285714286e-05\n",
      "epoch: 1, loss: 4.313, avg: 1.44, latest lr: 7.774285714285715e-05\n",
      "epoch: 1, loss: 4.683, avg: 1.44, latest lr: 7.772857142857142e-05\n",
      "epoch: 1, loss: 6.829, avg: 1.45, latest lr: 7.771428571428572e-05\n",
      "epoch: 1, loss: 5.752, avg: 1.45, latest lr: 7.77e-05\n",
      "epoch: 1, loss: 6.114, avg: 1.45, latest lr: 7.768571428571429e-05\n",
      "epoch: 1, loss: 5.755, avg: 1.45, latest lr: 7.767142857142857e-05\n",
      "epoch: 1, loss: 6.158, avg: 1.45, latest lr: 7.765714285714286e-05\n",
      "epoch: 1, loss: 5.531, avg: 1.45, latest lr: 7.764285714285715e-05\n",
      "epoch: 1, loss: 5.873, avg: 1.45, latest lr: 7.762857142857142e-05\n",
      "epoch: 1, loss: 4.977, avg: 1.45, latest lr: 7.761428571428572e-05\n",
      "epoch: 1, loss: 5.571, avg: 1.45, latest lr: 7.76e-05\n",
      "epoch: 1, loss: 5.865, avg: 1.45, latest lr: 7.75857142857143e-05\n",
      "epoch: 1, loss: 4.331, avg: 1.45, latest lr: 7.757142857142857e-05\n",
      "epoch: 1, loss: 5.421, avg: 1.45, latest lr: 7.755714285714287e-05\n",
      "epoch: 1, loss: 4.523, avg: 1.45, latest lr: 7.754285714285715e-05\n",
      "epoch: 1, loss: 5.114, avg: 1.46, latest lr: 7.752857142857143e-05\n",
      "epoch: 1, loss: 5.594, avg: 1.46, latest lr: 7.751428571428572e-05\n",
      "epoch: 1, loss: 4.464, avg: 1.46, latest lr: 7.75e-05\n",
      "epoch: 1, loss: 4.414, avg: 1.46, latest lr: 7.74857142857143e-05\n",
      "epoch: 1, loss: 5.314, avg: 1.46, latest lr: 7.747142857142857e-05\n",
      "epoch: 1, loss: 5.262, avg: 1.46, latest lr: 7.745714285714286e-05\n",
      "epoch: 1, loss: 4.988, avg: 1.46, latest lr: 7.744285714285715e-05\n",
      "epoch: 1, loss: 5.106, avg: 1.46, latest lr: 7.742857142857143e-05\n",
      "epoch: 1, loss: 3.491, avg: 1.46, latest lr: 7.741428571428571e-05\n",
      "epoch: 1, loss: 4.348, avg: 1.46, latest lr: 7.740000000000001e-05\n",
      "epoch: 1, loss: 6.081, avg: 1.46, latest lr: 7.73857142857143e-05\n",
      "epoch: 1, loss: 4.862, avg: 1.46, latest lr: 7.737142857142858e-05\n",
      "epoch: 1, loss: 6.315, avg: 1.46, latest lr: 7.735714285714286e-05\n",
      "epoch: 1, loss: 4.920, avg: 1.46, latest lr: 7.734285714285714e-05\n",
      "epoch: 1, loss: 6.377, avg: 1.47, latest lr: 7.732857142857143e-05\n",
      "epoch: 1, loss: 5.330, avg: 1.47, latest lr: 7.731428571428571e-05\n",
      "epoch: 1, loss: 4.940, avg: 1.47, latest lr: 7.730000000000001e-05\n",
      "epoch: 1, loss: 5.652, avg: 1.47, latest lr: 7.728571428571429e-05\n",
      "epoch: 1, loss: 4.608, avg: 1.47, latest lr: 7.727142857142858e-05\n",
      "epoch: 1, loss: 4.665, avg: 1.47, latest lr: 7.725714285714286e-05\n",
      "epoch: 1, loss: 4.068, avg: 1.47, latest lr: 7.724285714285716e-05\n",
      "epoch: 1, loss: 5.081, avg: 1.47, latest lr: 7.722857142857143e-05\n",
      "epoch: 1, loss: 5.298, avg: 1.47, latest lr: 7.721428571428572e-05\n",
      "epoch: 1, loss: 5.419, avg: 1.47, latest lr: 7.72e-05\n",
      "epoch: 1, loss: 6.012, avg: 1.47, latest lr: 7.718571428571429e-05\n",
      "epoch: 1, loss: 6.594, avg: 1.47, latest lr: 7.717142857142857e-05\n",
      "epoch: 1, loss: 6.337, avg: 1.47, latest lr: 7.715714285714286e-05\n",
      "epoch: 1, loss: 5.690, avg: 1.48, latest lr: 7.714285714285715e-05\n",
      "epoch: 1, loss: 4.304, avg: 1.48, latest lr: 7.712857142857142e-05\n",
      "epoch: 1, loss: 5.478, avg: 1.48, latest lr: 7.711428571428572e-05\n",
      "epoch: 1, loss: 4.130, avg: 1.48, latest lr: 7.71e-05\n",
      "epoch: 1, loss: 5.304, avg: 1.48, latest lr: 7.70857142857143e-05\n",
      "epoch: 1, loss: 4.111, avg: 1.48, latest lr: 7.707142857142857e-05\n",
      "epoch: 1, loss: 6.283, avg: 1.48, latest lr: 7.705714285714287e-05\n",
      "epoch: 1, loss: 4.158, avg: 1.48, latest lr: 7.704285714285715e-05\n",
      "epoch: 1, loss: 4.248, avg: 1.48, latest lr: 7.702857142857142e-05\n",
      "epoch: 1, loss: 4.494, avg: 1.48, latest lr: 7.701428571428572e-05\n",
      "epoch: 1, loss: 5.840, avg: 1.48, latest lr: 7.7e-05\n",
      "epoch: 1, loss: 4.272, avg: 1.48, latest lr: 7.69857142857143e-05\n",
      "epoch: 1, loss: 6.560, avg: 1.48, latest lr: 7.697142857142857e-05\n",
      "epoch: 1, loss: 6.318, avg: 1.48, latest lr: 7.695714285714287e-05\n",
      "epoch: 1, loss: 6.844, avg: 1.49, latest lr: 7.694285714285715e-05\n",
      "epoch: 1, loss: 5.793, avg: 1.49, latest lr: 7.692857142857143e-05\n",
      "epoch: 1, loss: 4.117, avg: 1.49, latest lr: 7.691428571428572e-05\n",
      "epoch: 1, loss: 5.918, avg: 1.49, latest lr: 7.69e-05\n",
      "epoch: 1, loss: 5.508, avg: 1.49, latest lr: 7.68857142857143e-05\n",
      "epoch: 1, loss: 6.017, avg: 1.49, latest lr: 7.687142857142857e-05\n",
      "epoch: 1, loss: 5.310, avg: 1.49, latest lr: 7.685714285714286e-05\n",
      "epoch: 1, loss: 5.954, avg: 1.49, latest lr: 7.684285714285715e-05\n",
      "epoch: 1, loss: 6.260, avg: 1.49, latest lr: 7.682857142857143e-05\n",
      "epoch: 1, loss: 5.139, avg: 1.49, latest lr: 7.681428571428571e-05\n",
      "epoch: 1, loss: 4.235, avg: 1.49, latest lr: 7.680000000000001e-05\n",
      "epoch: 1, loss: 4.729, avg: 1.49, latest lr: 7.67857142857143e-05\n",
      "epoch: 1, loss: 5.061, avg: 1.50, latest lr: 7.677142857142858e-05\n",
      "epoch: 1, loss: 6.509, avg: 1.50, latest lr: 7.675714285714286e-05\n",
      "epoch: 1, loss: 5.107, avg: 1.50, latest lr: 7.674285714285714e-05\n",
      "epoch: 1, loss: 5.787, avg: 1.50, latest lr: 7.672857142857143e-05\n",
      "epoch: 1, loss: 5.378, avg: 1.50, latest lr: 7.671428571428571e-05\n",
      "epoch: 1, loss: 6.236, avg: 1.50, latest lr: 7.670000000000001e-05\n",
      "epoch: 1, loss: 4.459, avg: 1.50, latest lr: 7.668571428571429e-05\n",
      "epoch: 1, loss: 4.703, avg: 1.50, latest lr: 7.667142857142857e-05\n",
      "epoch: 1, loss: 6.480, avg: 1.50, latest lr: 7.665714285714286e-05\n",
      "epoch: 1, loss: 4.581, avg: 1.50, latest lr: 7.664285714285715e-05\n",
      "epoch: 1, loss: 4.851, avg: 1.50, latest lr: 7.662857142857142e-05\n",
      "epoch: 1, loss: 4.810, avg: 1.50, latest lr: 7.661428571428572e-05\n",
      "epoch: 1, loss: 5.638, avg: 1.50, latest lr: 7.66e-05\n",
      "epoch: 1, loss: 3.919, avg: 1.50, latest lr: 7.658571428571429e-05\n",
      "epoch: 1, loss: 5.732, avg: 1.51, latest lr: 7.657142857142857e-05\n",
      "epoch: 1, loss: 5.165, avg: 1.51, latest lr: 7.655714285714286e-05\n",
      "epoch: 1, loss: 3.888, avg: 1.51, latest lr: 7.654285714285715e-05\n",
      "epoch: 1, loss: 6.270, avg: 1.51, latest lr: 7.652857142857142e-05\n",
      "epoch: 1, loss: 5.609, avg: 1.51, latest lr: 7.651428571428572e-05\n",
      "epoch: 1, loss: 4.774, avg: 1.51, latest lr: 7.65e-05\n",
      "epoch: 1, loss: 5.553, avg: 1.51, latest lr: 7.64857142857143e-05\n",
      "epoch: 1, loss: 5.717, avg: 1.51, latest lr: 7.647142857142857e-05\n",
      "epoch: 1, loss: 4.191, avg: 1.51, latest lr: 7.645714285714287e-05\n",
      "epoch: 1, loss: 5.321, avg: 1.51, latest lr: 7.644285714285715e-05\n",
      "epoch: 1, loss: 6.393, avg: 1.51, latest lr: 7.642857142857143e-05\n",
      "epoch: 1, loss: 5.612, avg: 1.51, latest lr: 7.641428571428572e-05\n",
      "epoch: 1, loss: 4.748, avg: 1.51, latest lr: 7.64e-05\n",
      "epoch: 1, loss: 5.061, avg: 1.52, latest lr: 7.63857142857143e-05\n",
      "epoch: 1, loss: 5.592, avg: 1.52, latest lr: 7.637142857142857e-05\n",
      "epoch: 1, loss: 4.902, avg: 1.52, latest lr: 7.635714285714286e-05\n",
      "epoch: 1, loss: 4.366, avg: 1.52, latest lr: 7.634285714285715e-05\n",
      "epoch: 1, loss: 4.184, avg: 1.52, latest lr: 7.632857142857143e-05\n",
      "epoch: 1, loss: 3.772, avg: 1.52, latest lr: 7.631428571428571e-05\n",
      "epoch: 1, loss: 5.273, avg: 1.52, latest lr: 7.630000000000001e-05\n",
      "epoch: 1, loss: 4.822, avg: 1.52, latest lr: 7.62857142857143e-05\n",
      "epoch: 1, loss: 6.225, avg: 1.52, latest lr: 7.627142857142856e-05\n",
      "epoch: 1, loss: 5.955, avg: 1.52, latest lr: 7.625714285714286e-05\n",
      "epoch: 1, loss: 6.238, avg: 1.52, latest lr: 7.624285714285715e-05\n",
      "epoch: 1, loss: 5.091, avg: 1.52, latest lr: 7.622857142857143e-05\n",
      "epoch: 1, loss: 5.674, avg: 1.52, latest lr: 7.621428571428571e-05\n",
      "epoch: 1, loss: 5.833, avg: 1.53, latest lr: 7.620000000000001e-05\n",
      "epoch: 1, loss: 4.674, avg: 1.53, latest lr: 7.618571428571429e-05\n",
      "epoch: 1, loss: 3.836, avg: 1.53, latest lr: 7.617142857142858e-05\n",
      "epoch: 1, loss: 7.238, avg: 1.53, latest lr: 7.615714285714286e-05\n",
      "epoch: 1, loss: 5.750, avg: 1.53, latest lr: 7.614285714285714e-05\n",
      "epoch: 1, loss: 6.233, avg: 1.53, latest lr: 7.612857142857143e-05\n",
      "epoch: 1, loss: 5.759, avg: 1.53, latest lr: 7.611428571428571e-05\n",
      "epoch: 1, loss: 5.085, avg: 1.53, latest lr: 7.61e-05\n",
      "epoch: 1, loss: 6.019, avg: 1.53, latest lr: 7.608571428571429e-05\n",
      "epoch: 1, loss: 4.541, avg: 1.53, latest lr: 7.607142857142857e-05\n",
      "epoch: 1, loss: 4.238, avg: 1.53, latest lr: 7.605714285714286e-05\n",
      "epoch: 1, loss: 4.365, avg: 1.53, latest lr: 7.604285714285715e-05\n",
      "epoch: 1, loss: 6.663, avg: 1.53, latest lr: 7.602857142857142e-05\n",
      "epoch: 1, loss: 5.402, avg: 1.54, latest lr: 7.601428571428572e-05\n",
      "epoch: 1, loss: 5.427, avg: 1.54, latest lr: 7.6e-05\n",
      "epoch: 1, loss: 5.325, avg: 1.54, latest lr: 7.598571428571429e-05\n",
      "epoch: 1, loss: 6.257, avg: 1.54, latest lr: 7.597142857142857e-05\n",
      "epoch: 1, loss: 5.767, avg: 1.54, latest lr: 7.595714285714285e-05\n",
      "epoch: 1, loss: 5.404, avg: 1.54, latest lr: 7.594285714285715e-05\n",
      "epoch: 1, loss: 6.238, avg: 1.54, latest lr: 7.592857142857142e-05\n",
      "epoch: 1, loss: 4.414, avg: 1.54, latest lr: 7.591428571428572e-05\n",
      "epoch: 1, loss: 5.658, avg: 1.54, latest lr: 7.59e-05\n",
      "epoch: 1, loss: 6.578, avg: 1.54, latest lr: 7.58857142857143e-05\n",
      "epoch: 1, loss: 5.239, avg: 1.54, latest lr: 7.587142857142857e-05\n",
      "epoch: 1, loss: 3.755, avg: 1.54, latest lr: 7.585714285714287e-05\n",
      "epoch: 1, loss: 5.133, avg: 1.54, latest lr: 7.584285714285715e-05\n",
      "epoch: 1, loss: 5.270, avg: 1.55, latest lr: 7.582857142857143e-05\n",
      "epoch: 1, loss: 4.888, avg: 1.55, latest lr: 7.581428571428572e-05\n",
      "epoch: 1, loss: 5.493, avg: 1.55, latest lr: 7.58e-05\n",
      "epoch: 1, loss: 5.302, avg: 1.55, latest lr: 7.57857142857143e-05\n",
      "epoch: 1, loss: 6.092, avg: 1.55, latest lr: 7.577142857142857e-05\n",
      "epoch: 1, loss: 6.603, avg: 1.55, latest lr: 7.575714285714286e-05\n",
      "epoch: 1, loss: 6.164, avg: 1.55, latest lr: 7.574285714285715e-05\n",
      "epoch: 1, loss: 5.022, avg: 1.55, latest lr: 7.572857142857144e-05\n",
      "epoch: 1, loss: 5.619, avg: 1.55, latest lr: 7.571428571428571e-05\n",
      "epoch: 1, loss: 5.406, avg: 1.55, latest lr: 7.570000000000001e-05\n",
      "epoch: 1, loss: 4.722, avg: 1.55, latest lr: 7.56857142857143e-05\n",
      "epoch: 1, loss: 5.749, avg: 1.55, latest lr: 7.567142857142858e-05\n",
      "epoch: 1, loss: 4.933, avg: 1.55, latest lr: 7.565714285714286e-05\n",
      "epoch: 1, loss: 5.310, avg: 1.56, latest lr: 7.564285714285714e-05\n",
      "epoch: 1, loss: 6.108, avg: 1.56, latest lr: 7.562857142857144e-05\n",
      "epoch: 1, loss: 5.793, avg: 1.56, latest lr: 7.561428571428571e-05\n",
      "epoch: 1, loss: 4.842, avg: 1.56, latest lr: 7.560000000000001e-05\n",
      "epoch: 1, loss: 5.192, avg: 1.56, latest lr: 7.558571428571429e-05\n",
      "epoch: 1, loss: 5.059, avg: 1.56, latest lr: 7.557142857142857e-05\n",
      "epoch: 1, loss: 6.157, avg: 1.56, latest lr: 7.555714285714286e-05\n",
      "epoch: 1, loss: 4.725, avg: 1.56, latest lr: 7.554285714285716e-05\n",
      "epoch: 1, loss: 6.027, avg: 1.56, latest lr: 7.552857142857144e-05\n",
      "epoch: 1, loss: 5.249, avg: 1.56, latest lr: 7.551428571428571e-05\n",
      "epoch: 1, loss: 5.727, avg: 1.56, latest lr: 7.55e-05\n",
      "epoch: 1, loss: 4.454, avg: 1.56, latest lr: 7.548571428571429e-05\n",
      "epoch: 1, loss: 5.991, avg: 1.56, latest lr: 7.547142857142857e-05\n",
      "epoch: 1, loss: 4.978, avg: 1.57, latest lr: 7.545714285714286e-05\n",
      "epoch: 1, loss: 4.698, avg: 1.57, latest lr: 7.544285714285715e-05\n",
      "epoch: 1, loss: 4.765, avg: 1.57, latest lr: 7.542857142857144e-05\n",
      "epoch: 1, loss: 5.363, avg: 1.57, latest lr: 7.541428571428572e-05\n",
      "epoch: 1, loss: 4.527, avg: 1.57, latest lr: 7.54e-05\n",
      "epoch: 1, loss: 5.468, avg: 1.57, latest lr: 7.538571428571429e-05\n",
      "epoch: 1, loss: 6.079, avg: 1.57, latest lr: 7.537142857142857e-05\n",
      "epoch: 1, loss: 5.495, avg: 1.57, latest lr: 7.535714285714285e-05\n",
      "epoch: 1, loss: 6.303, avg: 1.57, latest lr: 7.534285714285715e-05\n",
      "epoch: 1, loss: 5.449, avg: 1.57, latest lr: 7.532857142857143e-05\n",
      "epoch: 1, loss: 7.108, avg: 1.57, latest lr: 7.531428571428572e-05\n",
      "epoch: 1, loss: 5.787, avg: 1.57, latest lr: 7.53e-05\n",
      "epoch: 1, loss: 5.724, avg: 1.57, latest lr: 7.52857142857143e-05\n",
      "epoch: 1, loss: 5.403, avg: 1.58, latest lr: 7.527142857142857e-05\n",
      "epoch: 1, loss: 5.438, avg: 1.58, latest lr: 7.525714285714286e-05\n",
      "epoch: 1, loss: 7.825, avg: 1.58, latest lr: 7.524285714285715e-05\n",
      "epoch: 1, loss: 5.384, avg: 1.58, latest lr: 7.522857142857143e-05\n",
      "epoch: 1, loss: 6.163, avg: 1.58, latest lr: 7.521428571428571e-05\n",
      "epoch: 1, loss: 6.248, avg: 1.58, latest lr: 7.52e-05\n",
      "epoch: 1, loss: 5.087, avg: 1.58, latest lr: 7.51857142857143e-05\n",
      "epoch: 1, loss: 5.204, avg: 1.58, latest lr: 7.517142857142857e-05\n",
      "epoch: 1, loss: 6.118, avg: 1.58, latest lr: 7.515714285714286e-05\n",
      "epoch: 1, loss: 4.220, avg: 1.58, latest lr: 7.514285714285715e-05\n",
      "epoch: 1, loss: 3.706, avg: 1.58, latest lr: 7.512857142857144e-05\n",
      "epoch: 1, loss: 6.104, avg: 1.58, latest lr: 7.511428571428571e-05\n",
      "epoch: 1, loss: 4.916, avg: 1.59, latest lr: 7.510000000000001e-05\n",
      "epoch: 1, loss: 6.636, avg: 1.59, latest lr: 7.508571428571429e-05\n",
      "epoch: 1, loss: 5.635, avg: 1.59, latest lr: 7.507142857142858e-05\n",
      "epoch: 1, loss: 4.183, avg: 1.59, latest lr: 7.505714285714286e-05\n",
      "epoch: 1, loss: 5.752, avg: 1.59, latest lr: 7.504285714285714e-05\n",
      "epoch: 1, loss: 5.434, avg: 1.59, latest lr: 7.502857142857144e-05\n",
      "epoch: 1, loss: 5.271, avg: 1.59, latest lr: 7.501428571428571e-05\n",
      "epoch: 1, loss: 4.261, avg: 1.59, latest lr: 7.500000000000001e-05\n",
      "epoch: 1, loss: 6.469, avg: 1.59, latest lr: 7.498571428571429e-05\n",
      "epoch: 1, loss: 4.951, avg: 1.59, latest lr: 7.497142857142857e-05\n",
      "epoch: 1, loss: 5.140, avg: 1.59, latest lr: 7.495714285714286e-05\n",
      "epoch: 1, loss: 5.616, avg: 1.59, latest lr: 7.494285714285715e-05\n",
      "epoch: 1, loss: 4.213, avg: 1.59, latest lr: 7.492857142857144e-05\n",
      "epoch: 1, loss: 4.832, avg: 1.59, latest lr: 7.491428571428572e-05\n",
      "epoch: 1, loss: 6.247, avg: 1.60, latest lr: 7.49e-05\n",
      "epoch: 1, loss: 3.939, avg: 1.60, latest lr: 7.488571428571429e-05\n",
      "epoch: 1, loss: 6.855, avg: 1.60, latest lr: 7.487142857142857e-05\n",
      "epoch: 1, loss: 5.523, avg: 1.60, latest lr: 7.485714285714285e-05\n",
      "epoch: 1, loss: 5.066, avg: 1.60, latest lr: 7.484285714285715e-05\n",
      "epoch: 1, loss: 4.831, avg: 1.60, latest lr: 7.482857142857144e-05\n",
      "epoch: 1, loss: 5.404, avg: 1.60, latest lr: 7.481428571428572e-05\n",
      "epoch: 1, loss: 4.688, avg: 1.60, latest lr: 7.48e-05\n",
      "epoch: 1, loss: 5.028, avg: 1.60, latest lr: 7.478571428571429e-05\n",
      "epoch: 1, loss: 4.775, avg: 1.60, latest lr: 7.477142857142857e-05\n",
      "epoch: 1, loss: 5.575, avg: 1.60, latest lr: 7.475714285714285e-05\n",
      "epoch: 1, loss: 5.615, avg: 1.60, latest lr: 7.474285714285715e-05\n",
      "epoch: 1, loss: 5.891, avg: 1.60, latest lr: 7.472857142857143e-05\n",
      "epoch: 1, loss: 4.909, avg: 1.61, latest lr: 7.471428571428572e-05\n",
      "epoch: 1, loss: 3.763, avg: 1.61, latest lr: 7.47e-05\n",
      "epoch: 1, loss: 6.342, avg: 1.61, latest lr: 7.46857142857143e-05\n",
      "epoch: 1, loss: 4.252, avg: 1.61, latest lr: 7.467142857142857e-05\n",
      "epoch: 1, loss: 3.866, avg: 1.61, latest lr: 7.465714285714286e-05\n",
      "epoch: 1, loss: 5.090, avg: 1.61, latest lr: 7.464285714285715e-05\n",
      "epoch: 1, loss: 5.872, avg: 1.61, latest lr: 7.462857142857143e-05\n",
      "epoch: 1, loss: 6.758, avg: 1.61, latest lr: 7.461428571428571e-05\n",
      "epoch: 1, loss: 4.324, avg: 1.61, latest lr: 7.46e-05\n",
      "epoch: 1, loss: 5.113, avg: 1.61, latest lr: 7.45857142857143e-05\n",
      "epoch: 1, loss: 6.366, avg: 1.61, latest lr: 7.457142857142856e-05\n",
      "epoch: 1, loss: 5.146, avg: 1.61, latest lr: 7.455714285714286e-05\n",
      "epoch: 1, loss: 4.540, avg: 1.61, latest lr: 7.454285714285714e-05\n",
      "epoch: 1, loss: 5.045, avg: 1.62, latest lr: 7.452857142857144e-05\n",
      "epoch: 1, loss: 5.539, avg: 1.62, latest lr: 7.451428571428571e-05\n",
      "epoch: 1, loss: 4.790, avg: 1.62, latest lr: 7.450000000000001e-05\n",
      "epoch: 1, loss: 5.066, avg: 1.62, latest lr: 7.448571428571429e-05\n",
      "epoch: 1, loss: 5.148, avg: 1.62, latest lr: 7.447142857142858e-05\n",
      "epoch: 1, loss: 5.260, avg: 1.62, latest lr: 7.445714285714286e-05\n",
      "epoch: 1, loss: 4.595, avg: 1.62, latest lr: 7.444285714285714e-05\n",
      "epoch: 1, loss: 5.111, avg: 1.62, latest lr: 7.442857142857144e-05\n",
      "epoch: 1, loss: 5.424, avg: 1.62, latest lr: 7.441428571428571e-05\n",
      "epoch: 1, loss: 4.215, avg: 1.62, latest lr: 7.44e-05\n",
      "epoch: 1, loss: 5.424, avg: 1.62, latest lr: 7.438571428571429e-05\n",
      "epoch: 1, loss: 4.320, avg: 1.62, latest lr: 7.437142857142857e-05\n",
      "epoch: 1, loss: 4.639, avg: 1.62, latest lr: 7.435714285714286e-05\n",
      "epoch: 1, loss: 4.901, avg: 1.62, latest lr: 7.434285714285715e-05\n",
      "epoch: 1, loss: 3.980, avg: 1.62, latest lr: 7.432857142857144e-05\n",
      "epoch: 1, loss: 5.398, avg: 1.63, latest lr: 7.431428571428572e-05\n",
      "epoch: 1, loss: 5.243, avg: 1.63, latest lr: 7.43e-05\n",
      "epoch: 1, loss: 5.404, avg: 1.63, latest lr: 7.428571428571429e-05\n",
      "epoch: 1, loss: 5.716, avg: 1.63, latest lr: 7.427142857142857e-05\n",
      "epoch: 1, loss: 5.720, avg: 1.63, latest lr: 7.425714285714285e-05\n",
      "epoch: 1, loss: 5.295, avg: 1.63, latest lr: 7.424285714285715e-05\n",
      "epoch: 1, loss: 4.840, avg: 1.63, latest lr: 7.422857142857143e-05\n",
      "epoch: 1, loss: 5.928, avg: 1.63, latest lr: 7.421428571428572e-05\n",
      "epoch: 1, loss: 4.408, avg: 1.63, latest lr: 7.42e-05\n",
      "epoch: 1, loss: 5.802, avg: 1.63, latest lr: 7.41857142857143e-05\n",
      "epoch: 1, loss: 3.698, avg: 1.63, latest lr: 7.417142857142857e-05\n",
      "epoch: 1, loss: 5.395, avg: 1.63, latest lr: 7.415714285714286e-05\n",
      "epoch: 1, loss: 3.882, avg: 1.63, latest lr: 7.414285714285715e-05\n",
      "epoch: 1, loss: 6.122, avg: 1.64, latest lr: 7.412857142857143e-05\n",
      "epoch: 1, loss: 6.237, avg: 1.64, latest lr: 7.411428571428572e-05\n",
      "epoch: 1, loss: 5.048, avg: 1.64, latest lr: 7.41e-05\n",
      "epoch: 1, loss: 6.781, avg: 1.64, latest lr: 7.40857142857143e-05\n",
      "epoch: 1, loss: 4.420, avg: 1.64, latest lr: 7.407142857142858e-05\n",
      "epoch: 1, loss: 5.562, avg: 1.64, latest lr: 7.405714285714286e-05\n",
      "epoch: 1, loss: 8.625, avg: 1.64, latest lr: 7.404285714285715e-05\n",
      "epoch: 1, loss: 4.402, avg: 1.64, latest lr: 7.402857142857143e-05\n",
      "epoch: 1, loss: 5.482, avg: 1.64, latest lr: 7.401428571428571e-05\n",
      "epoch: 1, loss: 4.285, avg: 1.64, latest lr: 7.4e-05\n",
      "epoch: 1, loss: 6.766, avg: 1.64, latest lr: 7.398571428571429e-05\n",
      "epoch: 1, loss: 5.956, avg: 1.64, latest lr: 7.397142857142858e-05\n",
      "epoch: 1, loss: 4.917, avg: 1.64, latest lr: 7.395714285714286e-05\n",
      "epoch: 1, loss: 4.734, avg: 1.65, latest lr: 7.394285714285714e-05\n",
      "epoch: 1, loss: 5.290, avg: 1.65, latest lr: 7.392857142857144e-05\n",
      "epoch: 1, loss: 4.108, avg: 1.65, latest lr: 7.391428571428571e-05\n",
      "epoch: 1, loss: 5.651, avg: 1.65, latest lr: 7.390000000000001e-05\n",
      "epoch: 1, loss: 4.976, avg: 1.65, latest lr: 7.388571428571429e-05\n",
      "epoch: 1, loss: 5.359, avg: 1.65, latest lr: 7.387142857142857e-05\n",
      "epoch: 1, loss: 5.761, avg: 1.65, latest lr: 7.385714285714286e-05\n",
      "epoch: 1, loss: 5.159, avg: 1.65, latest lr: 7.384285714285714e-05\n",
      "epoch: 1, loss: 5.162, avg: 1.65, latest lr: 7.382857142857144e-05\n",
      "epoch: 1, loss: 6.237, avg: 1.65, latest lr: 7.381428571428571e-05\n",
      "epoch: 1, loss: 5.373, avg: 1.65, latest lr: 7.38e-05\n",
      "epoch: 1, loss: 5.497, avg: 1.65, latest lr: 7.378571428571429e-05\n",
      "epoch: 1, loss: 4.866, avg: 1.65, latest lr: 7.377142857142859e-05\n",
      "epoch: 1, loss: 4.648, avg: 1.66, latest lr: 7.375714285714286e-05\n",
      "epoch: 1, loss: 6.656, avg: 1.66, latest lr: 7.374285714285715e-05\n",
      "epoch: 1, loss: 5.048, avg: 1.66, latest lr: 7.372857142857144e-05\n",
      "epoch: 1, loss: 5.640, avg: 1.66, latest lr: 7.371428571428572e-05\n",
      "epoch: 1, loss: 5.386, avg: 1.66, latest lr: 7.37e-05\n",
      "epoch: 1, loss: 5.447, avg: 1.66, latest lr: 7.368571428571429e-05\n",
      "epoch: 1, loss: 6.596, avg: 1.66, latest lr: 7.367142857142858e-05\n",
      "epoch: 1, loss: 5.180, avg: 1.66, latest lr: 7.365714285714285e-05\n",
      "epoch: 1, loss: 4.265, avg: 1.66, latest lr: 7.364285714285715e-05\n",
      "epoch: 1, loss: 5.840, avg: 1.66, latest lr: 7.362857142857143e-05\n",
      "epoch: 1, loss: 4.459, avg: 1.66, latest lr: 7.361428571428572e-05\n",
      "epoch: 1, loss: 5.887, avg: 1.66, latest lr: 7.36e-05\n",
      "epoch: 1, loss: 5.542, avg: 1.66, latest lr: 7.35857142857143e-05\n",
      "epoch: 1, loss: 6.374, avg: 1.67, latest lr: 7.357142857142858e-05\n",
      "epoch: 1, loss: 5.044, avg: 1.67, latest lr: 7.355714285714286e-05\n",
      "epoch: 1, loss: 4.822, avg: 1.67, latest lr: 7.354285714285715e-05\n",
      "epoch: 1, loss: 4.857, avg: 1.67, latest lr: 7.352857142857143e-05\n",
      "epoch: 1, loss: 5.206, avg: 1.67, latest lr: 7.351428571428571e-05\n",
      "epoch: 1, loss: 5.721, avg: 1.67, latest lr: 7.35e-05\n",
      "epoch: 1, loss: 6.341, avg: 1.67, latest lr: 7.34857142857143e-05\n",
      "epoch: 1, loss: 5.224, avg: 1.67, latest lr: 7.347142857142858e-05\n",
      "epoch: 1, loss: 4.914, avg: 1.67, latest lr: 7.345714285714286e-05\n",
      "epoch: 1, loss: 6.388, avg: 1.67, latest lr: 7.344285714285714e-05\n",
      "epoch: 1, loss: 4.576, avg: 1.67, latest lr: 7.342857142857144e-05\n",
      "epoch: 1, loss: 5.759, avg: 1.67, latest lr: 7.341428571428571e-05\n",
      "epoch: 1, loss: 6.030, avg: 1.68, latest lr: 7.340000000000001e-05\n",
      "epoch: 1, loss: 6.015, avg: 1.68, latest lr: 7.338571428571429e-05\n",
      "epoch: 1, loss: 4.688, avg: 1.68, latest lr: 7.337142857142858e-05\n",
      "epoch: 1, loss: 4.411, avg: 1.68, latest lr: 7.335714285714286e-05\n",
      "epoch: 1, loss: 5.013, avg: 1.68, latest lr: 7.334285714285714e-05\n",
      "epoch: 1, loss: 5.118, avg: 1.68, latest lr: 7.332857142857144e-05\n",
      "epoch: 1, loss: 4.575, avg: 1.68, latest lr: 7.331428571428571e-05\n",
      "epoch: 1, loss: 5.493, avg: 1.68, latest lr: 7.33e-05\n",
      "epoch: 1, loss: 4.981, avg: 1.68, latest lr: 7.328571428571429e-05\n",
      "epoch: 1, loss: 5.128, avg: 1.68, latest lr: 7.327142857142857e-05\n",
      "epoch: 1, loss: 3.286, avg: 1.68, latest lr: 7.325714285714286e-05\n",
      "epoch: 1, loss: 5.752, avg: 1.68, latest lr: 7.324285714285714e-05\n",
      "epoch: 1, loss: 6.909, avg: 1.68, latest lr: 7.322857142857144e-05\n",
      "epoch: 1, loss: 4.418, avg: 1.68, latest lr: 7.321428571428571e-05\n",
      "epoch: 1, loss: 5.590, avg: 1.69, latest lr: 7.32e-05\n",
      "epoch: 1, loss: 5.020, avg: 1.69, latest lr: 7.318571428571429e-05\n",
      "epoch: 1, loss: 5.930, avg: 1.69, latest lr: 7.317142857142858e-05\n",
      "epoch: 1, loss: 4.443, avg: 1.69, latest lr: 7.315714285714285e-05\n",
      "epoch: 1, loss: 6.349, avg: 1.69, latest lr: 7.314285714285715e-05\n",
      "epoch: 1, loss: 5.146, avg: 1.69, latest lr: 7.312857142857143e-05\n",
      "epoch: 1, loss: 5.134, avg: 1.69, latest lr: 7.311428571428572e-05\n",
      "epoch: 1, loss: 5.807, avg: 1.69, latest lr: 7.31e-05\n",
      "epoch: 1, loss: 5.623, avg: 1.69, latest lr: 7.308571428571428e-05\n",
      "epoch: 1, loss: 4.035, avg: 1.69, latest lr: 7.307142857142858e-05\n",
      "epoch: 1, loss: 6.069, avg: 1.69, latest lr: 7.305714285714285e-05\n",
      "epoch: 1, loss: 5.151, avg: 1.69, latest lr: 7.304285714285715e-05\n",
      "epoch: 1, loss: 4.615, avg: 1.69, latest lr: 7.302857142857143e-05\n",
      "epoch: 1, loss: 4.306, avg: 1.69, latest lr: 7.301428571428572e-05\n",
      "epoch: 1, loss: 5.677, avg: 1.70, latest lr: 7.3e-05\n",
      "epoch: 1, loss: 5.507, avg: 1.70, latest lr: 7.29857142857143e-05\n",
      "epoch: 1, loss: 3.702, avg: 1.70, latest lr: 7.297142857142858e-05\n",
      "epoch: 1, loss: 5.035, avg: 1.70, latest lr: 7.295714285714286e-05\n",
      "epoch: 1, loss: 4.569, avg: 1.70, latest lr: 7.294285714285715e-05\n",
      "epoch: 1, loss: 6.122, avg: 1.70, latest lr: 7.292857142857143e-05\n",
      "epoch: 1, loss: 5.530, avg: 1.70, latest lr: 7.291428571428571e-05\n",
      "epoch: 1, loss: 4.934, avg: 1.70, latest lr: 7.29e-05\n",
      "epoch: 1, loss: 5.598, avg: 1.70, latest lr: 7.28857142857143e-05\n",
      "epoch: 1, loss: 5.529, avg: 1.70, latest lr: 7.287142857142858e-05\n",
      "epoch: 1, loss: 3.764, avg: 1.70, latest lr: 7.285714285714286e-05\n",
      "epoch: 1, loss: 6.142, avg: 1.70, latest lr: 7.284285714285714e-05\n",
      "epoch: 1, loss: 4.448, avg: 1.70, latest lr: 7.282857142857144e-05\n",
      "epoch: 1, loss: 5.728, avg: 1.71, latest lr: 7.281428571428571e-05\n",
      "epoch: 1, loss: 4.434, avg: 1.71, latest lr: 7.280000000000001e-05\n",
      "epoch: 1, loss: 5.509, avg: 1.71, latest lr: 7.278571428571429e-05\n",
      "epoch: 1, loss: 5.010, avg: 1.71, latest lr: 7.277142857142857e-05\n",
      "epoch: 1, loss: 5.679, avg: 1.71, latest lr: 7.275714285714286e-05\n",
      "epoch: 1, loss: 4.147, avg: 1.71, latest lr: 7.274285714285714e-05\n",
      "epoch: 1, loss: 5.815, avg: 1.71, latest lr: 7.272857142857144e-05\n",
      "epoch: 1, loss: 3.757, avg: 1.71, latest lr: 7.271428571428571e-05\n",
      "epoch: 1, loss: 5.470, avg: 1.71, latest lr: 7.27e-05\n",
      "epoch: 1, loss: 4.389, avg: 1.71, latest lr: 7.268571428571429e-05\n",
      "epoch: 1, loss: 5.340, avg: 1.71, latest lr: 7.267142857142859e-05\n",
      "epoch: 1, loss: 4.639, avg: 1.71, latest lr: 7.265714285714286e-05\n",
      "epoch: 1, loss: 5.442, avg: 1.71, latest lr: 7.264285714285715e-05\n",
      "epoch: 1, loss: 5.633, avg: 1.71, latest lr: 7.262857142857144e-05\n",
      "epoch: 1, loss: 6.589, avg: 1.72, latest lr: 7.26142857142857e-05\n",
      "epoch: 1, loss: 4.696, avg: 1.72, latest lr: 7.26e-05\n",
      "epoch: 1, loss: 5.242, avg: 1.72, latest lr: 7.258571428571429e-05\n",
      "epoch: 1, loss: 5.367, avg: 1.72, latest lr: 7.257142857142858e-05\n",
      "epoch: 1, loss: 4.574, avg: 1.72, latest lr: 7.255714285714285e-05\n",
      "epoch: 1, loss: 4.949, avg: 1.72, latest lr: 7.254285714285715e-05\n",
      "epoch: 1, loss: 4.477, avg: 1.72, latest lr: 7.252857142857143e-05\n",
      "epoch: 1, loss: 5.489, avg: 1.72, latest lr: 7.251428571428572e-05\n",
      "epoch: 1, loss: 5.243, avg: 1.72, latest lr: 7.25e-05\n",
      "epoch: 1, loss: 4.397, avg: 1.72, latest lr: 7.248571428571428e-05\n",
      "epoch: 1, loss: 5.005, avg: 1.72, latest lr: 7.247142857142858e-05\n",
      "epoch: 1, loss: 5.060, avg: 1.72, latest lr: 7.245714285714285e-05\n",
      "epoch: 1, loss: 4.760, avg: 1.72, latest lr: 7.244285714285715e-05\n",
      "epoch: 1, loss: 3.249, avg: 1.72, latest lr: 7.242857142857143e-05\n",
      "epoch: 1, loss: 5.110, avg: 1.73, latest lr: 7.241428571428571e-05\n",
      "epoch: 1, loss: 5.659, avg: 1.73, latest lr: 7.24e-05\n",
      "epoch: 1, loss: 6.302, avg: 1.73, latest lr: 7.23857142857143e-05\n",
      "epoch: 1, loss: 5.412, avg: 1.73, latest lr: 7.237142857142858e-05\n",
      "epoch: 1, loss: 6.120, avg: 1.73, latest lr: 7.235714285714286e-05\n",
      "epoch: 1, loss: 4.862, avg: 1.73, latest lr: 7.234285714285715e-05\n",
      "epoch: 1, loss: 5.282, avg: 1.73, latest lr: 7.232857142857143e-05\n",
      "epoch: 1, loss: 6.065, avg: 1.73, latest lr: 7.231428571428573e-05\n",
      "epoch: 1, loss: 6.390, avg: 1.73, latest lr: 7.23e-05\n",
      "epoch: 1, loss: 5.301, avg: 1.73, latest lr: 7.228571428571429e-05\n",
      "epoch: 1, loss: 5.648, avg: 1.73, latest lr: 7.227142857142858e-05\n",
      "epoch: 1, loss: 4.581, avg: 1.73, latest lr: 7.225714285714286e-05\n",
      "epoch: 1, loss: 4.314, avg: 1.73, latest lr: 7.224285714285714e-05\n",
      "epoch: 1, loss: 5.404, avg: 1.74, latest lr: 7.222857142857144e-05\n",
      "epoch: 1, loss: 4.999, avg: 1.74, latest lr: 7.221428571428572e-05\n",
      "epoch: 1, loss: 6.572, avg: 1.74, latest lr: 7.22e-05\n",
      "epoch: 1, loss: 4.589, avg: 1.74, latest lr: 7.218571428571429e-05\n",
      "epoch: 1, loss: 5.704, avg: 1.74, latest lr: 7.217142857142857e-05\n",
      "epoch: 1, loss: 6.244, avg: 1.74, latest lr: 7.215714285714286e-05\n",
      "epoch: 1, loss: 5.764, avg: 1.74, latest lr: 7.214285714285714e-05\n",
      "epoch: 1, loss: 5.238, avg: 1.74, latest lr: 7.212857142857144e-05\n",
      "epoch: 1, loss: 4.572, avg: 1.74, latest lr: 7.211428571428572e-05\n",
      "epoch: 1, loss: 5.091, avg: 1.74, latest lr: 7.21e-05\n",
      "epoch: 1, loss: 5.729, avg: 1.74, latest lr: 7.208571428571429e-05\n",
      "epoch: 1, loss: 6.553, avg: 1.74, latest lr: 7.207142857142858e-05\n",
      "epoch: 1, loss: 4.974, avg: 1.74, latest lr: 7.205714285714285e-05\n",
      "epoch: 1, loss: 6.210, avg: 1.75, latest lr: 7.204285714285715e-05\n",
      "epoch: 1, loss: 5.979, avg: 1.75, latest lr: 7.202857142857143e-05\n",
      "epoch: 1, loss: 4.646, avg: 1.75, latest lr: 7.201428571428572e-05\n",
      "epoch: 1, loss: 5.227, avg: 1.75, latest lr: 7.2e-05\n",
      "epoch: 1, loss: 5.564, avg: 1.75, latest lr: 7.198571428571429e-05\n",
      "epoch: 1, loss: 5.565, avg: 1.75, latest lr: 7.197142857142858e-05\n",
      "epoch: 1, loss: 3.881, avg: 1.75, latest lr: 7.195714285714285e-05\n",
      "epoch: 1, loss: 5.678, avg: 1.75, latest lr: 7.194285714285715e-05\n",
      "epoch: 1, loss: 5.949, avg: 1.75, latest lr: 7.192857142857143e-05\n",
      "epoch: 1, loss: 6.132, avg: 1.75, latest lr: 7.191428571428573e-05\n",
      "epoch: 1, loss: 5.257, avg: 1.75, latest lr: 7.19e-05\n",
      "epoch: 1, loss: 4.635, avg: 1.75, latest lr: 7.188571428571428e-05\n",
      "epoch: 1, loss: 6.052, avg: 1.75, latest lr: 7.187142857142858e-05\n",
      "epoch: 1, loss: 6.123, avg: 1.76, latest lr: 7.185714285714285e-05\n",
      "epoch: 1, loss: 4.519, avg: 1.76, latest lr: 7.184285714285715e-05\n",
      "epoch: 1, loss: 5.742, avg: 1.76, latest lr: 7.182857142857143e-05\n",
      "epoch: 1, loss: 5.025, avg: 1.76, latest lr: 7.181428571428573e-05\n",
      "epoch: 1, loss: 4.481, avg: 1.76, latest lr: 7.18e-05\n",
      "epoch: 1, loss: 4.547, avg: 1.76, latest lr: 7.17857142857143e-05\n",
      "epoch: 1, loss: 4.861, avg: 1.76, latest lr: 7.177142857142858e-05\n",
      "epoch: 1, loss: 5.312, avg: 1.76, latest lr: 7.175714285714286e-05\n",
      "epoch: 1, loss: 4.470, avg: 1.76, latest lr: 7.174285714285714e-05\n",
      "epoch: 1, loss: 5.249, avg: 1.76, latest lr: 7.172857142857143e-05\n",
      "epoch: 1, loss: 4.768, avg: 1.76, latest lr: 7.171428571428572e-05\n",
      "epoch: 1, loss: 5.367, avg: 1.76, latest lr: 7.17e-05\n",
      "epoch: 1, loss: 5.255, avg: 1.76, latest lr: 7.168571428571429e-05\n",
      "epoch: 1, loss: 5.655, avg: 1.77, latest lr: 7.167142857142857e-05\n",
      "epoch: 1, loss: 5.503, avg: 1.77, latest lr: 7.165714285714286e-05\n",
      "epoch: 1, loss: 5.830, avg: 1.77, latest lr: 7.164285714285714e-05\n",
      "epoch: 1, loss: 5.482, avg: 1.77, latest lr: 7.162857142857144e-05\n",
      "epoch: 1, loss: 3.797, avg: 1.77, latest lr: 7.161428571428572e-05\n",
      "epoch: 1, loss: 4.533, avg: 1.77, latest lr: 7.16e-05\n",
      "epoch: 1, loss: 5.762, avg: 1.77, latest lr: 7.158571428571429e-05\n",
      "epoch: 1, loss: 6.207, avg: 1.77, latest lr: 7.157142857142857e-05\n",
      "epoch: 1, loss: 5.466, avg: 1.77, latest lr: 7.155714285714286e-05\n",
      "epoch: 1, loss: 6.173, avg: 1.77, latest lr: 7.154285714285714e-05\n",
      "epoch: 1, loss: 5.517, avg: 1.77, latest lr: 7.152857142857144e-05\n",
      "epoch: 1, loss: 4.974, avg: 1.77, latest lr: 7.151428571428572e-05\n",
      "epoch: 1, loss: 5.305, avg: 1.77, latest lr: 7.15e-05\n",
      "epoch: 1, loss: 6.201, avg: 1.78, latest lr: 7.148571428571429e-05\n",
      "epoch: 1, loss: 5.918, avg: 1.78, latest lr: 7.147142857142858e-05\n",
      "epoch: 1, loss: 3.891, avg: 1.78, latest lr: 7.145714285714285e-05\n",
      "epoch: 1, loss: 5.316, avg: 1.78, latest lr: 7.144285714285715e-05\n",
      "epoch: 1, loss: 3.978, avg: 1.78, latest lr: 7.142857142857143e-05\n",
      "epoch: 1, loss: 4.400, avg: 1.78, latest lr: 7.141428571428572e-05\n",
      "epoch: 1, loss: 3.522, avg: 1.78, latest lr: 7.14e-05\n",
      "epoch: 1, loss: 6.027, avg: 1.78, latest lr: 7.138571428571428e-05\n",
      "epoch: 1, loss: 6.309, avg: 1.78, latest lr: 7.137142857142858e-05\n",
      "epoch: 1, loss: 4.789, avg: 1.78, latest lr: 7.135714285714285e-05\n",
      "epoch: 1, loss: 4.317, avg: 1.78, latest lr: 7.134285714285715e-05\n",
      "epoch: 1, loss: 4.052, avg: 1.78, latest lr: 7.132857142857143e-05\n",
      "epoch: 1, loss: 4.903, avg: 1.78, latest lr: 7.131428571428573e-05\n",
      "epoch: 1, loss: 5.639, avg: 1.78, latest lr: 7.13e-05\n",
      "epoch: 1, loss: 4.888, avg: 1.78, latest lr: 7.12857142857143e-05\n",
      "epoch: 1, loss: 4.836, avg: 1.79, latest lr: 7.127142857142858e-05\n",
      "epoch: 1, loss: 4.391, avg: 1.79, latest lr: 7.125714285714286e-05\n",
      "epoch: 1, loss: 5.335, avg: 1.79, latest lr: 7.124285714285715e-05\n",
      "epoch: 1, loss: 5.750, avg: 1.79, latest lr: 7.122857142857143e-05\n",
      "epoch: 1, loss: 5.428, avg: 1.79, latest lr: 7.121428571428573e-05\n",
      "epoch: 1, loss: 6.134, avg: 1.79, latest lr: 7.12e-05\n",
      "epoch: 1, loss: 4.609, avg: 1.79, latest lr: 7.118571428571429e-05\n",
      "epoch: 1, loss: 4.518, avg: 1.79, latest lr: 7.117142857142858e-05\n",
      "epoch: 1, loss: 6.162, avg: 1.79, latest lr: 7.115714285714286e-05\n",
      "epoch: 1, loss: 4.903, avg: 1.79, latest lr: 7.114285714285714e-05\n",
      "epoch: 1, loss: 6.110, avg: 1.79, latest lr: 7.112857142857143e-05\n",
      "epoch: 1, loss: 4.736, avg: 1.79, latest lr: 7.111428571428572e-05\n",
      "epoch: 1, loss: 4.730, avg: 1.79, latest lr: 7.11e-05\n",
      "epoch: 1, loss: 5.657, avg: 1.80, latest lr: 7.108571428571429e-05\n",
      "epoch: 1, loss: 4.871, avg: 1.80, latest lr: 7.107142857142857e-05\n",
      "epoch: 1, loss: 5.910, avg: 1.80, latest lr: 7.105714285714286e-05\n",
      "epoch: 1, loss: 5.349, avg: 1.80, latest lr: 7.104285714285714e-05\n",
      "epoch: 1, loss: 4.810, avg: 1.80, latest lr: 7.102857142857144e-05\n",
      "epoch: 1, loss: 4.069, avg: 1.80, latest lr: 7.101428571428572e-05\n",
      "epoch: 1, loss: 4.764, avg: 1.80, latest lr: 7.1e-05\n",
      "epoch: 1, loss: 4.601, avg: 1.80, latest lr: 7.098571428571429e-05\n",
      "epoch: 1, loss: 3.516, avg: 1.80, latest lr: 7.097142857142857e-05\n",
      "epoch: 1, loss: 5.226, avg: 1.80, latest lr: 7.095714285714285e-05\n",
      "epoch: 1, loss: 6.675, avg: 1.80, latest lr: 7.094285714285714e-05\n",
      "epoch: 1, loss: 5.415, avg: 1.80, latest lr: 7.092857142857144e-05\n",
      "epoch: 1, loss: 5.558, avg: 1.80, latest lr: 7.091428571428572e-05\n",
      "epoch: 1, loss: 4.799, avg: 1.80, latest lr: 7.09e-05\n",
      "epoch: 1, loss: 4.545, avg: 1.81, latest lr: 7.088571428571429e-05\n",
      "epoch: 1, loss: 5.529, avg: 1.81, latest lr: 7.087142857142858e-05\n",
      "epoch: 1, loss: 4.856, avg: 1.81, latest lr: 7.085714285714285e-05\n",
      "epoch: 1, loss: 4.680, avg: 1.81, latest lr: 7.084285714285715e-05\n",
      "epoch: 1, loss: 4.699, avg: 1.81, latest lr: 7.082857142857143e-05\n",
      "epoch: 1, loss: 4.507, avg: 1.81, latest lr: 7.081428571428572e-05\n",
      "epoch: 1, loss: 5.512, avg: 1.81, latest lr: 7.08e-05\n",
      "epoch: 1, loss: 5.662, avg: 1.81, latest lr: 7.078571428571428e-05\n",
      "epoch: 1, loss: 4.356, avg: 1.81, latest lr: 7.077142857142858e-05\n",
      "epoch: 1, loss: 4.100, avg: 1.81, latest lr: 7.075714285714285e-05\n",
      "epoch: 1, loss: 5.411, avg: 1.81, latest lr: 7.074285714285715e-05\n",
      "epoch: 1, loss: 5.412, avg: 1.81, latest lr: 7.072857142857143e-05\n",
      "epoch: 1, loss: 4.008, avg: 1.81, latest lr: 7.071428571428573e-05\n",
      "epoch: 1, loss: 4.023, avg: 1.81, latest lr: 7.07e-05\n",
      "epoch: 1, loss: 5.253, avg: 1.82, latest lr: 7.06857142857143e-05\n",
      "epoch: 1, loss: 3.313, avg: 1.82, latest lr: 7.067142857142858e-05\n",
      "epoch: 1, loss: 4.538, avg: 1.82, latest lr: 7.065714285714286e-05\n",
      "epoch: 1, loss: 4.808, avg: 1.82, latest lr: 7.064285714285714e-05\n",
      "epoch: 1, loss: 5.797, avg: 1.82, latest lr: 7.062857142857143e-05\n",
      "epoch: 1, loss: 3.463, avg: 1.82, latest lr: 7.061428571428573e-05\n",
      "epoch: 1, loss: 4.409, avg: 1.82, latest lr: 7.06e-05\n",
      "epoch: 1, loss: 4.469, avg: 1.82, latest lr: 7.058571428571429e-05\n",
      "epoch: 1, loss: 4.695, avg: 1.82, latest lr: 7.057142857142858e-05\n",
      "epoch: 1, loss: 5.911, avg: 1.82, latest lr: 7.055714285714286e-05\n",
      "epoch: 1, loss: 4.192, avg: 1.82, latest lr: 7.054285714285714e-05\n",
      "epoch: 1, loss: 6.490, avg: 1.82, latest lr: 7.052857142857144e-05\n",
      "epoch: 1, loss: 5.558, avg: 1.82, latest lr: 7.051428571428572e-05\n",
      "epoch: 1, loss: 4.303, avg: 1.82, latest lr: 7.05e-05\n",
      "epoch: 1, loss: 5.330, avg: 1.82, latest lr: 7.048571428571429e-05\n",
      "epoch: 1, loss: 4.478, avg: 1.83, latest lr: 7.047142857142857e-05\n",
      "epoch: 1, loss: 5.765, avg: 1.83, latest lr: 7.045714285714287e-05\n",
      "epoch: 1, loss: 4.281, avg: 1.83, latest lr: 7.044285714285714e-05\n",
      "epoch: 1, loss: 4.524, avg: 1.83, latest lr: 7.042857142857144e-05\n",
      "epoch: 1, loss: 5.299, avg: 1.83, latest lr: 7.041428571428572e-05\n",
      "epoch: 1, loss: 5.278, avg: 1.83, latest lr: 7.04e-05\n",
      "epoch: 1, loss: 5.351, avg: 1.83, latest lr: 7.038571428571429e-05\n",
      "epoch: 1, loss: 4.018, avg: 1.83, latest lr: 7.037142857142857e-05\n",
      "epoch: 1, loss: 5.206, avg: 1.83, latest lr: 7.035714285714287e-05\n",
      "epoch: 1, loss: 6.002, avg: 1.83, latest lr: 7.034285714285714e-05\n",
      "epoch: 1, loss: 5.224, avg: 1.83, latest lr: 7.032857142857143e-05\n",
      "epoch: 1, loss: 5.179, avg: 1.83, latest lr: 7.031428571428572e-05\n",
      "epoch: 1, loss: 5.337, avg: 1.83, latest lr: 7.03e-05\n",
      "epoch: 1, loss: 5.802, avg: 1.83, latest lr: 7.028571428571428e-05\n",
      "epoch: 1, loss: 5.268, avg: 1.84, latest lr: 7.027142857142858e-05\n",
      "epoch: 1, loss: 5.314, avg: 1.84, latest lr: 7.025714285714287e-05\n",
      "epoch: 1, loss: 4.992, avg: 1.84, latest lr: 7.024285714285715e-05\n",
      "epoch: 1, loss: 4.915, avg: 1.84, latest lr: 7.022857142857143e-05\n",
      "epoch: 1, loss: 5.412, avg: 1.84, latest lr: 7.021428571428572e-05\n",
      "epoch: 1, loss: 6.215, avg: 1.84, latest lr: 7.02e-05\n",
      "epoch: 1, loss: 6.075, avg: 1.84, latest lr: 7.018571428571428e-05\n",
      "epoch: 1, loss: 5.079, avg: 1.84, latest lr: 7.017142857142858e-05\n",
      "epoch: 1, loss: 5.332, avg: 1.84, latest lr: 7.015714285714286e-05\n",
      "epoch: 1, loss: 3.906, avg: 1.84, latest lr: 7.014285714285715e-05\n",
      "epoch: 1, loss: 5.355, avg: 1.84, latest lr: 7.012857142857143e-05\n",
      "epoch: 1, loss: 5.310, avg: 1.84, latest lr: 7.011428571428573e-05\n",
      "epoch: 1, loss: 4.694, avg: 1.84, latest lr: 7.01e-05\n",
      "epoch: 1, loss: 4.948, avg: 1.85, latest lr: 7.00857142857143e-05\n",
      "epoch: 1, loss: 4.473, avg: 1.85, latest lr: 7.007142857142858e-05\n",
      "epoch: 1, loss: 5.545, avg: 1.85, latest lr: 7.005714285714286e-05\n",
      "epoch: 1, loss: 5.306, avg: 1.85, latest lr: 7.004285714285714e-05\n",
      "epoch: 1, loss: 4.139, avg: 1.85, latest lr: 7.002857142857143e-05\n",
      "epoch: 1, loss: 4.981, avg: 1.85, latest lr: 7.001428571428572e-05\n",
      "epoch: 1, loss: 4.375, avg: 1.85, latest lr: 7e-05\n",
      "epoch: 1, loss: 4.396, avg: 1.85, latest lr: 6.998571428571429e-05\n",
      "epoch: 1, loss: 4.687, avg: 1.85, latest lr: 6.997142857142857e-05\n",
      "epoch: 1, loss: 5.539, avg: 1.85, latest lr: 6.995714285714287e-05\n",
      "epoch: 1, loss: 3.797, avg: 1.85, latest lr: 6.994285714285714e-05\n",
      "epoch: 1, loss: 5.502, avg: 1.85, latest lr: 6.992857142857144e-05\n",
      "epoch: 1, loss: 5.276, avg: 1.85, latest lr: 6.991428571428572e-05\n",
      "epoch: 1, loss: 4.321, avg: 1.85, latest lr: 6.99e-05\n",
      "epoch: 1, loss: 4.496, avg: 1.85, latest lr: 6.988571428571429e-05\n",
      "epoch: 1, loss: 4.165, avg: 1.86, latest lr: 6.987142857142857e-05\n",
      "epoch: 1, loss: 4.207, avg: 1.86, latest lr: 6.985714285714287e-05\n",
      "epoch: 1, loss: 6.235, avg: 1.86, latest lr: 6.984285714285714e-05\n",
      "epoch: 1, loss: 4.466, avg: 1.86, latest lr: 6.982857142857144e-05\n",
      "epoch: 1, loss: 4.944, avg: 1.86, latest lr: 6.981428571428572e-05\n",
      "epoch: 1, loss: 5.493, avg: 1.86, latest lr: 6.98e-05\n",
      "epoch: 1, loss: 6.175, avg: 1.86, latest lr: 6.978571428571429e-05\n",
      "epoch: 1, loss: 4.708, avg: 1.86, latest lr: 6.977142857142858e-05\n",
      "epoch: 1, loss: 4.019, avg: 1.86, latest lr: 6.975714285714287e-05\n",
      "epoch: 1, loss: 6.066, avg: 1.86, latest lr: 6.974285714285715e-05\n",
      "epoch: 1, loss: 4.740, avg: 1.86, latest lr: 6.972857142857143e-05\n",
      "epoch: 1, loss: 4.030, avg: 1.86, latest lr: 6.971428571428572e-05\n",
      "epoch: 1, loss: 5.011, avg: 1.86, latest lr: 6.97e-05\n",
      "epoch: 1, loss: 4.517, avg: 1.86, latest lr: 6.968571428571428e-05\n",
      "epoch: 1, loss: 3.750, avg: 1.87, latest lr: 6.967142857142858e-05\n",
      "epoch: 1, loss: 4.692, avg: 1.87, latest lr: 6.965714285714286e-05\n",
      "epoch: 1, loss: 3.546, avg: 1.87, latest lr: 6.964285714285715e-05\n",
      "epoch: 1, loss: 5.254, avg: 1.87, latest lr: 6.962857142857143e-05\n",
      "epoch: 1, loss: 5.617, avg: 1.87, latest lr: 6.961428571428571e-05\n",
      "epoch: 1, loss: 5.580, avg: 1.87, latest lr: 6.96e-05\n",
      "epoch: 1, loss: 4.563, avg: 1.87, latest lr: 6.958571428571428e-05\n",
      "epoch: 1, loss: 4.279, avg: 1.87, latest lr: 6.957142857142858e-05\n",
      "epoch: 1, loss: 5.005, avg: 1.87, latest lr: 6.955714285714286e-05\n",
      "epoch: 1, loss: 6.728, avg: 1.87, latest lr: 6.954285714285714e-05\n",
      "epoch: 1, loss: 5.565, avg: 1.87, latest lr: 6.952857142857143e-05\n",
      "epoch: 1, loss: 4.273, avg: 1.87, latest lr: 6.951428571428573e-05\n",
      "epoch: 1, loss: 5.571, avg: 1.87, latest lr: 6.95e-05\n",
      "epoch: 1, loss: 4.574, avg: 1.87, latest lr: 6.948571428571429e-05\n",
      "epoch: 1, loss: 6.169, avg: 1.88, latest lr: 6.947142857142858e-05\n",
      "epoch: 1, loss: 5.255, avg: 1.88, latest lr: 6.945714285714286e-05\n",
      "epoch: 1, loss: 5.413, avg: 1.88, latest lr: 6.944285714285714e-05\n",
      "epoch: 1, loss: 3.983, avg: 1.88, latest lr: 6.942857142857143e-05\n",
      "epoch: 1, loss: 4.562, avg: 1.88, latest lr: 6.941428571428572e-05\n",
      "epoch: 1, loss: 4.447, avg: 1.88, latest lr: 6.939999999999999e-05\n",
      "epoch: 1, loss: 4.112, avg: 1.88, latest lr: 6.938571428571429e-05\n",
      "epoch: 1, loss: 6.065, avg: 1.88, latest lr: 6.937142857142857e-05\n",
      "epoch: 1, loss: 4.332, avg: 1.88, latest lr: 6.935714285714287e-05\n",
      "epoch: 1, loss: 5.005, avg: 1.88, latest lr: 6.934285714285714e-05\n",
      "epoch: 1, loss: 4.904, avg: 1.88, latest lr: 6.932857142857144e-05\n",
      "epoch: 1, loss: 5.713, avg: 1.88, latest lr: 6.931428571428572e-05\n",
      "epoch: 1, loss: 4.656, avg: 1.88, latest lr: 6.93e-05\n",
      "epoch: 1, loss: 5.683, avg: 1.88, latest lr: 6.928571428571429e-05\n",
      "epoch: 1, loss: 5.431, avg: 1.89, latest lr: 6.927142857142857e-05\n",
      "epoch: 1, loss: 4.822, avg: 1.89, latest lr: 6.925714285714287e-05\n",
      "epoch: 1, loss: 4.576, avg: 1.89, latest lr: 6.924285714285714e-05\n",
      "epoch: 1, loss: 4.908, avg: 1.89, latest lr: 6.922857142857143e-05\n",
      "epoch: 1, loss: 3.668, avg: 1.89, latest lr: 6.921428571428572e-05\n",
      "epoch: 1, loss: 4.410, avg: 1.89, latest lr: 6.92e-05\n",
      "epoch: 1, loss: 4.932, avg: 1.89, latest lr: 6.918571428571428e-05\n",
      "epoch: 1, loss: 5.001, avg: 1.89, latest lr: 6.917142857142858e-05\n",
      "epoch: 1, loss: 4.393, avg: 1.89, latest lr: 6.915714285714287e-05\n",
      "epoch: 1, loss: 6.036, avg: 1.89, latest lr: 6.914285714285715e-05\n",
      "epoch: 1, loss: 5.490, avg: 1.89, latest lr: 6.912857142857143e-05\n",
      "epoch: 1, loss: 5.304, avg: 1.89, latest lr: 6.911428571428572e-05\n",
      "epoch: 1, loss: 6.533, avg: 1.89, latest lr: 6.91e-05\n",
      "epoch: 1, loss: 5.781, avg: 1.89, latest lr: 6.908571428571428e-05\n",
      "epoch: 1, loss: 5.775, avg: 1.90, latest lr: 6.907142857142858e-05\n",
      "epoch: 1, loss: 4.812, avg: 1.90, latest lr: 6.905714285714286e-05\n",
      "epoch: 1, loss: 5.005, avg: 1.90, latest lr: 6.904285714285715e-05\n",
      "epoch: 1, loss: 4.496, avg: 1.90, latest lr: 6.902857142857143e-05\n",
      "epoch: 1, loss: 6.131, avg: 1.90, latest lr: 6.901428571428573e-05\n",
      "epoch: 1, loss: 5.443, avg: 1.90, latest lr: 6.9e-05\n",
      "epoch: 1, loss: 5.536, avg: 1.90, latest lr: 6.898571428571428e-05\n",
      "epoch: 1, loss: 4.801, avg: 1.90, latest lr: 6.897142857142858e-05\n",
      "epoch: 1, loss: 4.800, avg: 1.90, latest lr: 6.895714285714286e-05\n",
      "epoch: 1, loss: 4.183, avg: 1.90, latest lr: 6.894285714285714e-05\n",
      "epoch: 1, loss: 6.476, avg: 1.90, latest lr: 6.892857142857143e-05\n",
      "epoch: 1, loss: 5.205, avg: 1.90, latest lr: 6.891428571428572e-05\n",
      "epoch: 1, loss: 5.304, avg: 1.90, latest lr: 6.89e-05\n",
      "epoch: 1, loss: 5.284, avg: 1.91, latest lr: 6.888571428571429e-05\n",
      "epoch: 1, loss: 6.853, avg: 1.91, latest lr: 6.887142857142857e-05\n",
      "epoch: 1, loss: 5.105, avg: 1.91, latest lr: 6.885714285714286e-05\n",
      "epoch: 1, loss: 4.072, avg: 1.91, latest lr: 6.884285714285714e-05\n",
      "epoch: 1, loss: 5.076, avg: 1.91, latest lr: 6.882857142857142e-05\n",
      "epoch: 1, loss: 5.566, avg: 1.91, latest lr: 6.881428571428572e-05\n",
      "epoch: 1, loss: 5.497, avg: 1.91, latest lr: 6.879999999999999e-05\n",
      "epoch: 1, loss: 4.955, avg: 1.91, latest lr: 6.878571428571429e-05\n",
      "epoch: 1, loss: 7.773, avg: 1.91, latest lr: 6.877142857142857e-05\n",
      "epoch: 1, loss: 3.816, avg: 1.91, latest lr: 6.875714285714287e-05\n",
      "epoch: 1, loss: 5.865, avg: 1.91, latest lr: 6.874285714285714e-05\n",
      "epoch: 1, loss: 5.355, avg: 1.91, latest lr: 6.872857142857144e-05\n",
      "epoch: 1, loss: 4.419, avg: 1.91, latest lr: 6.871428571428572e-05\n",
      "epoch: 1, loss: 4.988, avg: 1.92, latest lr: 6.87e-05\n",
      "epoch: 1, loss: 4.944, avg: 1.92, latest lr: 6.868571428571429e-05\n",
      "epoch: 1, loss: 5.135, avg: 1.92, latest lr: 6.867142857142857e-05\n",
      "epoch: 1, loss: 5.438, avg: 1.92, latest lr: 6.865714285714287e-05\n",
      "epoch: 1, loss: 4.441, avg: 1.92, latest lr: 6.864285714285714e-05\n",
      "epoch: 1, loss: 5.642, avg: 1.92, latest lr: 6.862857142857143e-05\n",
      "epoch: 1, loss: 5.476, avg: 1.92, latest lr: 6.861428571428572e-05\n",
      "epoch: 1, loss: 4.496, avg: 1.92, latest lr: 6.860000000000001e-05\n",
      "epoch: 1, loss: 5.390, avg: 1.92, latest lr: 6.858571428571428e-05\n",
      "epoch: 1, loss: 5.784, avg: 1.92, latest lr: 6.857142857142858e-05\n",
      "epoch: 1, loss: 5.773, avg: 1.92, latest lr: 6.855714285714286e-05\n",
      "epoch: 1, loss: 5.265, avg: 1.92, latest lr: 6.854285714285715e-05\n",
      "epoch: 1, loss: 5.675, avg: 1.92, latest lr: 6.852857142857143e-05\n",
      "epoch: 1, loss: 5.250, avg: 1.92, latest lr: 6.851428571428571e-05\n",
      "epoch: 1, loss: 4.363, avg: 1.93, latest lr: 6.850000000000001e-05\n",
      "epoch: 1, loss: 4.155, avg: 1.93, latest lr: 6.848571428571428e-05\n",
      "epoch: 1, loss: 3.604, avg: 1.93, latest lr: 6.847142857142858e-05\n",
      "epoch: 1, loss: 4.861, avg: 1.93, latest lr: 6.845714285714286e-05\n",
      "epoch: 1, loss: 3.638, avg: 1.93, latest lr: 6.844285714285715e-05\n",
      "epoch: 1, loss: 4.085, avg: 1.93, latest lr: 6.842857142857143e-05\n",
      "epoch: 1, loss: 5.865, avg: 1.93, latest lr: 6.841428571428573e-05\n",
      "epoch: 1, loss: 3.484, avg: 1.93, latest lr: 6.840000000000001e-05\n",
      "epoch: 1, loss: 6.042, avg: 1.93, latest lr: 6.838571428571429e-05\n",
      "epoch: 1, loss: 5.636, avg: 1.93, latest lr: 6.837142857142858e-05\n",
      "epoch: 1, loss: 5.613, avg: 1.93, latest lr: 6.835714285714286e-05\n",
      "epoch: 1, loss: 6.815, avg: 1.93, latest lr: 6.834285714285714e-05\n",
      "epoch: 1, loss: 5.196, avg: 1.93, latest lr: 6.832857142857143e-05\n",
      "epoch: 1, loss: 5.255, avg: 1.93, latest lr: 6.831428571428572e-05\n",
      "epoch: 1, loss: 5.725, avg: 1.94, latest lr: 6.83e-05\n",
      "epoch: 1, loss: 5.641, avg: 1.94, latest lr: 6.828571428571429e-05\n",
      "epoch: 1, loss: 4.806, avg: 1.94, latest lr: 6.827142857142857e-05\n",
      "epoch: 1, loss: 5.254, avg: 1.94, latest lr: 6.825714285714287e-05\n",
      "epoch: 1, loss: 5.124, avg: 1.94, latest lr: 6.824285714285714e-05\n",
      "epoch: 1, loss: 4.678, avg: 1.94, latest lr: 6.822857142857142e-05\n",
      "epoch: 1, loss: 4.376, avg: 1.94, latest lr: 6.821428571428572e-05\n",
      "epoch: 1, loss: 5.201, avg: 1.94, latest lr: 6.82e-05\n",
      "epoch: 1, loss: 5.339, avg: 1.94, latest lr: 6.818571428571429e-05\n",
      "epoch: 1, loss: 5.580, avg: 1.94, latest lr: 6.817142857142857e-05\n",
      "epoch: 1, loss: 4.857, avg: 1.94, latest lr: 6.815714285714287e-05\n",
      "epoch: 1, loss: 4.657, avg: 1.94, latest lr: 6.814285714285714e-05\n",
      "epoch: 1, loss: 4.021, avg: 1.94, latest lr: 6.812857142857144e-05\n",
      "epoch: 1, loss: 5.660, avg: 1.94, latest lr: 6.811428571428572e-05\n",
      "epoch: 1, loss: 4.857, avg: 1.95, latest lr: 6.81e-05\n",
      "epoch: 1, loss: 3.675, avg: 1.95, latest lr: 6.808571428571429e-05\n",
      "epoch: 1, loss: 4.145, avg: 1.95, latest lr: 6.807142857142857e-05\n",
      "epoch: 1, loss: 5.436, avg: 1.95, latest lr: 6.805714285714287e-05\n",
      "epoch: 1, loss: 5.858, avg: 1.95, latest lr: 6.804285714285714e-05\n",
      "epoch: 1, loss: 6.210, avg: 1.95, latest lr: 6.802857142857143e-05\n",
      "epoch: 1, loss: 4.217, avg: 1.95, latest lr: 6.801428571428572e-05\n",
      "epoch: 1, loss: 5.130, avg: 1.95, latest lr: 6.800000000000001e-05\n",
      "epoch: 1, loss: 5.280, avg: 1.95, latest lr: 6.798571428571428e-05\n",
      "epoch: 1, loss: 3.998, avg: 1.95, latest lr: 6.797142857142858e-05\n",
      "epoch: 1, loss: 6.431, avg: 1.95, latest lr: 6.795714285714286e-05\n",
      "epoch: 1, loss: 5.045, avg: 1.95, latest lr: 6.794285714285715e-05\n",
      "epoch: 1, loss: 5.384, avg: 1.95, latest lr: 6.792857142857143e-05\n",
      "epoch: 1, loss: 3.557, avg: 1.95, latest lr: 6.791428571428571e-05\n",
      "epoch: 1, loss: 5.146, avg: 1.96, latest lr: 6.790000000000001e-05\n",
      "epoch: 1, loss: 5.192, avg: 1.96, latest lr: 6.788571428571428e-05\n",
      "epoch: 1, loss: 4.134, avg: 1.96, latest lr: 6.787142857142858e-05\n",
      "epoch: 1, loss: 6.009, avg: 1.96, latest lr: 6.785714285714286e-05\n",
      "epoch: 1, loss: 4.976, avg: 1.96, latest lr: 6.784285714285714e-05\n",
      "epoch: 1, loss: 5.957, avg: 1.96, latest lr: 6.782857142857143e-05\n",
      "epoch: 1, loss: 5.016, avg: 1.96, latest lr: 6.781428571428572e-05\n",
      "epoch: 1, loss: 5.111, avg: 1.96, latest lr: 6.780000000000001e-05\n",
      "epoch: 1, loss: 5.338, avg: 1.96, latest lr: 6.778571428571429e-05\n",
      "epoch: 1, loss: 4.905, avg: 1.96, latest lr: 6.777142857142858e-05\n",
      "epoch: 1, loss: 4.035, avg: 1.96, latest lr: 6.775714285714286e-05\n",
      "epoch: 1, loss: 4.000, avg: 1.96, latest lr: 6.774285714285714e-05\n",
      "epoch: 1, loss: 5.159, avg: 1.96, latest lr: 6.772857142857143e-05\n",
      "epoch: 1, loss: 4.601, avg: 1.96, latest lr: 6.771428571428572e-05\n",
      "epoch: 1, loss: 5.903, avg: 1.97, latest lr: 6.77e-05\n",
      "epoch: 1, loss: 5.759, avg: 1.97, latest lr: 6.768571428571429e-05\n",
      "epoch: 1, loss: 4.435, avg: 1.97, latest lr: 6.767142857142857e-05\n",
      "epoch: 1, loss: 5.712, avg: 1.97, latest lr: 6.765714285714287e-05\n",
      "epoch: 1, loss: 5.659, avg: 1.97, latest lr: 6.764285714285714e-05\n",
      "epoch: 1, loss: 4.922, avg: 1.97, latest lr: 6.762857142857144e-05\n",
      "epoch: 1, loss: 5.140, avg: 1.97, latest lr: 6.761428571428572e-05\n",
      "epoch: 1, loss: 5.855, avg: 1.97, latest lr: 6.76e-05\n",
      "epoch: 1, loss: 4.933, avg: 1.97, latest lr: 6.758571428571429e-05\n",
      "epoch: 1, loss: 4.675, avg: 1.97, latest lr: 6.757142857142857e-05\n",
      "epoch: 1, loss: 5.725, avg: 1.97, latest lr: 6.755714285714287e-05\n",
      "epoch: 1, loss: 5.990, avg: 1.97, latest lr: 6.754285714285714e-05\n",
      "epoch: 1, loss: 5.016, avg: 1.97, latest lr: 6.752857142857143e-05\n",
      "epoch: 1, loss: 4.132, avg: 1.98, latest lr: 6.751428571428572e-05\n",
      "epoch: 1, loss: 5.294, avg: 1.98, latest lr: 6.750000000000001e-05\n",
      "epoch: 1, loss: 5.292, avg: 1.98, latest lr: 6.748571428571428e-05\n",
      "epoch: 1, loss: 5.563, avg: 1.98, latest lr: 6.747142857142857e-05\n",
      "epoch: 1, loss: 5.690, avg: 1.98, latest lr: 6.745714285714286e-05\n",
      "epoch: 1, loss: 3.658, avg: 1.98, latest lr: 6.744285714285713e-05\n",
      "epoch: 1, loss: 6.217, avg: 1.98, latest lr: 6.742857142857143e-05\n",
      "epoch: 1, loss: 5.571, avg: 1.98, latest lr: 6.741428571428572e-05\n",
      "epoch: 1, loss: 5.257, avg: 1.98, latest lr: 6.740000000000001e-05\n",
      "epoch: 1, loss: 5.704, avg: 1.98, latest lr: 6.738571428571428e-05\n",
      "epoch: 1, loss: 4.973, avg: 1.98, latest lr: 6.737142857142858e-05\n",
      "epoch: 1, loss: 5.346, avg: 1.98, latest lr: 6.735714285714286e-05\n",
      "epoch: 1, loss: 5.154, avg: 1.98, latest lr: 6.734285714285715e-05\n",
      "epoch: 1, loss: 4.820, avg: 1.99, latest lr: 6.732857142857143e-05\n",
      "epoch: 1, loss: 3.174, avg: 1.99, latest lr: 6.731428571428571e-05\n",
      "epoch: 1, loss: 5.378, avg: 1.99, latest lr: 6.730000000000001e-05\n",
      "epoch: 1, loss: 5.636, avg: 1.99, latest lr: 6.728571428571428e-05\n",
      "epoch: 1, loss: 5.528, avg: 1.99, latest lr: 6.727142857142858e-05\n",
      "epoch: 1, loss: 4.558, avg: 1.99, latest lr: 6.725714285714286e-05\n",
      "epoch: 1, loss: 5.439, avg: 1.99, latest lr: 6.724285714285714e-05\n",
      "epoch: 1, loss: 4.980, avg: 1.99, latest lr: 6.722857142857143e-05\n",
      "epoch: 1, loss: 5.722, avg: 1.99, latest lr: 6.721428571428572e-05\n",
      "epoch: 1, loss: 5.505, avg: 1.99, latest lr: 6.720000000000001e-05\n",
      "epoch: 1, loss: 4.921, avg: 1.99, latest lr: 6.718571428571429e-05\n",
      "epoch: 1, loss: 4.305, avg: 1.99, latest lr: 6.717142857142857e-05\n",
      "epoch: 1, loss: 4.951, avg: 1.99, latest lr: 6.715714285714286e-05\n",
      "epoch: 1, loss: 5.213, avg: 1.99, latest lr: 6.714285714285714e-05\n",
      "epoch: 1, loss: 4.829, avg: 2.00, latest lr: 6.712857142857142e-05\n",
      "epoch: 1, loss: 4.975, avg: 2.00, latest lr: 6.711428571428572e-05\n",
      "epoch: 1, loss: 5.467, avg: 2.00, latest lr: 6.71e-05\n",
      "epoch: 1, loss: 5.375, avg: 2.00, latest lr: 6.708571428571429e-05\n",
      "epoch: 1, loss: 4.487, avg: 2.00, latest lr: 6.707142857142857e-05\n",
      "epoch: 1, loss: 5.228, avg: 2.00, latest lr: 6.705714285714287e-05\n",
      "epoch: 1, loss: 3.850, avg: 2.00, latest lr: 6.704285714285714e-05\n",
      "epoch: 1, loss: 5.958, avg: 2.00, latest lr: 6.702857142857144e-05\n",
      "epoch: 1, loss: 3.955, avg: 2.00, latest lr: 6.701428571428572e-05\n",
      "epoch: 1, loss: 4.171, avg: 2.00, latest lr: 6.7e-05\n",
      "epoch: 1, loss: 4.567, avg: 2.00, latest lr: 6.698571428571429e-05\n",
      "epoch: 1, loss: 6.300, avg: 2.00, latest lr: 6.697142857142857e-05\n",
      "epoch: 1, loss: 5.007, avg: 2.00, latest lr: 6.695714285714287e-05\n",
      "epoch: 1, loss: 5.419, avg: 2.00, latest lr: 6.694285714285715e-05\n",
      "epoch: 1, loss: 6.609, avg: 2.01, latest lr: 6.692857142857143e-05\n",
      "epoch: 1, loss: 6.381, avg: 2.01, latest lr: 6.691428571428572e-05\n",
      "epoch: 1, loss: 4.893, avg: 2.01, latest lr: 6.690000000000001e-05\n",
      "epoch: 1, loss: 5.393, avg: 2.01, latest lr: 6.688571428571428e-05\n",
      "epoch: 1, loss: 5.825, avg: 2.01, latest lr: 6.687142857142858e-05\n",
      "epoch: 1, loss: 4.116, avg: 2.01, latest lr: 6.685714285714286e-05\n",
      "epoch: 1, loss: 7.169, avg: 2.01, latest lr: 6.684285714285715e-05\n",
      "epoch: 1, loss: 4.848, avg: 2.01, latest lr: 6.682857142857143e-05\n",
      "epoch: 1, loss: 4.579, avg: 2.01, latest lr: 6.681428571428571e-05\n",
      "epoch: 1, loss: 4.103, avg: 2.01, latest lr: 6.680000000000001e-05\n",
      "epoch: 1, loss: 4.381, avg: 2.01, latest lr: 6.678571428571428e-05\n",
      "epoch: 1, loss: 6.026, avg: 2.01, latest lr: 6.677142857142858e-05\n",
      "epoch: 1, loss: 6.330, avg: 2.01, latest lr: 6.675714285714286e-05\n",
      "epoch: 1, loss: 4.687, avg: 2.02, latest lr: 6.674285714285714e-05\n",
      "epoch: 1, loss: 4.872, avg: 2.02, latest lr: 6.672857142857143e-05\n",
      "epoch: 1, loss: 4.225, avg: 2.02, latest lr: 6.671428571428571e-05\n",
      "epoch: 1, loss: 5.098, avg: 2.02, latest lr: 6.670000000000001e-05\n",
      "epoch: 1, loss: 5.899, avg: 2.02, latest lr: 6.668571428571428e-05\n",
      "epoch: 1, loss: 6.389, avg: 2.02, latest lr: 6.667142857142858e-05\n",
      "epoch: 1, loss: 3.829, avg: 2.02, latest lr: 6.665714285714286e-05\n",
      "epoch: 1, loss: 5.034, avg: 2.02, latest lr: 6.664285714285716e-05\n",
      "epoch: 1, loss: 4.464, avg: 2.02, latest lr: 6.662857142857143e-05\n",
      "epoch: 1, loss: 5.331, avg: 2.02, latest lr: 6.661428571428572e-05\n",
      "epoch: 1, loss: 4.597, avg: 2.02, latest lr: 6.66e-05\n",
      "epoch: 1, loss: 6.279, avg: 2.02, latest lr: 6.658571428571429e-05\n",
      "epoch: 1, loss: 5.949, avg: 2.02, latest lr: 6.657142857142857e-05\n",
      "epoch: 1, loss: 5.447, avg: 2.02, latest lr: 6.655714285714286e-05\n",
      "epoch: 1, loss: 5.507, avg: 2.03, latest lr: 6.654285714285715e-05\n",
      "epoch: 1, loss: 6.584, avg: 2.03, latest lr: 6.652857142857142e-05\n",
      "epoch: 1, loss: 5.908, avg: 2.03, latest lr: 6.651428571428572e-05\n",
      "epoch: 1, loss: 4.353, avg: 2.03, latest lr: 6.65e-05\n",
      "epoch: 1, loss: 5.875, avg: 2.03, latest lr: 6.648571428571429e-05\n",
      "epoch: 1, loss: 5.041, avg: 2.03, latest lr: 6.647142857142857e-05\n",
      "epoch: 1, loss: 5.414, avg: 2.03, latest lr: 6.645714285714287e-05\n",
      "epoch: 1, loss: 4.782, avg: 2.03, latest lr: 6.644285714285715e-05\n",
      "epoch: 1, loss: 5.087, avg: 2.03, latest lr: 6.642857142857143e-05\n",
      "epoch: 1, loss: 5.028, avg: 2.03, latest lr: 6.641428571428572e-05\n",
      "epoch: 1, loss: 4.804, avg: 2.03, latest lr: 6.64e-05\n",
      "epoch: 1, loss: 5.604, avg: 2.03, latest lr: 6.638571428571428e-05\n",
      "epoch: 1, loss: 4.953, avg: 2.03, latest lr: 6.637142857142857e-05\n",
      "epoch: 1, loss: 4.803, avg: 2.04, latest lr: 6.635714285714287e-05\n",
      "epoch: 1, loss: 4.177, avg: 2.04, latest lr: 6.634285714285715e-05\n",
      "epoch: 1, loss: 4.591, avg: 2.04, latest lr: 6.632857142857143e-05\n",
      "epoch: 1, loss: 5.636, avg: 2.04, latest lr: 6.631428571428572e-05\n",
      "epoch: 1, loss: 4.167, avg: 2.04, latest lr: 6.630000000000001e-05\n",
      "epoch: 1, loss: 4.399, avg: 2.04, latest lr: 6.628571428571428e-05\n",
      "epoch: 1, loss: 5.668, avg: 2.04, latest lr: 6.627142857142858e-05\n",
      "epoch: 1, loss: 5.456, avg: 2.04, latest lr: 6.625714285714286e-05\n",
      "epoch: 1, loss: 5.111, avg: 2.04, latest lr: 6.624285714285715e-05\n",
      "epoch: 1, loss: 5.040, avg: 2.04, latest lr: 6.622857142857143e-05\n",
      "epoch: 1, loss: 4.694, avg: 2.04, latest lr: 6.621428571428571e-05\n",
      "epoch: 1, loss: 5.468, avg: 2.04, latest lr: 6.620000000000001e-05\n",
      "epoch: 1, loss: 5.311, avg: 2.04, latest lr: 6.618571428571428e-05\n",
      "epoch: 1, loss: 5.650, avg: 2.04, latest lr: 6.617142857142858e-05\n",
      "epoch: 1, loss: 3.420, avg: 2.05, latest lr: 6.615714285714286e-05\n",
      "epoch: 1, loss: 4.795, avg: 2.05, latest lr: 6.614285714285716e-05\n",
      "epoch: 1, loss: 4.937, avg: 2.05, latest lr: 6.612857142857143e-05\n",
      "epoch: 1, loss: 5.915, avg: 2.05, latest lr: 6.611428571428572e-05\n",
      "epoch: 1, loss: 5.684, avg: 2.05, latest lr: 6.610000000000001e-05\n",
      "epoch: 1, loss: 4.341, avg: 2.05, latest lr: 6.608571428571428e-05\n",
      "epoch: 1, loss: 6.157, avg: 2.05, latest lr: 6.607142857142857e-05\n",
      "epoch: 1, loss: 4.777, avg: 2.05, latest lr: 6.605714285714286e-05\n",
      "epoch: 1, loss: 3.654, avg: 2.05, latest lr: 6.604285714285715e-05\n",
      "epoch: 1, loss: 5.356, avg: 2.05, latest lr: 6.602857142857142e-05\n",
      "epoch: 1, loss: 5.821, avg: 2.05, latest lr: 6.601428571428572e-05\n",
      "epoch: 1, loss: 5.545, avg: 2.05, latest lr: 6.6e-05\n",
      "epoch: 1, loss: 5.154, avg: 2.05, latest lr: 6.598571428571429e-05\n",
      "epoch: 1, loss: 5.741, avg: 2.05, latest lr: 6.597142857142857e-05\n",
      "epoch: 1, loss: 4.347, avg: 2.06, latest lr: 6.595714285714286e-05\n",
      "epoch: 1, loss: 5.788, avg: 2.06, latest lr: 6.594285714285715e-05\n",
      "epoch: 1, loss: 5.830, avg: 2.06, latest lr: 6.592857142857142e-05\n",
      "epoch: 1, loss: 5.450, avg: 2.06, latest lr: 6.591428571428572e-05\n",
      "epoch: 1, loss: 5.627, avg: 2.06, latest lr: 6.59e-05\n",
      "epoch: 1, loss: 5.825, avg: 2.06, latest lr: 6.588571428571429e-05\n",
      "epoch: 1, loss: 4.728, avg: 2.06, latest lr: 6.587142857142857e-05\n",
      "epoch: 1, loss: 3.523, avg: 2.06, latest lr: 6.585714285714287e-05\n",
      "epoch: 1, loss: 5.664, avg: 2.06, latest lr: 6.584285714285715e-05\n",
      "epoch: 1, loss: 5.474, avg: 2.06, latest lr: 6.582857142857143e-05\n",
      "epoch: 1, loss: 4.900, avg: 2.06, latest lr: 6.581428571428572e-05\n",
      "epoch: 1, loss: 3.788, avg: 2.06, latest lr: 6.58e-05\n",
      "epoch: 1, loss: 4.752, avg: 2.06, latest lr: 6.578571428571428e-05\n",
      "epoch: 1, loss: 6.436, avg: 2.07, latest lr: 6.577142857142857e-05\n",
      "epoch: 1, loss: 5.185, avg: 2.07, latest lr: 6.575714285714286e-05\n",
      "epoch: 1, loss: 3.656, avg: 2.07, latest lr: 6.574285714285715e-05\n",
      "epoch: 1, loss: 5.107, avg: 2.07, latest lr: 6.572857142857143e-05\n",
      "epoch: 1, loss: 4.474, avg: 2.07, latest lr: 6.571428571428571e-05\n",
      "epoch: 1, loss: 5.525, avg: 2.07, latest lr: 6.570000000000001e-05\n",
      "epoch: 1, loss: 4.091, avg: 2.07, latest lr: 6.568571428571428e-05\n",
      "epoch: 1, loss: 5.151, avg: 2.07, latest lr: 6.567142857142858e-05\n",
      "epoch: 1, loss: 5.006, avg: 2.07, latest lr: 6.565714285714286e-05\n",
      "epoch: 1, loss: 3.503, avg: 2.07, latest lr: 6.564285714285715e-05\n",
      "epoch: 1, loss: 3.929, avg: 2.07, latest lr: 6.562857142857143e-05\n",
      "epoch: 1, loss: 4.363, avg: 2.07, latest lr: 6.561428571428571e-05\n",
      "epoch: 1, loss: 4.903, avg: 2.07, latest lr: 6.560000000000001e-05\n",
      "epoch: 1, loss: 5.462, avg: 2.07, latest lr: 6.558571428571428e-05\n",
      "epoch: 1, loss: 4.557, avg: 2.07, latest lr: 6.557142857142858e-05\n",
      "epoch: 1, loss: 4.939, avg: 2.08, latest lr: 6.555714285714286e-05\n",
      "epoch: 1, loss: 5.354, avg: 2.08, latest lr: 6.554285714285716e-05\n",
      "epoch: 1, loss: 5.803, avg: 2.08, latest lr: 6.552857142857143e-05\n",
      "epoch: 1, loss: 4.789, avg: 2.08, latest lr: 6.551428571428572e-05\n",
      "epoch: 1, loss: 5.621, avg: 2.08, latest lr: 6.55e-05\n",
      "epoch: 1, loss: 6.207, avg: 2.08, latest lr: 6.548571428571429e-05\n",
      "epoch: 1, loss: 5.789, avg: 2.08, latest lr: 6.547142857142857e-05\n",
      "epoch: 1, loss: 5.530, avg: 2.08, latest lr: 6.545714285714286e-05\n",
      "epoch: 1, loss: 5.227, avg: 2.08, latest lr: 6.544285714285715e-05\n",
      "epoch: 1, loss: 4.562, avg: 2.08, latest lr: 6.542857142857142e-05\n",
      "epoch: 1, loss: 4.693, avg: 2.08, latest lr: 6.541428571428572e-05\n",
      "epoch: 1, loss: 4.157, avg: 2.08, latest lr: 6.54e-05\n",
      "epoch: 1, loss: 5.310, avg: 2.08, latest lr: 6.538571428571429e-05\n",
      "epoch: 1, loss: 5.090, avg: 2.08, latest lr: 6.537142857142857e-05\n",
      "epoch: 1, loss: 5.431, avg: 2.09, latest lr: 6.535714285714287e-05\n",
      "epoch: 1, loss: 4.501, avg: 2.09, latest lr: 6.534285714285715e-05\n",
      "epoch: 1, loss: 7.034, avg: 2.09, latest lr: 6.532857142857142e-05\n",
      "epoch: 1, loss: 5.711, avg: 2.09, latest lr: 6.531428571428572e-05\n",
      "epoch: 1, loss: 4.115, avg: 2.09, latest lr: 6.53e-05\n",
      "epoch: 1, loss: 4.525, avg: 2.09, latest lr: 6.528571428571429e-05\n",
      "epoch: 1, loss: 5.237, avg: 2.09, latest lr: 6.527142857142857e-05\n",
      "epoch: 1, loss: 5.392, avg: 2.09, latest lr: 6.525714285714287e-05\n",
      "epoch: 1, loss: 5.952, avg: 2.09, latest lr: 6.524285714285715e-05\n",
      "epoch: 1, loss: 5.352, avg: 2.09, latest lr: 6.522857142857143e-05\n",
      "epoch: 1, loss: 4.670, avg: 2.09, latest lr: 6.521428571428572e-05\n",
      "epoch: 1, loss: 5.472, avg: 2.09, latest lr: 6.52e-05\n",
      "epoch: 1, loss: 6.021, avg: 2.09, latest lr: 6.518571428571428e-05\n",
      "epoch: 1, loss: 6.123, avg: 2.10, latest lr: 6.517142857142857e-05\n",
      "epoch: 1, loss: 4.900, avg: 2.10, latest lr: 6.515714285714286e-05\n",
      "epoch: 1, loss: 5.137, avg: 2.10, latest lr: 6.514285714285715e-05\n",
      "epoch: 1, loss: 4.980, avg: 2.10, latest lr: 6.512857142857143e-05\n",
      "epoch: 1, loss: 5.000, avg: 2.10, latest lr: 6.511428571428571e-05\n",
      "epoch: 1, loss: 7.717, avg: 2.10, latest lr: 6.510000000000001e-05\n",
      "epoch: 1, loss: 5.747, avg: 2.10, latest lr: 6.50857142857143e-05\n",
      "epoch: 1, loss: 3.886, avg: 2.10, latest lr: 6.507142857142858e-05\n",
      "epoch: 1, loss: 6.428, avg: 2.10, latest lr: 6.505714285714286e-05\n",
      "epoch: 1, loss: 4.792, avg: 2.10, latest lr: 6.504285714285714e-05\n",
      "epoch: 1, loss: 4.918, avg: 2.10, latest lr: 6.502857142857143e-05\n",
      "epoch: 1, loss: 4.274, avg: 2.10, latest lr: 6.501428571428571e-05\n",
      "epoch: 1, loss: 5.275, avg: 2.10, latest lr: 6.500000000000001e-05\n",
      "epoch: 1, loss: 4.292, avg: 2.11, latest lr: 6.498571428571429e-05\n",
      "epoch: 1, loss: 5.592, avg: 2.11, latest lr: 6.497142857142857e-05\n",
      "epoch: 1, loss: 5.629, avg: 2.11, latest lr: 6.495714285714286e-05\n",
      "epoch: 1, loss: 5.059, avg: 2.11, latest lr: 6.494285714285716e-05\n",
      "epoch: 1, loss: 5.314, avg: 2.11, latest lr: 6.492857142857143e-05\n",
      "epoch: 1, loss: 6.527, avg: 2.11, latest lr: 6.491428571428572e-05\n",
      "epoch: 1, loss: 4.367, avg: 2.11, latest lr: 6.49e-05\n",
      "epoch: 1, loss: 4.246, avg: 2.11, latest lr: 6.488571428571429e-05\n",
      "epoch: 1, loss: 5.413, avg: 2.11, latest lr: 6.487142857142857e-05\n",
      "epoch: 1, loss: 4.901, avg: 2.11, latest lr: 6.485714285714286e-05\n",
      "epoch: 1, loss: 4.013, avg: 2.11, latest lr: 6.484285714285715e-05\n",
      "epoch: 1, loss: 4.977, avg: 2.11, latest lr: 6.482857142857142e-05\n",
      "epoch: 1, loss: 5.628, avg: 2.11, latest lr: 6.481428571428572e-05\n",
      "epoch: 1, loss: 5.528, avg: 2.11, latest lr: 6.48e-05\n",
      "epoch: 1, loss: 5.471, avg: 2.12, latest lr: 6.47857142857143e-05\n",
      "epoch: 1, loss: 4.880, avg: 2.12, latest lr: 6.477142857142857e-05\n",
      "epoch: 1, loss: 4.489, avg: 2.12, latest lr: 6.475714285714287e-05\n",
      "epoch: 1, loss: 5.903, avg: 2.12, latest lr: 6.474285714285715e-05\n",
      "epoch: 1, loss: 5.613, avg: 2.12, latest lr: 6.472857142857143e-05\n",
      "epoch: 1, loss: 4.458, avg: 2.12, latest lr: 6.471428571428572e-05\n",
      "epoch: 1, loss: 5.352, avg: 2.12, latest lr: 6.47e-05\n",
      "epoch: 1, loss: 4.699, avg: 2.12, latest lr: 6.46857142857143e-05\n",
      "epoch: 1, loss: 6.079, avg: 2.12, latest lr: 6.467142857142857e-05\n",
      "epoch: 1, loss: 5.970, avg: 2.12, latest lr: 6.465714285714286e-05\n",
      "epoch: 1, loss: 5.360, avg: 2.12, latest lr: 6.464285714285715e-05\n",
      "epoch: 1, loss: 5.124, avg: 2.12, latest lr: 6.462857142857143e-05\n",
      "epoch: 1, loss: 4.658, avg: 2.12, latest lr: 6.461428571428571e-05\n",
      "epoch: 1, loss: 5.229, avg: 2.13, latest lr: 6.460000000000001e-05\n",
      "epoch: 1, loss: 6.355, avg: 2.13, latest lr: 6.45857142857143e-05\n",
      "epoch: 1, loss: 3.992, avg: 2.13, latest lr: 6.457142857142856e-05\n",
      "epoch: 1, loss: 4.333, avg: 2.13, latest lr: 6.455714285714286e-05\n",
      "epoch: 1, loss: 2.542, avg: 2.13, latest lr: 6.454285714285715e-05\n",
      "epoch: 1, loss: 5.973, avg: 2.13, latest lr: 6.452857142857143e-05\n",
      "epoch: 1, loss: 5.300, avg: 2.13, latest lr: 6.451428571428571e-05\n",
      "epoch: 1, loss: 6.049, avg: 2.13, latest lr: 6.450000000000001e-05\n",
      "epoch: 1, loss: 6.665, avg: 2.13, latest lr: 6.448571428571429e-05\n",
      "epoch: 1, loss: 4.522, avg: 2.13, latest lr: 6.447142857142858e-05\n",
      "epoch: 1, loss: 5.423, avg: 2.13, latest lr: 6.445714285714286e-05\n",
      "epoch: 1, loss: 4.011, avg: 2.13, latest lr: 6.444285714285714e-05\n",
      "epoch: 1, loss: 5.277, avg: 2.13, latest lr: 6.442857142857143e-05\n",
      "epoch: 1, loss: 6.019, avg: 2.13, latest lr: 6.441428571428571e-05\n",
      "epoch: 1, loss: 4.332, avg: 2.14, latest lr: 6.440000000000001e-05\n",
      "epoch: 1, loss: 3.995, avg: 2.14, latest lr: 6.438571428571429e-05\n",
      "epoch: 1, loss: 4.386, avg: 2.14, latest lr: 6.437142857142857e-05\n",
      "epoch: 1, loss: 5.098, avg: 2.14, latest lr: 6.435714285714286e-05\n",
      "epoch: 1, loss: 3.966, avg: 2.14, latest lr: 6.434285714285715e-05\n",
      "epoch: 1, loss: 6.320, avg: 2.14, latest lr: 6.432857142857142e-05\n",
      "epoch: 1, loss: 4.619, avg: 2.14, latest lr: 6.431428571428572e-05\n",
      "epoch: 1, loss: 4.174, avg: 2.14, latest lr: 6.43e-05\n",
      "epoch: 1, loss: 5.765, avg: 2.14, latest lr: 6.428571428571429e-05\n",
      "epoch: 1, loss: 4.671, avg: 2.14, latest lr: 6.427142857142857e-05\n",
      "epoch: 1, loss: 4.875, avg: 2.14, latest lr: 6.425714285714285e-05\n",
      "epoch: 1, loss: 6.185, avg: 2.14, latest lr: 6.424285714285715e-05\n",
      "epoch: 1, loss: 4.461, avg: 2.14, latest lr: 6.422857142857142e-05\n",
      "epoch: 1, loss: 4.637, avg: 2.14, latest lr: 6.421428571428572e-05\n",
      "epoch: 1, loss: 4.239, avg: 2.15, latest lr: 6.42e-05\n",
      "epoch: 1, loss: 4.346, avg: 2.15, latest lr: 6.41857142857143e-05\n",
      "epoch: 1, loss: 3.901, avg: 2.15, latest lr: 6.417142857142857e-05\n",
      "epoch: 1, loss: 4.777, avg: 2.15, latest lr: 6.415714285714287e-05\n",
      "epoch: 1, loss: 4.593, avg: 2.15, latest lr: 6.414285714285715e-05\n",
      "epoch: 1, loss: 6.231, avg: 2.15, latest lr: 6.412857142857143e-05\n",
      "epoch: 1, loss: 5.952, avg: 2.15, latest lr: 6.411428571428572e-05\n",
      "epoch: 1, loss: 4.366, avg: 2.15, latest lr: 6.41e-05\n",
      "epoch: 1, loss: 4.130, avg: 2.15, latest lr: 6.40857142857143e-05\n",
      "epoch: 1, loss: 4.790, avg: 2.15, latest lr: 6.407142857142857e-05\n",
      "epoch: 1, loss: 4.905, avg: 2.15, latest lr: 6.405714285714286e-05\n",
      "epoch: 1, loss: 5.342, avg: 2.15, latest lr: 6.404285714285715e-05\n",
      "epoch: 1, loss: 5.679, avg: 2.15, latest lr: 6.402857142857143e-05\n",
      "epoch: 1, loss: 5.206, avg: 2.15, latest lr: 6.401428571428571e-05\n",
      "epoch: 1, loss: 4.701, avg: 2.15, latest lr: 6.400000000000001e-05\n",
      "epoch: 1, loss: 4.913, avg: 2.16, latest lr: 6.39857142857143e-05\n",
      "epoch: 1, loss: 4.504, avg: 2.16, latest lr: 6.397142857142858e-05\n",
      "epoch: 1, loss: 5.514, avg: 2.16, latest lr: 6.395714285714286e-05\n",
      "epoch: 1, loss: 5.418, avg: 2.16, latest lr: 6.394285714285714e-05\n",
      "epoch: 1, loss: 3.964, avg: 2.16, latest lr: 6.392857142857143e-05\n",
      "epoch: 1, loss: 5.119, avg: 2.16, latest lr: 6.391428571428571e-05\n",
      "epoch: 1, loss: 5.620, avg: 2.16, latest lr: 6.390000000000001e-05\n",
      "epoch: 1, loss: 5.407, avg: 2.16, latest lr: 6.388571428571429e-05\n",
      "epoch: 1, loss: 4.697, avg: 2.16, latest lr: 6.387142857142858e-05\n",
      "epoch: 1, loss: 4.305, avg: 2.16, latest lr: 6.385714285714286e-05\n",
      "epoch: 1, loss: 4.416, avg: 2.16, latest lr: 6.384285714285714e-05\n",
      "epoch: 1, loss: 5.156, avg: 2.16, latest lr: 6.382857142857143e-05\n",
      "epoch: 1, loss: 4.892, avg: 2.16, latest lr: 6.381428571428571e-05\n",
      "epoch: 1, loss: 4.803, avg: 2.16, latest lr: 6.38e-05\n",
      "epoch: 1, loss: 3.795, avg: 2.17, latest lr: 6.378571428571429e-05\n",
      "epoch: 1, loss: 4.237, avg: 2.17, latest lr: 6.377142857142857e-05\n",
      "epoch: 1, loss: 5.173, avg: 2.17, latest lr: 6.375714285714286e-05\n",
      "epoch: 1, loss: 4.576, avg: 2.17, latest lr: 6.374285714285715e-05\n",
      "epoch: 1, loss: 6.010, avg: 2.17, latest lr: 6.372857142857142e-05\n",
      "epoch: 1, loss: 4.776, avg: 2.17, latest lr: 6.371428571428572e-05\n",
      "epoch: 1, loss: 4.280, avg: 2.17, latest lr: 6.37e-05\n",
      "epoch: 1, loss: 4.951, avg: 2.17, latest lr: 6.368571428571429e-05\n",
      "epoch: 1, loss: 4.868, avg: 2.17, latest lr: 6.367142857142857e-05\n",
      "epoch: 1, loss: 5.046, avg: 2.17, latest lr: 6.365714285714285e-05\n",
      "epoch: 1, loss: 5.231, avg: 2.17, latest lr: 6.364285714285715e-05\n",
      "epoch: 1, loss: 6.085, avg: 2.17, latest lr: 6.362857142857142e-05\n",
      "epoch: 1, loss: 4.720, avg: 2.17, latest lr: 6.361428571428572e-05\n",
      "epoch: 1, loss: 6.099, avg: 2.17, latest lr: 6.36e-05\n",
      "epoch: 1, loss: 4.080, avg: 2.18, latest lr: 6.35857142857143e-05\n",
      "epoch: 1, loss: 6.431, avg: 2.18, latest lr: 6.357142857142857e-05\n",
      "epoch: 1, loss: 5.994, avg: 2.18, latest lr: 6.355714285714286e-05\n",
      "epoch: 1, loss: 4.977, avg: 2.18, latest lr: 6.354285714285715e-05\n",
      "epoch: 1, loss: 3.964, avg: 2.18, latest lr: 6.352857142857143e-05\n",
      "epoch: 1, loss: 3.649, avg: 2.18, latest lr: 6.351428571428572e-05\n",
      "epoch: 1, loss: 5.344, avg: 2.18, latest lr: 6.35e-05\n",
      "epoch: 1, loss: 4.474, avg: 2.18, latest lr: 6.34857142857143e-05\n",
      "epoch: 1, loss: 5.385, avg: 2.18, latest lr: 6.347142857142857e-05\n",
      "epoch: 1, loss: 4.356, avg: 2.18, latest lr: 6.345714285714286e-05\n",
      "epoch: 1, loss: 5.463, avg: 2.18, latest lr: 6.344285714285715e-05\n",
      "epoch: 1, loss: 4.544, avg: 2.18, latest lr: 6.342857142857143e-05\n",
      "epoch: 1, loss: 5.006, avg: 2.18, latest lr: 6.341428571428571e-05\n",
      "epoch: 1, loss: 5.308, avg: 2.18, latest lr: 6.340000000000001e-05\n",
      "epoch: 1, loss: 5.641, avg: 2.19, latest lr: 6.338571428571429e-05\n",
      "epoch: 1, loss: 5.235, avg: 2.19, latest lr: 6.337142857142858e-05\n",
      "epoch: 1, loss: 3.219, avg: 2.19, latest lr: 6.335714285714286e-05\n",
      "epoch: 1, loss: 4.949, avg: 2.19, latest lr: 6.334285714285714e-05\n",
      "epoch: 1, loss: 4.931, avg: 2.19, latest lr: 6.332857142857144e-05\n",
      "epoch: 1, loss: 5.762, avg: 2.19, latest lr: 6.331428571428571e-05\n",
      "epoch: 1, loss: 5.039, avg: 2.19, latest lr: 6.330000000000001e-05\n",
      "epoch: 1, loss: 3.833, avg: 2.19, latest lr: 6.328571428571429e-05\n",
      "epoch: 1, loss: 4.763, avg: 2.19, latest lr: 6.327142857142857e-05\n",
      "epoch: 1, loss: 4.755, avg: 2.19, latest lr: 6.325714285714286e-05\n",
      "epoch: 1, loss: 4.625, avg: 2.19, latest lr: 6.324285714285715e-05\n",
      "epoch: 1, loss: 5.098, avg: 2.19, latest lr: 6.322857142857144e-05\n",
      "epoch: 1, loss: 7.040, avg: 2.19, latest lr: 6.321428571428572e-05\n",
      "epoch: 1, loss: 5.569, avg: 2.19, latest lr: 6.32e-05\n",
      "epoch: 1, loss: 6.764, avg: 2.20, latest lr: 6.318571428571429e-05\n",
      "epoch: 1, loss: 4.018, avg: 2.20, latest lr: 6.317142857142857e-05\n",
      "epoch: 1, loss: 4.148, avg: 2.20, latest lr: 6.315714285714286e-05\n",
      "epoch: 1, loss: 5.586, avg: 2.20, latest lr: 6.314285714285715e-05\n",
      "epoch: 1, loss: 5.278, avg: 2.20, latest lr: 6.312857142857144e-05\n",
      "epoch: 1, loss: 4.745, avg: 2.20, latest lr: 6.311428571428572e-05\n",
      "epoch: 1, loss: 5.158, avg: 2.20, latest lr: 6.31e-05\n",
      "epoch: 1, loss: 6.905, avg: 2.20, latest lr: 6.308571428571429e-05\n",
      "epoch: 1, loss: 5.941, avg: 2.20, latest lr: 6.307142857142857e-05\n",
      "epoch: 1, loss: 7.156, avg: 2.20, latest lr: 6.305714285714285e-05\n",
      "epoch: 1, loss: 4.120, avg: 2.20, latest lr: 6.304285714285715e-05\n",
      "epoch: 1, loss: 4.032, avg: 2.20, latest lr: 6.302857142857143e-05\n",
      "epoch: 1, loss: 3.460, avg: 2.20, latest lr: 6.301428571428572e-05\n",
      "epoch: 1, loss: 4.862, avg: 2.20, latest lr: 6.3e-05\n",
      "epoch: 1, loss: 4.116, avg: 2.21, latest lr: 6.29857142857143e-05\n",
      "epoch: 1, loss: 4.236, avg: 2.21, latest lr: 6.297142857142857e-05\n",
      "epoch: 1, loss: 3.537, avg: 2.21, latest lr: 6.295714285714286e-05\n",
      "epoch: 1, loss: 6.384, avg: 2.21, latest lr: 6.294285714285715e-05\n",
      "epoch: 1, loss: 6.156, avg: 2.21, latest lr: 6.292857142857143e-05\n",
      "epoch: 1, loss: 5.666, avg: 2.21, latest lr: 6.291428571428571e-05\n",
      "epoch: 1, loss: 5.840, avg: 2.21, latest lr: 6.29e-05\n",
      "epoch: 1, loss: 5.447, avg: 2.21, latest lr: 6.28857142857143e-05\n",
      "epoch: 1, loss: 6.155, avg: 2.21, latest lr: 6.287142857142856e-05\n",
      "epoch: 1, loss: 6.783, avg: 2.21, latest lr: 6.285714285714286e-05\n",
      "epoch: 1, loss: 3.929, avg: 2.21, latest lr: 6.284285714285714e-05\n",
      "epoch: 1, loss: 5.021, avg: 2.21, latest lr: 6.282857142857144e-05\n",
      "epoch: 1, loss: 6.005, avg: 2.21, latest lr: 6.281428571428571e-05\n",
      "epoch: 1, loss: 4.894, avg: 2.22, latest lr: 6.280000000000001e-05\n",
      "epoch: 1, loss: 7.175, avg: 2.22, latest lr: 6.278571428571429e-05\n",
      "epoch: 1, loss: 5.573, avg: 2.22, latest lr: 6.277142857142858e-05\n",
      "epoch: 1, loss: 4.477, avg: 2.22, latest lr: 6.275714285714286e-05\n",
      "epoch: 1, loss: 6.238, avg: 2.22, latest lr: 6.274285714285714e-05\n",
      "epoch: 1, loss: 6.733, avg: 2.22, latest lr: 6.272857142857144e-05\n",
      "epoch: 1, loss: 3.943, avg: 2.22, latest lr: 6.271428571428571e-05\n",
      "epoch: 1, loss: 5.093, avg: 2.22, latest lr: 6.27e-05\n",
      "epoch: 1, loss: 5.972, avg: 2.22, latest lr: 6.268571428571429e-05\n",
      "epoch: 1, loss: 3.502, avg: 2.22, latest lr: 6.267142857142857e-05\n",
      "epoch: 1, loss: 3.520, avg: 2.22, latest lr: 6.265714285714286e-05\n",
      "epoch: 1, loss: 4.861, avg: 2.22, latest lr: 6.264285714285715e-05\n",
      "epoch: 1, loss: 5.382, avg: 2.22, latest lr: 6.262857142857144e-05\n",
      "epoch: 1, loss: 4.335, avg: 2.23, latest lr: 6.261428571428572e-05\n",
      "epoch: 1, loss: 3.696, avg: 2.23, latest lr: 6.26e-05\n",
      "epoch: 1, loss: 4.974, avg: 2.23, latest lr: 6.258571428571429e-05\n",
      "epoch: 1, loss: 5.304, avg: 2.23, latest lr: 6.257142857142857e-05\n",
      "epoch: 1, loss: 6.080, avg: 2.23, latest lr: 6.255714285714285e-05\n",
      "epoch: 1, loss: 4.819, avg: 2.23, latest lr: 6.254285714285715e-05\n",
      "epoch: 1, loss: 5.543, avg: 2.23, latest lr: 6.252857142857143e-05\n",
      "epoch: 1, loss: 4.055, avg: 2.23, latest lr: 6.251428571428572e-05\n",
      "epoch: 1, loss: 5.158, avg: 2.23, latest lr: 6.25e-05\n",
      "epoch: 1, loss: 5.479, avg: 2.23, latest lr: 6.24857142857143e-05\n",
      "epoch: 1, loss: 5.479, avg: 2.23, latest lr: 6.247142857142857e-05\n",
      "epoch: 1, loss: 4.909, avg: 2.23, latest lr: 6.245714285714287e-05\n",
      "epoch: 1, loss: 5.998, avg: 2.23, latest lr: 6.244285714285715e-05\n",
      "epoch: 1, loss: 5.185, avg: 2.23, latest lr: 6.242857142857143e-05\n",
      "epoch: 1, loss: 5.279, avg: 2.24, latest lr: 6.241428571428572e-05\n",
      "epoch: 1, loss: 4.483, avg: 2.24, latest lr: 6.24e-05\n",
      "epoch: 1, loss: 5.717, avg: 2.24, latest lr: 6.23857142857143e-05\n",
      "epoch: 1, loss: 5.933, avg: 2.24, latest lr: 6.237142857142857e-05\n",
      "epoch: 1, loss: 5.938, avg: 2.24, latest lr: 6.235714285714286e-05\n",
      "epoch: 1, loss: 5.398, avg: 2.24, latest lr: 6.234285714285715e-05\n",
      "epoch: 1, loss: 5.847, avg: 2.24, latest lr: 6.232857142857143e-05\n",
      "epoch: 1, loss: 4.208, avg: 2.24, latest lr: 6.231428571428571e-05\n",
      "epoch: 1, loss: 6.278, avg: 2.24, latest lr: 6.23e-05\n",
      "epoch: 1, loss: 5.149, avg: 2.24, latest lr: 6.22857142857143e-05\n",
      "epoch: 1, loss: 5.167, avg: 2.24, latest lr: 6.227142857142856e-05\n",
      "epoch: 1, loss: 4.526, avg: 2.24, latest lr: 6.225714285714286e-05\n",
      "epoch: 1, loss: 4.270, avg: 2.24, latest lr: 6.224285714285714e-05\n",
      "epoch: 1, loss: 4.923, avg: 2.25, latest lr: 6.222857142857144e-05\n",
      "epoch: 1, loss: 4.201, avg: 2.25, latest lr: 6.221428571428571e-05\n",
      "epoch: 1, loss: 4.827, avg: 2.25, latest lr: 6.220000000000001e-05\n",
      "epoch: 1, loss: 5.307, avg: 2.25, latest lr: 6.218571428571429e-05\n",
      "epoch: 1, loss: 5.101, avg: 2.25, latest lr: 6.217142857142857e-05\n",
      "epoch: 1, loss: 6.304, avg: 2.25, latest lr: 6.215714285714286e-05\n",
      "epoch: 1, loss: 6.452, avg: 2.25, latest lr: 6.214285714285714e-05\n",
      "epoch: 1, loss: 4.946, avg: 2.25, latest lr: 6.212857142857144e-05\n",
      "epoch: 1, loss: 5.246, avg: 2.25, latest lr: 6.211428571428571e-05\n",
      "epoch: 1, loss: 5.719, avg: 2.25, latest lr: 6.21e-05\n",
      "epoch: 1, loss: 5.028, avg: 2.25, latest lr: 6.208571428571429e-05\n",
      "epoch: 1, loss: 5.859, avg: 2.25, latest lr: 6.207142857142857e-05\n",
      "epoch: 1, loss: 6.815, avg: 2.25, latest lr: 6.205714285714286e-05\n",
      "epoch: 1, loss: 4.135, avg: 2.25, latest lr: 6.204285714285715e-05\n",
      "epoch: 1, loss: 5.934, avg: 2.26, latest lr: 6.202857142857144e-05\n",
      "epoch: 1, loss: 4.779, avg: 2.26, latest lr: 6.201428571428572e-05\n",
      "epoch: 1, loss: 5.985, avg: 2.26, latest lr: 6.2e-05\n",
      "epoch: 1, loss: 4.120, avg: 2.26, latest lr: 6.198571428571429e-05\n",
      "epoch: 1, loss: 5.341, avg: 2.26, latest lr: 6.197142857142857e-05\n",
      "epoch: 1, loss: 4.930, avg: 2.26, latest lr: 6.195714285714285e-05\n",
      "epoch: 1, loss: 6.097, avg: 2.26, latest lr: 6.194285714285715e-05\n",
      "epoch: 1, loss: 5.151, avg: 2.26, latest lr: 6.192857142857143e-05\n",
      "epoch: 1, loss: 4.921, avg: 2.26, latest lr: 6.191428571428572e-05\n",
      "epoch: 1, loss: 3.759, avg: 2.26, latest lr: 6.19e-05\n",
      "epoch: 1, loss: 5.390, avg: 2.26, latest lr: 6.18857142857143e-05\n",
      "epoch: 1, loss: 4.700, avg: 2.26, latest lr: 6.187142857142857e-05\n",
      "epoch: 1, loss: 5.715, avg: 2.26, latest lr: 6.185714285714286e-05\n",
      "epoch: 1, loss: 4.350, avg: 2.27, latest lr: 6.184285714285715e-05\n",
      "epoch: 1, loss: 4.014, avg: 2.27, latest lr: 6.182857142857143e-05\n",
      "epoch: 1, loss: 6.693, avg: 2.27, latest lr: 6.181428571428571e-05\n",
      "epoch: 1, loss: 5.933, avg: 2.27, latest lr: 6.18e-05\n",
      "epoch: 1, loss: 5.131, avg: 2.27, latest lr: 6.17857142857143e-05\n",
      "epoch: 1, loss: 3.699, avg: 2.27, latest lr: 6.177142857142856e-05\n",
      "epoch: 1, loss: 5.569, avg: 2.27, latest lr: 6.175714285714286e-05\n",
      "epoch: 1, loss: 5.093, avg: 2.27, latest lr: 6.174285714285715e-05\n",
      "epoch: 1, loss: 4.990, avg: 2.27, latest lr: 6.172857142857144e-05\n",
      "epoch: 1, loss: 6.613, avg: 2.27, latest lr: 6.171428571428571e-05\n",
      "epoch: 1, loss: 5.128, avg: 2.27, latest lr: 6.170000000000001e-05\n",
      "epoch: 1, loss: 5.180, avg: 2.27, latest lr: 6.168571428571429e-05\n",
      "epoch: 1, loss: 5.812, avg: 2.27, latest lr: 6.167142857142856e-05\n",
      "epoch: 1, loss: 5.065, avg: 2.28, latest lr: 6.165714285714286e-05\n",
      "epoch: 1, loss: 4.240, avg: 2.28, latest lr: 6.164285714285714e-05\n",
      "epoch: 1, loss: 4.913, avg: 2.28, latest lr: 6.162857142857144e-05\n",
      "epoch: 1, loss: 4.201, avg: 2.28, latest lr: 6.161428571428571e-05\n",
      "epoch: 1, loss: 3.818, avg: 2.28, latest lr: 6.16e-05\n",
      "epoch: 1, loss: 5.946, avg: 2.28, latest lr: 6.158571428571429e-05\n",
      "epoch: 1, loss: 5.334, avg: 2.28, latest lr: 6.157142857142857e-05\n",
      "epoch: 1, loss: 5.690, avg: 2.28, latest lr: 6.155714285714286e-05\n",
      "epoch: 1, loss: 5.123, avg: 2.28, latest lr: 6.154285714285714e-05\n",
      "epoch: 1, loss: 5.199, avg: 2.28, latest lr: 6.152857142857144e-05\n",
      "epoch: 1, loss: 5.333, avg: 2.28, latest lr: 6.151428571428571e-05\n",
      "epoch: 1, loss: 5.915, avg: 2.28, latest lr: 6.15e-05\n",
      "epoch: 1, loss: 5.656, avg: 2.28, latest lr: 6.148571428571429e-05\n",
      "epoch: 1, loss: 4.013, avg: 2.28, latest lr: 6.147142857142858e-05\n",
      "epoch: 1, loss: 5.276, avg: 2.29, latest lr: 6.145714285714285e-05\n",
      "epoch: 1, loss: 4.202, avg: 2.29, latest lr: 6.144285714285715e-05\n",
      "epoch: 1, loss: 4.619, avg: 2.29, latest lr: 6.142857142857143e-05\n",
      "epoch: 1, loss: 4.827, avg: 2.29, latest lr: 6.141428571428572e-05\n",
      "epoch: 1, loss: 4.944, avg: 2.29, latest lr: 6.14e-05\n",
      "epoch: 1, loss: 4.800, avg: 2.29, latest lr: 6.138571428571429e-05\n",
      "epoch: 1, loss: 3.766, avg: 2.29, latest lr: 6.137142857142858e-05\n",
      "epoch: 1, loss: 4.456, avg: 2.29, latest lr: 6.135714285714285e-05\n",
      "epoch: 1, loss: 4.174, avg: 2.29, latest lr: 6.134285714285715e-05\n",
      "epoch: 1, loss: 4.422, avg: 2.29, latest lr: 6.132857142857143e-05\n",
      "epoch: 1, loss: 5.772, avg: 2.29, latest lr: 6.131428571428572e-05\n",
      "epoch: 1, loss: 4.808, avg: 2.29, latest lr: 6.13e-05\n",
      "epoch: 1, loss: 5.846, avg: 2.29, latest lr: 6.12857142857143e-05\n",
      "epoch: 1, loss: 5.779, avg: 2.29, latest lr: 6.127142857142858e-05\n",
      "epoch: 1, loss: 4.137, avg: 2.29, latest lr: 6.125714285714286e-05\n",
      "epoch: 1, loss: 3.684, avg: 2.30, latest lr: 6.124285714285715e-05\n",
      "epoch: 1, loss: 4.526, avg: 2.30, latest lr: 6.122857142857143e-05\n",
      "epoch: 1, loss: 5.447, avg: 2.30, latest lr: 6.121428571428571e-05\n",
      "epoch: 1, loss: 5.058, avg: 2.30, latest lr: 6.12e-05\n",
      "epoch: 1, loss: 4.478, avg: 2.30, latest lr: 6.11857142857143e-05\n",
      "epoch: 1, loss: 4.520, avg: 2.30, latest lr: 6.117142857142858e-05\n",
      "epoch: 1, loss: 5.127, avg: 2.30, latest lr: 6.115714285714286e-05\n",
      "epoch: 1, loss: 6.804, avg: 2.30, latest lr: 6.114285714285714e-05\n",
      "epoch: 1, loss: 4.643, avg: 2.30, latest lr: 6.112857142857144e-05\n",
      "epoch: 1, loss: 6.076, avg: 2.30, latest lr: 6.111428571428571e-05\n",
      "epoch: 1, loss: 6.705, avg: 2.30, latest lr: 6.110000000000001e-05\n",
      "epoch: 1, loss: 5.203, avg: 2.30, latest lr: 6.108571428571429e-05\n",
      "epoch: 1, loss: 5.902, avg: 2.30, latest lr: 6.107142857142857e-05\n",
      "epoch: 1, loss: 4.428, avg: 2.30, latest lr: 6.105714285714286e-05\n",
      "epoch: 1, loss: 4.811, avg: 2.31, latest lr: 6.104285714285714e-05\n",
      "epoch: 1, loss: 3.861, avg: 2.31, latest lr: 6.102857142857143e-05\n",
      "epoch: 1, loss: 4.325, avg: 2.31, latest lr: 6.1014285714285715e-05\n",
      "epoch: 1, loss: 5.737, avg: 2.31, latest lr: 6.1e-05\n",
      "epoch: 1, loss: 4.213, avg: 2.31, latest lr: 6.098571428571429e-05\n",
      "epoch: 1, loss: 4.848, avg: 2.31, latest lr: 6.097142857142858e-05\n",
      "epoch: 1, loss: 4.537, avg: 2.31, latest lr: 6.0957142857142856e-05\n",
      "epoch: 1, loss: 5.067, avg: 2.31, latest lr: 6.0942857142857146e-05\n",
      "epoch: 1, loss: 5.398, avg: 2.31, latest lr: 6.0928571428571436e-05\n",
      "epoch: 1, loss: 4.442, avg: 2.31, latest lr: 6.091428571428571e-05\n",
      "epoch: 1, loss: 4.289, avg: 2.31, latest lr: 6.09e-05\n",
      "epoch: 1, loss: 5.463, avg: 2.31, latest lr: 6.088571428571429e-05\n",
      "epoch: 1, loss: 4.518, avg: 2.31, latest lr: 6.087142857142858e-05\n",
      "epoch: 1, loss: 4.377, avg: 2.31, latest lr: 6.085714285714286e-05\n",
      "epoch: 1, loss: 5.471, avg: 2.32, latest lr: 6.0842857142857144e-05\n",
      "epoch: 1, loss: 5.616, avg: 2.32, latest lr: 6.0828571428571434e-05\n",
      "epoch: 1, loss: 5.463, avg: 2.32, latest lr: 6.081428571428571e-05\n",
      "epoch: 1, loss: 4.704, avg: 2.32, latest lr: 6.08e-05\n",
      "epoch: 1, loss: 4.575, avg: 2.32, latest lr: 6.078571428571429e-05\n",
      "epoch: 1, loss: 6.378, avg: 2.32, latest lr: 6.077142857142858e-05\n",
      "epoch: 1, loss: 5.292, avg: 2.32, latest lr: 6.075714285714286e-05\n",
      "epoch: 1, loss: 4.610, avg: 2.32, latest lr: 6.074285714285715e-05\n",
      "epoch: 1, loss: 5.301, avg: 2.32, latest lr: 6.072857142857143e-05\n",
      "epoch: 1, loss: 5.818, avg: 2.32, latest lr: 6.0714285714285715e-05\n",
      "epoch: 1, loss: 4.745, avg: 2.32, latest lr: 6.07e-05\n",
      "epoch: 1, loss: 4.890, avg: 2.32, latest lr: 6.068571428571429e-05\n",
      "epoch: 1, loss: 5.342, avg: 2.32, latest lr: 6.067142857142858e-05\n",
      "epoch: 1, loss: 5.892, avg: 2.32, latest lr: 6.0657142857142855e-05\n",
      "epoch: 1, loss: 5.173, avg: 2.33, latest lr: 6.0642857142857145e-05\n",
      "epoch: 1, loss: 4.260, avg: 2.33, latest lr: 6.0628571428571436e-05\n",
      "epoch: 1, loss: 5.452, avg: 2.33, latest lr: 6.061428571428571e-05\n",
      "epoch: 1, loss: 5.721, avg: 2.33, latest lr: 6.06e-05\n",
      "epoch: 1, loss: 5.667, avg: 2.33, latest lr: 6.058571428571429e-05\n",
      "epoch: 1, loss: 6.059, avg: 2.33, latest lr: 6.0571428571428576e-05\n",
      "epoch: 1, loss: 5.372, avg: 2.33, latest lr: 6.055714285714286e-05\n",
      "epoch: 1, loss: 6.651, avg: 2.33, latest lr: 6.054285714285714e-05\n",
      "epoch: 1, loss: 4.490, avg: 2.33, latest lr: 6.052857142857143e-05\n",
      "epoch: 1, loss: 6.579, avg: 2.33, latest lr: 6.051428571428571e-05\n",
      "epoch: 1, loss: 5.522, avg: 2.33, latest lr: 6.05e-05\n",
      "epoch: 1, loss: 4.518, avg: 2.33, latest lr: 6.048571428571429e-05\n",
      "epoch: 1, loss: 5.759, avg: 2.34, latest lr: 6.047142857142858e-05\n",
      "epoch: 1, loss: 5.809, avg: 2.34, latest lr: 6.045714285714286e-05\n",
      "epoch: 1, loss: 5.749, avg: 2.34, latest lr: 6.044285714285715e-05\n",
      "epoch: 1, loss: 6.417, avg: 2.34, latest lr: 6.042857142857144e-05\n",
      "epoch: 1, loss: 5.649, avg: 2.34, latest lr: 6.0414285714285714e-05\n",
      "epoch: 1, loss: 5.246, avg: 2.34, latest lr: 6.04e-05\n",
      "epoch: 1, loss: 5.435, avg: 2.34, latest lr: 6.038571428571429e-05\n",
      "epoch: 1, loss: 3.996, avg: 2.34, latest lr: 6.037142857142858e-05\n",
      "epoch: 1, loss: 4.666, avg: 2.34, latest lr: 6.0357142857142855e-05\n",
      "epoch: 1, loss: 5.473, avg: 2.34, latest lr: 6.0342857142857145e-05\n",
      "epoch: 1, loss: 5.759, avg: 2.34, latest lr: 6.0328571428571435e-05\n",
      "epoch: 1, loss: 4.426, avg: 2.34, latest lr: 6.031428571428571e-05\n",
      "epoch: 1, loss: 3.779, avg: 2.34, latest lr: 6.03e-05\n",
      "epoch: 1, loss: 5.293, avg: 2.34, latest lr: 6.028571428571429e-05\n",
      "epoch: 1, loss: 4.906, avg: 2.35, latest lr: 6.0271428571428576e-05\n",
      "epoch: 1, loss: 4.406, avg: 2.35, latest lr: 6.025714285714286e-05\n",
      "epoch: 1, loss: 4.368, avg: 2.35, latest lr: 6.024285714285714e-05\n",
      "epoch: 1, loss: 4.206, avg: 2.35, latest lr: 6.022857142857143e-05\n",
      "epoch: 1, loss: 4.772, avg: 2.35, latest lr: 6.021428571428571e-05\n",
      "epoch: 1, loss: 4.535, avg: 2.35, latest lr: 6.02e-05\n",
      "epoch: 1, loss: 4.658, avg: 2.35, latest lr: 6.018571428571429e-05\n",
      "epoch: 1, loss: 4.314, avg: 2.35, latest lr: 6.017142857142858e-05\n",
      "epoch: 1, loss: 5.606, avg: 2.35, latest lr: 6.015714285714286e-05\n",
      "epoch: 1, loss: 5.190, avg: 2.35, latest lr: 6.014285714285715e-05\n",
      "epoch: 1, loss: 5.812, avg: 2.35, latest lr: 6.012857142857144e-05\n",
      "epoch: 1, loss: 3.697, avg: 2.35, latest lr: 6.0114285714285714e-05\n",
      "epoch: 1, loss: 4.986, avg: 2.35, latest lr: 6.0100000000000004e-05\n",
      "epoch: 1, loss: 4.919, avg: 2.35, latest lr: 6.008571428571429e-05\n",
      "epoch: 1, loss: 4.499, avg: 2.35, latest lr: 6.007142857142858e-05\n",
      "epoch: 1, loss: 5.109, avg: 2.36, latest lr: 6.0057142857142854e-05\n",
      "epoch: 1, loss: 4.946, avg: 2.36, latest lr: 6.0042857142857144e-05\n",
      "epoch: 1, loss: 5.199, avg: 2.36, latest lr: 6.0028571428571435e-05\n",
      "epoch: 1, loss: 4.840, avg: 2.36, latest lr: 6.001428571428571e-05\n",
      "epoch: 1, loss: 5.534, avg: 2.36, latest lr: 6e-05\n",
      "epoch: 1, loss: 5.243, avg: 2.36, latest lr: 5.998571428571429e-05\n",
      "epoch: 1, loss: 4.467, avg: 2.36, latest lr: 5.9971428571428575e-05\n",
      "epoch: 1, loss: 4.670, avg: 2.36, latest lr: 5.995714285714286e-05\n",
      "epoch: 1, loss: 5.872, avg: 2.36, latest lr: 5.994285714285714e-05\n",
      "epoch: 1, loss: 4.408, avg: 2.36, latest lr: 5.992857142857143e-05\n",
      "epoch: 1, loss: 4.123, avg: 2.36, latest lr: 5.991428571428571e-05\n",
      "epoch: 1, loss: 4.933, avg: 2.36, latest lr: 5.99e-05\n",
      "epoch: 1, loss: 4.447, avg: 2.36, latest lr: 5.988571428571429e-05\n",
      "epoch: 1, loss: 5.522, avg: 2.36, latest lr: 5.987142857142858e-05\n",
      "epoch: 1, loss: 5.560, avg: 2.37, latest lr: 5.9857142857142856e-05\n",
      "epoch: 1, loss: 5.861, avg: 2.37, latest lr: 5.9842857142857146e-05\n",
      "epoch: 1, loss: 5.040, avg: 2.37, latest lr: 5.9828571428571437e-05\n",
      "epoch: 1, loss: 5.173, avg: 2.37, latest lr: 5.981428571428572e-05\n",
      "epoch: 1, loss: 5.162, avg: 2.37, latest lr: 5.9800000000000003e-05\n",
      "epoch: 1, loss: 4.872, avg: 2.37, latest lr: 5.978571428571429e-05\n",
      "epoch: 1, loss: 4.156, avg: 2.37, latest lr: 5.977142857142858e-05\n",
      "epoch: 1, loss: 3.862, avg: 2.37, latest lr: 5.9757142857142854e-05\n",
      "epoch: 1, loss: 4.578, avg: 2.37, latest lr: 5.9742857142857144e-05\n",
      "epoch: 1, loss: 5.829, avg: 2.37, latest lr: 5.9728571428571434e-05\n",
      "epoch: 1, loss: 5.433, avg: 2.37, latest lr: 5.9714285714285724e-05\n",
      "epoch: 1, loss: 5.228, avg: 2.37, latest lr: 5.97e-05\n",
      "epoch: 1, loss: 5.306, avg: 2.37, latest lr: 5.968571428571429e-05\n",
      "epoch: 1, loss: 4.923, avg: 2.37, latest lr: 5.967142857142858e-05\n",
      "epoch: 1, loss: 5.155, avg: 2.38, latest lr: 5.965714285714286e-05\n",
      "epoch: 1, loss: 4.495, avg: 2.38, latest lr: 5.964285714285714e-05\n",
      "epoch: 1, loss: 6.471, avg: 2.38, latest lr: 5.962857142857143e-05\n",
      "epoch: 1, loss: 4.589, avg: 2.38, latest lr: 5.961428571428572e-05\n",
      "epoch: 1, loss: 5.178, avg: 2.38, latest lr: 5.96e-05\n",
      "epoch: 1, loss: 5.709, avg: 2.38, latest lr: 5.958571428571429e-05\n",
      "epoch: 1, loss: 5.145, avg: 2.38, latest lr: 5.957142857142858e-05\n",
      "epoch: 1, loss: 5.137, avg: 2.38, latest lr: 5.9557142857142856e-05\n",
      "epoch: 1, loss: 4.829, avg: 2.38, latest lr: 5.9542857142857146e-05\n",
      "epoch: 1, loss: 5.017, avg: 2.38, latest lr: 5.9528571428571436e-05\n",
      "epoch: 1, loss: 4.462, avg: 2.38, latest lr: 5.951428571428572e-05\n",
      "epoch: 1, loss: 5.481, avg: 2.38, latest lr: 5.95e-05\n",
      "epoch: 1, loss: 5.119, avg: 2.38, latest lr: 5.9485714285714286e-05\n",
      "epoch: 1, loss: 5.051, avg: 2.39, latest lr: 5.9471428571428577e-05\n",
      "epoch: 1, loss: 4.471, avg: 2.39, latest lr: 5.945714285714285e-05\n",
      "epoch: 1, loss: 3.299, avg: 2.39, latest lr: 5.9442857142857143e-05\n",
      "epoch: 1, loss: 4.790, avg: 2.39, latest lr: 5.9428571428571434e-05\n",
      "epoch: 1, loss: 4.890, avg: 2.39, latest lr: 5.9414285714285724e-05\n",
      "epoch: 1, loss: 5.074, avg: 2.39, latest lr: 5.94e-05\n",
      "epoch: 1, loss: 4.269, avg: 2.39, latest lr: 5.938571428571429e-05\n",
      "epoch: 1, loss: 5.905, avg: 2.39, latest lr: 5.937142857142858e-05\n",
      "epoch: 1, loss: 5.255, avg: 2.39, latest lr: 5.935714285714286e-05\n",
      "epoch: 1, loss: 4.682, avg: 2.39, latest lr: 5.934285714285715e-05\n",
      "epoch: 1, loss: 3.218, avg: 2.39, latest lr: 5.932857142857143e-05\n",
      "epoch: 1, loss: 6.060, avg: 2.39, latest lr: 5.931428571428572e-05\n",
      "epoch: 1, loss: 4.503, avg: 2.39, latest lr: 5.93e-05\n",
      "epoch: 1, loss: 5.016, avg: 2.39, latest lr: 5.928571428571429e-05\n",
      "epoch: 1, loss: 3.571, avg: 2.39, latest lr: 5.927142857142858e-05\n",
      "epoch: 1, loss: 4.946, avg: 2.40, latest lr: 5.9257142857142855e-05\n",
      "epoch: 1, loss: 4.740, avg: 2.40, latest lr: 5.9242857142857145e-05\n",
      "epoch: 1, loss: 5.441, avg: 2.40, latest lr: 5.9228571428571436e-05\n",
      "epoch: 1, loss: 5.281, avg: 2.40, latest lr: 5.921428571428572e-05\n",
      "epoch: 1, loss: 4.246, avg: 2.40, latest lr: 5.92e-05\n",
      "epoch: 1, loss: 4.404, avg: 2.40, latest lr: 5.9185714285714286e-05\n",
      "epoch: 1, loss: 5.363, avg: 2.40, latest lr: 5.9171428571428576e-05\n",
      "epoch: 1, loss: 5.572, avg: 2.40, latest lr: 5.915714285714285e-05\n",
      "epoch: 1, loss: 6.794, avg: 2.40, latest lr: 5.914285714285714e-05\n",
      "epoch: 1, loss: 4.602, avg: 2.40, latest lr: 5.912857142857143e-05\n",
      "epoch: 1, loss: 5.153, avg: 2.40, latest lr: 5.911428571428572e-05\n",
      "epoch: 1, loss: 5.831, avg: 2.40, latest lr: 5.91e-05\n",
      "epoch: 1, loss: 5.348, avg: 2.40, latest lr: 5.908571428571429e-05\n",
      "epoch: 1, loss: 4.129, avg: 2.40, latest lr: 5.907142857142858e-05\n",
      "epoch: 1, loss: 5.869, avg: 2.41, latest lr: 5.905714285714286e-05\n",
      "epoch: 1, loss: 5.145, avg: 2.41, latest lr: 5.904285714285715e-05\n",
      "epoch: 1, loss: 4.979, avg: 2.41, latest lr: 5.902857142857143e-05\n",
      "epoch: 1, loss: 4.891, avg: 2.41, latest lr: 5.901428571428572e-05\n",
      "epoch: 1, loss: 6.078, avg: 2.41, latest lr: 5.9e-05\n",
      "epoch: 1, loss: 5.057, avg: 2.41, latest lr: 5.898571428571429e-05\n",
      "epoch: 1, loss: 3.374, avg: 2.41, latest lr: 5.897142857142858e-05\n",
      "epoch: 1, loss: 4.155, avg: 2.41, latest lr: 5.8957142857142855e-05\n",
      "epoch: 1, loss: 5.003, avg: 2.41, latest lr: 5.8942857142857145e-05\n",
      "epoch: 1, loss: 3.205, avg: 2.41, latest lr: 5.8928571428571435e-05\n",
      "epoch: 1, loss: 6.049, avg: 2.41, latest lr: 5.8914285714285725e-05\n",
      "epoch: 1, loss: 5.243, avg: 2.41, latest lr: 5.89e-05\n",
      "epoch: 1, loss: 6.068, avg: 2.41, latest lr: 5.8885714285714285e-05\n",
      "epoch: 1, loss: 5.734, avg: 2.41, latest lr: 5.8871428571428576e-05\n",
      "epoch: 1, loss: 5.282, avg: 2.42, latest lr: 5.885714285714285e-05\n",
      "epoch: 1, loss: 5.791, avg: 2.42, latest lr: 5.884285714285714e-05\n",
      "epoch: 1, loss: 5.094, avg: 2.42, latest lr: 5.882857142857143e-05\n",
      "epoch: 1, loss: 5.599, avg: 2.42, latest lr: 5.881428571428572e-05\n",
      "epoch: 1, loss: 5.951, avg: 2.42, latest lr: 5.88e-05\n",
      "epoch: 1, loss: 3.920, avg: 2.42, latest lr: 5.878571428571429e-05\n",
      "epoch: 1, loss: 5.118, avg: 2.42, latest lr: 5.877142857142858e-05\n",
      "epoch: 1, loss: 5.423, avg: 2.42, latest lr: 5.8757142857142857e-05\n",
      "epoch: 1, loss: 4.706, avg: 2.42, latest lr: 5.874285714285715e-05\n",
      "epoch: 1, loss: 4.167, avg: 2.42, latest lr: 5.872857142857143e-05\n",
      "epoch: 1, loss: 5.516, avg: 2.42, latest lr: 5.871428571428572e-05\n",
      "epoch: 1, loss: 5.585, avg: 2.42, latest lr: 5.87e-05\n",
      "epoch: 1, loss: 4.967, avg: 2.42, latest lr: 5.868571428571429e-05\n",
      "epoch: 1, loss: 6.087, avg: 2.43, latest lr: 5.867142857142858e-05\n",
      "epoch: 1, loss: 6.033, avg: 2.43, latest lr: 5.8657142857142854e-05\n",
      "epoch: 1, loss: 4.891, avg: 2.43, latest lr: 5.8642857142857144e-05\n",
      "epoch: 1, loss: 4.374, avg: 2.43, latest lr: 5.8628571428571435e-05\n",
      "epoch: 1, loss: 5.673, avg: 2.43, latest lr: 5.8614285714285725e-05\n",
      "epoch: 1, loss: 5.994, avg: 2.43, latest lr: 5.86e-05\n",
      "epoch: 1, loss: 5.372, avg: 2.43, latest lr: 5.858571428571429e-05\n",
      "epoch: 1, loss: 3.430, avg: 2.43, latest lr: 5.8571428571428575e-05\n",
      "epoch: 1, loss: 5.176, avg: 2.43, latest lr: 5.855714285714285e-05\n",
      "epoch: 1, loss: 5.108, avg: 2.43, latest lr: 5.854285714285714e-05\n",
      "epoch: 1, loss: 5.191, avg: 2.43, latest lr: 5.852857142857143e-05\n",
      "epoch: 1, loss: 4.095, avg: 2.43, latest lr: 5.851428571428572e-05\n",
      "epoch: 1, loss: 4.542, avg: 2.43, latest lr: 5.85e-05\n",
      "epoch: 1, loss: 5.016, avg: 2.43, latest lr: 5.848571428571429e-05\n",
      "epoch: 1, loss: 4.411, avg: 2.44, latest lr: 5.847142857142858e-05\n",
      "epoch: 1, loss: 3.966, avg: 2.44, latest lr: 5.8457142857142856e-05\n",
      "epoch: 1, loss: 3.743, avg: 2.44, latest lr: 5.8442857142857146e-05\n",
      "epoch: 1, loss: 5.367, avg: 2.44, latest lr: 5.842857142857143e-05\n",
      "epoch: 1, loss: 5.094, avg: 2.44, latest lr: 5.841428571428572e-05\n",
      "epoch: 1, loss: 4.272, avg: 2.44, latest lr: 5.8399999999999997e-05\n",
      "epoch: 1, loss: 4.000, avg: 2.44, latest lr: 5.838571428571429e-05\n",
      "epoch: 1, loss: 4.199, avg: 2.44, latest lr: 5.837142857142858e-05\n",
      "epoch: 1, loss: 4.933, avg: 2.44, latest lr: 5.8357142857142854e-05\n",
      "epoch: 1, loss: 4.666, avg: 2.44, latest lr: 5.8342857142857144e-05\n",
      "epoch: 1, loss: 6.277, avg: 2.44, latest lr: 5.8328571428571434e-05\n",
      "epoch: 1, loss: 5.617, avg: 2.44, latest lr: 5.8314285714285724e-05\n",
      "epoch: 1, loss: 3.964, avg: 2.44, latest lr: 5.83e-05\n",
      "epoch: 1, loss: 5.773, avg: 2.44, latest lr: 5.828571428571429e-05\n",
      "epoch: 1, loss: 4.568, avg: 2.44, latest lr: 5.8271428571428574e-05\n",
      "epoch: 1, loss: 4.254, avg: 2.45, latest lr: 5.825714285714286e-05\n",
      "epoch: 1, loss: 5.398, avg: 2.45, latest lr: 5.824285714285714e-05\n",
      "epoch: 1, loss: 4.113, avg: 2.45, latest lr: 5.822857142857143e-05\n",
      "epoch: 1, loss: 5.283, avg: 2.45, latest lr: 5.821428571428572e-05\n",
      "epoch: 1, loss: 5.958, avg: 2.45, latest lr: 5.82e-05\n",
      "epoch: 1, loss: 5.566, avg: 2.45, latest lr: 5.818571428571429e-05\n",
      "epoch: 1, loss: 5.069, avg: 2.45, latest lr: 5.817142857142858e-05\n",
      "epoch: 1, loss: 3.833, avg: 2.45, latest lr: 5.8157142857142855e-05\n",
      "epoch: 1, loss: 5.174, avg: 2.45, latest lr: 5.8142857142857146e-05\n",
      "epoch: 1, loss: 5.912, avg: 2.45, latest lr: 5.812857142857143e-05\n",
      "epoch: 1, loss: 4.955, avg: 2.45, latest lr: 5.811428571428572e-05\n",
      "epoch: 1, loss: 5.267, avg: 2.45, latest lr: 5.8099999999999996e-05\n",
      "epoch: 1, loss: 4.693, avg: 2.45, latest lr: 5.8085714285714286e-05\n",
      "epoch: 1, loss: 5.217, avg: 2.45, latest lr: 5.8071428571428576e-05\n",
      "epoch: 1, loss: 5.044, avg: 2.46, latest lr: 5.805714285714285e-05\n",
      "epoch: 1, loss: 5.535, avg: 2.46, latest lr: 5.804285714285714e-05\n",
      "epoch: 1, loss: 5.092, avg: 2.46, latest lr: 5.8028571428571433e-05\n",
      "epoch: 1, loss: 3.297, avg: 2.46, latest lr: 5.8014285714285724e-05\n",
      "epoch: 1, loss: 5.014, avg: 2.46, latest lr: 5.8e-05\n",
      "epoch: 1, loss: 3.931, avg: 2.46, latest lr: 5.798571428571429e-05\n",
      "epoch: 1, loss: 6.219, avg: 2.46, latest lr: 5.7971428571428574e-05\n",
      "epoch: 1, loss: 5.457, avg: 2.46, latest lr: 5.7957142857142864e-05\n",
      "epoch: 1, loss: 5.541, avg: 2.46, latest lr: 5.794285714285714e-05\n",
      "epoch: 1, loss: 5.552, avg: 2.46, latest lr: 5.792857142857143e-05\n",
      "epoch: 1, loss: 5.005, avg: 2.46, latest lr: 5.791428571428572e-05\n",
      "epoch: 1, loss: 4.644, avg: 2.46, latest lr: 5.79e-05\n",
      "epoch: 1, loss: 5.892, avg: 2.46, latest lr: 5.788571428571429e-05\n",
      "epoch: 1, loss: 5.359, avg: 2.47, latest lr: 5.787142857142858e-05\n",
      "epoch: 1, loss: 5.166, avg: 2.47, latest lr: 5.785714285714287e-05\n",
      "epoch: 1, loss: 4.875, avg: 2.47, latest lr: 5.7842857142857145e-05\n",
      "epoch: 1, loss: 5.246, avg: 2.47, latest lr: 5.782857142857143e-05\n",
      "epoch: 1, loss: 4.201, avg: 2.47, latest lr: 5.781428571428572e-05\n",
      "epoch: 1, loss: 5.462, avg: 2.47, latest lr: 5.7799999999999995e-05\n",
      "epoch: 1, loss: 5.243, avg: 2.47, latest lr: 5.7785714285714286e-05\n",
      "epoch: 1, loss: 4.780, avg: 2.47, latest lr: 5.7771428571428576e-05\n",
      "epoch: 1, loss: 5.334, avg: 2.47, latest lr: 5.7757142857142866e-05\n",
      "epoch: 1, loss: 4.042, avg: 2.47, latest lr: 5.774285714285714e-05\n",
      "epoch: 1, loss: 5.319, avg: 2.47, latest lr: 5.772857142857143e-05\n",
      "epoch: 1, loss: 6.482, avg: 2.47, latest lr: 5.771428571428572e-05\n",
      "epoch: 1, loss: 5.591, avg: 2.47, latest lr: 5.77e-05\n",
      "epoch: 1, loss: 5.505, avg: 2.47, latest lr: 5.768571428571429e-05\n",
      "epoch: 1, loss: 4.890, avg: 2.48, latest lr: 5.7671428571428573e-05\n",
      "epoch: 1, loss: 4.853, avg: 2.48, latest lr: 5.7657142857142864e-05\n",
      "epoch: 1, loss: 4.578, avg: 2.48, latest lr: 5.764285714285714e-05\n",
      "epoch: 1, loss: 6.206, avg: 2.48, latest lr: 5.762857142857143e-05\n",
      "epoch: 1, loss: 5.001, avg: 2.48, latest lr: 5.761428571428572e-05\n",
      "epoch: 1, loss: 6.671, avg: 2.48, latest lr: 5.76e-05\n",
      "epoch: 1, loss: 4.372, avg: 2.48, latest lr: 5.758571428571429e-05\n",
      "epoch: 1, loss: 4.134, avg: 2.48, latest lr: 5.757142857142858e-05\n",
      "epoch: 1, loss: 4.534, avg: 2.48, latest lr: 5.755714285714287e-05\n",
      "epoch: 1, loss: 5.549, avg: 2.48, latest lr: 5.7542857142857145e-05\n",
      "epoch: 1, loss: 5.558, avg: 2.48, latest lr: 5.7528571428571435e-05\n",
      "epoch: 1, loss: 5.012, avg: 2.48, latest lr: 5.751428571428572e-05\n",
      "epoch: 1, loss: 5.227, avg: 2.48, latest lr: 5.7499999999999995e-05\n",
      "epoch: 1, loss: 4.538, avg: 2.48, latest lr: 5.7485714285714285e-05\n",
      "epoch: 1, loss: 5.587, avg: 2.49, latest lr: 5.7471428571428575e-05\n",
      "epoch: 1, loss: 4.627, avg: 2.49, latest lr: 5.7457142857142866e-05\n",
      "epoch: 1, loss: 4.967, avg: 2.49, latest lr: 5.744285714285714e-05\n",
      "epoch: 1, loss: 5.784, avg: 2.49, latest lr: 5.742857142857143e-05\n",
      "epoch: 1, loss: 4.162, avg: 2.49, latest lr: 5.741428571428572e-05\n",
      "epoch: 1, loss: 4.022, avg: 2.49, latest lr: 5.74e-05\n",
      "epoch: 1, loss: 5.537, avg: 2.49, latest lr: 5.738571428571429e-05\n",
      "epoch: 1, loss: 5.748, avg: 2.49, latest lr: 5.737142857142857e-05\n",
      "epoch: 1, loss: 3.979, avg: 2.49, latest lr: 5.735714285714286e-05\n",
      "epoch: 1, loss: 5.196, avg: 2.49, latest lr: 5.734285714285714e-05\n",
      "epoch: 1, loss: 5.231, avg: 2.49, latest lr: 5.732857142857143e-05\n",
      "epoch: 1, loss: 5.776, avg: 2.49, latest lr: 5.731428571428572e-05\n",
      "epoch: 1, loss: 5.128, avg: 2.49, latest lr: 5.73e-05\n",
      "epoch: 1, loss: 5.407, avg: 2.50, latest lr: 5.728571428571429e-05\n",
      "epoch: 1, loss: 4.480, avg: 2.50, latest lr: 5.727142857142858e-05\n",
      "epoch: 1, loss: 5.476, avg: 2.50, latest lr: 5.725714285714287e-05\n",
      "epoch: 1, loss: 3.572, avg: 2.50, latest lr: 5.7242857142857144e-05\n",
      "epoch: 1, loss: 7.149, avg: 2.50, latest lr: 5.7228571428571434e-05\n",
      "epoch: 1, loss: 3.580, avg: 2.50, latest lr: 5.721428571428572e-05\n",
      "epoch: 1, loss: 4.826, avg: 2.50, latest lr: 5.72e-05\n",
      "epoch: 1, loss: 5.292, avg: 2.50, latest lr: 5.7185714285714285e-05\n",
      "epoch: 1, loss: 4.440, avg: 2.50, latest lr: 5.7171428571428575e-05\n",
      "epoch: 1, loss: 5.458, avg: 2.50, latest lr: 5.7157142857142865e-05\n",
      "epoch: 1, loss: 4.737, avg: 2.50, latest lr: 5.714285714285714e-05\n",
      "epoch: 1, loss: 4.627, avg: 2.50, latest lr: 5.712857142857143e-05\n",
      "epoch: 1, loss: 5.512, avg: 2.50, latest lr: 5.711428571428572e-05\n",
      "epoch: 1, loss: 5.155, avg: 2.50, latest lr: 5.71e-05\n",
      "epoch: 1, loss: 4.540, avg: 2.50, latest lr: 5.708571428571429e-05\n",
      "epoch: 1, loss: 4.292, avg: 2.51, latest lr: 5.707142857142857e-05\n",
      "epoch: 1, loss: 4.836, avg: 2.51, latest lr: 5.705714285714286e-05\n",
      "epoch: 1, loss: 5.303, avg: 2.51, latest lr: 5.704285714285714e-05\n",
      "epoch: 1, loss: 5.000, avg: 2.51, latest lr: 5.702857142857143e-05\n",
      "epoch: 1, loss: 5.550, avg: 2.51, latest lr: 5.701428571428572e-05\n",
      "epoch: 1, loss: 5.458, avg: 2.51, latest lr: 5.6999999999999996e-05\n",
      "epoch: 1, loss: 4.632, avg: 2.51, latest lr: 5.6985714285714287e-05\n",
      "epoch: 1, loss: 6.011, avg: 2.51, latest lr: 5.697142857142858e-05\n",
      "epoch: 1, loss: 3.448, avg: 2.51, latest lr: 5.695714285714287e-05\n",
      "epoch: 1, loss: 5.872, avg: 2.51, latest lr: 5.6942857142857144e-05\n",
      "epoch: 1, loss: 4.965, avg: 2.51, latest lr: 5.6928571428571434e-05\n",
      "epoch: 1, loss: 5.385, avg: 2.51, latest lr: 5.691428571428572e-05\n",
      "epoch: 1, loss: 5.282, avg: 2.51, latest lr: 5.69e-05\n",
      "epoch: 1, loss: 4.194, avg: 2.51, latest lr: 5.6885714285714284e-05\n",
      "epoch: 1, loss: 5.482, avg: 2.52, latest lr: 5.6871428571428574e-05\n",
      "epoch: 1, loss: 4.968, avg: 2.52, latest lr: 5.6857142857142865e-05\n",
      "epoch: 1, loss: 3.338, avg: 2.52, latest lr: 5.684285714285714e-05\n",
      "epoch: 1, loss: 5.888, avg: 2.52, latest lr: 5.682857142857143e-05\n",
      "epoch: 1, loss: 4.914, avg: 2.52, latest lr: 5.681428571428572e-05\n",
      "epoch: 1, loss: 5.081, avg: 2.52, latest lr: 5.68e-05\n",
      "epoch: 1, loss: 4.311, avg: 2.52, latest lr: 5.678571428571429e-05\n",
      "epoch: 1, loss: 5.714, avg: 2.52, latest lr: 5.677142857142858e-05\n",
      "epoch: 1, loss: 6.266, avg: 2.52, latest lr: 5.675714285714286e-05\n",
      "epoch: 1, loss: 5.893, avg: 2.52, latest lr: 5.674285714285714e-05\n",
      "epoch: 1, loss: 4.387, avg: 2.52, latest lr: 5.672857142857143e-05\n",
      "epoch: 1, loss: 5.575, avg: 2.52, latest lr: 5.671428571428572e-05\n",
      "epoch: 1, loss: 5.270, avg: 2.52, latest lr: 5.6699999999999996e-05\n",
      "epoch: 1, loss: 4.662, avg: 2.53, latest lr: 5.6685714285714286e-05\n",
      "epoch: 1, loss: 4.336, avg: 2.53, latest lr: 5.6671428571428576e-05\n",
      "epoch: 1, loss: 4.853, avg: 2.53, latest lr: 5.6657142857142866e-05\n",
      "epoch: 1, loss: 4.232, avg: 2.53, latest lr: 5.664285714285714e-05\n",
      "epoch: 1, loss: 5.461, avg: 2.53, latest lr: 5.662857142857143e-05\n",
      "epoch: 1, loss: 5.978, avg: 2.53, latest lr: 5.661428571428572e-05\n",
      "epoch: 1, loss: 4.974, avg: 2.53, latest lr: 5.66e-05\n",
      "epoch: 1, loss: 4.747, avg: 2.53, latest lr: 5.6585714285714284e-05\n",
      "epoch: 1, loss: 4.154, avg: 2.53, latest lr: 5.6571428571428574e-05\n",
      "epoch: 1, loss: 5.315, avg: 2.53, latest lr: 5.6557142857142864e-05\n",
      "epoch: 1, loss: 6.236, avg: 2.53, latest lr: 5.654285714285714e-05\n",
      "epoch: 1, loss: 5.405, avg: 2.53, latest lr: 5.652857142857143e-05\n",
      "epoch: 1, loss: 5.253, avg: 2.53, latest lr: 5.651428571428572e-05\n",
      "epoch: 1, loss: 3.628, avg: 2.53, latest lr: 5.65e-05\n",
      "epoch: 1, loss: 5.864, avg: 2.54, latest lr: 5.648571428571429e-05\n",
      "epoch: 1, loss: 5.838, avg: 2.54, latest lr: 5.647142857142858e-05\n",
      "epoch: 1, loss: 3.765, avg: 2.54, latest lr: 5.645714285714286e-05\n",
      "epoch: 1, loss: 4.993, avg: 2.54, latest lr: 5.6442857142857145e-05\n",
      "epoch: 1, loss: 5.917, avg: 2.54, latest lr: 5.642857142857143e-05\n",
      "epoch: 1, loss: 3.165, avg: 2.54, latest lr: 5.641428571428572e-05\n",
      "epoch: 1, loss: 5.524, avg: 2.54, latest lr: 5.6399999999999995e-05\n",
      "epoch: 1, loss: 3.880, avg: 2.54, latest lr: 5.6385714285714286e-05\n",
      "epoch: 1, loss: 4.914, avg: 2.54, latest lr: 5.6371428571428576e-05\n",
      "epoch: 1, loss: 5.309, avg: 2.54, latest lr: 5.6357142857142866e-05\n",
      "epoch: 1, loss: 6.651, avg: 2.54, latest lr: 5.634285714285714e-05\n",
      "epoch: 1, loss: 5.233, avg: 2.54, latest lr: 5.632857142857143e-05\n",
      "epoch: 1, loss: 2.716, avg: 2.54, latest lr: 5.6314285714285716e-05\n",
      "epoch: 1, loss: 5.515, avg: 2.54, latest lr: 5.63e-05\n",
      "epoch: 1, loss: 5.299, avg: 2.55, latest lr: 5.628571428571428e-05\n",
      "epoch: 1, loss: 5.210, avg: 2.55, latest lr: 5.627142857142857e-05\n",
      "epoch: 1, loss: 5.468, avg: 2.55, latest lr: 5.6257142857142864e-05\n",
      "epoch: 1, loss: 5.091, avg: 2.55, latest lr: 5.624285714285714e-05\n",
      "epoch: 1, loss: 5.768, avg: 2.55, latest lr: 5.622857142857143e-05\n",
      "epoch: 1, loss: 3.871, avg: 2.55, latest lr: 5.621428571428572e-05\n",
      "epoch: 1, loss: 3.913, avg: 2.55, latest lr: 5.620000000000001e-05\n",
      "epoch: 1, loss: 3.846, avg: 2.55, latest lr: 5.618571428571429e-05\n",
      "epoch: 1, loss: 5.273, avg: 2.55, latest lr: 5.617142857142858e-05\n",
      "epoch: 1, loss: 4.154, avg: 2.55, latest lr: 5.615714285714286e-05\n",
      "epoch: 1, loss: 5.120, avg: 2.55, latest lr: 5.6142857142857145e-05\n",
      "epoch: 1, loss: 6.747, avg: 2.55, latest lr: 5.612857142857143e-05\n",
      "epoch: 1, loss: 3.837, avg: 2.55, latest lr: 5.611428571428572e-05\n",
      "epoch: 1, loss: 3.874, avg: 2.55, latest lr: 5.610000000000001e-05\n",
      "epoch: 1, loss: 5.431, avg: 2.55, latest lr: 5.6085714285714285e-05\n",
      "epoch: 1, loss: 4.740, avg: 2.56, latest lr: 5.6071428571428575e-05\n",
      "epoch: 1, loss: 6.092, avg: 2.56, latest lr: 5.6057142857142865e-05\n",
      "epoch: 1, loss: 4.939, avg: 2.56, latest lr: 5.604285714285714e-05\n",
      "epoch: 1, loss: 4.035, avg: 2.56, latest lr: 5.602857142857143e-05\n",
      "epoch: 1, loss: 4.297, avg: 2.56, latest lr: 5.601428571428572e-05\n",
      "epoch: 1, loss: 5.291, avg: 2.56, latest lr: 5.6000000000000006e-05\n",
      "epoch: 1, loss: 3.780, avg: 2.56, latest lr: 5.598571428571428e-05\n",
      "epoch: 1, loss: 4.155, avg: 2.56, latest lr: 5.597142857142857e-05\n",
      "epoch: 1, loss: 4.832, avg: 2.56, latest lr: 5.595714285714286e-05\n",
      "epoch: 1, loss: 5.037, avg: 2.56, latest lr: 5.594285714285714e-05\n",
      "epoch: 1, loss: 4.490, avg: 2.56, latest lr: 5.592857142857143e-05\n",
      "epoch: 1, loss: 5.773, avg: 2.56, latest lr: 5.591428571428572e-05\n",
      "epoch: 1, loss: 5.778, avg: 2.56, latest lr: 5.590000000000001e-05\n",
      "epoch: 1, loss: 4.838, avg: 2.56, latest lr: 5.588571428571429e-05\n",
      "epoch: 1, loss: 5.824, avg: 2.57, latest lr: 5.587142857142858e-05\n",
      "epoch: 1, loss: 4.811, avg: 2.57, latest lr: 5.585714285714286e-05\n",
      "epoch: 1, loss: 4.987, avg: 2.57, latest lr: 5.5842857142857144e-05\n",
      "epoch: 1, loss: 4.492, avg: 2.57, latest lr: 5.582857142857143e-05\n",
      "epoch: 1, loss: 4.733, avg: 2.57, latest lr: 5.581428571428572e-05\n",
      "epoch: 1, loss: 3.809, avg: 2.57, latest lr: 5.580000000000001e-05\n",
      "epoch: 1, loss: 4.921, avg: 2.57, latest lr: 5.5785714285714285e-05\n",
      "epoch: 1, loss: 6.377, avg: 2.57, latest lr: 5.5771428571428575e-05\n",
      "epoch: 1, loss: 5.148, avg: 2.57, latest lr: 5.5757142857142865e-05\n",
      "epoch: 1, loss: 4.558, avg: 2.57, latest lr: 5.574285714285714e-05\n",
      "epoch: 1, loss: 4.201, avg: 2.57, latest lr: 5.572857142857143e-05\n",
      "epoch: 1, loss: 5.935, avg: 2.57, latest lr: 5.571428571428572e-05\n",
      "epoch: 1, loss: 6.029, avg: 2.57, latest lr: 5.5700000000000005e-05\n",
      "epoch: 1, loss: 5.034, avg: 2.57, latest lr: 5.568571428571429e-05\n",
      "epoch: 1, loss: 4.123, avg: 2.58, latest lr: 5.567142857142857e-05\n",
      "epoch: 1, loss: 4.869, avg: 2.58, latest lr: 5.565714285714286e-05\n",
      "epoch: 1, loss: 6.051, avg: 2.58, latest lr: 5.564285714285714e-05\n",
      "epoch: 1, loss: 5.060, avg: 2.58, latest lr: 5.562857142857143e-05\n",
      "epoch: 1, loss: 3.730, avg: 2.58, latest lr: 5.561428571428572e-05\n",
      "epoch: 1, loss: 3.971, avg: 2.58, latest lr: 5.560000000000001e-05\n",
      "epoch: 1, loss: 5.292, avg: 2.58, latest lr: 5.5585714285714286e-05\n",
      "epoch: 1, loss: 5.905, avg: 2.58, latest lr: 5.557142857142858e-05\n",
      "epoch: 1, loss: 6.143, avg: 2.58, latest lr: 5.555714285714286e-05\n",
      "epoch: 1, loss: 4.564, avg: 2.58, latest lr: 5.5542857142857143e-05\n",
      "epoch: 1, loss: 5.001, avg: 2.58, latest lr: 5.552857142857143e-05\n",
      "epoch: 1, loss: 5.592, avg: 2.58, latest lr: 5.551428571428572e-05\n",
      "epoch: 1, loss: 5.707, avg: 2.58, latest lr: 5.550000000000001e-05\n",
      "epoch: 1, loss: 4.916, avg: 2.58, latest lr: 5.5485714285714284e-05\n",
      "epoch: 1, loss: 6.719, avg: 2.59, latest lr: 5.5471428571428574e-05\n",
      "epoch: 1, loss: 5.144, avg: 2.59, latest lr: 5.5457142857142864e-05\n",
      "epoch: 1, loss: 6.180, avg: 2.59, latest lr: 5.544285714285714e-05\n",
      "epoch: 1, loss: 6.488, avg: 2.59, latest lr: 5.542857142857143e-05\n",
      "epoch: 1, loss: 3.658, avg: 2.59, latest lr: 5.541428571428572e-05\n",
      "epoch: 1, loss: 4.869, avg: 2.59, latest lr: 5.5400000000000005e-05\n",
      "epoch: 1, loss: 3.932, avg: 2.59, latest lr: 5.538571428571429e-05\n",
      "epoch: 1, loss: 4.084, avg: 2.59, latest lr: 5.537142857142857e-05\n",
      "epoch: 1, loss: 5.278, avg: 2.59, latest lr: 5.535714285714286e-05\n",
      "epoch: 1, loss: 5.323, avg: 2.59, latest lr: 5.534285714285714e-05\n",
      "epoch: 1, loss: 5.041, avg: 2.59, latest lr: 5.532857142857143e-05\n",
      "epoch: 1, loss: 5.526, avg: 2.59, latest lr: 5.531428571428572e-05\n",
      "epoch: 1, loss: 4.754, avg: 2.59, latest lr: 5.530000000000001e-05\n",
      "epoch: 1, loss: 4.579, avg: 2.59, latest lr: 5.5285714285714286e-05\n",
      "epoch: 1, loss: 3.484, avg: 2.60, latest lr: 5.5271428571428576e-05\n",
      "epoch: 1, loss: 4.309, avg: 2.60, latest lr: 5.525714285714286e-05\n",
      "epoch: 1, loss: 4.213, avg: 2.60, latest lr: 5.524285714285714e-05\n",
      "epoch: 1, loss: 4.886, avg: 2.60, latest lr: 5.5228571428571426e-05\n",
      "epoch: 1, loss: 5.323, avg: 2.60, latest lr: 5.521428571428572e-05\n",
      "epoch: 1, loss: 5.180, avg: 2.60, latest lr: 5.520000000000001e-05\n",
      "epoch: 1, loss: 3.650, avg: 2.60, latest lr: 5.5185714285714283e-05\n",
      "epoch: 1, loss: 6.107, avg: 2.60, latest lr: 5.5171428571428574e-05\n",
      "epoch: 1, loss: 5.626, avg: 2.60, latest lr: 5.5157142857142864e-05\n",
      "epoch: 1, loss: 5.432, avg: 2.60, latest lr: 5.514285714285714e-05\n",
      "epoch: 1, loss: 3.759, avg: 2.60, latest lr: 5.512857142857143e-05\n",
      "epoch: 1, loss: 5.461, avg: 2.60, latest lr: 5.511428571428572e-05\n",
      "epoch: 1, loss: 3.884, avg: 2.60, latest lr: 5.5100000000000004e-05\n",
      "epoch: 1, loss: 4.113, avg: 2.60, latest lr: 5.508571428571429e-05\n",
      "epoch: 1, loss: 5.768, avg: 2.61, latest lr: 5.507142857142857e-05\n",
      "epoch: 1, loss: 5.369, avg: 2.61, latest lr: 5.505714285714286e-05\n",
      "epoch: 1, loss: 5.381, avg: 2.61, latest lr: 5.504285714285714e-05\n",
      "epoch: 1, loss: 5.183, avg: 2.61, latest lr: 5.502857142857143e-05\n",
      "epoch: 1, loss: 5.859, avg: 2.61, latest lr: 5.501428571428572e-05\n",
      "epoch: 1, loss: 4.634, avg: 2.61, latest lr: 5.500000000000001e-05\n",
      "epoch: 1, loss: 4.217, avg: 2.61, latest lr: 5.4985714285714285e-05\n",
      "epoch: 1, loss: 4.833, avg: 2.61, latest lr: 5.4971428571428576e-05\n",
      "epoch: 1, loss: 6.425, avg: 2.61, latest lr: 5.4957142857142866e-05\n",
      "epoch: 1, loss: 4.977, avg: 2.61, latest lr: 5.494285714285714e-05\n",
      "epoch: 1, loss: 3.901, avg: 2.61, latest lr: 5.4928571428571426e-05\n",
      "epoch: 1, loss: 5.459, avg: 2.61, latest lr: 5.4914285714285716e-05\n",
      "epoch: 1, loss: 3.548, avg: 2.61, latest lr: 5.4900000000000006e-05\n",
      "epoch: 1, loss: 4.244, avg: 2.61, latest lr: 5.488571428571428e-05\n",
      "epoch: 1, loss: 5.883, avg: 2.62, latest lr: 5.487142857142857e-05\n",
      "epoch: 1, loss: 4.612, avg: 2.62, latest lr: 5.485714285714286e-05\n",
      "epoch: 1, loss: 5.266, avg: 2.62, latest lr: 5.484285714285714e-05\n",
      "epoch: 1, loss: 4.939, avg: 2.62, latest lr: 5.482857142857143e-05\n",
      "epoch: 1, loss: 5.511, avg: 2.62, latest lr: 5.481428571428572e-05\n",
      "epoch: 1, loss: 5.811, avg: 2.62, latest lr: 5.4800000000000004e-05\n",
      "epoch: 1, loss: 5.062, avg: 2.62, latest lr: 5.478571428571429e-05\n",
      "epoch: 1, loss: 4.261, avg: 2.62, latest lr: 5.477142857142857e-05\n",
      "epoch: 1, loss: 3.608, avg: 2.62, latest lr: 5.475714285714286e-05\n",
      "epoch: 1, loss: 5.483, avg: 2.62, latest lr: 5.474285714285714e-05\n",
      "epoch: 1, loss: 5.213, avg: 2.62, latest lr: 5.472857142857143e-05\n",
      "epoch: 1, loss: 5.311, avg: 2.62, latest lr: 5.471428571428572e-05\n",
      "epoch: 1, loss: 3.338, avg: 2.62, latest lr: 5.470000000000001e-05\n",
      "epoch: 1, loss: 4.557, avg: 2.62, latest lr: 5.4685714285714285e-05\n",
      "epoch: 1, loss: 5.900, avg: 2.62, latest lr: 5.4671428571428575e-05\n",
      "epoch: 1, loss: 5.265, avg: 2.63, latest lr: 5.4657142857142865e-05\n",
      "epoch: 1, loss: 2.947, avg: 2.63, latest lr: 5.464285714285714e-05\n",
      "epoch: 1, loss: 5.000, avg: 2.63, latest lr: 5.462857142857143e-05\n",
      "epoch: 1, loss: 5.790, avg: 2.63, latest lr: 5.4614285714285716e-05\n",
      "epoch: 1, loss: 4.983, avg: 2.63, latest lr: 5.4600000000000006e-05\n",
      "epoch: 1, loss: 3.876, avg: 2.63, latest lr: 5.458571428571428e-05\n",
      "epoch: 1, loss: 4.354, avg: 2.63, latest lr: 5.457142857142857e-05\n",
      "epoch: 1, loss: 5.335, avg: 2.63, latest lr: 5.455714285714286e-05\n",
      "epoch: 1, loss: 6.351, avg: 2.63, latest lr: 5.454285714285714e-05\n",
      "epoch: 1, loss: 5.537, avg: 2.63, latest lr: 5.452857142857143e-05\n",
      "epoch: 1, loss: 4.913, avg: 2.63, latest lr: 5.451428571428572e-05\n",
      "epoch: 1, loss: 5.113, avg: 2.63, latest lr: 5.45e-05\n",
      "epoch: 1, loss: 4.433, avg: 2.63, latest lr: 5.448571428571429e-05\n",
      "epoch: 1, loss: 4.016, avg: 2.63, latest lr: 5.447142857142857e-05\n",
      "epoch: 1, loss: 5.016, avg: 2.64, latest lr: 5.445714285714286e-05\n",
      "epoch: 1, loss: 5.932, avg: 2.64, latest lr: 5.444285714285715e-05\n",
      "epoch: 1, loss: 6.074, avg: 2.64, latest lr: 5.442857142857143e-05\n",
      "epoch: 1, loss: 4.681, avg: 2.64, latest lr: 5.441428571428572e-05\n",
      "epoch: 1, loss: 5.300, avg: 2.64, latest lr: 5.440000000000001e-05\n",
      "epoch: 1, loss: 4.917, avg: 2.64, latest lr: 5.4385714285714284e-05\n",
      "epoch: 1, loss: 5.817, avg: 2.64, latest lr: 5.4371428571428575e-05\n",
      "epoch: 1, loss: 4.606, avg: 2.64, latest lr: 5.4357142857142865e-05\n",
      "epoch: 1, loss: 5.662, avg: 2.64, latest lr: 5.434285714285715e-05\n",
      "epoch: 1, loss: 3.526, avg: 2.64, latest lr: 5.432857142857143e-05\n",
      "epoch: 1, loss: 6.095, avg: 2.64, latest lr: 5.4314285714285715e-05\n",
      "epoch: 1, loss: 5.048, avg: 2.64, latest lr: 5.4300000000000005e-05\n",
      "epoch: 1, loss: 4.736, avg: 2.64, latest lr: 5.428571428571428e-05\n",
      "epoch: 1, loss: 5.448, avg: 2.65, latest lr: 5.427142857142857e-05\n",
      "epoch: 1, loss: 4.736, avg: 2.65, latest lr: 5.425714285714286e-05\n",
      "epoch: 1, loss: 4.281, avg: 2.65, latest lr: 5.424285714285715e-05\n",
      "epoch: 1, loss: 5.585, avg: 2.65, latest lr: 5.422857142857143e-05\n",
      "epoch: 1, loss: 5.851, avg: 2.65, latest lr: 5.421428571428572e-05\n",
      "epoch: 1, loss: 4.944, avg: 2.65, latest lr: 5.420000000000001e-05\n",
      "epoch: 1, loss: 4.159, avg: 2.65, latest lr: 5.4185714285714286e-05\n",
      "epoch: 1, loss: 4.049, avg: 2.65, latest lr: 5.417142857142857e-05\n",
      "epoch: 1, loss: 3.946, avg: 2.65, latest lr: 5.415714285714286e-05\n",
      "epoch: 1, loss: 4.763, avg: 2.65, latest lr: 5.414285714285715e-05\n",
      "epoch: 1, loss: 3.393, avg: 2.65, latest lr: 5.412857142857143e-05\n",
      "epoch: 1, loss: 4.290, avg: 2.65, latest lr: 5.411428571428572e-05\n",
      "epoch: 1, loss: 5.571, avg: 2.65, latest lr: 5.410000000000001e-05\n",
      "epoch: 1, loss: 3.360, avg: 2.65, latest lr: 5.4085714285714284e-05\n",
      "epoch: 1, loss: 4.656, avg: 2.65, latest lr: 5.4071428571428574e-05\n",
      "epoch: 1, loss: 5.449, avg: 2.65, latest lr: 5.4057142857142864e-05\n",
      "epoch: 1, loss: 5.456, avg: 2.66, latest lr: 5.404285714285715e-05\n",
      "epoch: 1, loss: 4.667, avg: 2.66, latest lr: 5.402857142857143e-05\n",
      "epoch: 1, loss: 5.635, avg: 2.66, latest lr: 5.4014285714285715e-05\n",
      "epoch: 1, loss: 4.687, avg: 2.66, latest lr: 5.4000000000000005e-05\n",
      "epoch: 1, loss: 4.959, avg: 2.66, latest lr: 5.398571428571428e-05\n",
      "epoch: 1, loss: 4.833, avg: 2.66, latest lr: 5.397142857142857e-05\n",
      "epoch: 1, loss: 4.193, avg: 2.66, latest lr: 5.395714285714286e-05\n",
      "epoch: 1, loss: 3.997, avg: 2.66, latest lr: 5.394285714285715e-05\n",
      "epoch: 1, loss: 4.188, avg: 2.66, latest lr: 5.392857142857143e-05\n",
      "epoch: 1, loss: 4.001, avg: 2.66, latest lr: 5.391428571428572e-05\n",
      "epoch: 1, loss: 5.550, avg: 2.66, latest lr: 5.390000000000001e-05\n",
      "epoch: 1, loss: 4.976, avg: 2.66, latest lr: 5.3885714285714286e-05\n",
      "epoch: 1, loss: 4.109, avg: 2.66, latest lr: 5.3871428571428576e-05\n",
      "epoch: 1, loss: 5.640, avg: 2.66, latest lr: 5.385714285714286e-05\n",
      "epoch: 1, loss: 4.344, avg: 2.67, latest lr: 5.384285714285715e-05\n",
      "epoch: 1, loss: 5.782, avg: 2.67, latest lr: 5.3828571428571426e-05\n",
      "epoch: 1, loss: 4.383, avg: 2.67, latest lr: 5.3814285714285716e-05\n",
      "epoch: 1, loss: 4.417, avg: 2.67, latest lr: 5.380000000000001e-05\n",
      "epoch: 1, loss: 5.716, avg: 2.67, latest lr: 5.378571428571428e-05\n",
      "epoch: 1, loss: 4.617, avg: 2.67, latest lr: 5.3771428571428574e-05\n",
      "epoch: 1, loss: 3.504, avg: 2.67, latest lr: 5.3757142857142864e-05\n",
      "epoch: 1, loss: 5.306, avg: 2.67, latest lr: 5.374285714285715e-05\n",
      "epoch: 1, loss: 4.510, avg: 2.67, latest lr: 5.372857142857143e-05\n",
      "epoch: 1, loss: 5.516, avg: 2.67, latest lr: 5.3714285714285714e-05\n",
      "epoch: 1, loss: 5.044, avg: 2.67, latest lr: 5.3700000000000004e-05\n",
      "epoch: 1, loss: 3.503, avg: 2.67, latest lr: 5.368571428571428e-05\n",
      "epoch: 1, loss: 5.632, avg: 2.67, latest lr: 5.367142857142857e-05\n",
      "epoch: 1, loss: 3.943, avg: 2.67, latest lr: 5.365714285714286e-05\n",
      "epoch: 1, loss: 3.925, avg: 2.67, latest lr: 5.364285714285715e-05\n",
      "epoch: 1, loss: 5.015, avg: 2.68, latest lr: 5.362857142857143e-05\n",
      "epoch: 1, loss: 3.645, avg: 2.68, latest lr: 5.361428571428572e-05\n",
      "epoch: 1, loss: 6.545, avg: 2.68, latest lr: 5.360000000000001e-05\n",
      "epoch: 1, loss: 5.719, avg: 2.68, latest lr: 5.3585714285714285e-05\n",
      "epoch: 1, loss: 3.571, avg: 2.68, latest lr: 5.3571428571428575e-05\n",
      "epoch: 1, loss: 5.592, avg: 2.68, latest lr: 5.355714285714286e-05\n",
      "epoch: 1, loss: 4.993, avg: 2.68, latest lr: 5.354285714285715e-05\n",
      "epoch: 1, loss: 5.294, avg: 2.68, latest lr: 5.3528571428571426e-05\n",
      "epoch: 1, loss: 4.203, avg: 2.68, latest lr: 5.3514285714285716e-05\n",
      "epoch: 1, loss: 5.037, avg: 2.68, latest lr: 5.3500000000000006e-05\n",
      "epoch: 1, loss: 5.505, avg: 2.68, latest lr: 5.348571428571428e-05\n",
      "epoch: 1, loss: 5.568, avg: 2.68, latest lr: 5.347142857142857e-05\n",
      "epoch: 1, loss: 4.541, avg: 2.68, latest lr: 5.345714285714286e-05\n",
      "epoch: 1, loss: 5.102, avg: 2.68, latest lr: 5.3442857142857153e-05\n",
      "epoch: 1, loss: 5.058, avg: 2.69, latest lr: 5.342857142857143e-05\n",
      "epoch: 1, loss: 4.424, avg: 2.69, latest lr: 5.3414285714285714e-05\n",
      "epoch: 1, loss: 5.518, avg: 2.69, latest lr: 5.3400000000000004e-05\n",
      "epoch: 1, loss: 4.661, avg: 2.69, latest lr: 5.338571428571428e-05\n",
      "epoch: 1, loss: 6.686, avg: 2.69, latest lr: 5.337142857142857e-05\n",
      "epoch: 1, loss: 4.545, avg: 2.69, latest lr: 5.335714285714286e-05\n",
      "epoch: 1, loss: 4.982, avg: 2.69, latest lr: 5.334285714285715e-05\n",
      "epoch: 1, loss: 5.035, avg: 2.69, latest lr: 5.332857142857143e-05\n",
      "epoch: 1, loss: 4.461, avg: 2.69, latest lr: 5.331428571428572e-05\n",
      "epoch: 1, loss: 5.336, avg: 2.69, latest lr: 5.330000000000001e-05\n",
      "epoch: 1, loss: 4.196, avg: 2.69, latest lr: 5.3285714285714285e-05\n",
      "epoch: 1, loss: 4.333, avg: 2.69, latest lr: 5.3271428571428575e-05\n",
      "epoch: 1, loss: 5.179, avg: 2.69, latest lr: 5.325714285714286e-05\n",
      "epoch: 1, loss: 4.551, avg: 2.69, latest lr: 5.324285714285715e-05\n",
      "epoch: 1, loss: 4.316, avg: 2.69, latest lr: 5.3228571428571425e-05\n",
      "epoch: 1, loss: 4.652, avg: 2.70, latest lr: 5.3214285714285715e-05\n",
      "epoch: 1, loss: 4.005, avg: 2.70, latest lr: 5.3200000000000006e-05\n",
      "epoch: 1, loss: 3.872, avg: 2.70, latest lr: 5.318571428571428e-05\n",
      "epoch: 1, loss: 5.474, avg: 2.70, latest lr: 5.317142857142857e-05\n",
      "epoch: 1, loss: 3.309, avg: 2.70, latest lr: 5.315714285714286e-05\n",
      "epoch: 1, loss: 5.286, avg: 2.70, latest lr: 5.314285714285715e-05\n",
      "epoch: 1, loss: 5.138, avg: 2.70, latest lr: 5.312857142857143e-05\n",
      "epoch: 1, loss: 4.441, avg: 2.70, latest lr: 5.311428571428572e-05\n",
      "epoch: 1, loss: 5.003, avg: 2.70, latest lr: 5.31e-05\n",
      "epoch: 1, loss: 4.299, avg: 2.70, latest lr: 5.308571428571428e-05\n",
      "epoch: 1, loss: 4.297, avg: 2.70, latest lr: 5.307142857142857e-05\n",
      "epoch: 1, loss: 6.766, avg: 2.70, latest lr: 5.305714285714286e-05\n",
      "epoch: 1, loss: 4.404, avg: 2.70, latest lr: 5.304285714285715e-05\n",
      "epoch: 1, loss: 5.151, avg: 2.70, latest lr: 5.302857142857143e-05\n",
      "epoch: 1, loss: 5.182, avg: 2.71, latest lr: 5.301428571428572e-05\n",
      "epoch: 1, loss: 4.672, avg: 2.71, latest lr: 5.300000000000001e-05\n",
      "epoch: 1, loss: 4.449, avg: 2.71, latest lr: 5.2985714285714284e-05\n",
      "epoch: 1, loss: 6.348, avg: 2.71, latest lr: 5.2971428571428574e-05\n",
      "epoch: 1, loss: 6.054, avg: 2.71, latest lr: 5.295714285714286e-05\n",
      "epoch: 1, loss: 5.010, avg: 2.71, latest lr: 5.294285714285715e-05\n",
      "epoch: 1, loss: 6.103, avg: 2.71, latest lr: 5.2928571428571425e-05\n",
      "epoch: 1, loss: 4.904, avg: 2.71, latest lr: 5.2914285714285715e-05\n",
      "epoch: 1, loss: 6.033, avg: 2.71, latest lr: 5.2900000000000005e-05\n",
      "epoch: 1, loss: 4.706, avg: 2.71, latest lr: 5.288571428571428e-05\n",
      "epoch: 1, loss: 4.504, avg: 2.71, latest lr: 5.287142857142857e-05\n",
      "epoch: 1, loss: 5.369, avg: 2.71, latest lr: 5.285714285714286e-05\n",
      "epoch: 1, loss: 6.145, avg: 2.71, latest lr: 5.284285714285715e-05\n",
      "epoch: 1, loss: 4.517, avg: 2.71, latest lr: 5.282857142857143e-05\n",
      "epoch: 1, loss: 4.320, avg: 2.72, latest lr: 5.281428571428572e-05\n",
      "epoch: 1, loss: 4.594, avg: 2.72, latest lr: 5.28e-05\n",
      "epoch: 1, loss: 4.758, avg: 2.72, latest lr: 5.2785714285714286e-05\n",
      "epoch: 1, loss: 4.084, avg: 2.72, latest lr: 5.277142857142857e-05\n",
      "epoch: 1, loss: 4.633, avg: 2.72, latest lr: 5.275714285714286e-05\n",
      "epoch: 1, loss: 5.228, avg: 2.72, latest lr: 5.274285714285715e-05\n",
      "epoch: 1, loss: 4.144, avg: 2.72, latest lr: 5.272857142857143e-05\n",
      "epoch: 1, loss: 4.731, avg: 2.72, latest lr: 5.271428571428572e-05\n",
      "epoch: 1, loss: 5.326, avg: 2.72, latest lr: 5.270000000000001e-05\n",
      "epoch: 1, loss: 4.906, avg: 2.72, latest lr: 5.2685714285714284e-05\n",
      "epoch: 1, loss: 3.430, avg: 2.72, latest lr: 5.2671428571428574e-05\n",
      "epoch: 1, loss: 5.054, avg: 2.72, latest lr: 5.265714285714286e-05\n",
      "epoch: 1, loss: 4.342, avg: 2.72, latest lr: 5.264285714285715e-05\n",
      "epoch: 1, loss: 4.057, avg: 2.72, latest lr: 5.2628571428571424e-05\n",
      "epoch: 1, loss: 5.318, avg: 2.72, latest lr: 5.2614285714285714e-05\n",
      "epoch: 1, loss: 4.934, avg: 2.73, latest lr: 5.2600000000000005e-05\n",
      "epoch: 1, loss: 5.949, avg: 2.73, latest lr: 5.2585714285714295e-05\n",
      "epoch: 1, loss: 4.785, avg: 2.73, latest lr: 5.257142857142857e-05\n",
      "epoch: 1, loss: 6.975, avg: 2.73, latest lr: 5.255714285714286e-05\n",
      "epoch: 1, loss: 5.033, avg: 2.73, latest lr: 5.254285714285715e-05\n",
      "epoch: 1, loss: 5.507, avg: 2.73, latest lr: 5.252857142857143e-05\n",
      "epoch: 1, loss: 4.511, avg: 2.73, latest lr: 5.251428571428572e-05\n",
      "epoch: 1, loss: 5.757, avg: 2.73, latest lr: 5.25e-05\n",
      "epoch: 1, loss: 5.148, avg: 2.73, latest lr: 5.248571428571429e-05\n",
      "epoch: 1, loss: 5.044, avg: 2.73, latest lr: 5.247142857142857e-05\n",
      "epoch: 1, loss: 4.911, avg: 2.73, latest lr: 5.245714285714286e-05\n",
      "epoch: 1, loss: 5.618, avg: 2.73, latest lr: 5.244285714285715e-05\n",
      "epoch: 1, loss: 5.488, avg: 2.73, latest lr: 5.2428571428571426e-05\n",
      "epoch: 1, loss: 5.683, avg: 2.74, latest lr: 5.2414285714285716e-05\n",
      "epoch: 1, loss: 4.218, avg: 2.74, latest lr: 5.2400000000000007e-05\n",
      "epoch: 1, loss: 4.749, avg: 2.74, latest lr: 5.23857142857143e-05\n",
      "epoch: 1, loss: 4.273, avg: 2.74, latest lr: 5.237142857142857e-05\n",
      "epoch: 1, loss: 5.455, avg: 2.74, latest lr: 5.235714285714286e-05\n",
      "epoch: 1, loss: 5.056, avg: 2.74, latest lr: 5.234285714285715e-05\n",
      "epoch: 1, loss: 6.192, avg: 2.74, latest lr: 5.2328571428571424e-05\n",
      "epoch: 1, loss: 4.566, avg: 2.74, latest lr: 5.2314285714285714e-05\n",
      "epoch: 1, loss: 4.801, avg: 2.74, latest lr: 5.2300000000000004e-05\n",
      "epoch: 1, loss: 5.754, avg: 2.74, latest lr: 5.2285714285714294e-05\n",
      "epoch: 1, loss: 3.966, avg: 2.74, latest lr: 5.227142857142857e-05\n",
      "epoch: 1, loss: 3.858, avg: 2.74, latest lr: 5.225714285714286e-05\n",
      "epoch: 1, loss: 4.465, avg: 2.74, latest lr: 5.224285714285715e-05\n",
      "epoch: 1, loss: 4.924, avg: 2.74, latest lr: 5.222857142857143e-05\n",
      "epoch: 1, loss: 4.075, avg: 2.75, latest lr: 5.221428571428572e-05\n",
      "epoch: 1, loss: 3.767, avg: 2.75, latest lr: 5.22e-05\n",
      "epoch: 1, loss: 4.649, avg: 2.75, latest lr: 5.218571428571429e-05\n",
      "epoch: 1, loss: 5.046, avg: 2.75, latest lr: 5.217142857142857e-05\n",
      "epoch: 1, loss: 6.148, avg: 2.75, latest lr: 5.215714285714286e-05\n",
      "epoch: 1, loss: 4.646, avg: 2.75, latest lr: 5.214285714285715e-05\n",
      "epoch: 1, loss: 4.600, avg: 2.75, latest lr: 5.2128571428571426e-05\n",
      "epoch: 1, loss: 3.425, avg: 2.75, latest lr: 5.2114285714285716e-05\n",
      "epoch: 1, loss: 3.724, avg: 2.75, latest lr: 5.2100000000000006e-05\n",
      "epoch: 1, loss: 4.474, avg: 2.75, latest lr: 5.2085714285714296e-05\n",
      "epoch: 1, loss: 4.444, avg: 2.75, latest lr: 5.207142857142857e-05\n",
      "epoch: 1, loss: 5.603, avg: 2.75, latest lr: 5.205714285714286e-05\n",
      "epoch: 1, loss: 5.965, avg: 2.75, latest lr: 5.2042857142857147e-05\n",
      "epoch: 1, loss: 4.947, avg: 2.75, latest lr: 5.202857142857142e-05\n",
      "epoch: 1, loss: 5.780, avg: 2.75, latest lr: 5.201428571428571e-05\n",
      "epoch: 1, loss: 5.589, avg: 2.76, latest lr: 5.2000000000000004e-05\n",
      "epoch: 1, loss: 5.912, avg: 2.76, latest lr: 5.1985714285714294e-05\n",
      "epoch: 1, loss: 6.394, avg: 2.76, latest lr: 5.197142857142857e-05\n",
      "epoch: 1, loss: 5.051, avg: 2.76, latest lr: 5.195714285714286e-05\n",
      "epoch: 1, loss: 5.011, avg: 2.76, latest lr: 5.194285714285715e-05\n",
      "epoch: 1, loss: 3.567, avg: 2.76, latest lr: 5.192857142857143e-05\n",
      "epoch: 1, loss: 5.196, avg: 2.76, latest lr: 5.191428571428572e-05\n",
      "epoch: 1, loss: 5.742, avg: 2.76, latest lr: 5.19e-05\n",
      "epoch: 1, loss: 5.225, avg: 2.76, latest lr: 5.188571428571429e-05\n",
      "epoch: 1, loss: 5.317, avg: 2.76, latest lr: 5.187142857142857e-05\n",
      "epoch: 1, loss: 4.291, avg: 2.76, latest lr: 5.185714285714286e-05\n",
      "epoch: 1, loss: 5.291, avg: 2.76, latest lr: 5.184285714285715e-05\n",
      "epoch: 1, loss: 5.674, avg: 2.76, latest lr: 5.1828571428571425e-05\n",
      "epoch: 1, loss: 3.752, avg: 2.76, latest lr: 5.1814285714285715e-05\n",
      "epoch: 1, loss: 5.665, avg: 2.77, latest lr: 5.1800000000000005e-05\n",
      "epoch: 1, loss: 3.257, avg: 2.77, latest lr: 5.1785714285714296e-05\n",
      "epoch: 1, loss: 5.484, avg: 2.77, latest lr: 5.177142857142857e-05\n",
      "epoch: 1, loss: 5.239, avg: 2.77, latest lr: 5.175714285714286e-05\n",
      "epoch: 1, loss: 5.022, avg: 2.77, latest lr: 5.1742857142857146e-05\n",
      "epoch: 1, loss: 4.049, avg: 2.77, latest lr: 5.172857142857143e-05\n",
      "epoch: 1, loss: 5.362, avg: 2.77, latest lr: 5.171428571428571e-05\n",
      "epoch: 1, loss: 5.277, avg: 2.77, latest lr: 5.17e-05\n",
      "epoch: 1, loss: 4.824, avg: 2.77, latest lr: 5.168571428571429e-05\n",
      "epoch: 1, loss: 4.816, avg: 2.77, latest lr: 5.167142857142857e-05\n",
      "epoch: 1, loss: 4.659, avg: 2.77, latest lr: 5.165714285714286e-05\n",
      "epoch: 1, loss: 5.795, avg: 2.77, latest lr: 5.164285714285715e-05\n",
      "epoch: 1, loss: 3.968, avg: 2.77, latest lr: 5.162857142857143e-05\n",
      "epoch: 1, loss: 5.891, avg: 2.77, latest lr: 5.161428571428572e-05\n",
      "epoch: 1, loss: 5.650, avg: 2.78, latest lr: 5.16e-05\n",
      "epoch: 1, loss: 4.427, avg: 2.78, latest lr: 5.158571428571429e-05\n",
      "epoch: 1, loss: 4.051, avg: 2.78, latest lr: 5.157142857142857e-05\n",
      "epoch: 1, loss: 6.265, avg: 2.78, latest lr: 5.155714285714286e-05\n",
      "epoch: 1, loss: 4.699, avg: 2.78, latest lr: 5.154285714285715e-05\n",
      "epoch: 1, loss: 4.422, avg: 2.78, latest lr: 5.1528571428571425e-05\n",
      "epoch: 1, loss: 5.032, avg: 2.78, latest lr: 5.1514285714285715e-05\n",
      "epoch: 1, loss: 4.461, avg: 2.78, latest lr: 5.1500000000000005e-05\n",
      "epoch: 1, loss: 4.534, avg: 2.78, latest lr: 5.1485714285714295e-05\n",
      "epoch: 1, loss: 3.735, avg: 2.78, latest lr: 5.147142857142857e-05\n",
      "epoch: 1, loss: 4.181, avg: 2.78, latest lr: 5.145714285714286e-05\n",
      "epoch: 1, loss: 4.422, avg: 2.78, latest lr: 5.1442857142857145e-05\n",
      "epoch: 1, loss: 4.678, avg: 2.78, latest lr: 5.142857142857143e-05\n",
      "epoch: 1, loss: 4.724, avg: 2.78, latest lr: 5.141428571428571e-05\n",
      "epoch: 1, loss: 5.034, avg: 2.78, latest lr: 5.14e-05\n",
      "epoch: 1, loss: 4.951, avg: 2.79, latest lr: 5.138571428571429e-05\n",
      "epoch: 1, loss: 5.289, avg: 2.79, latest lr: 5.137142857142857e-05\n",
      "epoch: 1, loss: 5.751, avg: 2.79, latest lr: 5.135714285714286e-05\n",
      "epoch: 1, loss: 4.428, avg: 2.79, latest lr: 5.134285714285715e-05\n",
      "epoch: 1, loss: 5.122, avg: 2.79, latest lr: 5.1328571428571426e-05\n",
      "epoch: 1, loss: 5.585, avg: 2.79, latest lr: 5.131428571428572e-05\n",
      "epoch: 1, loss: 4.713, avg: 2.79, latest lr: 5.130000000000001e-05\n",
      "epoch: 1, loss: 3.099, avg: 2.79, latest lr: 5.128571428571429e-05\n",
      "epoch: 1, loss: 4.992, avg: 2.79, latest lr: 5.127142857142857e-05\n",
      "epoch: 1, loss: 5.837, avg: 2.79, latest lr: 5.125714285714286e-05\n",
      "epoch: 1, loss: 5.642, avg: 2.79, latest lr: 5.124285714285715e-05\n",
      "epoch: 1, loss: 4.809, avg: 2.79, latest lr: 5.1228571428571424e-05\n",
      "epoch: 1, loss: 4.990, avg: 2.79, latest lr: 5.1214285714285714e-05\n",
      "epoch: 1, loss: 3.755, avg: 2.79, latest lr: 5.1200000000000004e-05\n",
      "epoch: 1, loss: 5.040, avg: 2.80, latest lr: 5.1185714285714295e-05\n",
      "epoch: 1, loss: 4.548, avg: 2.80, latest lr: 5.117142857142857e-05\n",
      "epoch: 1, loss: 5.061, avg: 2.80, latest lr: 5.115714285714286e-05\n",
      "epoch: 1, loss: 5.359, avg: 2.80, latest lr: 5.1142857142857145e-05\n",
      "epoch: 1, loss: 3.987, avg: 2.80, latest lr: 5.112857142857143e-05\n",
      "epoch: 1, loss: 2.942, avg: 2.80, latest lr: 5.111428571428571e-05\n",
      "epoch: 1, loss: 4.090, avg: 2.80, latest lr: 5.11e-05\n",
      "epoch: 1, loss: 4.611, avg: 2.80, latest lr: 5.108571428571429e-05\n",
      "epoch: 1, loss: 5.682, avg: 2.80, latest lr: 5.107142857142857e-05\n",
      "epoch: 1, loss: 4.371, avg: 2.80, latest lr: 5.105714285714286e-05\n",
      "epoch: 1, loss: 3.858, avg: 2.80, latest lr: 5.104285714285715e-05\n",
      "epoch: 1, loss: 5.557, avg: 2.80, latest lr: 5.1028571428571426e-05\n",
      "epoch: 1, loss: 4.215, avg: 2.80, latest lr: 5.1014285714285716e-05\n",
      "epoch: 1, loss: 4.727, avg: 2.80, latest lr: 5.1000000000000006e-05\n",
      "epoch: 1, loss: 4.947, avg: 2.80, latest lr: 5.098571428571429e-05\n",
      "epoch: 1, loss: 5.969, avg: 2.81, latest lr: 5.097142857142857e-05\n",
      "epoch: 1, loss: 4.000, avg: 2.81, latest lr: 5.095714285714286e-05\n",
      "epoch: 1, loss: 4.653, avg: 2.81, latest lr: 5.094285714285715e-05\n",
      "epoch: 1, loss: 3.993, avg: 2.81, latest lr: 5.0928571428571424e-05\n",
      "epoch: 1, loss: 4.053, avg: 2.81, latest lr: 5.0914285714285714e-05\n",
      "epoch: 1, loss: 5.902, avg: 2.81, latest lr: 5.0900000000000004e-05\n",
      "epoch: 1, loss: 4.243, avg: 2.81, latest lr: 5.0885714285714294e-05\n",
      "epoch: 1, loss: 5.115, avg: 2.81, latest lr: 5.087142857142857e-05\n",
      "epoch: 1, loss: 3.802, avg: 2.81, latest lr: 5.085714285714286e-05\n",
      "epoch: 1, loss: 5.720, avg: 2.81, latest lr: 5.0842857142857144e-05\n",
      "epoch: 1, loss: 4.297, avg: 2.81, latest lr: 5.0828571428571435e-05\n",
      "epoch: 1, loss: 3.218, avg: 2.81, latest lr: 5.081428571428571e-05\n",
      "epoch: 1, loss: 6.538, avg: 2.81, latest lr: 5.08e-05\n",
      "epoch: 1, loss: 5.906, avg: 2.81, latest lr: 5.078571428571429e-05\n",
      "epoch: 1, loss: 6.550, avg: 2.82, latest lr: 5.077142857142857e-05\n",
      "epoch: 1, loss: 4.566, avg: 2.82, latest lr: 5.075714285714286e-05\n",
      "epoch: 1, loss: 3.789, avg: 2.82, latest lr: 5.074285714285715e-05\n",
      "epoch: 1, loss: 4.124, avg: 2.82, latest lr: 5.072857142857144e-05\n",
      "epoch: 1, loss: 4.099, avg: 2.82, latest lr: 5.0714285714285716e-05\n",
      "epoch: 1, loss: 6.179, avg: 2.82, latest lr: 5.0700000000000006e-05\n",
      "epoch: 1, loss: 5.006, avg: 2.82, latest lr: 5.068571428571429e-05\n",
      "epoch: 1, loss: 3.930, avg: 2.82, latest lr: 5.067142857142857e-05\n",
      "epoch: 1, loss: 5.344, avg: 2.82, latest lr: 5.0657142857142856e-05\n",
      "epoch: 1, loss: 4.503, avg: 2.82, latest lr: 5.0642857142857146e-05\n",
      "epoch: 1, loss: 5.089, avg: 2.82, latest lr: 5.0628571428571437e-05\n",
      "epoch: 1, loss: 4.803, avg: 2.82, latest lr: 5.061428571428571e-05\n",
      "epoch: 1, loss: 4.277, avg: 2.82, latest lr: 5.0600000000000003e-05\n",
      "epoch: 1, loss: 4.508, avg: 2.82, latest lr: 5.0585714285714294e-05\n",
      "epoch: 1, loss: 5.993, avg: 2.82, latest lr: 5.057142857142857e-05\n",
      "epoch: 1, loss: 5.106, avg: 2.83, latest lr: 5.055714285714286e-05\n",
      "epoch: 1, loss: 5.052, avg: 2.83, latest lr: 5.054285714285715e-05\n",
      "epoch: 1, loss: 4.826, avg: 2.83, latest lr: 5.0528571428571434e-05\n",
      "epoch: 1, loss: 5.254, avg: 2.83, latest lr: 5.051428571428571e-05\n",
      "epoch: 1, loss: 4.286, avg: 2.83, latest lr: 5.05e-05\n",
      "epoch: 1, loss: 4.312, avg: 2.83, latest lr: 5.048571428571429e-05\n",
      "epoch: 1, loss: 3.728, avg: 2.83, latest lr: 5.047142857142857e-05\n",
      "epoch: 1, loss: 5.271, avg: 2.83, latest lr: 5.045714285714286e-05\n",
      "epoch: 1, loss: 4.776, avg: 2.83, latest lr: 5.044285714285715e-05\n",
      "epoch: 1, loss: 5.059, avg: 2.83, latest lr: 5.042857142857144e-05\n",
      "epoch: 1, loss: 4.790, avg: 2.83, latest lr: 5.0414285714285715e-05\n",
      "epoch: 1, loss: 5.879, avg: 2.83, latest lr: 5.0400000000000005e-05\n",
      "epoch: 1, loss: 4.933, avg: 2.83, latest lr: 5.038571428571429e-05\n",
      "epoch: 1, loss: 4.534, avg: 2.83, latest lr: 5.037142857142857e-05\n",
      "epoch: 1, loss: 3.815, avg: 2.83, latest lr: 5.0357142857142856e-05\n",
      "epoch: 1, loss: 5.839, avg: 2.84, latest lr: 5.0342857142857146e-05\n",
      "epoch: 1, loss: 4.212, avg: 2.84, latest lr: 5.0328571428571436e-05\n",
      "epoch: 1, loss: 5.380, avg: 2.84, latest lr: 5.031428571428571e-05\n",
      "epoch: 1, loss: 3.847, avg: 2.84, latest lr: 5.03e-05\n",
      "epoch: 1, loss: 3.686, avg: 2.84, latest lr: 5.028571428571429e-05\n",
      "epoch: 1, loss: 4.180, avg: 2.84, latest lr: 5.027142857142857e-05\n",
      "epoch: 1, loss: 4.264, avg: 2.84, latest lr: 5.025714285714286e-05\n",
      "epoch: 1, loss: 6.365, avg: 2.84, latest lr: 5.024285714285715e-05\n",
      "epoch: 1, loss: 3.845, avg: 2.84, latest lr: 5.0228571428571434e-05\n",
      "epoch: 1, loss: 4.518, avg: 2.84, latest lr: 5.021428571428572e-05\n",
      "epoch: 1, loss: 4.899, avg: 2.84, latest lr: 5.02e-05\n",
      "epoch: 1, loss: 4.618, avg: 2.84, latest lr: 5.018571428571429e-05\n",
      "epoch: 1, loss: 3.751, avg: 2.84, latest lr: 5.017142857142857e-05\n",
      "epoch: 1, loss: 5.368, avg: 2.84, latest lr: 5.015714285714286e-05\n",
      "epoch: 1, loss: 5.048, avg: 2.84, latest lr: 5.014285714285715e-05\n",
      "epoch: 1, loss: 4.597, avg: 2.85, latest lr: 5.012857142857144e-05\n",
      "epoch: 1, loss: 4.085, avg: 2.85, latest lr: 5.0114285714285715e-05\n",
      "epoch: 1, loss: 3.949, avg: 2.85, latest lr: 5.0100000000000005e-05\n",
      "epoch: 1, loss: 5.523, avg: 2.85, latest lr: 5.008571428571429e-05\n",
      "epoch: 1, loss: 4.600, avg: 2.85, latest lr: 5.007142857142857e-05\n",
      "epoch: 1, loss: 3.657, avg: 2.85, latest lr: 5.0057142857142855e-05\n",
      "epoch: 1, loss: 5.501, avg: 2.85, latest lr: 5.0042857142857145e-05\n",
      "epoch: 1, loss: 4.683, avg: 2.85, latest lr: 5.0028571428571436e-05\n",
      "epoch: 1, loss: 4.557, avg: 2.85, latest lr: 5.001428571428571e-05\n",
      "epoch: 1, loss: 4.591, avg: 2.85, latest lr: 5e-05\n",
      "epoch: 1, loss: 5.062, avg: 2.85, latest lr: 4.9985714285714286e-05\n",
      "epoch: 1, loss: 4.134, avg: 2.85, latest lr: 4.9971428571428576e-05\n",
      "epoch: 1, loss: 5.439, avg: 2.85, latest lr: 4.995714285714286e-05\n",
      "epoch: 1, loss: 6.741, avg: 2.85, latest lr: 4.994285714285715e-05\n",
      "epoch: 1, loss: 5.429, avg: 2.86, latest lr: 4.992857142857143e-05\n",
      "epoch: 1, loss: 6.524, avg: 2.86, latest lr: 4.9914285714285717e-05\n",
      "epoch: 1, loss: 4.577, avg: 2.86, latest lr: 4.99e-05\n",
      "epoch: 1, loss: 5.163, avg: 2.86, latest lr: 4.9885714285714283e-05\n",
      "epoch: 1, loss: 5.000, avg: 2.86, latest lr: 4.9871428571428574e-05\n",
      "epoch: 1, loss: 4.555, avg: 2.86, latest lr: 4.985714285714286e-05\n",
      "epoch: 1, loss: 5.685, avg: 2.86, latest lr: 4.984285714285715e-05\n",
      "epoch: 1, loss: 5.657, avg: 2.86, latest lr: 4.982857142857143e-05\n",
      "epoch: 1, loss: 4.797, avg: 2.86, latest lr: 4.981428571428572e-05\n",
      "epoch: 1, loss: 5.252, avg: 2.86, latest lr: 4.9800000000000004e-05\n",
      "epoch: 1, loss: 4.262, avg: 2.86, latest lr: 4.978571428571429e-05\n",
      "epoch: 1, loss: 5.944, avg: 2.86, latest lr: 4.977142857142857e-05\n",
      "epoch: 1, loss: 5.123, avg: 2.86, latest lr: 4.9757142857142855e-05\n",
      "epoch: 1, loss: 3.691, avg: 2.86, latest lr: 4.9742857142857145e-05\n",
      "epoch: 1, loss: 4.267, avg: 2.87, latest lr: 4.972857142857143e-05\n",
      "epoch: 1, loss: 6.018, avg: 2.87, latest lr: 4.971428571428572e-05\n",
      "epoch: 1, loss: 4.145, avg: 2.87, latest lr: 4.97e-05\n",
      "epoch: 1, loss: 5.457, avg: 2.87, latest lr: 4.9685714285714285e-05\n",
      "epoch: 1, loss: 5.335, avg: 2.87, latest lr: 4.9671428571428576e-05\n",
      "epoch: 1, loss: 4.348, avg: 2.87, latest lr: 4.965714285714286e-05\n",
      "epoch: 1, loss: 4.890, avg: 2.87, latest lr: 4.964285714285715e-05\n",
      "epoch: 1, loss: 4.463, avg: 2.87, latest lr: 4.962857142857143e-05\n",
      "epoch: 1, loss: 4.422, avg: 2.87, latest lr: 4.9614285714285716e-05\n",
      "epoch: 1, loss: 3.883, avg: 2.87, latest lr: 4.96e-05\n",
      "epoch: 1, loss: 5.934, avg: 2.87, latest lr: 4.958571428571428e-05\n",
      "epoch: 1, loss: 5.087, avg: 2.87, latest lr: 4.957142857142857e-05\n",
      "epoch: 1, loss: 4.361, avg: 2.87, latest lr: 4.9557142857142857e-05\n",
      "epoch: 1, loss: 5.665, avg: 2.87, latest lr: 4.954285714285715e-05\n",
      "epoch: 1, loss: 4.529, avg: 2.88, latest lr: 4.952857142857143e-05\n",
      "epoch: 1, loss: 4.287, avg: 2.88, latest lr: 4.951428571428572e-05\n",
      "epoch: 1, loss: 4.860, avg: 2.88, latest lr: 4.9500000000000004e-05\n",
      "epoch: 1, loss: 5.271, avg: 2.88, latest lr: 4.9485714285714294e-05\n",
      "epoch: 1, loss: 6.416, avg: 2.88, latest lr: 4.947142857142858e-05\n",
      "epoch: 1, loss: 5.617, avg: 2.88, latest lr: 4.9457142857142854e-05\n",
      "epoch: 1, loss: 4.535, avg: 2.88, latest lr: 4.9442857142857144e-05\n",
      "epoch: 1, loss: 5.312, avg: 2.88, latest lr: 4.942857142857143e-05\n",
      "epoch: 1, loss: 5.120, avg: 2.88, latest lr: 4.941428571428572e-05\n",
      "epoch: 1, loss: 4.515, avg: 2.88, latest lr: 4.94e-05\n",
      "epoch: 1, loss: 5.474, avg: 2.88, latest lr: 4.938571428571429e-05\n",
      "epoch: 1, loss: 3.805, avg: 2.88, latest lr: 4.9371428571428575e-05\n",
      "epoch: 1, loss: 4.618, avg: 2.88, latest lr: 4.935714285714286e-05\n",
      "epoch: 1, loss: 4.243, avg: 2.88, latest lr: 4.934285714285715e-05\n",
      "epoch: 1, loss: 5.130, avg: 2.88, latest lr: 4.932857142857143e-05\n",
      "epoch: 1, loss: 5.567, avg: 2.89, latest lr: 4.9314285714285716e-05\n",
      "epoch: 1, loss: 5.016, avg: 2.89, latest lr: 4.93e-05\n",
      "epoch: 1, loss: 3.430, avg: 2.89, latest lr: 4.928571428571429e-05\n",
      "epoch: 1, loss: 3.804, avg: 2.89, latest lr: 4.927142857142857e-05\n",
      "epoch: 1, loss: 5.031, avg: 2.89, latest lr: 4.9257142857142856e-05\n",
      "epoch: 1, loss: 5.282, avg: 2.89, latest lr: 4.9242857142857146e-05\n",
      "epoch: 1, loss: 3.994, avg: 2.89, latest lr: 4.922857142857143e-05\n",
      "epoch: 1, loss: 5.731, avg: 2.89, latest lr: 4.921428571428572e-05\n",
      "epoch: 1, loss: 4.373, avg: 2.89, latest lr: 4.92e-05\n",
      "epoch: 1, loss: 4.833, avg: 2.89, latest lr: 4.9185714285714293e-05\n",
      "epoch: 1, loss: 4.906, avg: 2.89, latest lr: 4.917142857142858e-05\n",
      "epoch: 1, loss: 4.819, avg: 2.89, latest lr: 4.915714285714286e-05\n",
      "epoch: 1, loss: 5.189, avg: 2.89, latest lr: 4.9142857142857144e-05\n",
      "epoch: 1, loss: 4.233, avg: 2.89, latest lr: 4.912857142857143e-05\n",
      "epoch: 1, loss: 5.864, avg: 2.90, latest lr: 4.911428571428572e-05\n",
      "epoch: 1, loss: 5.029, avg: 2.90, latest lr: 4.91e-05\n",
      "epoch: 1, loss: 6.109, avg: 2.90, latest lr: 4.908571428571429e-05\n",
      "epoch: 1, loss: 3.987, avg: 2.90, latest lr: 4.9071428571428574e-05\n",
      "epoch: 1, loss: 5.192, avg: 2.90, latest lr: 4.905714285714286e-05\n",
      "epoch: 1, loss: 4.640, avg: 2.90, latest lr: 4.904285714285715e-05\n",
      "epoch: 1, loss: 4.441, avg: 2.90, latest lr: 4.902857142857143e-05\n",
      "epoch: 1, loss: 5.534, avg: 2.90, latest lr: 4.9014285714285715e-05\n",
      "epoch: 1, loss: 5.935, avg: 2.90, latest lr: 4.9e-05\n",
      "epoch: 1, loss: 5.068, avg: 2.90, latest lr: 4.898571428571429e-05\n",
      "epoch: 1, loss: 4.221, avg: 2.90, latest lr: 4.897142857142857e-05\n",
      "epoch: 1, loss: 3.998, avg: 2.90, latest lr: 4.8957142857142855e-05\n",
      "epoch: 1, loss: 4.297, avg: 2.90, latest lr: 4.8942857142857146e-05\n",
      "epoch: 1, loss: 3.332, avg: 2.90, latest lr: 4.892857142857143e-05\n",
      "epoch: 1, loss: 5.667, avg: 2.90, latest lr: 4.891428571428572e-05\n",
      "epoch: 1, loss: 4.117, avg: 2.91, latest lr: 4.89e-05\n",
      "epoch: 1, loss: 4.607, avg: 2.91, latest lr: 4.888571428571429e-05\n",
      "epoch: 1, loss: 5.395, avg: 2.91, latest lr: 4.8871428571428576e-05\n",
      "epoch: 1, loss: 4.994, avg: 2.91, latest lr: 4.885714285714286e-05\n",
      "epoch: 1, loss: 5.235, avg: 2.91, latest lr: 4.884285714285714e-05\n",
      "epoch: 1, loss: 4.561, avg: 2.91, latest lr: 4.882857142857143e-05\n",
      "epoch: 1, loss: 6.813, avg: 2.91, latest lr: 4.881428571428572e-05\n",
      "epoch: 1, loss: 4.199, avg: 2.91, latest lr: 4.88e-05\n",
      "epoch: 1, loss: 5.411, avg: 2.91, latest lr: 4.878571428571429e-05\n",
      "epoch: 1, loss: 4.981, avg: 2.91, latest lr: 4.8771428571428574e-05\n",
      "epoch: 1, loss: 3.903, avg: 2.91, latest lr: 4.875714285714286e-05\n",
      "epoch: 1, loss: 5.222, avg: 2.91, latest lr: 4.874285714285715e-05\n",
      "epoch: 1, loss: 5.491, avg: 2.91, latest lr: 4.872857142857143e-05\n",
      "epoch: 1, loss: 3.360, avg: 2.91, latest lr: 4.8714285714285714e-05\n",
      "epoch: 1, loss: 5.808, avg: 2.92, latest lr: 4.87e-05\n",
      "epoch: 1, loss: 3.429, avg: 2.92, latest lr: 4.868571428571429e-05\n",
      "epoch: 1, loss: 5.658, avg: 2.92, latest lr: 4.867142857142857e-05\n",
      "epoch: 1, loss: 5.332, avg: 2.92, latest lr: 4.865714285714286e-05\n",
      "epoch: 1, loss: 5.891, avg: 2.92, latest lr: 4.8642857142857145e-05\n",
      "epoch: 1, loss: 4.693, avg: 2.92, latest lr: 4.862857142857143e-05\n",
      "epoch: 1, loss: 6.409, avg: 2.92, latest lr: 4.861428571428572e-05\n",
      "epoch: 1, loss: 4.780, avg: 2.92, latest lr: 4.86e-05\n",
      "epoch: 1, loss: 5.954, avg: 2.92, latest lr: 4.858571428571429e-05\n",
      "epoch: 1, loss: 5.410, avg: 2.92, latest lr: 4.8571428571428576e-05\n",
      "epoch: 1, loss: 3.773, avg: 2.92, latest lr: 4.855714285714286e-05\n",
      "epoch: 1, loss: 4.783, avg: 2.92, latest lr: 4.854285714285714e-05\n",
      "epoch: 1, loss: 3.929, avg: 2.92, latest lr: 4.8528571428571426e-05\n",
      "epoch: 1, loss: 4.599, avg: 2.92, latest lr: 4.8514285714285716e-05\n",
      "epoch: 1, loss: 4.426, avg: 2.93, latest lr: 4.85e-05\n",
      "epoch: 1, loss: 4.788, avg: 2.93, latest lr: 4.848571428571429e-05\n",
      "epoch: 1, loss: 4.432, avg: 2.93, latest lr: 4.8471428571428573e-05\n",
      "epoch: 1, loss: 4.376, avg: 2.93, latest lr: 4.8457142857142864e-05\n",
      "epoch: 1, loss: 3.817, avg: 2.93, latest lr: 4.844285714285715e-05\n",
      "epoch: 1, loss: 5.146, avg: 2.93, latest lr: 4.842857142857143e-05\n",
      "epoch: 1, loss: 4.701, avg: 2.93, latest lr: 4.841428571428572e-05\n",
      "epoch: 1, loss: 5.162, avg: 2.93, latest lr: 4.8400000000000004e-05\n",
      "epoch: 1, loss: 4.958, avg: 2.93, latest lr: 4.838571428571429e-05\n",
      "epoch: 1, loss: 5.204, avg: 2.93, latest lr: 4.837142857142857e-05\n",
      "epoch: 1, loss: 3.661, avg: 2.93, latest lr: 4.835714285714286e-05\n",
      "epoch: 1, loss: 3.642, avg: 2.93, latest lr: 4.8342857142857145e-05\n",
      "epoch: 1, loss: 3.985, avg: 2.93, latest lr: 4.832857142857143e-05\n",
      "epoch: 1, loss: 5.509, avg: 2.93, latest lr: 4.831428571428572e-05\n",
      "epoch: 1, loss: 5.381, avg: 2.93, latest lr: 4.83e-05\n",
      "epoch: 1, loss: 5.694, avg: 2.94, latest lr: 4.828571428571429e-05\n",
      "epoch: 1, loss: 3.442, avg: 2.94, latest lr: 4.8271428571428575e-05\n",
      "epoch: 1, loss: 5.118, avg: 2.94, latest lr: 4.825714285714286e-05\n",
      "epoch: 1, loss: 4.610, avg: 2.94, latest lr: 4.824285714285714e-05\n",
      "epoch: 1, loss: 4.772, avg: 2.94, latest lr: 4.8228571428571426e-05\n",
      "epoch: 1, loss: 6.726, avg: 2.94, latest lr: 4.8214285714285716e-05\n",
      "epoch: 1, loss: 5.357, avg: 2.94, latest lr: 4.82e-05\n",
      "epoch: 1, loss: 5.532, avg: 2.94, latest lr: 4.818571428571429e-05\n",
      "epoch: 1, loss: 4.997, avg: 2.94, latest lr: 4.817142857142857e-05\n",
      "epoch: 1, loss: 4.728, avg: 2.94, latest lr: 4.815714285714286e-05\n",
      "epoch: 1, loss: 4.916, avg: 2.94, latest lr: 4.8142857142857147e-05\n",
      "epoch: 1, loss: 5.786, avg: 2.94, latest lr: 4.812857142857143e-05\n",
      "epoch: 1, loss: 5.086, avg: 2.94, latest lr: 4.811428571428572e-05\n",
      "epoch: 1, loss: 6.687, avg: 2.95, latest lr: 4.8100000000000004e-05\n",
      "epoch: 1, loss: 5.590, avg: 2.95, latest lr: 4.808571428571429e-05\n",
      "epoch: 1, loss: 3.923, avg: 2.95, latest lr: 4.807142857142857e-05\n",
      "epoch: 1, loss: 4.494, avg: 2.95, latest lr: 4.805714285714286e-05\n",
      "epoch: 1, loss: 5.603, avg: 2.95, latest lr: 4.8042857142857144e-05\n",
      "epoch: 1, loss: 3.821, avg: 2.95, latest lr: 4.802857142857143e-05\n",
      "epoch: 1, loss: 5.391, avg: 2.95, latest lr: 4.801428571428572e-05\n",
      "epoch: 1, loss: 4.618, avg: 2.95, latest lr: 4.8e-05\n",
      "epoch: 1, loss: 4.960, avg: 2.95, latest lr: 4.798571428571429e-05\n",
      "epoch: 1, loss: 4.893, avg: 2.95, latest lr: 4.7971428571428575e-05\n",
      "epoch: 1, loss: 4.399, avg: 2.95, latest lr: 4.795714285714286e-05\n",
      "epoch: 1, loss: 5.475, avg: 2.95, latest lr: 4.794285714285714e-05\n",
      "epoch: 1, loss: 6.218, avg: 2.95, latest lr: 4.7928571428571425e-05\n",
      "epoch: 1, loss: 4.140, avg: 2.95, latest lr: 4.7914285714285715e-05\n",
      "epoch: 1, loss: 3.938, avg: 2.95, latest lr: 4.79e-05\n",
      "epoch: 1, loss: 4.213, avg: 2.96, latest lr: 4.788571428571429e-05\n",
      "epoch: 1, loss: 5.192, avg: 2.96, latest lr: 4.787142857142857e-05\n",
      "epoch: 1, loss: 5.196, avg: 2.96, latest lr: 4.785714285714286e-05\n",
      "epoch: 1, loss: 5.784, avg: 2.96, latest lr: 4.7842857142857146e-05\n",
      "epoch: 1, loss: 5.062, avg: 2.96, latest lr: 4.782857142857143e-05\n",
      "epoch: 1, loss: 5.113, avg: 2.96, latest lr: 4.781428571428572e-05\n",
      "epoch: 1, loss: 3.899, avg: 2.96, latest lr: 4.78e-05\n",
      "epoch: 1, loss: 3.937, avg: 2.96, latest lr: 4.7785714285714287e-05\n",
      "epoch: 1, loss: 4.429, avg: 2.96, latest lr: 4.777142857142857e-05\n",
      "epoch: 1, loss: 5.007, avg: 2.96, latest lr: 4.775714285714286e-05\n",
      "epoch: 1, loss: 4.940, avg: 2.96, latest lr: 4.7742857142857144e-05\n",
      "epoch: 1, loss: 3.691, avg: 2.96, latest lr: 4.7728571428571434e-05\n",
      "epoch: 1, loss: 3.065, avg: 2.96, latest lr: 4.771428571428572e-05\n",
      "epoch: 1, loss: 4.602, avg: 2.96, latest lr: 4.77e-05\n",
      "epoch: 1, loss: 5.509, avg: 2.96, latest lr: 4.768571428571429e-05\n",
      "epoch: 1, loss: 5.115, avg: 2.97, latest lr: 4.7671428571428574e-05\n",
      "epoch: 1, loss: 4.152, avg: 2.97, latest lr: 4.7657142857142865e-05\n",
      "epoch: 1, loss: 4.530, avg: 2.97, latest lr: 4.764285714285715e-05\n",
      "epoch: 1, loss: 4.721, avg: 2.97, latest lr: 4.762857142857143e-05\n",
      "epoch: 1, loss: 3.661, avg: 2.97, latest lr: 4.7614285714285715e-05\n",
      "epoch: 1, loss: 4.796, avg: 2.97, latest lr: 4.76e-05\n",
      "epoch: 1, loss: 5.410, avg: 2.97, latest lr: 4.758571428571429e-05\n",
      "epoch: 1, loss: 5.253, avg: 2.97, latest lr: 4.757142857142857e-05\n",
      "epoch: 1, loss: 4.465, avg: 2.97, latest lr: 4.755714285714286e-05\n",
      "epoch: 1, loss: 5.287, avg: 2.97, latest lr: 4.7542857142857146e-05\n",
      "epoch: 1, loss: 3.993, avg: 2.97, latest lr: 4.7528571428571436e-05\n",
      "epoch: 1, loss: 3.833, avg: 2.97, latest lr: 4.751428571428572e-05\n",
      "epoch: 1, loss: 5.051, avg: 2.97, latest lr: 4.75e-05\n",
      "epoch: 1, loss: 3.779, avg: 2.97, latest lr: 4.7485714285714286e-05\n",
      "epoch: 1, loss: 4.260, avg: 2.97, latest lr: 4.747142857142857e-05\n",
      "epoch: 1, loss: 2.988, avg: 2.97, latest lr: 4.745714285714286e-05\n",
      "epoch: 1, loss: 3.962, avg: 2.98, latest lr: 4.744285714285714e-05\n",
      "epoch: 1, loss: 5.899, avg: 2.98, latest lr: 4.742857142857143e-05\n",
      "epoch: 1, loss: 4.070, avg: 2.98, latest lr: 4.741428571428572e-05\n",
      "epoch: 1, loss: 3.781, avg: 2.98, latest lr: 4.74e-05\n",
      "epoch: 1, loss: 5.814, avg: 2.98, latest lr: 4.738571428571429e-05\n",
      "epoch: 1, loss: 3.707, avg: 2.98, latest lr: 4.7371428571428574e-05\n",
      "epoch: 1, loss: 4.972, avg: 2.98, latest lr: 4.7357142857142864e-05\n",
      "epoch: 1, loss: 4.582, avg: 2.98, latest lr: 4.734285714285715e-05\n",
      "epoch: 1, loss: 5.285, avg: 2.98, latest lr: 4.732857142857143e-05\n",
      "epoch: 1, loss: 4.478, avg: 2.98, latest lr: 4.7314285714285714e-05\n",
      "epoch: 1, loss: 4.806, avg: 2.98, latest lr: 4.73e-05\n",
      "epoch: 1, loss: 3.909, avg: 2.98, latest lr: 4.728571428571429e-05\n",
      "epoch: 1, loss: 4.498, avg: 2.98, latest lr: 4.727142857142857e-05\n",
      "epoch: 1, loss: 5.100, avg: 2.98, latest lr: 4.725714285714286e-05\n",
      "epoch: 1, loss: 5.636, avg: 2.98, latest lr: 4.7242857142857145e-05\n",
      "epoch: 1, loss: 4.353, avg: 2.99, latest lr: 4.7228571428571435e-05\n",
      "epoch: 1, loss: 3.866, avg: 2.99, latest lr: 4.721428571428572e-05\n",
      "epoch: 1, loss: 5.607, avg: 2.99, latest lr: 4.72e-05\n",
      "epoch: 1, loss: 4.410, avg: 2.99, latest lr: 4.7185714285714286e-05\n",
      "epoch: 1, loss: 5.270, avg: 2.99, latest lr: 4.717142857142857e-05\n",
      "epoch: 1, loss: 4.567, avg: 2.99, latest lr: 4.715714285714286e-05\n",
      "epoch: 1, loss: 5.304, avg: 2.99, latest lr: 4.714285714285714e-05\n",
      "epoch: 1, loss: 4.409, avg: 2.99, latest lr: 4.712857142857143e-05\n",
      "epoch: 1, loss: 5.773, avg: 2.99, latest lr: 4.7114285714285716e-05\n",
      "epoch: 1, loss: 5.006, avg: 2.99, latest lr: 4.71e-05\n",
      "epoch: 1, loss: 5.076, avg: 2.99, latest lr: 4.708571428571429e-05\n",
      "epoch: 1, loss: 6.396, avg: 2.99, latest lr: 4.707142857142857e-05\n",
      "epoch: 1, loss: 4.921, avg: 2.99, latest lr: 4.7057142857142864e-05\n",
      "epoch: 1, loss: 3.118, avg: 2.99, latest lr: 4.704285714285715e-05\n",
      "epoch: 1, loss: 5.463, avg: 3.00, latest lr: 4.702857142857143e-05\n",
      "epoch: 1, loss: 3.828, avg: 3.00, latest lr: 4.7014285714285714e-05\n",
      "epoch: 1, loss: 4.623, avg: 3.00, latest lr: 4.7e-05\n",
      "epoch: 1, loss: 4.692, avg: 3.00, latest lr: 4.698571428571429e-05\n",
      "epoch: 1, loss: 5.297, avg: 3.00, latest lr: 4.697142857142857e-05\n",
      "epoch: 1, loss: 5.772, avg: 3.00, latest lr: 4.695714285714286e-05\n",
      "epoch: 1, loss: 4.405, avg: 3.00, latest lr: 4.6942857142857145e-05\n",
      "epoch: 1, loss: 5.997, avg: 3.00, latest lr: 4.6928571428571435e-05\n",
      "epoch: 1, loss: 3.861, avg: 3.00, latest lr: 4.691428571428572e-05\n",
      "epoch: 1, loss: 5.236, avg: 3.00, latest lr: 4.69e-05\n",
      "epoch: 1, loss: 5.109, avg: 3.00, latest lr: 4.6885714285714285e-05\n",
      "epoch: 1, loss: 5.395, avg: 3.00, latest lr: 4.687142857142857e-05\n",
      "epoch: 1, loss: 4.678, avg: 3.00, latest lr: 4.685714285714286e-05\n",
      "epoch: 1, loss: 6.428, avg: 3.00, latest lr: 4.684285714285714e-05\n",
      "epoch: 1, loss: 5.080, avg: 3.01, latest lr: 4.682857142857143e-05\n",
      "epoch: 1, loss: 4.847, avg: 3.01, latest lr: 4.6814285714285716e-05\n",
      "epoch: 1, loss: 3.726, avg: 3.01, latest lr: 4.6800000000000006e-05\n",
      "epoch: 1, loss: 4.952, avg: 3.01, latest lr: 4.678571428571429e-05\n",
      "epoch: 1, loss: 5.562, avg: 3.01, latest lr: 4.677142857142857e-05\n",
      "epoch: 1, loss: 5.212, avg: 3.01, latest lr: 4.675714285714286e-05\n",
      "epoch: 1, loss: 4.916, avg: 3.01, latest lr: 4.6742857142857146e-05\n",
      "epoch: 1, loss: 4.943, avg: 3.01, latest lr: 4.672857142857143e-05\n",
      "epoch: 1, loss: 3.449, avg: 3.01, latest lr: 4.671428571428571e-05\n",
      "epoch: 1, loss: 4.183, avg: 3.01, latest lr: 4.6700000000000003e-05\n",
      "epoch: 1, loss: 3.773, avg: 3.01, latest lr: 4.668571428571429e-05\n",
      "epoch: 1, loss: 5.853, avg: 3.01, latest lr: 4.667142857142857e-05\n",
      "epoch: 1, loss: 3.309, avg: 3.01, latest lr: 4.665714285714286e-05\n",
      "epoch: 1, loss: 5.601, avg: 3.01, latest lr: 4.6642857142857144e-05\n",
      "epoch: 1, loss: 3.940, avg: 3.01, latest lr: 4.6628571428571434e-05\n",
      "epoch: 1, loss: 6.004, avg: 3.02, latest lr: 4.661428571428572e-05\n",
      "epoch: 1, loss: 4.572, avg: 3.02, latest lr: 4.660000000000001e-05\n",
      "epoch: 1, loss: 4.735, avg: 3.02, latest lr: 4.658571428571429e-05\n",
      "epoch: 1, loss: 5.861, avg: 3.02, latest lr: 4.6571428571428575e-05\n",
      "epoch: 1, loss: 4.605, avg: 3.02, latest lr: 4.655714285714286e-05\n",
      "epoch: 1, loss: 5.890, avg: 3.02, latest lr: 4.654285714285714e-05\n",
      "epoch: 1, loss: 5.270, avg: 3.02, latest lr: 4.652857142857143e-05\n",
      "epoch: 1, loss: 4.192, avg: 3.02, latest lr: 4.6514285714285715e-05\n",
      "epoch: 1, loss: 4.770, avg: 3.02, latest lr: 4.6500000000000005e-05\n",
      "epoch: 1, loss: 4.590, avg: 3.02, latest lr: 4.648571428571429e-05\n",
      "epoch: 1, loss: 4.092, avg: 3.02, latest lr: 4.647142857142857e-05\n",
      "epoch: 1, loss: 3.876, avg: 3.02, latest lr: 4.645714285714286e-05\n",
      "epoch: 1, loss: 5.986, avg: 3.02, latest lr: 4.6442857142857146e-05\n",
      "epoch: 1, loss: 4.206, avg: 3.02, latest lr: 4.642857142857143e-05\n",
      "epoch: 1, loss: 5.635, avg: 3.03, latest lr: 4.641428571428571e-05\n",
      "epoch: 1, loss: 4.040, avg: 3.03, latest lr: 4.64e-05\n",
      "epoch: 1, loss: 4.187, avg: 3.03, latest lr: 4.6385714285714286e-05\n",
      "epoch: 1, loss: 4.676, avg: 3.03, latest lr: 4.637142857142857e-05\n",
      "epoch: 1, loss: 3.958, avg: 3.03, latest lr: 4.635714285714286e-05\n",
      "epoch: 1, loss: 6.435, avg: 3.03, latest lr: 4.6342857142857143e-05\n",
      "epoch: 1, loss: 5.216, avg: 3.03, latest lr: 4.6328571428571434e-05\n",
      "epoch: 1, loss: 4.954, avg: 3.03, latest lr: 4.631428571428572e-05\n",
      "epoch: 1, loss: 4.672, avg: 3.03, latest lr: 4.630000000000001e-05\n",
      "epoch: 1, loss: 4.926, avg: 3.03, latest lr: 4.628571428571429e-05\n",
      "epoch: 1, loss: 3.678, avg: 3.03, latest lr: 4.6271428571428574e-05\n",
      "epoch: 1, loss: 4.955, avg: 3.03, latest lr: 4.625714285714286e-05\n",
      "epoch: 1, loss: 5.657, avg: 3.03, latest lr: 4.624285714285714e-05\n",
      "epoch: 1, loss: 5.118, avg: 3.03, latest lr: 4.622857142857143e-05\n",
      "epoch: 1, loss: 5.366, avg: 3.03, latest lr: 4.6214285714285715e-05\n",
      "epoch: 1, loss: 4.118, avg: 3.04, latest lr: 4.6200000000000005e-05\n",
      "epoch: 1, loss: 3.927, avg: 3.04, latest lr: 4.618571428571429e-05\n",
      "epoch: 1, loss: 5.760, avg: 3.04, latest lr: 4.617142857142857e-05\n",
      "epoch: 1, loss: 4.938, avg: 3.04, latest lr: 4.615714285714286e-05\n",
      "epoch: 1, loss: 5.623, avg: 3.04, latest lr: 4.6142857142857145e-05\n",
      "epoch: 1, loss: 6.227, avg: 3.04, latest lr: 4.612857142857143e-05\n",
      "epoch: 1, loss: 4.593, avg: 3.04, latest lr: 4.611428571428571e-05\n",
      "epoch: 1, loss: 5.964, avg: 3.04, latest lr: 4.61e-05\n",
      "epoch: 1, loss: 5.205, avg: 3.04, latest lr: 4.6085714285714286e-05\n",
      "epoch: 1, loss: 4.166, avg: 3.04, latest lr: 4.607142857142857e-05\n",
      "epoch: 1, loss: 5.274, avg: 3.04, latest lr: 4.605714285714286e-05\n",
      "epoch: 1, loss: 4.480, avg: 3.04, latest lr: 4.604285714285714e-05\n",
      "epoch: 1, loss: 4.370, avg: 3.04, latest lr: 4.602857142857143e-05\n",
      "epoch: 1, loss: 4.136, avg: 3.04, latest lr: 4.6014285714285717e-05\n",
      "epoch: 1, loss: 5.871, avg: 3.05, latest lr: 4.600000000000001e-05\n",
      "epoch: 1, loss: 5.305, avg: 3.05, latest lr: 4.598571428571429e-05\n",
      "epoch: 1, loss: 6.033, avg: 3.05, latest lr: 4.5971428571428574e-05\n",
      "epoch: 1, loss: 4.196, avg: 3.05, latest lr: 4.595714285714286e-05\n",
      "epoch: 1, loss: 4.075, avg: 3.05, latest lr: 4.594285714285714e-05\n",
      "epoch: 1, loss: 4.118, avg: 3.05, latest lr: 4.592857142857143e-05\n",
      "epoch: 1, loss: 3.434, avg: 3.05, latest lr: 4.5914285714285714e-05\n",
      "epoch: 1, loss: 4.520, avg: 3.05, latest lr: 4.5900000000000004e-05\n",
      "epoch: 1, loss: 3.667, avg: 3.05, latest lr: 4.588571428571429e-05\n",
      "epoch: 1, loss: 4.434, avg: 3.05, latest lr: 4.587142857142858e-05\n",
      "epoch: 1, loss: 4.683, avg: 3.05, latest lr: 4.585714285714286e-05\n",
      "epoch: 1, loss: 5.271, avg: 3.05, latest lr: 4.5842857142857145e-05\n",
      "epoch: 1, loss: 4.372, avg: 3.05, latest lr: 4.5828571428571435e-05\n",
      "epoch: 1, loss: 5.109, avg: 3.05, latest lr: 4.581428571428572e-05\n",
      "epoch: 1, loss: 4.962, avg: 3.05, latest lr: 4.58e-05\n",
      "epoch: 1, loss: 5.768, avg: 3.06, latest lr: 4.5785714285714285e-05\n",
      "epoch: 1, loss: 4.498, avg: 3.06, latest lr: 4.5771428571428576e-05\n",
      "epoch: 1, loss: 5.934, avg: 3.06, latest lr: 4.575714285714286e-05\n",
      "epoch: 1, loss: 5.428, avg: 3.06, latest lr: 4.574285714285714e-05\n",
      "epoch: 1, loss: 3.418, avg: 3.06, latest lr: 4.572857142857143e-05\n",
      "epoch: 1, loss: 4.930, avg: 3.06, latest lr: 4.5714285714285716e-05\n",
      "epoch: 1, loss: 5.186, avg: 3.06, latest lr: 4.5700000000000006e-05\n",
      "epoch: 1, loss: 4.658, avg: 3.06, latest lr: 4.568571428571429e-05\n",
      "epoch: 1, loss: 4.064, avg: 3.06, latest lr: 4.567142857142857e-05\n",
      "epoch: 1, loss: 5.895, avg: 3.06, latest lr: 4.5657142857142857e-05\n",
      "epoch: 1, loss: 5.729, avg: 3.06, latest lr: 4.564285714285714e-05\n",
      "epoch: 1, loss: 4.785, avg: 3.06, latest lr: 4.562857142857143e-05\n",
      "epoch: 1, loss: 3.338, avg: 3.06, latest lr: 4.5614285714285714e-05\n",
      "epoch: 1, loss: 3.769, avg: 3.06, latest lr: 4.5600000000000004e-05\n",
      "epoch: 1, loss: 5.228, avg: 3.07, latest lr: 4.558571428571429e-05\n",
      "epoch: 1, loss: 4.009, avg: 3.07, latest lr: 4.557142857142858e-05\n",
      "epoch: 1, loss: 4.274, avg: 3.07, latest lr: 4.555714285714286e-05\n",
      "epoch: 1, loss: 5.796, avg: 3.07, latest lr: 4.5542857142857144e-05\n",
      "epoch: 1, loss: 4.921, avg: 3.07, latest lr: 4.5528571428571435e-05\n",
      "epoch: 1, loss: 3.853, avg: 3.07, latest lr: 4.551428571428572e-05\n",
      "epoch: 1, loss: 3.686, avg: 3.07, latest lr: 4.55e-05\n",
      "epoch: 1, loss: 3.741, avg: 3.07, latest lr: 4.5485714285714285e-05\n",
      "epoch: 1, loss: 4.062, avg: 3.07, latest lr: 4.5471428571428575e-05\n",
      "epoch: 1, loss: 3.821, avg: 3.07, latest lr: 4.545714285714286e-05\n",
      "epoch: 1, loss: 4.615, avg: 3.07, latest lr: 4.544285714285714e-05\n",
      "epoch: 1, loss: 6.134, avg: 3.07, latest lr: 4.542857142857143e-05\n",
      "epoch: 1, loss: 4.047, avg: 3.07, latest lr: 4.5414285714285716e-05\n",
      "epoch: 1, loss: 5.027, avg: 3.07, latest lr: 4.5400000000000006e-05\n",
      "epoch: 1, loss: 5.357, avg: 3.07, latest lr: 4.538571428571429e-05\n",
      "epoch: 1, loss: 3.804, avg: 3.07, latest lr: 4.537142857142857e-05\n",
      "epoch: 1, loss: 3.517, avg: 3.08, latest lr: 4.5357142857142856e-05\n",
      "epoch: 1, loss: 5.009, avg: 3.08, latest lr: 4.534285714285714e-05\n",
      "epoch: 1, loss: 5.391, avg: 3.08, latest lr: 4.532857142857143e-05\n",
      "epoch: 1, loss: 5.231, avg: 3.08, latest lr: 4.531428571428571e-05\n",
      "epoch: 1, loss: 5.125, avg: 3.08, latest lr: 4.53e-05\n",
      "epoch: 1, loss: 4.523, avg: 3.08, latest lr: 4.528571428571429e-05\n",
      "epoch: 1, loss: 5.682, avg: 3.08, latest lr: 4.527142857142858e-05\n",
      "epoch: 1, loss: 5.560, avg: 3.08, latest lr: 4.525714285714286e-05\n",
      "epoch: 1, loss: 4.312, avg: 3.08, latest lr: 4.5242857142857144e-05\n",
      "epoch: 1, loss: 3.955, avg: 3.08, latest lr: 4.5228571428571434e-05\n",
      "epoch: 1, loss: 5.397, avg: 3.08, latest lr: 4.521428571428572e-05\n",
      "epoch: 1, loss: 4.032, avg: 3.08, latest lr: 4.52e-05\n",
      "epoch: 1, loss: 5.097, avg: 3.08, latest lr: 4.5185714285714284e-05\n",
      "epoch: 1, loss: 4.376, avg: 3.08, latest lr: 4.5171428571428575e-05\n",
      "epoch: 1, loss: 4.044, avg: 3.08, latest lr: 4.515714285714286e-05\n",
      "epoch: 1, loss: 5.109, avg: 3.09, latest lr: 4.514285714285714e-05\n",
      "epoch: 1, loss: 5.580, avg: 3.09, latest lr: 4.512857142857143e-05\n",
      "epoch: 1, loss: 4.809, avg: 3.09, latest lr: 4.5114285714285715e-05\n",
      "epoch: 1, loss: 3.827, avg: 3.09, latest lr: 4.5100000000000005e-05\n",
      "epoch: 1, loss: 5.539, avg: 3.09, latest lr: 4.508571428571429e-05\n",
      "epoch: 1, loss: 3.728, avg: 3.09, latest lr: 4.507142857142858e-05\n",
      "epoch: 1, loss: 5.101, avg: 3.09, latest lr: 4.5057142857142856e-05\n",
      "epoch: 1, loss: 4.238, avg: 3.09, latest lr: 4.5042857142857146e-05\n",
      "epoch: 1, loss: 5.172, avg: 3.09, latest lr: 4.502857142857143e-05\n",
      "epoch: 1, loss: 6.102, avg: 3.09, latest lr: 4.501428571428571e-05\n",
      "epoch: 1, loss: 6.299, avg: 3.09, latest lr: 4.5e-05\n",
      "epoch: 1, loss: 5.301, avg: 3.09, latest lr: 4.4985714285714286e-05\n",
      "epoch: 1, loss: 5.045, avg: 3.09, latest lr: 4.4971428571428576e-05\n",
      "epoch: 1, loss: 4.178, avg: 3.09, latest lr: 4.495714285714286e-05\n",
      "epoch: 1, loss: 6.204, avg: 3.10, latest lr: 4.494285714285715e-05\n",
      "epoch: 1, loss: 4.639, avg: 3.10, latest lr: 4.4928571428571434e-05\n",
      "epoch: 1, loss: 4.861, avg: 3.10, latest lr: 4.491428571428572e-05\n",
      "epoch: 1, loss: 4.934, avg: 3.10, latest lr: 4.49e-05\n",
      "epoch: 1, loss: 5.057, avg: 3.10, latest lr: 4.4885714285714284e-05\n",
      "epoch: 1, loss: 4.389, avg: 3.10, latest lr: 4.4871428571428574e-05\n",
      "epoch: 1, loss: 4.517, avg: 3.10, latest lr: 4.485714285714286e-05\n",
      "epoch: 1, loss: 5.807, avg: 3.10, latest lr: 4.484285714285715e-05\n",
      "epoch: 1, loss: 4.872, avg: 3.10, latest lr: 4.482857142857143e-05\n",
      "epoch: 1, loss: 5.932, avg: 3.10, latest lr: 4.4814285714285715e-05\n",
      "epoch: 1, loss: 5.618, avg: 3.10, latest lr: 4.4800000000000005e-05\n",
      "epoch: 1, loss: 5.865, avg: 3.10, latest lr: 4.478571428571429e-05\n",
      "epoch: 1, loss: 4.760, avg: 3.10, latest lr: 4.477142857142858e-05\n",
      "epoch: 1, loss: 4.365, avg: 3.11, latest lr: 4.475714285714286e-05\n",
      "epoch: 1, loss: 4.489, avg: 3.11, latest lr: 4.4742857142857145e-05\n",
      "epoch: 1, loss: 4.143, avg: 3.11, latest lr: 4.472857142857143e-05\n",
      "epoch: 1, loss: 4.508, avg: 3.11, latest lr: 4.471428571428571e-05\n",
      "epoch: 1, loss: 3.993, avg: 3.11, latest lr: 4.47e-05\n",
      "epoch: 1, loss: 5.682, avg: 3.11, latest lr: 4.4685714285714286e-05\n",
      "epoch: 1, loss: 2.904, avg: 3.11, latest lr: 4.4671428571428576e-05\n",
      "epoch: 1, loss: 4.812, avg: 3.11, latest lr: 4.465714285714286e-05\n",
      "epoch: 1, loss: 4.992, avg: 3.11, latest lr: 4.464285714285715e-05\n",
      "epoch: 1, loss: 5.515, avg: 3.11, latest lr: 4.462857142857143e-05\n",
      "epoch: 1, loss: 4.946, avg: 3.11, latest lr: 4.4614285714285716e-05\n",
      "epoch: 1, loss: 6.106, avg: 3.11, latest lr: 4.46e-05\n",
      "epoch: 1, loss: 4.999, avg: 3.11, latest lr: 4.458571428571428e-05\n",
      "epoch: 1, loss: 5.040, avg: 3.11, latest lr: 4.4571428571428574e-05\n",
      "epoch: 1, loss: 4.229, avg: 3.11, latest lr: 4.455714285714286e-05\n",
      "epoch: 1, loss: 4.829, avg: 3.12, latest lr: 4.454285714285715e-05\n",
      "epoch: 1, loss: 5.551, avg: 3.12, latest lr: 4.452857142857143e-05\n",
      "epoch: 1, loss: 3.142, avg: 3.12, latest lr: 4.4514285714285714e-05\n",
      "epoch: 1, loss: 5.056, avg: 3.12, latest lr: 4.4500000000000004e-05\n",
      "epoch: 1, loss: 6.165, avg: 3.12, latest lr: 4.448571428571429e-05\n",
      "epoch: 1, loss: 4.552, avg: 3.12, latest lr: 4.447142857142858e-05\n",
      "epoch: 1, loss: 4.125, avg: 3.12, latest lr: 4.445714285714286e-05\n",
      "epoch: 1, loss: 5.987, avg: 3.12, latest lr: 4.4442857142857145e-05\n",
      "epoch: 1, loss: 4.315, avg: 3.12, latest lr: 4.442857142857143e-05\n",
      "epoch: 1, loss: 5.356, avg: 3.12, latest lr: 4.441428571428571e-05\n",
      "epoch: 1, loss: 4.625, avg: 3.12, latest lr: 4.44e-05\n",
      "epoch: 1, loss: 3.201, avg: 3.12, latest lr: 4.4385714285714285e-05\n",
      "epoch: 1, loss: 4.585, avg: 3.12, latest lr: 4.4371428571428575e-05\n",
      "epoch: 1, loss: 4.877, avg: 3.12, latest lr: 4.435714285714286e-05\n",
      "epoch: 1, loss: 5.686, avg: 3.12, latest lr: 4.434285714285715e-05\n",
      "epoch: 1, loss: 5.553, avg: 3.13, latest lr: 4.432857142857143e-05\n",
      "epoch: 1, loss: 5.206, avg: 3.13, latest lr: 4.4314285714285716e-05\n",
      "epoch: 1, loss: 5.041, avg: 3.13, latest lr: 4.43e-05\n",
      "epoch: 1, loss: 5.409, avg: 3.13, latest lr: 4.428571428571428e-05\n",
      "epoch: 1, loss: 4.608, avg: 3.13, latest lr: 4.427142857142857e-05\n",
      "epoch: 1, loss: 5.094, avg: 3.13, latest lr: 4.4257142857142856e-05\n",
      "epoch: 1, loss: 3.677, avg: 3.13, latest lr: 4.424285714285715e-05\n",
      "epoch: 1, loss: 3.945, avg: 3.13, latest lr: 4.422857142857143e-05\n",
      "epoch: 1, loss: 3.512, avg: 3.13, latest lr: 4.4214285714285714e-05\n",
      "epoch: 1, loss: 5.922, avg: 3.13, latest lr: 4.4200000000000004e-05\n",
      "epoch: 1, loss: 4.146, avg: 3.13, latest lr: 4.418571428571429e-05\n",
      "epoch: 1, loss: 3.719, avg: 3.13, latest lr: 4.417142857142858e-05\n",
      "epoch: 1, loss: 4.630, avg: 3.13, latest lr: 4.415714285714286e-05\n",
      "epoch: 1, loss: 4.361, avg: 3.13, latest lr: 4.4142857142857144e-05\n",
      "epoch: 1, loss: 4.837, avg: 3.13, latest lr: 4.412857142857143e-05\n",
      "epoch: 1, loss: 5.134, avg: 3.14, latest lr: 4.411428571428572e-05\n",
      "epoch: 1, loss: 4.740, avg: 3.14, latest lr: 4.41e-05\n",
      "epoch: 1, loss: 5.383, avg: 3.14, latest lr: 4.4085714285714285e-05\n",
      "epoch: 1, loss: 6.103, avg: 3.14, latest lr: 4.4071428571428575e-05\n",
      "epoch: 1, loss: 4.345, avg: 3.14, latest lr: 4.405714285714286e-05\n",
      "epoch: 1, loss: 5.432, avg: 3.14, latest lr: 4.404285714285715e-05\n",
      "epoch: 1, loss: 4.951, avg: 3.14, latest lr: 4.402857142857143e-05\n",
      "epoch: 1, loss: 3.819, avg: 3.14, latest lr: 4.401428571428572e-05\n",
      "epoch: 1, loss: 5.479, avg: 3.14, latest lr: 4.4000000000000006e-05\n",
      "epoch: 1, loss: 5.634, avg: 3.14, latest lr: 4.398571428571428e-05\n",
      "epoch: 1, loss: 4.068, avg: 3.14, latest lr: 4.397142857142857e-05\n",
      "epoch: 1, loss: 3.337, avg: 3.14, latest lr: 4.3957142857142856e-05\n",
      "epoch: 1, loss: 4.321, avg: 3.14, latest lr: 4.3942857142857146e-05\n",
      "epoch: 1, loss: 4.771, avg: 3.14, latest lr: 4.392857142857143e-05\n",
      "epoch: 1, loss: 3.899, avg: 3.15, latest lr: 4.391428571428572e-05\n",
      "epoch: 1, loss: 5.494, avg: 3.15, latest lr: 4.39e-05\n",
      "epoch: 1, loss: 4.871, avg: 3.15, latest lr: 4.388571428571429e-05\n",
      "epoch: 1, loss: 4.946, avg: 3.15, latest lr: 4.387142857142858e-05\n",
      "epoch: 1, loss: 5.188, avg: 3.15, latest lr: 4.385714285714286e-05\n",
      "epoch: 1, loss: 4.973, avg: 3.15, latest lr: 4.3842857142857144e-05\n",
      "epoch: 1, loss: 5.249, avg: 3.15, latest lr: 4.382857142857143e-05\n",
      "epoch: 1, loss: 3.996, avg: 3.15, latest lr: 4.381428571428572e-05\n",
      "epoch: 1, loss: 4.359, avg: 3.15, latest lr: 4.38e-05\n",
      "epoch: 1, loss: 5.354, avg: 3.15, latest lr: 4.3785714285714284e-05\n",
      "epoch: 1, loss: 4.858, avg: 3.15, latest lr: 4.3771428571428574e-05\n",
      "epoch: 1, loss: 4.478, avg: 3.15, latest lr: 4.375714285714286e-05\n",
      "epoch: 1, loss: 3.061, avg: 3.15, latest lr: 4.374285714285715e-05\n",
      "epoch: 1, loss: 5.221, avg: 3.15, latest lr: 4.372857142857143e-05\n",
      "epoch: 1, loss: 5.488, avg: 3.15, latest lr: 4.371428571428572e-05\n",
      "epoch: 1, loss: 4.041, avg: 3.16, latest lr: 4.3700000000000005e-05\n",
      "epoch: 1, loss: 5.587, avg: 3.16, latest lr: 4.368571428571429e-05\n",
      "epoch: 1, loss: 4.171, avg: 3.16, latest lr: 4.367142857142857e-05\n",
      "epoch: 1, loss: 5.742, avg: 3.16, latest lr: 4.3657142857142855e-05\n",
      "epoch: 1, loss: 4.867, avg: 3.16, latest lr: 4.3642857142857146e-05\n",
      "epoch: 1, loss: 4.561, avg: 3.16, latest lr: 4.362857142857143e-05\n",
      "epoch: 1, loss: 5.342, avg: 3.16, latest lr: 4.361428571428572e-05\n",
      "epoch: 1, loss: 5.387, avg: 3.16, latest lr: 4.36e-05\n",
      "epoch: 1, loss: 4.762, avg: 3.16, latest lr: 4.3585714285714286e-05\n",
      "epoch: 1, loss: 5.330, avg: 3.16, latest lr: 4.3571428571428576e-05\n",
      "epoch: 1, loss: 4.080, avg: 3.16, latest lr: 4.355714285714286e-05\n",
      "epoch: 1, loss: 5.786, avg: 3.16, latest lr: 4.354285714285714e-05\n",
      "epoch: 1, loss: 4.291, avg: 3.16, latest lr: 4.352857142857143e-05\n",
      "epoch: 1, loss: 5.660, avg: 3.16, latest lr: 4.351428571428572e-05\n",
      "epoch: 1, loss: 3.903, avg: 3.17, latest lr: 4.35e-05\n",
      "epoch: 1, loss: 4.942, avg: 3.17, latest lr: 4.3485714285714284e-05\n",
      "epoch: 1, loss: 5.049, avg: 3.17, latest lr: 4.3471428571428574e-05\n",
      "epoch: 1, loss: 6.513, avg: 3.17, latest lr: 4.345714285714286e-05\n",
      "epoch: 1, loss: 5.600, avg: 3.17, latest lr: 4.344285714285715e-05\n",
      "epoch: 1, loss: 5.078, avg: 3.17, latest lr: 4.342857142857143e-05\n",
      "epoch: 1, loss: 4.717, avg: 3.17, latest lr: 4.341428571428572e-05\n",
      "epoch: 1, loss: 5.464, avg: 3.17, latest lr: 4.3400000000000005e-05\n",
      "epoch: 1, loss: 4.431, avg: 3.17, latest lr: 4.338571428571429e-05\n",
      "epoch: 1, loss: 5.916, avg: 3.17, latest lr: 4.337142857142857e-05\n",
      "epoch: 1, loss: 3.435, avg: 3.17, latest lr: 4.3357142857142855e-05\n",
      "epoch: 1, loss: 4.938, avg: 3.17, latest lr: 4.3342857142857145e-05\n",
      "epoch: 1, loss: 6.161, avg: 3.17, latest lr: 4.332857142857143e-05\n",
      "epoch: 1, loss: 2.849, avg: 3.17, latest lr: 4.331428571428572e-05\n",
      "epoch: 1, loss: 3.278, avg: 3.18, latest lr: 4.33e-05\n",
      "epoch: 1, loss: 6.882, avg: 3.18, latest lr: 4.328571428571429e-05\n",
      "epoch: 1, loss: 5.594, avg: 3.18, latest lr: 4.3271428571428576e-05\n",
      "epoch: 1, loss: 5.668, avg: 3.18, latest lr: 4.325714285714286e-05\n",
      "epoch: 1, loss: 5.829, avg: 3.18, latest lr: 4.324285714285715e-05\n",
      "epoch: 1, loss: 5.076, avg: 3.18, latest lr: 4.3228571428571426e-05\n",
      "epoch: 1, loss: 4.134, avg: 3.18, latest lr: 4.3214285714285716e-05\n",
      "epoch: 1, loss: 4.394, avg: 3.18, latest lr: 4.32e-05\n",
      "epoch: 1, loss: 4.354, avg: 3.18, latest lr: 4.318571428571429e-05\n",
      "epoch: 1, loss: 4.141, avg: 3.18, latest lr: 4.317142857142857e-05\n",
      "epoch: 1, loss: 4.255, avg: 3.18, latest lr: 4.315714285714286e-05\n",
      "epoch: 1, loss: 4.894, avg: 3.18, latest lr: 4.314285714285715e-05\n",
      "epoch: 1, loss: 5.129, avg: 3.18, latest lr: 4.312857142857143e-05\n",
      "epoch: 1, loss: 4.703, avg: 3.18, latest lr: 4.311428571428572e-05\n",
      "epoch: 1, loss: 4.755, avg: 3.19, latest lr: 4.3100000000000004e-05\n",
      "epoch: 1, loss: 4.628, avg: 3.19, latest lr: 4.308571428571429e-05\n",
      "epoch: 1, loss: 6.322, avg: 3.19, latest lr: 4.307142857142857e-05\n",
      "epoch: 1, loss: 6.036, avg: 3.19, latest lr: 4.3057142857142854e-05\n",
      "epoch: 1, loss: 4.381, avg: 3.19, latest lr: 4.3042857142857145e-05\n",
      "epoch: 1, loss: 3.291, avg: 3.19, latest lr: 4.302857142857143e-05\n",
      "epoch: 1, loss: 5.056, avg: 3.19, latest lr: 4.301428571428572e-05\n",
      "epoch: 1, loss: 5.123, avg: 3.19, latest lr: 4.3e-05\n",
      "epoch: 1, loss: 4.125, avg: 3.19, latest lr: 4.298571428571429e-05\n",
      "epoch: 1, loss: 4.448, avg: 3.19, latest lr: 4.2971428571428575e-05\n",
      "epoch: 1, loss: 4.634, avg: 3.19, latest lr: 4.295714285714286e-05\n",
      "epoch: 1, loss: 4.669, avg: 3.19, latest lr: 4.294285714285715e-05\n",
      "epoch: 1, loss: 5.445, avg: 3.19, latest lr: 4.292857142857143e-05\n",
      "epoch: 1, loss: 4.417, avg: 3.19, latest lr: 4.2914285714285716e-05\n",
      "epoch: 1, loss: 5.625, avg: 3.19, latest lr: 4.29e-05\n",
      "epoch: 1, loss: 4.825, avg: 3.20, latest lr: 4.288571428571429e-05\n",
      "epoch: 1, loss: 3.966, avg: 3.20, latest lr: 4.287142857142857e-05\n",
      "epoch: 1, loss: 4.813, avg: 3.20, latest lr: 4.2857142857142856e-05\n",
      "epoch: 1, loss: 3.606, avg: 3.20, latest lr: 4.2842857142857146e-05\n",
      "epoch: 1, loss: 4.681, avg: 3.20, latest lr: 4.282857142857143e-05\n",
      "epoch: 1, loss: 4.824, avg: 3.20, latest lr: 4.281428571428572e-05\n",
      "epoch: 1, loss: 3.790, avg: 3.20, latest lr: 4.2800000000000004e-05\n",
      "epoch: 1, loss: 5.132, avg: 3.20, latest lr: 4.278571428571429e-05\n",
      "epoch: 1, loss: 3.969, avg: 3.20, latest lr: 4.277142857142857e-05\n",
      "epoch: 1, loss: 5.203, avg: 3.20, latest lr: 4.2757142857142854e-05\n",
      "epoch: 1, loss: 5.384, avg: 3.20, latest lr: 4.2742857142857144e-05\n",
      "epoch: 1, loss: 4.838, avg: 3.20, latest lr: 4.272857142857143e-05\n",
      "epoch: 1, loss: 4.318, avg: 3.20, latest lr: 4.271428571428572e-05\n",
      "epoch: 1, loss: 5.008, avg: 3.20, latest lr: 4.27e-05\n",
      "epoch: 1, loss: 4.763, avg: 3.20, latest lr: 4.268571428571429e-05\n",
      "epoch: 1, loss: 2.635, avg: 3.21, latest lr: 4.2671428571428575e-05\n",
      "epoch: 1, loss: 5.046, avg: 3.21, latest lr: 4.265714285714286e-05\n",
      "epoch: 1, loss: 3.453, avg: 3.21, latest lr: 4.264285714285715e-05\n",
      "epoch: 1, loss: 4.259, avg: 3.21, latest lr: 4.262857142857143e-05\n",
      "epoch: 1, loss: 5.693, avg: 3.21, latest lr: 4.2614285714285715e-05\n",
      "epoch: 1, loss: 5.476, avg: 3.21, latest lr: 4.26e-05\n",
      "epoch: 1, loss: 5.584, avg: 3.21, latest lr: 4.258571428571429e-05\n",
      "epoch: 1, loss: 5.543, avg: 3.21, latest lr: 4.257142857142857e-05\n",
      "epoch: 1, loss: 4.547, avg: 3.21, latest lr: 4.2557142857142856e-05\n",
      "epoch: 1, loss: 4.152, avg: 3.21, latest lr: 4.2542857142857146e-05\n",
      "epoch: 1, loss: 3.894, avg: 3.21, latest lr: 4.252857142857143e-05\n",
      "epoch: 1, loss: 4.158, avg: 3.21, latest lr: 4.251428571428572e-05\n",
      "epoch: 1, loss: 4.596, avg: 3.21, latest lr: 4.25e-05\n",
      "epoch: 1, loss: 4.360, avg: 3.21, latest lr: 4.2485714285714286e-05\n",
      "epoch: 1, loss: 6.013, avg: 3.21, latest lr: 4.247142857142857e-05\n",
      "epoch: 1, loss: 4.362, avg: 3.22, latest lr: 4.245714285714285e-05\n",
      "epoch: 1, loss: 4.398, avg: 3.22, latest lr: 4.2442857142857144e-05\n",
      "epoch: 1, loss: 4.756, avg: 3.22, latest lr: 4.242857142857143e-05\n",
      "epoch: 1, loss: 3.955, avg: 3.22, latest lr: 4.241428571428572e-05\n",
      "epoch: 1, loss: 3.452, avg: 3.22, latest lr: 4.24e-05\n",
      "epoch: 1, loss: 5.688, avg: 3.22, latest lr: 4.238571428571429e-05\n",
      "epoch: 1, loss: 3.836, avg: 3.22, latest lr: 4.2371428571428574e-05\n",
      "epoch: 1, loss: 4.738, avg: 3.22, latest lr: 4.2357142857142864e-05\n",
      "epoch: 1, loss: 5.890, avg: 3.22, latest lr: 4.234285714285715e-05\n",
      "epoch: 1, loss: 4.359, avg: 3.22, latest lr: 4.232857142857143e-05\n",
      "epoch: 1, loss: 4.201, avg: 3.22, latest lr: 4.2314285714285715e-05\n",
      "epoch: 1, loss: 4.692, avg: 3.22, latest lr: 4.23e-05\n",
      "epoch: 1, loss: 4.703, avg: 3.22, latest lr: 4.228571428571429e-05\n",
      "epoch: 1, loss: 4.088, avg: 3.22, latest lr: 4.227142857142857e-05\n",
      "epoch: 1, loss: 5.224, avg: 3.22, latest lr: 4.225714285714286e-05\n",
      "epoch: 1, loss: 4.461, avg: 3.22, latest lr: 4.2242857142857145e-05\n",
      "epoch: 1, loss: 4.145, avg: 3.23, latest lr: 4.222857142857143e-05\n",
      "epoch: 1, loss: 4.256, avg: 3.23, latest lr: 4.221428571428572e-05\n",
      "epoch: 1, loss: 3.737, avg: 3.23, latest lr: 4.22e-05\n",
      "epoch: 1, loss: 4.104, avg: 3.23, latest lr: 4.218571428571429e-05\n",
      "epoch: 1, loss: 4.953, avg: 3.23, latest lr: 4.2171428571428576e-05\n",
      "epoch: 1, loss: 5.627, avg: 3.23, latest lr: 4.215714285714286e-05\n",
      "epoch: 1, loss: 4.701, avg: 3.23, latest lr: 4.214285714285714e-05\n",
      "epoch: 1, loss: 5.984, avg: 3.23, latest lr: 4.2128571428571426e-05\n",
      "epoch: 1, loss: 5.678, avg: 3.23, latest lr: 4.211428571428572e-05\n",
      "epoch: 1, loss: 6.246, avg: 3.23, latest lr: 4.21e-05\n",
      "epoch: 1, loss: 4.753, avg: 3.23, latest lr: 4.208571428571429e-05\n",
      "epoch: 1, loss: 4.286, avg: 3.23, latest lr: 4.2071428571428574e-05\n",
      "epoch: 1, loss: 4.729, avg: 3.23, latest lr: 4.2057142857142864e-05\n",
      "epoch: 1, loss: 5.202, avg: 3.23, latest lr: 4.204285714285715e-05\n",
      "epoch: 1, loss: 4.586, avg: 3.24, latest lr: 4.202857142857143e-05\n",
      "epoch: 1, loss: 4.134, avg: 3.24, latest lr: 4.2014285714285714e-05\n",
      "epoch: 1, loss: 5.211, avg: 3.24, latest lr: 4.2e-05\n",
      "epoch: 1, loss: 5.582, avg: 3.24, latest lr: 4.198571428571429e-05\n",
      "epoch: 1, loss: 5.428, avg: 3.24, latest lr: 4.197142857142857e-05\n",
      "epoch: 1, loss: 4.901, avg: 3.24, latest lr: 4.195714285714286e-05\n",
      "epoch: 1, loss: 4.900, avg: 3.24, latest lr: 4.1942857142857145e-05\n",
      "epoch: 1, loss: 7.264, avg: 3.24, latest lr: 4.192857142857143e-05\n",
      "epoch: 1, loss: 4.563, avg: 3.24, latest lr: 4.191428571428572e-05\n",
      "epoch: 1, loss: 5.800, avg: 3.24, latest lr: 4.19e-05\n",
      "epoch: 1, loss: 4.821, avg: 3.24, latest lr: 4.188571428571429e-05\n",
      "epoch: 1, loss: 5.674, avg: 3.24, latest lr: 4.1871428571428576e-05\n",
      "epoch: 1, loss: 4.116, avg: 3.24, latest lr: 4.185714285714286e-05\n",
      "epoch: 1, loss: 4.541, avg: 3.24, latest lr: 4.184285714285714e-05\n",
      "epoch: 1, loss: 6.117, avg: 3.25, latest lr: 4.1828571428571426e-05\n",
      "epoch: 1, loss: 3.781, avg: 3.25, latest lr: 4.1814285714285716e-05\n",
      "epoch: 1, loss: 4.122, avg: 3.25, latest lr: 4.18e-05\n",
      "epoch: 1, loss: 4.682, avg: 3.25, latest lr: 4.178571428571429e-05\n",
      "epoch: 1, loss: 5.200, avg: 3.25, latest lr: 4.177142857142857e-05\n",
      "epoch: 1, loss: 4.956, avg: 3.25, latest lr: 4.1757142857142863e-05\n",
      "epoch: 1, loss: 4.766, avg: 3.25, latest lr: 4.174285714285715e-05\n",
      "epoch: 1, loss: 4.020, avg: 3.25, latest lr: 4.172857142857143e-05\n",
      "epoch: 1, loss: 4.250, avg: 3.25, latest lr: 4.1714285714285714e-05\n",
      "epoch: 1, loss: 4.118, avg: 3.25, latest lr: 4.17e-05\n",
      "epoch: 1, loss: 5.874, avg: 3.25, latest lr: 4.168571428571429e-05\n",
      "epoch: 1, loss: 5.630, avg: 3.25, latest lr: 4.167142857142857e-05\n",
      "epoch: 1, loss: 5.089, avg: 3.25, latest lr: 4.165714285714286e-05\n",
      "epoch: 1, loss: 4.616, avg: 3.25, latest lr: 4.1642857142857144e-05\n",
      "epoch: 1, loss: 4.164, avg: 3.26, latest lr: 4.162857142857143e-05\n",
      "epoch: 1, loss: 5.686, avg: 3.26, latest lr: 4.161428571428572e-05\n",
      "epoch: 1, loss: 4.182, avg: 3.26, latest lr: 4.16e-05\n",
      "epoch: 1, loss: 4.338, avg: 3.26, latest lr: 4.158571428571429e-05\n",
      "epoch: 1, loss: 5.679, avg: 3.26, latest lr: 4.1571428571428575e-05\n",
      "epoch: 1, loss: 4.846, avg: 3.26, latest lr: 4.155714285714286e-05\n",
      "epoch: 1, loss: 4.919, avg: 3.26, latest lr: 4.154285714285714e-05\n",
      "epoch: 1, loss: 4.375, avg: 3.26, latest lr: 4.1528571428571425e-05\n",
      "epoch: 1, loss: 4.625, avg: 3.26, latest lr: 4.1514285714285716e-05\n",
      "epoch: 1, loss: 5.503, avg: 3.26, latest lr: 4.15e-05\n",
      "epoch: 1, loss: 3.877, avg: 3.26, latest lr: 4.148571428571429e-05\n",
      "epoch: 1, loss: 3.937, avg: 3.26, latest lr: 4.147142857142857e-05\n",
      "epoch: 1, loss: 6.026, avg: 3.26, latest lr: 4.145714285714286e-05\n",
      "epoch: 1, loss: 5.172, avg: 3.26, latest lr: 4.1442857142857146e-05\n",
      "epoch: 1, loss: 4.954, avg: 3.26, latest lr: 4.1428571428571437e-05\n",
      "epoch: 1, loss: 4.935, avg: 3.27, latest lr: 4.141428571428571e-05\n",
      "epoch: 1, loss: 3.989, avg: 3.27, latest lr: 4.14e-05\n",
      "epoch: 1, loss: 5.010, avg: 3.27, latest lr: 4.138571428571429e-05\n",
      "epoch: 1, loss: 4.826, avg: 3.27, latest lr: 4.137142857142857e-05\n",
      "epoch: 1, loss: 3.938, avg: 3.27, latest lr: 4.135714285714286e-05\n",
      "epoch: 1, loss: 5.339, avg: 3.27, latest lr: 4.1342857142857144e-05\n",
      "epoch: 1, loss: 5.509, avg: 3.27, latest lr: 4.1328571428571434e-05\n",
      "epoch: 1, loss: 4.687, avg: 3.27, latest lr: 4.131428571428572e-05\n",
      "epoch: 1, loss: 4.535, avg: 3.27, latest lr: 4.13e-05\n",
      "epoch: 1, loss: 4.753, avg: 3.27, latest lr: 4.128571428571429e-05\n",
      "epoch: 1, loss: 4.523, avg: 3.27, latest lr: 4.1271428571428575e-05\n",
      "epoch: 1, loss: 5.992, avg: 3.27, latest lr: 4.125714285714286e-05\n",
      "epoch: 1, loss: 4.754, avg: 3.27, latest lr: 4.124285714285714e-05\n",
      "epoch: 1, loss: 4.076, avg: 3.27, latest lr: 4.122857142857143e-05\n",
      "epoch: 1, loss: 4.064, avg: 3.28, latest lr: 4.1214285714285715e-05\n",
      "epoch: 1, loss: 3.873, avg: 3.28, latest lr: 4.12e-05\n",
      "epoch: 1, loss: 5.209, avg: 3.28, latest lr: 4.118571428571429e-05\n",
      "epoch: 1, loss: 5.149, avg: 3.28, latest lr: 4.117142857142857e-05\n",
      "epoch: 1, loss: 4.816, avg: 3.28, latest lr: 4.115714285714286e-05\n",
      "epoch: 1, loss: 5.848, avg: 3.28, latest lr: 4.1142857142857146e-05\n",
      "epoch: 1, loss: 4.211, avg: 3.28, latest lr: 4.1128571428571436e-05\n",
      "epoch: 1, loss: 4.772, avg: 3.28, latest lr: 4.111428571428572e-05\n",
      "epoch: 1, loss: 5.684, avg: 3.28, latest lr: 4.11e-05\n",
      "epoch: 1, loss: 5.876, avg: 3.28, latest lr: 4.1085714285714286e-05\n",
      "epoch: 1, loss: 3.388, avg: 3.28, latest lr: 4.107142857142857e-05\n",
      "epoch: 1, loss: 3.735, avg: 3.28, latest lr: 4.105714285714286e-05\n",
      "epoch: 1, loss: 5.498, avg: 3.28, latest lr: 4.1042857142857143e-05\n",
      "epoch: 1, loss: 5.441, avg: 3.28, latest lr: 4.1028571428571434e-05\n",
      "epoch: 1, loss: 4.899, avg: 3.28, latest lr: 4.101428571428572e-05\n",
      "epoch: 1, loss: 5.165, avg: 3.29, latest lr: 4.1e-05\n",
      "epoch: 1, loss: 5.026, avg: 3.29, latest lr: 4.098571428571429e-05\n",
      "epoch: 1, loss: 6.162, avg: 3.29, latest lr: 4.0971428571428574e-05\n",
      "epoch: 1, loss: 4.482, avg: 3.29, latest lr: 4.095714285714286e-05\n",
      "epoch: 1, loss: 4.029, avg: 3.29, latest lr: 4.094285714285714e-05\n",
      "epoch: 1, loss: 5.098, avg: 3.29, latest lr: 4.092857142857143e-05\n",
      "epoch: 1, loss: 5.680, avg: 3.29, latest lr: 4.0914285714285715e-05\n",
      "epoch: 1, loss: 4.802, avg: 3.29, latest lr: 4.09e-05\n",
      "epoch: 1, loss: 4.037, avg: 3.29, latest lr: 4.088571428571429e-05\n",
      "epoch: 1, loss: 4.165, avg: 3.29, latest lr: 4.087142857142857e-05\n",
      "epoch: 1, loss: 3.480, avg: 3.29, latest lr: 4.085714285714286e-05\n",
      "epoch: 1, loss: 6.229, avg: 3.29, latest lr: 4.0842857142857145e-05\n",
      "epoch: 1, loss: 3.939, avg: 3.29, latest lr: 4.0828571428571436e-05\n",
      "epoch: 1, loss: 4.744, avg: 3.29, latest lr: 4.081428571428572e-05\n",
      "epoch: 1, loss: 5.456, avg: 3.30, latest lr: 4.08e-05\n",
      "epoch: 1, loss: 3.512, avg: 3.30, latest lr: 4.0785714285714286e-05\n",
      "epoch: 1, loss: 4.055, avg: 3.30, latest lr: 4.077142857142857e-05\n",
      "epoch: 1, loss: 3.944, avg: 3.30, latest lr: 4.075714285714286e-05\n",
      "epoch: 1, loss: 4.073, avg: 3.30, latest lr: 4.074285714285714e-05\n",
      "epoch: 1, loss: 5.118, avg: 3.30, latest lr: 4.072857142857143e-05\n",
      "epoch: 1, loss: 5.666, avg: 3.30, latest lr: 4.0714285714285717e-05\n",
      "epoch: 1, loss: 4.396, avg: 3.30, latest lr: 4.07e-05\n",
      "epoch: 1, loss: 6.277, avg: 3.30, latest lr: 4.068571428571429e-05\n",
      "epoch: 1, loss: 5.682, avg: 3.30, latest lr: 4.0671428571428574e-05\n",
      "epoch: 1, loss: 4.261, avg: 3.30, latest lr: 4.065714285714286e-05\n",
      "epoch: 1, loss: 4.445, avg: 3.30, latest lr: 4.064285714285714e-05\n",
      "epoch: 1, loss: 4.115, avg: 3.30, latest lr: 4.062857142857143e-05\n",
      "epoch: 1, loss: 5.596, avg: 3.30, latest lr: 4.0614285714285714e-05\n",
      "epoch: 1, loss: 3.146, avg: 3.30, latest lr: 4.0600000000000004e-05\n",
      "epoch: 1, loss: 3.591, avg: 3.30, latest lr: 4.058571428571429e-05\n",
      "epoch: 1, loss: 5.121, avg: 3.31, latest lr: 4.057142857142857e-05\n",
      "epoch: 1, loss: 6.320, avg: 3.31, latest lr: 4.055714285714286e-05\n",
      "epoch: 1, loss: 4.303, avg: 3.31, latest lr: 4.0542857142857145e-05\n",
      "epoch: 1, loss: 4.159, avg: 3.31, latest lr: 4.0528571428571435e-05\n",
      "epoch: 1, loss: 3.480, avg: 3.31, latest lr: 4.051428571428572e-05\n",
      "epoch: 1, loss: 4.276, avg: 3.31, latest lr: 4.05e-05\n",
      "epoch: 1, loss: 5.791, avg: 3.31, latest lr: 4.0485714285714285e-05\n",
      "epoch: 1, loss: 4.081, avg: 3.31, latest lr: 4.047142857142857e-05\n",
      "epoch: 1, loss: 5.839, avg: 3.31, latest lr: 4.045714285714286e-05\n",
      "epoch: 1, loss: 2.905, avg: 3.31, latest lr: 4.044285714285714e-05\n",
      "epoch: 1, loss: 3.301, avg: 3.31, latest lr: 4.042857142857143e-05\n",
      "epoch: 1, loss: 3.884, avg: 3.31, latest lr: 4.0414285714285716e-05\n",
      "epoch: 1, loss: 4.889, avg: 3.31, latest lr: 4.0400000000000006e-05\n",
      "epoch: 1, loss: 4.793, avg: 3.31, latest lr: 4.038571428571429e-05\n",
      "epoch: 1, loss: 4.515, avg: 3.31, latest lr: 4.037142857142857e-05\n",
      "epoch: 1, loss: 3.800, avg: 3.32, latest lr: 4.035714285714286e-05\n",
      "epoch: 1, loss: 3.099, avg: 3.32, latest lr: 4.034285714285715e-05\n",
      "epoch: 1, loss: 3.799, avg: 3.32, latest lr: 4.032857142857143e-05\n",
      "epoch: 1, loss: 3.336, avg: 3.32, latest lr: 4.0314285714285714e-05\n",
      "epoch: 1, loss: 4.153, avg: 3.32, latest lr: 4.0300000000000004e-05\n",
      "epoch: 1, loss: 3.967, avg: 3.32, latest lr: 4.028571428571429e-05\n",
      "epoch: 1, loss: 4.182, avg: 3.32, latest lr: 4.027142857142857e-05\n",
      "epoch: 1, loss: 4.415, avg: 3.32, latest lr: 4.025714285714286e-05\n",
      "epoch: 1, loss: 5.437, avg: 3.32, latest lr: 4.0242857142857144e-05\n",
      "epoch: 1, loss: 4.608, avg: 3.32, latest lr: 4.0228571428571434e-05\n",
      "epoch: 1, loss: 5.586, avg: 3.32, latest lr: 4.021428571428572e-05\n",
      "epoch: 1, loss: 4.199, avg: 3.32, latest lr: 4.02e-05\n",
      "epoch: 1, loss: 2.475, avg: 3.32, latest lr: 4.0185714285714285e-05\n",
      "epoch: 1, loss: 5.569, avg: 3.32, latest lr: 4.017142857142857e-05\n",
      "epoch: 1, loss: 4.084, avg: 3.32, latest lr: 4.015714285714286e-05\n",
      "epoch: 1, loss: 4.739, avg: 3.32, latest lr: 4.014285714285714e-05\n",
      "epoch: 1, loss: 4.671, avg: 3.32, latest lr: 4.012857142857143e-05\n",
      "epoch: 1, loss: 5.282, avg: 3.33, latest lr: 4.0114285714285715e-05\n",
      "epoch: 1, loss: 5.383, avg: 3.33, latest lr: 4.0100000000000006e-05\n",
      "epoch: 1, loss: 5.320, avg: 3.33, latest lr: 4.008571428571429e-05\n",
      "epoch: 1, loss: 5.881, avg: 3.33, latest lr: 4.007142857142857e-05\n",
      "epoch: 1, loss: 5.621, avg: 3.33, latest lr: 4.005714285714286e-05\n",
      "epoch: 1, loss: 4.269, avg: 3.33, latest lr: 4.0042857142857146e-05\n",
      "epoch: 1, loss: 5.209, avg: 3.33, latest lr: 4.002857142857143e-05\n",
      "epoch: 1, loss: 3.948, avg: 3.33, latest lr: 4.001428571428571e-05\n",
      "epoch: 1, loss: 4.109, avg: 3.33, latest lr: 4e-05\n",
      "epoch: 1, loss: 4.122, avg: 3.33, latest lr: 3.998571428571429e-05\n",
      "epoch: 1, loss: 5.381, avg: 3.33, latest lr: 3.997142857142857e-05\n",
      "epoch: 1, loss: 5.088, avg: 3.33, latest lr: 3.995714285714286e-05\n",
      "epoch: 1, loss: 4.302, avg: 3.33, latest lr: 3.9942857142857144e-05\n",
      "epoch: 1, loss: 3.360, avg: 3.33, latest lr: 3.9928571428571434e-05\n",
      "epoch: 1, loss: 4.931, avg: 3.34, latest lr: 3.991428571428572e-05\n",
      "epoch: 1, loss: 4.250, avg: 3.34, latest lr: 3.99e-05\n",
      "epoch: 1, loss: 4.977, avg: 3.34, latest lr: 3.9885714285714284e-05\n",
      "epoch: 1, loss: 5.064, avg: 3.34, latest lr: 3.987142857142857e-05\n",
      "epoch: 1, loss: 5.233, avg: 3.34, latest lr: 3.985714285714286e-05\n",
      "epoch: 1, loss: 3.953, avg: 3.34, latest lr: 3.984285714285714e-05\n",
      "epoch: 1, loss: 4.972, avg: 3.34, latest lr: 3.982857142857143e-05\n",
      "epoch: 1, loss: 5.345, avg: 3.34, latest lr: 3.9814285714285715e-05\n",
      "epoch: 1, loss: 5.562, avg: 3.34, latest lr: 3.9800000000000005e-05\n",
      "epoch: 1, loss: 4.257, avg: 3.34, latest lr: 3.978571428571429e-05\n",
      "epoch: 1, loss: 5.486, avg: 3.34, latest lr: 3.977142857142857e-05\n",
      "epoch: 1, loss: 4.406, avg: 3.34, latest lr: 3.975714285714286e-05\n",
      "epoch: 1, loss: 4.790, avg: 3.34, latest lr: 3.9742857142857146e-05\n",
      "epoch: 1, loss: 3.789, avg: 3.34, latest lr: 3.972857142857143e-05\n",
      "epoch: 1, loss: 4.868, avg: 3.34, latest lr: 3.971428571428571e-05\n",
      "epoch: 1, loss: 4.964, avg: 3.35, latest lr: 3.97e-05\n",
      "epoch: 1, loss: 5.092, avg: 3.35, latest lr: 3.9685714285714286e-05\n",
      "epoch: 1, loss: 4.532, avg: 3.35, latest lr: 3.9671428571428576e-05\n",
      "epoch: 1, loss: 5.254, avg: 3.35, latest lr: 3.965714285714286e-05\n",
      "epoch: 1, loss: 3.881, avg: 3.35, latest lr: 3.964285714285714e-05\n",
      "epoch: 1, loss: 5.057, avg: 3.35, latest lr: 3.9628571428571433e-05\n",
      "epoch: 1, loss: 4.149, avg: 3.35, latest lr: 3.961428571428572e-05\n",
      "epoch: 1, loss: 4.488, avg: 3.35, latest lr: 3.960000000000001e-05\n",
      "epoch: 1, loss: 4.120, avg: 3.35, latest lr: 3.9585714285714284e-05\n",
      "epoch: 1, loss: 4.244, avg: 3.35, latest lr: 3.9571428571428574e-05\n",
      "epoch: 1, loss: 5.145, avg: 3.35, latest lr: 3.955714285714286e-05\n",
      "epoch: 1, loss: 4.610, avg: 3.35, latest lr: 3.954285714285714e-05\n",
      "epoch: 1, loss: 4.358, avg: 3.35, latest lr: 3.952857142857143e-05\n",
      "epoch: 1, loss: 4.363, avg: 3.35, latest lr: 3.9514285714285714e-05\n",
      "epoch: 1, loss: 4.693, avg: 3.35, latest lr: 3.9500000000000005e-05\n",
      "epoch: 1, loss: 5.152, avg: 3.36, latest lr: 3.948571428571429e-05\n",
      "epoch: 1, loss: 4.856, avg: 3.36, latest lr: 3.947142857142858e-05\n",
      "epoch: 1, loss: 4.621, avg: 3.36, latest lr: 3.945714285714286e-05\n",
      "epoch: 1, loss: 5.557, avg: 3.36, latest lr: 3.9442857142857145e-05\n",
      "epoch: 1, loss: 5.322, avg: 3.36, latest lr: 3.942857142857143e-05\n",
      "epoch: 1, loss: 4.794, avg: 3.36, latest lr: 3.941428571428571e-05\n",
      "epoch: 1, loss: 5.608, avg: 3.36, latest lr: 3.94e-05\n",
      "epoch: 1, loss: 2.683, avg: 3.36, latest lr: 3.9385714285714286e-05\n",
      "epoch: 1, loss: 4.875, avg: 3.36, latest lr: 3.9371428571428576e-05\n",
      "epoch: 1, loss: 2.733, avg: 3.36, latest lr: 3.935714285714286e-05\n",
      "epoch: 1, loss: 5.571, avg: 3.36, latest lr: 3.934285714285714e-05\n",
      "epoch: 1, loss: 4.661, avg: 3.36, latest lr: 3.932857142857143e-05\n",
      "epoch: 1, loss: 4.121, avg: 3.36, latest lr: 3.9314285714285716e-05\n",
      "epoch: 1, loss: 4.013, avg: 3.36, latest lr: 3.9300000000000007e-05\n",
      "epoch: 1, loss: 4.302, avg: 3.36, latest lr: 3.928571428571429e-05\n",
      "epoch: 1, loss: 4.094, avg: 3.36, latest lr: 3.9271428571428573e-05\n",
      "epoch: 1, loss: 5.414, avg: 3.37, latest lr: 3.925714285714286e-05\n",
      "epoch: 1, loss: 4.439, avg: 3.37, latest lr: 3.924285714285714e-05\n",
      "epoch: 1, loss: 5.254, avg: 3.37, latest lr: 3.922857142857143e-05\n",
      "epoch: 1, loss: 4.948, avg: 3.37, latest lr: 3.9214285714285714e-05\n",
      "epoch: 1, loss: 5.185, avg: 3.37, latest lr: 3.9200000000000004e-05\n",
      "epoch: 1, loss: 3.638, avg: 3.37, latest lr: 3.918571428571429e-05\n",
      "epoch: 1, loss: 5.113, avg: 3.37, latest lr: 3.917142857142858e-05\n",
      "epoch: 1, loss: 5.757, avg: 3.37, latest lr: 3.915714285714286e-05\n",
      "epoch: 1, loss: 4.544, avg: 3.37, latest lr: 3.9142857142857145e-05\n",
      "epoch: 1, loss: 5.344, avg: 3.37, latest lr: 3.912857142857143e-05\n",
      "epoch: 1, loss: 3.788, avg: 3.37, latest lr: 3.911428571428571e-05\n",
      "epoch: 1, loss: 2.738, avg: 3.37, latest lr: 3.91e-05\n",
      "epoch: 1, loss: 5.892, avg: 3.37, latest lr: 3.9085714285714285e-05\n",
      "epoch: 1, loss: 3.844, avg: 3.37, latest lr: 3.9071428571428575e-05\n",
      "epoch: 1, loss: 4.239, avg: 3.37, latest lr: 3.905714285714286e-05\n",
      "epoch: 1, loss: 6.038, avg: 3.38, latest lr: 3.904285714285714e-05\n",
      "epoch: 1, loss: 4.297, avg: 3.38, latest lr: 3.902857142857143e-05\n",
      "epoch: 1, loss: 4.391, avg: 3.38, latest lr: 3.9014285714285716e-05\n",
      "epoch: 1, loss: 4.979, avg: 3.38, latest lr: 3.9000000000000006e-05\n",
      "epoch: 1, loss: 4.097, avg: 3.38, latest lr: 3.898571428571429e-05\n",
      "epoch: 1, loss: 5.451, avg: 3.38, latest lr: 3.897142857142857e-05\n",
      "epoch: 1, loss: 3.617, avg: 3.38, latest lr: 3.8957142857142856e-05\n",
      "epoch: 1, loss: 6.265, avg: 3.38, latest lr: 3.894285714285714e-05\n",
      "epoch: 1, loss: 3.845, avg: 3.38, latest lr: 3.892857142857143e-05\n",
      "epoch: 1, loss: 6.020, avg: 3.38, latest lr: 3.8914285714285713e-05\n",
      "epoch: 1, loss: 4.730, avg: 3.38, latest lr: 3.8900000000000004e-05\n",
      "epoch: 1, loss: 3.918, avg: 3.38, latest lr: 3.888571428571429e-05\n",
      "epoch: 1, loss: 4.834, avg: 3.38, latest lr: 3.887142857142858e-05\n",
      "epoch: 1, loss: 5.028, avg: 3.38, latest lr: 3.885714285714286e-05\n",
      "epoch: 1, loss: 6.570, avg: 3.39, latest lr: 3.8842857142857144e-05\n",
      "epoch: 1, loss: 4.168, avg: 3.39, latest lr: 3.882857142857143e-05\n",
      "epoch: 1, loss: 3.296, avg: 3.39, latest lr: 3.881428571428571e-05\n",
      "epoch: 1, loss: 5.533, avg: 3.39, latest lr: 3.88e-05\n",
      "epoch: 1, loss: 5.696, avg: 3.39, latest lr: 3.8785714285714285e-05\n",
      "epoch: 1, loss: 5.041, avg: 3.39, latest lr: 3.8771428571428575e-05\n",
      "epoch: 1, loss: 4.453, avg: 3.39, latest lr: 3.875714285714286e-05\n",
      "epoch: 1, loss: 3.638, avg: 3.39, latest lr: 3.874285714285715e-05\n",
      "epoch: 1, loss: 4.997, avg: 3.39, latest lr: 3.872857142857143e-05\n",
      "epoch: 1, loss: 4.273, avg: 3.39, latest lr: 3.8714285714285715e-05\n",
      "epoch: 1, loss: 5.078, avg: 3.39, latest lr: 3.8700000000000006e-05\n",
      "epoch: 1, loss: 4.773, avg: 3.39, latest lr: 3.868571428571429e-05\n",
      "epoch: 1, loss: 4.697, avg: 3.39, latest lr: 3.867142857142857e-05\n",
      "epoch: 1, loss: 6.152, avg: 3.39, latest lr: 3.8657142857142856e-05\n",
      "epoch: 1, loss: 3.670, avg: 3.39, latest lr: 3.8642857142857146e-05\n",
      "epoch: 1, loss: 3.743, avg: 3.40, latest lr: 3.862857142857143e-05\n",
      "epoch: 1, loss: 4.490, avg: 3.40, latest lr: 3.861428571428571e-05\n",
      "epoch: 1, loss: 5.497, avg: 3.40, latest lr: 3.86e-05\n",
      "epoch: 1, loss: 5.787, avg: 3.40, latest lr: 3.8585714285714287e-05\n",
      "epoch: 1, loss: 3.922, avg: 3.40, latest lr: 3.857142857142858e-05\n",
      "epoch: 1, loss: 4.886, avg: 3.40, latest lr: 3.855714285714286e-05\n",
      "epoch: 1, loss: 4.746, avg: 3.40, latest lr: 3.854285714285715e-05\n",
      "epoch: 1, loss: 4.136, avg: 3.40, latest lr: 3.8528571428571434e-05\n",
      "epoch: 1, loss: 5.121, avg: 3.40, latest lr: 3.851428571428571e-05\n",
      "epoch: 1, loss: 6.597, avg: 3.40, latest lr: 3.85e-05\n",
      "epoch: 1, loss: 4.379, avg: 3.40, latest lr: 3.8485714285714284e-05\n",
      "epoch: 1, loss: 5.750, avg: 3.40, latest lr: 3.8471428571428574e-05\n",
      "epoch: 1, loss: 4.728, avg: 3.40, latest lr: 3.845714285714286e-05\n",
      "epoch: 1, loss: 3.838, avg: 3.40, latest lr: 3.844285714285715e-05\n",
      "epoch: 1, loss: 3.048, avg: 3.41, latest lr: 3.842857142857143e-05\n",
      "epoch: 1, loss: 3.995, avg: 3.41, latest lr: 3.8414285714285715e-05\n",
      "epoch: 1, loss: 4.115, avg: 3.41, latest lr: 3.8400000000000005e-05\n",
      "epoch: 1, loss: 4.428, avg: 3.41, latest lr: 3.838571428571429e-05\n",
      "epoch: 1, loss: 3.272, avg: 3.41, latest lr: 3.837142857142857e-05\n",
      "epoch: 1, loss: 5.413, avg: 3.41, latest lr: 3.8357142857142855e-05\n",
      "epoch: 1, loss: 5.149, avg: 3.41, latest lr: 3.8342857142857146e-05\n",
      "epoch: 1, loss: 4.220, avg: 3.41, latest lr: 3.832857142857143e-05\n",
      "epoch: 1, loss: 4.784, avg: 3.41, latest lr: 3.831428571428571e-05\n",
      "epoch: 1, loss: 3.644, avg: 3.41, latest lr: 3.83e-05\n",
      "epoch: 1, loss: 6.130, avg: 3.41, latest lr: 3.8285714285714286e-05\n",
      "epoch: 1, loss: 5.061, avg: 3.41, latest lr: 3.8271428571428576e-05\n",
      "epoch: 1, loss: 4.922, avg: 3.41, latest lr: 3.825714285714286e-05\n",
      "epoch: 1, loss: 4.613, avg: 3.41, latest lr: 3.824285714285715e-05\n",
      "epoch: 1, loss: 5.023, avg: 3.41, latest lr: 3.822857142857143e-05\n",
      "epoch: 1, loss: 4.269, avg: 3.41, latest lr: 3.821428571428572e-05\n",
      "epoch: 1, loss: 4.704, avg: 3.42, latest lr: 3.82e-05\n",
      "epoch: 1, loss: 5.575, avg: 3.42, latest lr: 3.8185714285714284e-05\n",
      "epoch: 1, loss: 5.230, avg: 3.42, latest lr: 3.8171428571428574e-05\n",
      "epoch: 1, loss: 5.107, avg: 3.42, latest lr: 3.815714285714286e-05\n",
      "epoch: 1, loss: 4.858, avg: 3.42, latest lr: 3.814285714285715e-05\n",
      "epoch: 1, loss: 5.122, avg: 3.42, latest lr: 3.812857142857143e-05\n",
      "epoch: 1, loss: 5.144, avg: 3.42, latest lr: 3.8114285714285714e-05\n",
      "epoch: 1, loss: 5.024, avg: 3.42, latest lr: 3.8100000000000005e-05\n",
      "epoch: 1, loss: 3.324, avg: 3.42, latest lr: 3.808571428571429e-05\n",
      "epoch: 1, loss: 5.614, avg: 3.42, latest lr: 3.807142857142857e-05\n",
      "epoch: 1, loss: 4.440, avg: 3.42, latest lr: 3.8057142857142855e-05\n",
      "epoch: 1, loss: 3.425, avg: 3.42, latest lr: 3.8042857142857145e-05\n",
      "epoch: 1, loss: 4.323, avg: 3.42, latest lr: 3.802857142857143e-05\n",
      "epoch: 1, loss: 5.434, avg: 3.42, latest lr: 3.801428571428571e-05\n",
      "epoch: 1, loss: 4.240, avg: 3.43, latest lr: 3.8e-05\n",
      "epoch: 1, loss: 4.975, avg: 3.43, latest lr: 3.7985714285714286e-05\n",
      "epoch: 1, loss: 5.334, avg: 3.43, latest lr: 3.7971428571428576e-05\n",
      "epoch: 1, loss: 3.755, avg: 3.43, latest lr: 3.795714285714286e-05\n",
      "epoch: 1, loss: 5.068, avg: 3.43, latest lr: 3.794285714285715e-05\n",
      "epoch: 1, loss: 6.177, avg: 3.43, latest lr: 3.792857142857143e-05\n",
      "epoch: 1, loss: 5.128, avg: 3.43, latest lr: 3.7914285714285716e-05\n",
      "epoch: 1, loss: 3.929, avg: 3.43, latest lr: 3.79e-05\n",
      "epoch: 1, loss: 4.801, avg: 3.43, latest lr: 3.788571428571428e-05\n",
      "epoch: 1, loss: 6.014, avg: 3.43, latest lr: 3.787142857142857e-05\n",
      "epoch: 1, loss: 5.204, avg: 3.43, latest lr: 3.785714285714286e-05\n",
      "epoch: 1, loss: 5.254, avg: 3.43, latest lr: 3.784285714285715e-05\n",
      "epoch: 1, loss: 3.495, avg: 3.43, latest lr: 3.782857142857143e-05\n",
      "epoch: 1, loss: 4.073, avg: 3.43, latest lr: 3.781428571428572e-05\n",
      "epoch: 1, loss: 5.926, avg: 3.43, latest lr: 3.7800000000000004e-05\n",
      "epoch: 1, loss: 3.967, avg: 3.44, latest lr: 3.778571428571429e-05\n",
      "epoch: 1, loss: 4.610, avg: 3.44, latest lr: 3.777142857142858e-05\n",
      "epoch: 1, loss: 5.321, avg: 3.44, latest lr: 3.7757142857142854e-05\n",
      "epoch: 1, loss: 5.161, avg: 3.44, latest lr: 3.7742857142857145e-05\n",
      "epoch: 1, loss: 4.711, avg: 3.44, latest lr: 3.772857142857143e-05\n",
      "epoch: 1, loss: 5.036, avg: 3.44, latest lr: 3.771428571428572e-05\n",
      "epoch: 1, loss: 4.447, avg: 3.44, latest lr: 3.77e-05\n",
      "epoch: 1, loss: 4.675, avg: 3.44, latest lr: 3.7685714285714285e-05\n",
      "epoch: 1, loss: 4.910, avg: 3.44, latest lr: 3.7671428571428575e-05\n",
      "epoch: 1, loss: 4.247, avg: 3.44, latest lr: 3.765714285714286e-05\n",
      "epoch: 1, loss: 3.782, avg: 3.44, latest lr: 3.764285714285715e-05\n",
      "epoch: 1, loss: 5.353, avg: 3.44, latest lr: 3.762857142857143e-05\n",
      "epoch: 1, loss: 4.249, avg: 3.44, latest lr: 3.7614285714285716e-05\n",
      "epoch: 1, loss: 4.793, avg: 3.44, latest lr: 3.76e-05\n",
      "epoch: 1, loss: 3.450, avg: 3.44, latest lr: 3.758571428571428e-05\n",
      "epoch: 1, loss: 5.130, avg: 3.45, latest lr: 3.757142857142857e-05\n",
      "epoch: 1, loss: 3.865, avg: 3.45, latest lr: 3.7557142857142856e-05\n",
      "epoch: 1, loss: 5.761, avg: 3.45, latest lr: 3.7542857142857146e-05\n",
      "epoch: 1, loss: 5.560, avg: 3.45, latest lr: 3.752857142857143e-05\n",
      "epoch: 1, loss: 3.545, avg: 3.45, latest lr: 3.751428571428572e-05\n",
      "epoch: 1, loss: 4.503, avg: 3.45, latest lr: 3.7500000000000003e-05\n",
      "epoch: 1, loss: 4.859, avg: 3.45, latest lr: 3.748571428571429e-05\n",
      "epoch: 1, loss: 5.032, avg: 3.45, latest lr: 3.747142857142858e-05\n",
      "epoch: 1, loss: 6.084, avg: 3.45, latest lr: 3.745714285714286e-05\n",
      "epoch: 1, loss: 4.337, avg: 3.45, latest lr: 3.7442857142857144e-05\n",
      "epoch: 1, loss: 5.669, avg: 3.45, latest lr: 3.742857142857143e-05\n",
      "epoch: 1, loss: 5.375, avg: 3.45, latest lr: 3.741428571428572e-05\n",
      "epoch: 1, loss: 5.376, avg: 3.45, latest lr: 3.74e-05\n",
      "epoch: 1, loss: 5.458, avg: 3.45, latest lr: 3.7385714285714284e-05\n",
      "epoch: 1, loss: 5.506, avg: 3.46, latest lr: 3.7371428571428575e-05\n",
      "epoch: 1, loss: 4.540, avg: 3.46, latest lr: 3.735714285714286e-05\n",
      "epoch: 1, loss: 5.264, avg: 3.46, latest lr: 3.734285714285715e-05\n",
      "epoch: 1, loss: 3.446, avg: 3.46, latest lr: 3.732857142857143e-05\n",
      "epoch: 1, loss: 5.290, avg: 3.46, latest lr: 3.7314285714285715e-05\n",
      "epoch: 1, loss: 4.607, avg: 3.46, latest lr: 3.73e-05\n",
      "epoch: 1, loss: 6.408, avg: 3.46, latest lr: 3.728571428571428e-05\n",
      "epoch: 1, loss: 4.941, avg: 3.46, latest lr: 3.727142857142857e-05\n",
      "epoch: 1, loss: 4.964, avg: 3.46, latest lr: 3.7257142857142856e-05\n",
      "epoch: 1, loss: 4.493, avg: 3.46, latest lr: 3.7242857142857146e-05\n",
      "epoch: 1, loss: 3.881, avg: 3.46, latest lr: 3.722857142857143e-05\n",
      "epoch: 1, loss: 5.272, avg: 3.46, latest lr: 3.721428571428572e-05\n",
      "epoch: 1, loss: 4.070, avg: 3.46, latest lr: 3.72e-05\n",
      "epoch: 1, loss: 4.094, avg: 3.46, latest lr: 3.7185714285714286e-05\n",
      "epoch: 1, loss: 5.382, avg: 3.47, latest lr: 3.717142857142858e-05\n",
      "epoch: 1, loss: 4.094, avg: 3.47, latest lr: 3.715714285714286e-05\n",
      "epoch: 1, loss: 4.906, avg: 3.47, latest lr: 3.7142857142857143e-05\n",
      "epoch: 1, loss: 3.993, avg: 3.47, latest lr: 3.712857142857143e-05\n",
      "epoch: 1, loss: 4.552, avg: 3.47, latest lr: 3.711428571428572e-05\n",
      "epoch: 1, loss: 4.675, avg: 3.47, latest lr: 3.71e-05\n",
      "epoch: 1, loss: 4.927, avg: 3.47, latest lr: 3.7085714285714284e-05\n",
      "epoch: 1, loss: 4.021, avg: 3.47, latest lr: 3.7071428571428574e-05\n",
      "epoch: 1, loss: 3.468, avg: 3.47, latest lr: 3.705714285714286e-05\n",
      "epoch: 1, loss: 5.371, avg: 3.47, latest lr: 3.704285714285715e-05\n",
      "epoch: 1, loss: 5.691, avg: 3.47, latest lr: 3.702857142857143e-05\n",
      "epoch: 1, loss: 4.070, avg: 3.47, latest lr: 3.7014285714285715e-05\n",
      "epoch: 1, loss: 3.923, avg: 3.47, latest lr: 3.7e-05\n",
      "epoch: 1, loss: 5.809, avg: 3.47, latest lr: 3.698571428571429e-05\n",
      "epoch: 1, loss: 4.828, avg: 3.47, latest lr: 3.697142857142857e-05\n",
      "epoch: 1, loss: 5.406, avg: 3.48, latest lr: 3.6957142857142855e-05\n",
      "epoch: 1, loss: 4.794, avg: 3.48, latest lr: 3.6942857142857145e-05\n",
      "epoch: 1, loss: 4.784, avg: 3.48, latest lr: 3.692857142857143e-05\n",
      "epoch: 1, loss: 5.416, avg: 3.48, latest lr: 3.691428571428572e-05\n",
      "epoch: 1, loss: 4.774, avg: 3.48, latest lr: 3.69e-05\n",
      "epoch: 1, loss: 5.352, avg: 3.48, latest lr: 3.688571428571429e-05\n",
      "epoch: 1, loss: 5.580, avg: 3.48, latest lr: 3.6871428571428576e-05\n",
      "epoch: 1, loss: 5.806, avg: 3.48, latest lr: 3.685714285714286e-05\n",
      "epoch: 1, loss: 3.527, avg: 3.48, latest lr: 3.684285714285714e-05\n",
      "epoch: 1, loss: 5.984, avg: 3.48, latest lr: 3.6828571428571426e-05\n",
      "epoch: 1, loss: 3.552, avg: 3.48, latest lr: 3.6814285714285717e-05\n",
      "epoch: 1, loss: 6.285, avg: 3.48, latest lr: 3.68e-05\n",
      "epoch: 1, loss: 4.882, avg: 3.48, latest lr: 3.678571428571429e-05\n",
      "epoch: 1, loss: 6.102, avg: 3.48, latest lr: 3.6771428571428574e-05\n",
      "epoch: 1, loss: 5.178, avg: 3.49, latest lr: 3.675714285714286e-05\n",
      "epoch: 1, loss: 4.863, avg: 3.49, latest lr: 3.674285714285715e-05\n",
      "epoch: 1, loss: 5.881, avg: 3.49, latest lr: 3.672857142857143e-05\n",
      "epoch: 1, loss: 4.634, avg: 3.49, latest lr: 3.671428571428572e-05\n",
      "epoch: 1, loss: 5.039, avg: 3.49, latest lr: 3.6700000000000004e-05\n",
      "epoch: 1, loss: 6.108, avg: 3.49, latest lr: 3.668571428571429e-05\n",
      "epoch: 1, loss: 5.143, avg: 3.49, latest lr: 3.667142857142857e-05\n",
      "epoch: 1, loss: 5.545, avg: 3.49, latest lr: 3.6657142857142855e-05\n",
      "epoch: 1, loss: 5.334, avg: 3.49, latest lr: 3.6642857142857145e-05\n",
      "epoch: 1, loss: 5.337, avg: 3.49, latest lr: 3.662857142857143e-05\n",
      "epoch: 1, loss: 4.356, avg: 3.49, latest lr: 3.661428571428572e-05\n",
      "epoch: 1, loss: 4.093, avg: 3.49, latest lr: 3.66e-05\n",
      "epoch: 1, loss: 4.899, avg: 3.49, latest lr: 3.658571428571429e-05\n",
      "epoch: 1, loss: 4.368, avg: 3.49, latest lr: 3.6571428571428576e-05\n",
      "epoch: 1, loss: 3.967, avg: 3.50, latest lr: 3.655714285714286e-05\n",
      "epoch: 1, loss: 4.807, avg: 3.50, latest lr: 3.654285714285714e-05\n",
      "epoch: 1, loss: 4.257, avg: 3.50, latest lr: 3.6528571428571426e-05\n",
      "epoch: 1, loss: 5.828, avg: 3.50, latest lr: 3.6514285714285716e-05\n",
      "epoch: 1, loss: 5.384, avg: 3.50, latest lr: 3.65e-05\n",
      "epoch: 1, loss: 4.859, avg: 3.50, latest lr: 3.648571428571429e-05\n",
      "epoch: 1, loss: 4.589, avg: 3.50, latest lr: 3.647142857142857e-05\n",
      "epoch: 1, loss: 4.924, avg: 3.50, latest lr: 3.6457142857142857e-05\n",
      "epoch: 1, loss: 2.994, avg: 3.50, latest lr: 3.644285714285715e-05\n",
      "epoch: 1, loss: 5.610, avg: 3.50, latest lr: 3.642857142857143e-05\n",
      "epoch: 1, loss: 3.326, avg: 3.50, latest lr: 3.641428571428572e-05\n",
      "epoch: 1, loss: 4.425, avg: 3.50, latest lr: 3.6400000000000004e-05\n",
      "epoch: 1, loss: 3.362, avg: 3.50, latest lr: 3.638571428571429e-05\n",
      "epoch: 1, loss: 4.549, avg: 3.50, latest lr: 3.637142857142857e-05\n",
      "epoch: 1, loss: 5.051, avg: 3.50, latest lr: 3.6357142857142854e-05\n",
      "epoch: 1, loss: 4.278, avg: 3.51, latest lr: 3.6342857142857144e-05\n",
      "epoch: 1, loss: 3.904, avg: 3.51, latest lr: 3.632857142857143e-05\n",
      "epoch: 1, loss: 4.580, avg: 3.51, latest lr: 3.631428571428572e-05\n",
      "epoch: 1, loss: 4.633, avg: 3.51, latest lr: 3.63e-05\n",
      "epoch: 1, loss: 3.913, avg: 3.51, latest lr: 3.628571428571429e-05\n",
      "epoch: 1, loss: 5.596, avg: 3.51, latest lr: 3.6271428571428575e-05\n",
      "epoch: 1, loss: 4.047, avg: 3.51, latest lr: 3.625714285714286e-05\n",
      "epoch: 1, loss: 4.913, avg: 3.51, latest lr: 3.624285714285714e-05\n",
      "epoch: 1, loss: 4.972, avg: 3.51, latest lr: 3.6228571428571425e-05\n",
      "epoch: 1, loss: 4.313, avg: 3.51, latest lr: 3.6214285714285716e-05\n",
      "epoch: 1, loss: 4.239, avg: 3.51, latest lr: 3.62e-05\n",
      "epoch: 1, loss: 4.771, avg: 3.51, latest lr: 3.618571428571429e-05\n",
      "epoch: 1, loss: 5.550, avg: 3.51, latest lr: 3.617142857142857e-05\n",
      "epoch: 1, loss: 4.851, avg: 3.51, latest lr: 3.615714285714286e-05\n",
      "epoch: 1, loss: 6.189, avg: 3.51, latest lr: 3.6142857142857146e-05\n",
      "epoch: 1, loss: 3.794, avg: 3.52, latest lr: 3.612857142857143e-05\n",
      "epoch: 1, loss: 6.075, avg: 3.52, latest lr: 3.611428571428572e-05\n",
      "epoch: 1, loss: 3.423, avg: 3.52, latest lr: 3.61e-05\n",
      "epoch: 1, loss: 5.331, avg: 3.52, latest lr: 3.608571428571429e-05\n",
      "epoch: 1, loss: 3.321, avg: 3.52, latest lr: 3.607142857142857e-05\n",
      "epoch: 1, loss: 5.685, avg: 3.52, latest lr: 3.605714285714286e-05\n",
      "epoch: 1, loss: 4.032, avg: 3.52, latest lr: 3.6042857142857144e-05\n",
      "epoch: 1, loss: 4.625, avg: 3.52, latest lr: 3.602857142857143e-05\n",
      "epoch: 1, loss: 4.790, avg: 3.52, latest lr: 3.601428571428572e-05\n",
      "epoch: 1, loss: 4.214, avg: 3.52, latest lr: 3.6e-05\n",
      "epoch: 1, loss: 4.831, avg: 3.52, latest lr: 3.598571428571429e-05\n",
      "epoch: 1, loss: 4.400, avg: 3.52, latest lr: 3.5971428571428575e-05\n",
      "epoch: 1, loss: 4.344, avg: 3.52, latest lr: 3.5957142857142865e-05\n",
      "epoch: 1, loss: 3.234, avg: 3.52, latest lr: 3.594285714285714e-05\n",
      "epoch: 1, loss: 5.700, avg: 3.52, latest lr: 3.5928571428571425e-05\n",
      "epoch: 1, loss: 5.151, avg: 3.53, latest lr: 3.5914285714285715e-05\n",
      "epoch: 1, loss: 3.857, avg: 3.53, latest lr: 3.59e-05\n",
      "epoch: 1, loss: 4.444, avg: 3.53, latest lr: 3.588571428571429e-05\n",
      "epoch: 1, loss: 4.301, avg: 3.53, latest lr: 3.587142857142857e-05\n",
      "epoch: 1, loss: 4.162, avg: 3.53, latest lr: 3.585714285714286e-05\n",
      "epoch: 1, loss: 4.524, avg: 3.53, latest lr: 3.5842857142857146e-05\n",
      "epoch: 1, loss: 5.382, avg: 3.53, latest lr: 3.582857142857143e-05\n",
      "epoch: 1, loss: 5.019, avg: 3.53, latest lr: 3.581428571428572e-05\n",
      "epoch: 1, loss: 5.307, avg: 3.53, latest lr: 3.58e-05\n",
      "epoch: 1, loss: 4.430, avg: 3.53, latest lr: 3.5785714285714286e-05\n",
      "epoch: 1, loss: 4.849, avg: 3.53, latest lr: 3.577142857142857e-05\n",
      "epoch: 1, loss: 4.713, avg: 3.53, latest lr: 3.575714285714286e-05\n",
      "epoch: 1, loss: 5.216, avg: 3.53, latest lr: 3.574285714285714e-05\n",
      "epoch: 1, loss: 6.120, avg: 3.53, latest lr: 3.572857142857143e-05\n",
      "epoch: 1, loss: 3.806, avg: 3.53, latest lr: 3.571428571428572e-05\n",
      "epoch: 1, loss: 4.125, avg: 3.54, latest lr: 3.57e-05\n",
      "epoch: 1, loss: 4.259, avg: 3.54, latest lr: 3.568571428571429e-05\n",
      "epoch: 1, loss: 4.654, avg: 3.54, latest lr: 3.5671428571428574e-05\n",
      "epoch: 1, loss: 4.381, avg: 3.54, latest lr: 3.5657142857142864e-05\n",
      "epoch: 1, loss: 4.224, avg: 3.54, latest lr: 3.564285714285715e-05\n",
      "epoch: 1, loss: 5.430, avg: 3.54, latest lr: 3.562857142857143e-05\n",
      "epoch: 1, loss: 5.177, avg: 3.54, latest lr: 3.5614285714285715e-05\n",
      "epoch: 1, loss: 4.335, avg: 3.54, latest lr: 3.56e-05\n",
      "epoch: 1, loss: 4.765, avg: 3.54, latest lr: 3.558571428571429e-05\n",
      "epoch: 1, loss: 5.003, avg: 3.54, latest lr: 3.557142857142857e-05\n",
      "epoch: 1, loss: 4.912, avg: 3.54, latest lr: 3.555714285714286e-05\n",
      "epoch: 1, loss: 5.822, avg: 3.54, latest lr: 3.5542857142857145e-05\n",
      "epoch: 1, loss: 3.739, avg: 3.54, latest lr: 3.552857142857143e-05\n",
      "epoch: 1, loss: 5.310, avg: 3.54, latest lr: 3.551428571428572e-05\n",
      "epoch: 1, loss: 5.742, avg: 3.54, latest lr: 3.55e-05\n",
      "epoch: 1, loss: 4.217, avg: 3.55, latest lr: 3.5485714285714286e-05\n",
      "epoch: 1, loss: 4.356, avg: 3.55, latest lr: 3.547142857142857e-05\n",
      "epoch: 1, loss: 5.500, avg: 3.55, latest lr: 3.545714285714286e-05\n",
      "epoch: 1, loss: 4.656, avg: 3.55, latest lr: 3.544285714285714e-05\n",
      "epoch: 1, loss: 3.906, avg: 3.55, latest lr: 3.5428571428571426e-05\n",
      "epoch: 1, loss: 5.537, avg: 3.55, latest lr: 3.5414285714285716e-05\n",
      "epoch: 1, loss: 4.202, avg: 3.55, latest lr: 3.54e-05\n",
      "epoch: 1, loss: 5.596, avg: 3.55, latest lr: 3.538571428571429e-05\n",
      "epoch: 1, loss: 3.718, avg: 3.55, latest lr: 3.5371428571428574e-05\n",
      "epoch: 1, loss: 4.505, avg: 3.55, latest lr: 3.5357142857142864e-05\n",
      "epoch: 1, loss: 4.498, avg: 3.55, latest lr: 3.534285714285715e-05\n",
      "epoch: 1, loss: 4.266, avg: 3.55, latest lr: 3.532857142857143e-05\n",
      "epoch: 1, loss: 3.042, avg: 3.55, latest lr: 3.5314285714285714e-05\n",
      "epoch: 1, loss: 4.004, avg: 3.55, latest lr: 3.53e-05\n",
      "epoch: 1, loss: 4.229, avg: 3.55, latest lr: 3.528571428571429e-05\n",
      "epoch: 1, loss: 5.548, avg: 3.55, latest lr: 3.527142857142857e-05\n",
      "epoch: 1, loss: 4.148, avg: 3.56, latest lr: 3.525714285714286e-05\n",
      "epoch: 1, loss: 4.379, avg: 3.56, latest lr: 3.5242857142857145e-05\n",
      "epoch: 1, loss: 4.983, avg: 3.56, latest lr: 3.5228571428571435e-05\n",
      "epoch: 1, loss: 3.836, avg: 3.56, latest lr: 3.521428571428572e-05\n",
      "epoch: 1, loss: 4.507, avg: 3.56, latest lr: 3.52e-05\n",
      "epoch: 1, loss: 5.055, avg: 3.56, latest lr: 3.5185714285714285e-05\n",
      "epoch: 1, loss: 5.585, avg: 3.56, latest lr: 3.517142857142857e-05\n",
      "epoch: 1, loss: 6.363, avg: 3.56, latest lr: 3.515714285714286e-05\n",
      "epoch: 1, loss: 3.865, avg: 3.56, latest lr: 3.514285714285714e-05\n",
      "epoch: 1, loss: 3.801, avg: 3.56, latest lr: 3.512857142857143e-05\n",
      "epoch: 1, loss: 5.903, avg: 3.56, latest lr: 3.5114285714285716e-05\n",
      "epoch: 1, loss: 5.668, avg: 3.56, latest lr: 3.51e-05\n",
      "epoch: 1, loss: 5.341, avg: 3.56, latest lr: 3.508571428571429e-05\n",
      "epoch: 1, loss: 4.350, avg: 3.56, latest lr: 3.507142857142857e-05\n",
      "epoch: 1, loss: 4.535, avg: 3.57, latest lr: 3.505714285714286e-05\n",
      "epoch: 1, loss: 3.144, avg: 3.57, latest lr: 3.504285714285715e-05\n",
      "epoch: 1, loss: 4.881, avg: 3.57, latest lr: 3.502857142857143e-05\n",
      "epoch: 1, loss: 5.421, avg: 3.57, latest lr: 3.5014285714285714e-05\n",
      "epoch: 1, loss: 5.724, avg: 3.57, latest lr: 3.5e-05\n",
      "epoch: 1, loss: 4.531, avg: 3.57, latest lr: 3.498571428571429e-05\n",
      "epoch: 1, loss: 3.747, avg: 3.57, latest lr: 3.497142857142857e-05\n",
      "epoch: 1, loss: 5.709, avg: 3.57, latest lr: 3.495714285714286e-05\n",
      "epoch: 1, loss: 4.331, avg: 3.57, latest lr: 3.4942857142857144e-05\n",
      "epoch: 1, loss: 5.583, avg: 3.57, latest lr: 3.4928571428571434e-05\n",
      "epoch: 1, loss: 3.873, avg: 3.57, latest lr: 3.491428571428572e-05\n",
      "epoch: 1, loss: 2.910, avg: 3.57, latest lr: 3.49e-05\n",
      "epoch: 1, loss: 5.493, avg: 3.57, latest lr: 3.488571428571429e-05\n",
      "epoch: 1, loss: 4.999, avg: 3.57, latest lr: 3.4871428571428575e-05\n",
      "epoch: 1, loss: 4.932, avg: 3.57, latest lr: 3.485714285714286e-05\n",
      "epoch: 1, loss: 3.939, avg: 3.58, latest lr: 3.484285714285714e-05\n",
      "epoch: 1, loss: 4.401, avg: 3.58, latest lr: 3.482857142857143e-05\n",
      "epoch: 1, loss: 4.975, avg: 3.58, latest lr: 3.4814285714285715e-05\n",
      "epoch: 1, loss: 3.903, avg: 3.58, latest lr: 3.48e-05\n",
      "epoch: 1, loss: 5.983, avg: 3.58, latest lr: 3.478571428571429e-05\n",
      "epoch: 1, loss: 3.860, avg: 3.58, latest lr: 3.477142857142857e-05\n",
      "epoch: 1, loss: 5.255, avg: 3.58, latest lr: 3.475714285714286e-05\n",
      "epoch: 1, loss: 4.751, avg: 3.58, latest lr: 3.4742857142857146e-05\n",
      "epoch: 1, loss: 2.828, avg: 3.58, latest lr: 3.472857142857143e-05\n",
      "epoch: 1, loss: 5.832, avg: 3.58, latest lr: 3.471428571428571e-05\n",
      "epoch: 1, loss: 4.815, avg: 3.58, latest lr: 3.4699999999999996e-05\n",
      "epoch: 1, loss: 3.362, avg: 3.58, latest lr: 3.468571428571429e-05\n",
      "epoch: 1, loss: 6.351, avg: 3.58, latest lr: 3.467142857142857e-05\n",
      "epoch: 1, loss: 4.561, avg: 3.58, latest lr: 3.465714285714286e-05\n",
      "epoch: 1, loss: 3.702, avg: 3.58, latest lr: 3.4642857142857144e-05\n",
      "epoch: 1, loss: 5.009, avg: 3.59, latest lr: 3.4628571428571434e-05\n",
      "epoch: 1, loss: 4.379, avg: 3.59, latest lr: 3.461428571428572e-05\n",
      "epoch: 1, loss: 5.535, avg: 3.59, latest lr: 3.46e-05\n",
      "epoch: 1, loss: 5.426, avg: 3.59, latest lr: 3.458571428571429e-05\n",
      "epoch: 1, loss: 5.329, avg: 3.59, latest lr: 3.4571428571428574e-05\n",
      "epoch: 1, loss: 5.241, avg: 3.59, latest lr: 3.455714285714286e-05\n",
      "epoch: 1, loss: 5.306, avg: 3.59, latest lr: 3.454285714285714e-05\n",
      "epoch: 1, loss: 3.969, avg: 3.59, latest lr: 3.452857142857143e-05\n",
      "epoch: 1, loss: 3.374, avg: 3.59, latest lr: 3.4514285714285715e-05\n",
      "epoch: 1, loss: 3.980, avg: 3.59, latest lr: 3.45e-05\n",
      "epoch: 1, loss: 3.966, avg: 3.59, latest lr: 3.448571428571429e-05\n",
      "epoch: 1, loss: 3.478, avg: 3.59, latest lr: 3.447142857142857e-05\n",
      "epoch: 1, loss: 6.226, avg: 3.59, latest lr: 3.445714285714286e-05\n",
      "epoch: 1, loss: 5.733, avg: 3.59, latest lr: 3.4442857142857146e-05\n",
      "epoch: 1, loss: 4.997, avg: 3.59, latest lr: 3.442857142857143e-05\n",
      "epoch: 1, loss: 4.747, avg: 3.60, latest lr: 3.441428571428571e-05\n",
      "epoch: 1, loss: 4.292, avg: 3.60, latest lr: 3.4399999999999996e-05\n",
      "epoch: 1, loss: 4.242, avg: 3.60, latest lr: 3.4385714285714286e-05\n",
      "epoch: 1, loss: 4.784, avg: 3.60, latest lr: 3.437142857142857e-05\n",
      "epoch: 1, loss: 6.031, avg: 3.60, latest lr: 3.435714285714286e-05\n",
      "epoch: 1, loss: 5.824, avg: 3.60, latest lr: 3.434285714285714e-05\n",
      "epoch: 1, loss: 3.651, avg: 3.60, latest lr: 3.432857142857143e-05\n",
      "epoch: 1, loss: 4.793, avg: 3.60, latest lr: 3.431428571428572e-05\n",
      "epoch: 1, loss: 4.610, avg: 3.60, latest lr: 3.430000000000001e-05\n",
      "epoch: 1, loss: 4.705, avg: 3.60, latest lr: 3.428571428571429e-05\n",
      "epoch: 1, loss: 3.454, avg: 3.60, latest lr: 3.4271428571428574e-05\n",
      "epoch: 1, loss: 4.299, avg: 3.60, latest lr: 3.425714285714286e-05\n",
      "epoch: 1, loss: 4.073, avg: 3.60, latest lr: 3.424285714285714e-05\n",
      "epoch: 1, loss: 5.149, avg: 3.60, latest lr: 3.422857142857143e-05\n",
      "epoch: 1, loss: 5.262, avg: 3.60, latest lr: 3.4214285714285714e-05\n",
      "epoch: 1, loss: 5.141, avg: 3.61, latest lr: 3.4200000000000005e-05\n",
      "epoch: 1, loss: 3.565, avg: 3.61, latest lr: 3.418571428571429e-05\n",
      "epoch: 1, loss: 4.189, avg: 3.61, latest lr: 3.417142857142857e-05\n",
      "epoch: 1, loss: 5.349, avg: 3.61, latest lr: 3.415714285714286e-05\n",
      "epoch: 1, loss: 3.492, avg: 3.61, latest lr: 3.4142857142857145e-05\n",
      "epoch: 1, loss: 5.958, avg: 3.61, latest lr: 3.4128571428571435e-05\n",
      "epoch: 1, loss: 5.444, avg: 3.61, latest lr: 3.411428571428571e-05\n",
      "epoch: 1, loss: 4.952, avg: 3.61, latest lr: 3.41e-05\n",
      "epoch: 1, loss: 3.486, avg: 3.61, latest lr: 3.4085714285714286e-05\n",
      "epoch: 1, loss: 3.785, avg: 3.61, latest lr: 3.407142857142857e-05\n",
      "epoch: 1, loss: 4.504, avg: 3.61, latest lr: 3.405714285714286e-05\n",
      "epoch: 1, loss: 4.024, avg: 3.61, latest lr: 3.404285714285714e-05\n",
      "epoch: 1, loss: 4.021, avg: 3.61, latest lr: 3.402857142857143e-05\n",
      "epoch: 1, loss: 5.491, avg: 3.61, latest lr: 3.4014285714285716e-05\n",
      "epoch: 1, loss: 4.611, avg: 3.61, latest lr: 3.4000000000000007e-05\n",
      "epoch: 1, loss: 4.496, avg: 3.62, latest lr: 3.398571428571429e-05\n",
      "epoch: 1, loss: 5.301, avg: 3.62, latest lr: 3.397142857142857e-05\n",
      "epoch: 1, loss: 3.797, avg: 3.62, latest lr: 3.395714285714286e-05\n",
      "epoch: 1, loss: 5.257, avg: 3.62, latest lr: 3.394285714285714e-05\n",
      "epoch: 1, loss: 4.896, avg: 3.62, latest lr: 3.392857142857143e-05\n",
      "epoch: 1, loss: 4.081, avg: 3.62, latest lr: 3.3914285714285714e-05\n",
      "epoch: 1, loss: 3.636, avg: 3.62, latest lr: 3.3900000000000004e-05\n",
      "epoch: 1, loss: 4.335, avg: 3.62, latest lr: 3.388571428571429e-05\n",
      "epoch: 1, loss: 4.036, avg: 3.62, latest lr: 3.387142857142857e-05\n",
      "epoch: 1, loss: 4.871, avg: 3.62, latest lr: 3.385714285714286e-05\n",
      "epoch: 1, loss: 4.182, avg: 3.62, latest lr: 3.3842857142857145e-05\n",
      "epoch: 1, loss: 5.448, avg: 3.62, latest lr: 3.3828571428571435e-05\n",
      "epoch: 1, loss: 5.646, avg: 3.62, latest lr: 3.381428571428572e-05\n",
      "epoch: 1, loss: 3.904, avg: 3.62, latest lr: 3.38e-05\n",
      "epoch: 1, loss: 3.260, avg: 3.62, latest lr: 3.3785714285714285e-05\n",
      "epoch: 1, loss: 3.135, avg: 3.62, latest lr: 3.377142857142857e-05\n",
      "epoch: 1, loss: 4.337, avg: 3.63, latest lr: 3.375714285714286e-05\n",
      "epoch: 1, loss: 4.130, avg: 3.63, latest lr: 3.374285714285714e-05\n",
      "epoch: 1, loss: 4.557, avg: 3.63, latest lr: 3.372857142857143e-05\n",
      "epoch: 1, loss: 3.999, avg: 3.63, latest lr: 3.3714285714285716e-05\n",
      "epoch: 1, loss: 3.379, avg: 3.63, latest lr: 3.3700000000000006e-05\n",
      "epoch: 1, loss: 3.864, avg: 3.63, latest lr: 3.368571428571429e-05\n",
      "epoch: 1, loss: 4.082, avg: 3.63, latest lr: 3.367142857142857e-05\n",
      "epoch: 1, loss: 3.354, avg: 3.63, latest lr: 3.3657142857142856e-05\n",
      "epoch: 1, loss: 3.360, avg: 3.63, latest lr: 3.364285714285714e-05\n",
      "epoch: 1, loss: 3.955, avg: 3.63, latest lr: 3.362857142857143e-05\n",
      "epoch: 1, loss: 3.563, avg: 3.63, latest lr: 3.361428571428571e-05\n",
      "epoch: 1, loss: 5.795, avg: 3.63, latest lr: 3.3600000000000004e-05\n",
      "epoch: 1, loss: 4.751, avg: 3.63, latest lr: 3.358571428571429e-05\n",
      "epoch: 1, loss: 4.573, avg: 3.63, latest lr: 3.357142857142857e-05\n",
      "epoch: 1, loss: 4.919, avg: 3.63, latest lr: 3.355714285714286e-05\n",
      "epoch: 1, loss: 5.670, avg: 3.63, latest lr: 3.3542857142857144e-05\n",
      "epoch: 1, loss: 6.798, avg: 3.64, latest lr: 3.3528571428571434e-05\n",
      "epoch: 1, loss: 6.002, avg: 3.64, latest lr: 3.351428571428572e-05\n",
      "epoch: 1, loss: 4.866, avg: 3.64, latest lr: 3.35e-05\n",
      "epoch: 1, loss: 3.643, avg: 3.64, latest lr: 3.3485714285714285e-05\n",
      "epoch: 1, loss: 4.614, avg: 3.64, latest lr: 3.3471428571428575e-05\n",
      "epoch: 1, loss: 3.967, avg: 3.64, latest lr: 3.345714285714286e-05\n",
      "epoch: 1, loss: 5.117, avg: 3.64, latest lr: 3.344285714285714e-05\n",
      "epoch: 1, loss: 5.583, avg: 3.64, latest lr: 3.342857142857143e-05\n",
      "epoch: 1, loss: 4.329, avg: 3.64, latest lr: 3.3414285714285715e-05\n",
      "epoch: 1, loss: 4.631, avg: 3.64, latest lr: 3.3400000000000005e-05\n",
      "epoch: 1, loss: 4.642, avg: 3.64, latest lr: 3.338571428571429e-05\n",
      "epoch: 1, loss: 4.208, avg: 3.64, latest lr: 3.337142857142857e-05\n",
      "epoch: 1, loss: 5.928, avg: 3.64, latest lr: 3.3357142857142856e-05\n",
      "epoch: 1, loss: 3.211, avg: 3.64, latest lr: 3.334285714285714e-05\n",
      "epoch: 1, loss: 3.460, avg: 3.64, latest lr: 3.332857142857143e-05\n",
      "epoch: 1, loss: 3.374, avg: 3.64, latest lr: 3.331428571428571e-05\n",
      "epoch: 1, loss: 5.254, avg: 3.65, latest lr: 3.33e-05\n",
      "epoch: 1, loss: 5.467, avg: 3.65, latest lr: 3.3285714285714286e-05\n",
      "epoch: 1, loss: 4.164, avg: 3.65, latest lr: 3.327142857142858e-05\n",
      "epoch: 1, loss: 4.753, avg: 3.65, latest lr: 3.325714285714286e-05\n",
      "epoch: 1, loss: 5.172, avg: 3.65, latest lr: 3.3242857142857144e-05\n",
      "epoch: 1, loss: 5.865, avg: 3.65, latest lr: 3.3228571428571434e-05\n",
      "epoch: 1, loss: 4.047, avg: 3.65, latest lr: 3.321428571428572e-05\n",
      "epoch: 1, loss: 4.714, avg: 3.65, latest lr: 3.32e-05\n",
      "epoch: 1, loss: 4.645, avg: 3.65, latest lr: 3.3185714285714284e-05\n",
      "epoch: 1, loss: 3.399, avg: 3.65, latest lr: 3.3171428571428574e-05\n",
      "epoch: 1, loss: 3.546, avg: 3.65, latest lr: 3.315714285714286e-05\n",
      "epoch: 1, loss: 4.274, avg: 3.65, latest lr: 3.314285714285714e-05\n",
      "epoch: 1, loss: 5.450, avg: 3.65, latest lr: 3.312857142857143e-05\n",
      "epoch: 1, loss: 5.225, avg: 3.65, latest lr: 3.3114285714285715e-05\n",
      "epoch: 1, loss: 5.223, avg: 3.66, latest lr: 3.3100000000000005e-05\n",
      "epoch: 1, loss: 5.475, avg: 3.66, latest lr: 3.308571428571429e-05\n",
      "epoch: 1, loss: 2.449, avg: 3.66, latest lr: 3.307142857142858e-05\n",
      "epoch: 1, loss: 4.857, avg: 3.66, latest lr: 3.305714285714286e-05\n",
      "epoch: 1, loss: 4.733, avg: 3.66, latest lr: 3.304285714285714e-05\n",
      "epoch: 1, loss: 5.327, avg: 3.66, latest lr: 3.302857142857143e-05\n",
      "epoch: 1, loss: 6.127, avg: 3.66, latest lr: 3.301428571428571e-05\n",
      "epoch: 1, loss: 4.631, avg: 3.66, latest lr: 3.3e-05\n",
      "epoch: 1, loss: 4.131, avg: 3.66, latest lr: 3.2985714285714286e-05\n",
      "epoch: 1, loss: 4.264, avg: 3.66, latest lr: 3.2971428571428576e-05\n",
      "epoch: 1, loss: 4.487, avg: 3.66, latest lr: 3.295714285714286e-05\n",
      "epoch: 1, loss: 4.326, avg: 3.66, latest lr: 3.294285714285714e-05\n",
      "epoch: 1, loss: 4.127, avg: 3.66, latest lr: 3.292857142857143e-05\n",
      "epoch: 1, loss: 4.058, avg: 3.66, latest lr: 3.291428571428572e-05\n",
      "epoch: 1, loss: 4.721, avg: 3.66, latest lr: 3.29e-05\n",
      "epoch: 1, loss: 4.935, avg: 3.66, latest lr: 3.2885714285714284e-05\n",
      "epoch: 1, loss: 4.102, avg: 3.67, latest lr: 3.2871428571428574e-05\n",
      "epoch: 1, loss: 4.717, avg: 3.67, latest lr: 3.285714285714286e-05\n",
      "epoch: 1, loss: 4.364, avg: 3.67, latest lr: 3.284285714285714e-05\n",
      "epoch: 1, loss: 4.182, avg: 3.67, latest lr: 3.282857142857143e-05\n",
      "epoch: 1, loss: 4.579, avg: 3.67, latest lr: 3.2814285714285714e-05\n",
      "epoch: 1, loss: 6.009, avg: 3.67, latest lr: 3.2800000000000004e-05\n",
      "epoch: 1, loss: 4.829, avg: 3.67, latest lr: 3.278571428571429e-05\n",
      "epoch: 1, loss: 5.135, avg: 3.67, latest lr: 3.277142857142858e-05\n",
      "epoch: 1, loss: 5.849, avg: 3.67, latest lr: 3.275714285714286e-05\n",
      "epoch: 1, loss: 4.564, avg: 3.67, latest lr: 3.2742857142857145e-05\n",
      "epoch: 1, loss: 4.841, avg: 3.67, latest lr: 3.272857142857143e-05\n",
      "epoch: 1, loss: 4.610, avg: 3.67, latest lr: 3.271428571428571e-05\n",
      "epoch: 1, loss: 4.796, avg: 3.67, latest lr: 3.27e-05\n",
      "epoch: 1, loss: 5.431, avg: 3.67, latest lr: 3.2685714285714285e-05\n",
      "epoch: 1, loss: 5.450, avg: 3.68, latest lr: 3.2671428571428576e-05\n",
      "epoch: 1, loss: 5.315, avg: 3.68, latest lr: 3.265714285714286e-05\n",
      "epoch: 1, loss: 4.117, avg: 3.68, latest lr: 3.264285714285714e-05\n",
      "epoch: 1, loss: 4.583, avg: 3.68, latest lr: 3.262857142857143e-05\n",
      "epoch: 1, loss: 3.918, avg: 3.68, latest lr: 3.2614285714285716e-05\n",
      "epoch: 1, loss: 4.917, avg: 3.68, latest lr: 3.26e-05\n",
      "epoch: 1, loss: 4.565, avg: 3.68, latest lr: 3.258571428571428e-05\n",
      "epoch: 1, loss: 5.183, avg: 3.68, latest lr: 3.257142857142857e-05\n",
      "epoch: 1, loss: 5.008, avg: 3.68, latest lr: 3.255714285714286e-05\n",
      "epoch: 1, loss: 5.679, avg: 3.68, latest lr: 3.254285714285715e-05\n",
      "epoch: 1, loss: 5.156, avg: 3.68, latest lr: 3.252857142857143e-05\n",
      "epoch: 1, loss: 5.012, avg: 3.68, latest lr: 3.2514285714285714e-05\n",
      "epoch: 1, loss: 4.059, avg: 3.68, latest lr: 3.2500000000000004e-05\n",
      "epoch: 1, loss: 5.595, avg: 3.68, latest lr: 3.248571428571429e-05\n",
      "epoch: 1, loss: 4.749, avg: 3.69, latest lr: 3.247142857142858e-05\n",
      "epoch: 1, loss: 5.042, avg: 3.69, latest lr: 3.245714285714286e-05\n",
      "epoch: 1, loss: 5.917, avg: 3.69, latest lr: 3.2442857142857144e-05\n",
      "epoch: 1, loss: 4.786, avg: 3.69, latest lr: 3.242857142857143e-05\n",
      "epoch: 1, loss: 5.445, avg: 3.69, latest lr: 3.241428571428571e-05\n",
      "epoch: 1, loss: 4.259, avg: 3.69, latest lr: 3.24e-05\n",
      "epoch: 1, loss: 4.249, avg: 3.69, latest lr: 3.2385714285714285e-05\n",
      "epoch: 1, loss: 5.016, avg: 3.69, latest lr: 3.2371428571428575e-05\n",
      "epoch: 1, loss: 4.723, avg: 3.69, latest lr: 3.235714285714286e-05\n",
      "epoch: 1, loss: 3.585, avg: 3.69, latest lr: 3.234285714285715e-05\n",
      "epoch: 1, loss: 4.971, avg: 3.69, latest lr: 3.232857142857143e-05\n",
      "epoch: 1, loss: 4.583, avg: 3.69, latest lr: 3.2314285714285716e-05\n",
      "epoch: 1, loss: 3.777, avg: 3.69, latest lr: 3.2300000000000006e-05\n",
      "epoch: 1, loss: 4.584, avg: 3.69, latest lr: 3.228571428571428e-05\n",
      "epoch: 1, loss: 4.963, avg: 3.69, latest lr: 3.227142857142857e-05\n",
      "epoch: 1, loss: 4.178, avg: 3.70, latest lr: 3.2257142857142856e-05\n",
      "epoch: 1, loss: 4.498, avg: 3.70, latest lr: 3.2242857142857146e-05\n",
      "epoch: 1, loss: 3.561, avg: 3.70, latest lr: 3.222857142857143e-05\n",
      "epoch: 1, loss: 5.667, avg: 3.70, latest lr: 3.221428571428571e-05\n",
      "epoch: 1, loss: 4.211, avg: 3.70, latest lr: 3.2200000000000003e-05\n",
      "epoch: 1, loss: 5.122, avg: 3.70, latest lr: 3.218571428571429e-05\n",
      "epoch: 1, loss: 3.753, avg: 3.70, latest lr: 3.217142857142858e-05\n",
      "epoch: 1, loss: 5.037, avg: 3.70, latest lr: 3.215714285714286e-05\n",
      "epoch: 1, loss: 5.950, avg: 3.70, latest lr: 3.2142857142857144e-05\n",
      "epoch: 1, loss: 4.432, avg: 3.70, latest lr: 3.212857142857143e-05\n",
      "epoch: 1, loss: 4.030, avg: 3.70, latest lr: 3.211428571428571e-05\n",
      "epoch: 1, loss: 5.417, avg: 3.70, latest lr: 3.21e-05\n",
      "epoch: 1, loss: 4.872, avg: 3.70, latest lr: 3.2085714285714284e-05\n",
      "epoch: 1, loss: 5.003, avg: 3.70, latest lr: 3.2071428571428575e-05\n",
      "epoch: 1, loss: 5.264, avg: 3.70, latest lr: 3.205714285714286e-05\n",
      "epoch: 1, loss: 4.145, avg: 3.71, latest lr: 3.204285714285715e-05\n",
      "epoch: 1, loss: 5.289, avg: 3.71, latest lr: 3.202857142857143e-05\n",
      "epoch: 1, loss: 4.479, avg: 3.71, latest lr: 3.2014285714285715e-05\n",
      "epoch: 1, loss: 5.839, avg: 3.71, latest lr: 3.2000000000000005e-05\n",
      "epoch: 1, loss: 4.866, avg: 3.71, latest lr: 3.198571428571429e-05\n",
      "epoch: 1, loss: 5.137, avg: 3.71, latest lr: 3.197142857142857e-05\n",
      "epoch: 1, loss: 4.253, avg: 3.71, latest lr: 3.1957142857142856e-05\n",
      "epoch: 1, loss: 4.669, avg: 3.71, latest lr: 3.1942857142857146e-05\n",
      "epoch: 1, loss: 4.659, avg: 3.71, latest lr: 3.192857142857143e-05\n",
      "epoch: 1, loss: 4.474, avg: 3.71, latest lr: 3.191428571428571e-05\n",
      "epoch: 1, loss: 5.197, avg: 3.71, latest lr: 3.19e-05\n",
      "epoch: 1, loss: 3.551, avg: 3.71, latest lr: 3.1885714285714286e-05\n",
      "epoch: 1, loss: 5.836, avg: 3.71, latest lr: 3.1871428571428577e-05\n",
      "epoch: 1, loss: 4.823, avg: 3.71, latest lr: 3.185714285714286e-05\n",
      "epoch: 1, loss: 5.175, avg: 3.71, latest lr: 3.1842857142857143e-05\n",
      "epoch: 1, loss: 5.828, avg: 3.72, latest lr: 3.182857142857143e-05\n",
      "epoch: 1, loss: 5.124, avg: 3.72, latest lr: 3.181428571428571e-05\n",
      "epoch: 1, loss: 4.235, avg: 3.72, latest lr: 3.18e-05\n",
      "epoch: 1, loss: 3.968, avg: 3.72, latest lr: 3.1785714285714284e-05\n",
      "epoch: 1, loss: 4.394, avg: 3.72, latest lr: 3.1771428571428574e-05\n",
      "epoch: 1, loss: 5.109, avg: 3.72, latest lr: 3.175714285714286e-05\n",
      "epoch: 1, loss: 5.202, avg: 3.72, latest lr: 3.174285714285715e-05\n",
      "epoch: 1, loss: 6.026, avg: 3.72, latest lr: 3.172857142857143e-05\n",
      "epoch: 1, loss: 4.004, avg: 3.72, latest lr: 3.1714285714285715e-05\n",
      "epoch: 1, loss: 4.156, avg: 3.72, latest lr: 3.1700000000000005e-05\n",
      "epoch: 1, loss: 3.618, avg: 3.72, latest lr: 3.168571428571429e-05\n",
      "epoch: 1, loss: 4.191, avg: 3.72, latest lr: 3.167142857142857e-05\n",
      "epoch: 1, loss: 5.053, avg: 3.72, latest lr: 3.1657142857142855e-05\n",
      "epoch: 1, loss: 4.699, avg: 3.72, latest lr: 3.1642857142857145e-05\n",
      "epoch: 1, loss: 5.043, avg: 3.72, latest lr: 3.162857142857143e-05\n",
      "epoch: 1, loss: 4.826, avg: 3.73, latest lr: 3.161428571428572e-05\n",
      "epoch: 1, loss: 4.008, avg: 3.73, latest lr: 3.16e-05\n",
      "epoch: 1, loss: 5.418, avg: 3.73, latest lr: 3.1585714285714286e-05\n",
      "epoch: 1, loss: 5.239, avg: 3.73, latest lr: 3.1571428571428576e-05\n",
      "epoch: 1, loss: 4.816, avg: 3.73, latest lr: 3.155714285714286e-05\n",
      "epoch: 1, loss: 5.102, avg: 3.73, latest lr: 3.154285714285714e-05\n",
      "epoch: 1, loss: 6.315, avg: 3.73, latest lr: 3.1528571428571426e-05\n",
      "epoch: 1, loss: 4.045, avg: 3.73, latest lr: 3.1514285714285717e-05\n",
      "epoch: 1, loss: 7.451, avg: 3.73, latest lr: 3.15e-05\n",
      "epoch: 1, loss: 5.389, avg: 3.73, latest lr: 3.148571428571428e-05\n",
      "epoch: 1, loss: 3.843, avg: 3.73, latest lr: 3.1471428571428574e-05\n",
      "epoch: 1, loss: 5.455, avg: 3.73, latest lr: 3.145714285714286e-05\n",
      "epoch: 1, loss: 3.793, avg: 3.73, latest lr: 3.144285714285715e-05\n",
      "epoch: 1, loss: 5.497, avg: 3.74, latest lr: 3.142857142857143e-05\n",
      "epoch: 1, loss: 4.906, avg: 3.74, latest lr: 3.141428571428572e-05\n",
      "epoch: 1, loss: 4.784, avg: 3.74, latest lr: 3.1400000000000004e-05\n",
      "epoch: 1, loss: 4.439, avg: 3.74, latest lr: 3.138571428571429e-05\n",
      "epoch: 1, loss: 6.129, avg: 3.74, latest lr: 3.137142857142857e-05\n",
      "epoch: 1, loss: 4.428, avg: 3.74, latest lr: 3.1357142857142855e-05\n",
      "epoch: 1, loss: 4.853, avg: 3.74, latest lr: 3.1342857142857145e-05\n",
      "epoch: 1, loss: 3.206, avg: 3.74, latest lr: 3.132857142857143e-05\n",
      "epoch: 1, loss: 4.118, avg: 3.74, latest lr: 3.131428571428572e-05\n",
      "epoch: 1, loss: 4.086, avg: 3.74, latest lr: 3.13e-05\n",
      "epoch: 1, loss: 4.227, avg: 3.74, latest lr: 3.1285714285714285e-05\n",
      "epoch: 1, loss: 4.888, avg: 3.74, latest lr: 3.1271428571428576e-05\n",
      "epoch: 1, loss: 5.686, avg: 3.74, latest lr: 3.125714285714286e-05\n",
      "epoch: 1, loss: 6.178, avg: 3.74, latest lr: 3.124285714285715e-05\n",
      "epoch: 1, loss: 4.241, avg: 3.74, latest lr: 3.122857142857143e-05\n",
      "epoch: 1, loss: 5.014, avg: 3.75, latest lr: 3.1214285714285716e-05\n",
      "epoch: 1, loss: 4.854, avg: 3.75, latest lr: 3.12e-05\n",
      "epoch: 1, loss: 5.579, avg: 3.75, latest lr: 3.118571428571428e-05\n",
      "epoch: 1, loss: 5.623, avg: 3.75, latest lr: 3.117142857142857e-05\n",
      "epoch: 1, loss: 3.503, avg: 3.75, latest lr: 3.1157142857142857e-05\n",
      "epoch: 1, loss: 4.857, avg: 3.75, latest lr: 3.114285714285715e-05\n",
      "epoch: 1, loss: 4.510, avg: 3.75, latest lr: 3.112857142857143e-05\n",
      "epoch: 1, loss: 4.538, avg: 3.75, latest lr: 3.111428571428572e-05\n",
      "epoch: 1, loss: 5.753, avg: 3.75, latest lr: 3.1100000000000004e-05\n",
      "epoch: 1, loss: 5.795, avg: 3.75, latest lr: 3.108571428571429e-05\n",
      "epoch: 1, loss: 5.536, avg: 3.75, latest lr: 3.107142857142857e-05\n",
      "epoch: 1, loss: 3.531, avg: 3.75, latest lr: 3.1057142857142854e-05\n",
      "epoch: 1, loss: 3.978, avg: 3.75, latest lr: 3.1042857142857144e-05\n",
      "epoch: 1, loss: 3.435, avg: 3.75, latest lr: 3.102857142857143e-05\n",
      "epoch: 1, loss: 3.697, avg: 3.75, latest lr: 3.101428571428572e-05\n",
      "epoch: 1, loss: 4.356, avg: 3.76, latest lr: 3.1e-05\n",
      "epoch: 1, loss: 4.882, avg: 3.76, latest lr: 3.0985714285714285e-05\n",
      "epoch: 1, loss: 5.554, avg: 3.76, latest lr: 3.0971428571428575e-05\n",
      "epoch: 1, loss: 4.881, avg: 3.76, latest lr: 3.095714285714286e-05\n",
      "epoch: 1, loss: 4.036, avg: 3.76, latest lr: 3.094285714285715e-05\n",
      "epoch: 1, loss: 5.522, avg: 3.76, latest lr: 3.092857142857143e-05\n",
      "epoch: 1, loss: 5.372, avg: 3.76, latest lr: 3.0914285714285715e-05\n",
      "epoch: 1, loss: 3.883, avg: 3.76, latest lr: 3.09e-05\n",
      "epoch: 1, loss: 4.577, avg: 3.76, latest lr: 3.088571428571428e-05\n",
      "epoch: 1, loss: 4.635, avg: 3.76, latest lr: 3.087142857142857e-05\n",
      "epoch: 1, loss: 4.167, avg: 3.76, latest lr: 3.0857142857142856e-05\n",
      "epoch: 1, loss: 4.850, avg: 3.76, latest lr: 3.0842857142857146e-05\n",
      "epoch: 1, loss: 4.470, avg: 3.76, latest lr: 3.082857142857143e-05\n",
      "epoch: 1, loss: 5.463, avg: 3.76, latest lr: 3.081428571428572e-05\n",
      "epoch: 1, loss: 4.166, avg: 3.76, latest lr: 3.08e-05\n",
      "epoch: 1, loss: 3.625, avg: 3.77, latest lr: 3.078571428571429e-05\n",
      "epoch: 1, loss: 3.770, avg: 3.77, latest lr: 3.077142857142857e-05\n",
      "epoch: 1, loss: 3.927, avg: 3.77, latest lr: 3.0757142857142854e-05\n",
      "epoch: 1, loss: 5.459, avg: 3.77, latest lr: 3.0742857142857144e-05\n",
      "epoch: 1, loss: 4.763, avg: 3.77, latest lr: 3.072857142857143e-05\n",
      "epoch: 1, loss: 4.121, avg: 3.77, latest lr: 3.071428571428572e-05\n",
      "epoch: 1, loss: 3.479, avg: 3.77, latest lr: 3.07e-05\n",
      "epoch: 1, loss: 3.857, avg: 3.77, latest lr: 3.068571428571429e-05\n",
      "epoch: 1, loss: 4.440, avg: 3.77, latest lr: 3.0671428571428574e-05\n",
      "epoch: 1, loss: 5.859, avg: 3.77, latest lr: 3.065714285714286e-05\n",
      "epoch: 1, loss: 5.622, avg: 3.77, latest lr: 3.064285714285715e-05\n",
      "epoch: 1, loss: 3.304, avg: 3.77, latest lr: 3.062857142857143e-05\n",
      "epoch: 1, loss: 4.701, avg: 3.77, latest lr: 3.0614285714285715e-05\n",
      "epoch: 1, loss: 3.591, avg: 3.77, latest lr: 3.06e-05\n",
      "epoch: 1, loss: 4.019, avg: 3.77, latest lr: 3.058571428571429e-05\n",
      "epoch: 1, loss: 4.178, avg: 3.77, latest lr: 3.057142857142857e-05\n",
      "epoch: 1, loss: 5.149, avg: 3.78, latest lr: 3.0557142857142855e-05\n",
      "epoch: 1, loss: 4.404, avg: 3.78, latest lr: 3.0542857142857146e-05\n",
      "epoch: 1, loss: 3.563, avg: 3.78, latest lr: 3.052857142857143e-05\n",
      "epoch: 1, loss: 4.869, avg: 3.78, latest lr: 3.0514285714285716e-05\n",
      "epoch: 1, loss: 4.164, avg: 3.78, latest lr: 3.05e-05\n",
      "epoch: 1, loss: 4.164, avg: 3.78, latest lr: 3.048571428571429e-05\n",
      "epoch: 1, loss: 3.505, avg: 3.78, latest lr: 3.0471428571428573e-05\n",
      "epoch: 1, loss: 4.564, avg: 3.78, latest lr: 3.0457142857142856e-05\n",
      "epoch: 1, loss: 5.136, avg: 3.78, latest lr: 3.0442857142857147e-05\n",
      "epoch: 1, loss: 4.888, avg: 3.78, latest lr: 3.042857142857143e-05\n",
      "epoch: 1, loss: 3.687, avg: 3.78, latest lr: 3.0414285714285717e-05\n",
      "epoch: 1, loss: 5.197, avg: 3.78, latest lr: 3.04e-05\n",
      "epoch: 1, loss: 4.457, avg: 3.78, latest lr: 3.038571428571429e-05\n",
      "epoch: 1, loss: 4.906, avg: 3.78, latest lr: 3.0371428571428574e-05\n",
      "epoch: 1, loss: 5.225, avg: 3.78, latest lr: 3.0357142857142857e-05\n",
      "epoch: 1, loss: 4.381, avg: 3.78, latest lr: 3.0342857142857144e-05\n",
      "epoch: 1, loss: 4.524, avg: 3.79, latest lr: 3.0328571428571428e-05\n",
      "epoch: 1, loss: 4.320, avg: 3.79, latest lr: 3.0314285714285718e-05\n",
      "epoch: 1, loss: 3.500, avg: 3.79, latest lr: 3.03e-05\n",
      "epoch: 1, loss: 5.090, avg: 3.79, latest lr: 3.0285714285714288e-05\n",
      "epoch: 1, loss: 5.012, avg: 3.79, latest lr: 3.027142857142857e-05\n",
      "epoch: 1, loss: 4.446, avg: 3.79, latest lr: 3.0257142857142855e-05\n",
      "epoch: 1, loss: 4.043, avg: 3.79, latest lr: 3.0242857142857145e-05\n",
      "epoch: 1, loss: 4.517, avg: 3.79, latest lr: 3.022857142857143e-05\n",
      "epoch: 1, loss: 4.660, avg: 3.79, latest lr: 3.021428571428572e-05\n",
      "epoch: 1, loss: 3.399, avg: 3.79, latest lr: 3.02e-05\n",
      "epoch: 1, loss: 5.468, avg: 3.79, latest lr: 3.018571428571429e-05\n",
      "epoch: 1, loss: 4.058, avg: 3.79, latest lr: 3.0171428571428572e-05\n",
      "epoch: 1, loss: 4.569, avg: 3.79, latest lr: 3.0157142857142856e-05\n",
      "epoch: 1, loss: 5.281, avg: 3.79, latest lr: 3.0142857142857146e-05\n",
      "epoch: 1, loss: 5.073, avg: 3.79, latest lr: 3.012857142857143e-05\n",
      "epoch: 1, loss: 3.834, avg: 3.80, latest lr: 3.0114285714285716e-05\n",
      "epoch: 1, loss: 3.852, avg: 3.80, latest lr: 3.01e-05\n",
      "epoch: 1, loss: 3.801, avg: 3.80, latest lr: 3.008571428571429e-05\n",
      "epoch: 1, loss: 4.690, avg: 3.80, latest lr: 3.0071428571428573e-05\n",
      "epoch: 1, loss: 4.022, avg: 3.80, latest lr: 3.0057142857142857e-05\n",
      "epoch: 1, loss: 3.749, avg: 3.80, latest lr: 3.0042857142857144e-05\n",
      "epoch: 1, loss: 3.648, avg: 3.80, latest lr: 3.0028571428571427e-05\n",
      "epoch: 1, loss: 4.431, avg: 3.80, latest lr: 3.0014285714285717e-05\n",
      "epoch: 1, loss: 4.581, avg: 3.80, latest lr: 3e-05\n",
      "epoch: 1, loss: 4.351, avg: 3.80, latest lr: 2.9985714285714288e-05\n",
      "epoch: 1, loss: 4.135, avg: 3.80, latest lr: 2.997142857142857e-05\n",
      "epoch: 1, loss: 4.037, avg: 3.80, latest lr: 2.9957142857142854e-05\n",
      "epoch: 1, loss: 4.962, avg: 3.80, latest lr: 2.9942857142857145e-05\n",
      "epoch: 1, loss: 4.339, avg: 3.80, latest lr: 2.9928571428571428e-05\n",
      "epoch: 1, loss: 5.704, avg: 3.80, latest lr: 2.9914285714285718e-05\n",
      "epoch: 1, loss: 4.964, avg: 3.80, latest lr: 2.9900000000000002e-05\n",
      "epoch: 1, loss: 5.005, avg: 3.81, latest lr: 2.988571428571429e-05\n",
      "epoch: 1, loss: 5.948, avg: 3.81, latest lr: 2.9871428571428572e-05\n",
      "epoch: 1, loss: 4.265, avg: 3.81, latest lr: 2.9857142857142862e-05\n",
      "epoch: 1, loss: 4.682, avg: 3.81, latest lr: 2.9842857142857146e-05\n",
      "epoch: 1, loss: 4.407, avg: 3.81, latest lr: 2.982857142857143e-05\n",
      "epoch: 1, loss: 3.689, avg: 3.81, latest lr: 2.9814285714285716e-05\n",
      "epoch: 1, loss: 4.871, avg: 3.81, latest lr: 2.98e-05\n",
      "epoch: 1, loss: 3.957, avg: 3.81, latest lr: 2.978571428571429e-05\n",
      "epoch: 1, loss: 6.115, avg: 3.81, latest lr: 2.9771428571428573e-05\n",
      "epoch: 1, loss: 4.802, avg: 3.81, latest lr: 2.975714285714286e-05\n",
      "epoch: 1, loss: 3.640, avg: 3.81, latest lr: 2.9742857142857143e-05\n",
      "epoch: 1, loss: 4.561, avg: 3.81, latest lr: 2.9728571428571427e-05\n",
      "epoch: 1, loss: 3.626, avg: 3.81, latest lr: 2.9714285714285717e-05\n",
      "epoch: 1, loss: 3.403, avg: 3.81, latest lr: 2.97e-05\n",
      "epoch: 1, loss: 3.612, avg: 3.81, latest lr: 2.968571428571429e-05\n",
      "epoch: 1, loss: 4.120, avg: 3.81, latest lr: 2.9671428571428574e-05\n",
      "epoch: 1, loss: 5.571, avg: 3.82, latest lr: 2.965714285714286e-05\n",
      "epoch: 1, loss: 4.950, avg: 3.82, latest lr: 2.9642857142857144e-05\n",
      "epoch: 1, loss: 4.276, avg: 3.82, latest lr: 2.9628571428571428e-05\n",
      "epoch: 1, loss: 4.751, avg: 3.82, latest lr: 2.9614285714285718e-05\n",
      "epoch: 1, loss: 4.544, avg: 3.82, latest lr: 2.96e-05\n",
      "epoch: 1, loss: 4.771, avg: 3.82, latest lr: 2.9585714285714288e-05\n",
      "epoch: 1, loss: 4.230, avg: 3.82, latest lr: 2.957142857142857e-05\n",
      "epoch: 1, loss: 4.681, avg: 3.82, latest lr: 2.955714285714286e-05\n",
      "epoch: 1, loss: 3.303, avg: 3.82, latest lr: 2.9542857142857145e-05\n",
      "epoch: 1, loss: 3.735, avg: 3.82, latest lr: 2.952857142857143e-05\n",
      "epoch: 1, loss: 5.248, avg: 3.82, latest lr: 2.9514285714285715e-05\n",
      "epoch: 1, loss: 4.597, avg: 3.82, latest lr: 2.95e-05\n",
      "epoch: 1, loss: 4.595, avg: 3.82, latest lr: 2.948571428571429e-05\n",
      "epoch: 1, loss: 4.624, avg: 3.82, latest lr: 2.9471428571428572e-05\n",
      "epoch: 1, loss: 5.689, avg: 3.82, latest lr: 2.9457142857142863e-05\n",
      "epoch: 1, loss: 5.663, avg: 3.83, latest lr: 2.9442857142857143e-05\n",
      "epoch: 1, loss: 3.852, avg: 3.83, latest lr: 2.9428571428571426e-05\n",
      "epoch: 1, loss: 5.147, avg: 3.83, latest lr: 2.9414285714285716e-05\n",
      "epoch: 1, loss: 4.646, avg: 3.83, latest lr: 2.94e-05\n",
      "epoch: 1, loss: 4.693, avg: 3.83, latest lr: 2.938571428571429e-05\n",
      "epoch: 1, loss: 5.929, avg: 3.83, latest lr: 2.9371428571428573e-05\n",
      "epoch: 1, loss: 3.419, avg: 3.83, latest lr: 2.935714285714286e-05\n",
      "epoch: 1, loss: 6.494, avg: 3.83, latest lr: 2.9342857142857144e-05\n",
      "epoch: 1, loss: 3.562, avg: 3.83, latest lr: 2.9328571428571427e-05\n",
      "epoch: 1, loss: 3.728, avg: 3.83, latest lr: 2.9314285714285717e-05\n",
      "epoch: 1, loss: 3.586, avg: 3.83, latest lr: 2.93e-05\n",
      "epoch: 1, loss: 6.514, avg: 3.83, latest lr: 2.9285714285714288e-05\n",
      "epoch: 1, loss: 3.758, avg: 3.83, latest lr: 2.927142857142857e-05\n",
      "epoch: 1, loss: 6.276, avg: 3.83, latest lr: 2.925714285714286e-05\n",
      "epoch: 1, loss: 4.444, avg: 3.83, latest lr: 2.9242857142857145e-05\n",
      "epoch: 1, loss: 4.194, avg: 3.84, latest lr: 2.9228571428571428e-05\n",
      "epoch: 1, loss: 5.533, avg: 3.84, latest lr: 2.9214285714285715e-05\n",
      "epoch: 1, loss: 4.362, avg: 3.84, latest lr: 2.9199999999999998e-05\n",
      "epoch: 1, loss: 3.818, avg: 3.84, latest lr: 2.918571428571429e-05\n",
      "epoch: 1, loss: 4.505, avg: 3.84, latest lr: 2.9171428571428572e-05\n",
      "epoch: 1, loss: 5.419, avg: 3.84, latest lr: 2.9157142857142862e-05\n",
      "epoch: 1, loss: 3.148, avg: 3.84, latest lr: 2.9142857142857146e-05\n",
      "epoch: 1, loss: 4.481, avg: 3.84, latest lr: 2.912857142857143e-05\n",
      "epoch: 1, loss: 4.814, avg: 3.84, latest lr: 2.9114285714285716e-05\n",
      "epoch: 1, loss: 4.185, avg: 3.84, latest lr: 2.91e-05\n",
      "epoch: 1, loss: 4.216, avg: 3.84, latest lr: 2.908571428571429e-05\n",
      "epoch: 1, loss: 4.282, avg: 3.84, latest lr: 2.9071428571428573e-05\n",
      "epoch: 1, loss: 4.403, avg: 3.84, latest lr: 2.905714285714286e-05\n",
      "epoch: 1, loss: 4.663, avg: 3.84, latest lr: 2.9042857142857143e-05\n",
      "epoch: 1, loss: 3.794, avg: 3.84, latest lr: 2.9028571428571427e-05\n",
      "epoch: 1, loss: 4.552, avg: 3.84, latest lr: 2.9014285714285717e-05\n",
      "epoch: 1, loss: 2.992, avg: 3.85, latest lr: 2.9e-05\n",
      "epoch: 1, loss: 5.333, avg: 3.85, latest lr: 2.8985714285714287e-05\n",
      "epoch: 1, loss: 4.051, avg: 3.85, latest lr: 2.897142857142857e-05\n",
      "epoch: 1, loss: 5.421, avg: 3.85, latest lr: 2.895714285714286e-05\n",
      "epoch: 1, loss: 4.661, avg: 3.85, latest lr: 2.8942857142857144e-05\n",
      "epoch: 1, loss: 5.874, avg: 3.85, latest lr: 2.8928571428571434e-05\n",
      "epoch: 1, loss: 4.935, avg: 3.85, latest lr: 2.8914285714285714e-05\n",
      "epoch: 1, loss: 5.774, avg: 3.85, latest lr: 2.8899999999999998e-05\n",
      "epoch: 1, loss: 4.102, avg: 3.85, latest lr: 2.8885714285714288e-05\n",
      "epoch: 1, loss: 4.537, avg: 3.85, latest lr: 2.887142857142857e-05\n",
      "epoch: 1, loss: 4.052, avg: 3.85, latest lr: 2.885714285714286e-05\n",
      "epoch: 1, loss: 4.229, avg: 3.85, latest lr: 2.8842857142857145e-05\n",
      "epoch: 1, loss: 4.600, avg: 3.85, latest lr: 2.8828571428571432e-05\n",
      "epoch: 1, loss: 4.898, avg: 3.85, latest lr: 2.8814285714285715e-05\n",
      "epoch: 1, loss: 4.582, avg: 3.85, latest lr: 2.88e-05\n",
      "epoch: 1, loss: 4.239, avg: 3.86, latest lr: 2.878571428571429e-05\n",
      "epoch: 1, loss: 3.639, avg: 3.86, latest lr: 2.8771428571428572e-05\n",
      "epoch: 1, loss: 4.995, avg: 3.86, latest lr: 2.875714285714286e-05\n",
      "epoch: 1, loss: 5.540, avg: 3.86, latest lr: 2.8742857142857143e-05\n",
      "epoch: 1, loss: 5.052, avg: 3.86, latest lr: 2.8728571428571433e-05\n",
      "epoch: 1, loss: 5.228, avg: 3.86, latest lr: 2.8714285714285716e-05\n",
      "epoch: 1, loss: 5.345, avg: 3.86, latest lr: 2.87e-05\n",
      "epoch: 1, loss: 3.468, avg: 3.86, latest lr: 2.8685714285714286e-05\n",
      "epoch: 1, loss: 4.225, avg: 3.86, latest lr: 2.867142857142857e-05\n",
      "epoch: 1, loss: 4.005, avg: 3.86, latest lr: 2.865714285714286e-05\n",
      "epoch: 1, loss: 5.411, avg: 3.86, latest lr: 2.8642857142857144e-05\n",
      "epoch: 1, loss: 5.077, avg: 3.86, latest lr: 2.8628571428571434e-05\n",
      "epoch: 1, loss: 5.326, avg: 3.86, latest lr: 2.8614285714285717e-05\n",
      "epoch: 1, loss: 3.371, avg: 3.86, latest lr: 2.86e-05\n",
      "epoch: 1, loss: 4.378, avg: 3.86, latest lr: 2.8585714285714287e-05\n",
      "epoch: 1, loss: 5.496, avg: 3.87, latest lr: 2.857142857142857e-05\n",
      "epoch: 1, loss: 4.460, avg: 3.87, latest lr: 2.855714285714286e-05\n",
      "epoch: 1, loss: 4.868, avg: 3.87, latest lr: 2.8542857142857144e-05\n",
      "epoch: 1, loss: 4.902, avg: 3.87, latest lr: 2.852857142857143e-05\n",
      "epoch: 1, loss: 4.544, avg: 3.87, latest lr: 2.8514285714285715e-05\n",
      "epoch: 1, loss: 4.989, avg: 3.87, latest lr: 2.8499999999999998e-05\n",
      "epoch: 1, loss: 4.486, avg: 3.87, latest lr: 2.848571428571429e-05\n",
      "epoch: 1, loss: 3.727, avg: 3.87, latest lr: 2.8471428571428572e-05\n",
      "epoch: 1, loss: 5.019, avg: 3.87, latest lr: 2.845714285714286e-05\n",
      "epoch: 1, loss: 6.262, avg: 3.87, latest lr: 2.8442857142857142e-05\n",
      "epoch: 1, loss: 4.396, avg: 3.87, latest lr: 2.8428571428571432e-05\n",
      "epoch: 1, loss: 4.501, avg: 3.87, latest lr: 2.8414285714285716e-05\n",
      "epoch: 1, loss: 4.433, avg: 3.87, latest lr: 2.84e-05\n",
      "epoch: 1, loss: 5.295, avg: 3.87, latest lr: 2.838571428571429e-05\n",
      "epoch: 1, loss: 3.658, avg: 3.87, latest lr: 2.837142857142857e-05\n",
      "epoch: 1, loss: 5.664, avg: 3.88, latest lr: 2.835714285714286e-05\n",
      "epoch: 1, loss: 5.149, avg: 3.88, latest lr: 2.8342857142857143e-05\n",
      "epoch: 1, loss: 7.134, avg: 3.88, latest lr: 2.8328571428571433e-05\n",
      "epoch: 1, loss: 3.905, avg: 3.88, latest lr: 2.8314285714285717e-05\n",
      "epoch: 1, loss: 5.248, avg: 3.88, latest lr: 2.83e-05\n",
      "epoch: 1, loss: 4.639, avg: 3.88, latest lr: 2.8285714285714287e-05\n",
      "epoch: 1, loss: 5.779, avg: 3.88, latest lr: 2.827142857142857e-05\n",
      "epoch: 1, loss: 3.697, avg: 3.88, latest lr: 2.825714285714286e-05\n",
      "epoch: 1, loss: 3.950, avg: 3.88, latest lr: 2.8242857142857144e-05\n",
      "epoch: 1, loss: 5.273, avg: 3.88, latest lr: 2.822857142857143e-05\n",
      "epoch: 1, loss: 4.958, avg: 3.88, latest lr: 2.8214285714285714e-05\n",
      "epoch: 1, loss: 4.746, avg: 3.88, latest lr: 2.8199999999999998e-05\n",
      "epoch: 1, loss: 4.565, avg: 3.88, latest lr: 2.8185714285714288e-05\n",
      "epoch: 1, loss: 3.962, avg: 3.88, latest lr: 2.817142857142857e-05\n",
      "epoch: 1, loss: 3.320, avg: 3.89, latest lr: 2.8157142857142858e-05\n",
      "epoch: 1, loss: 5.155, avg: 3.89, latest lr: 2.814285714285714e-05\n",
      "epoch: 1, loss: 3.480, avg: 3.89, latest lr: 2.8128571428571432e-05\n",
      "epoch: 1, loss: 5.382, avg: 3.89, latest lr: 2.8114285714285715e-05\n",
      "epoch: 1, loss: 4.353, avg: 3.89, latest lr: 2.8100000000000005e-05\n",
      "epoch: 1, loss: 5.922, avg: 3.89, latest lr: 2.808571428571429e-05\n",
      "epoch: 1, loss: 4.833, avg: 3.89, latest lr: 2.8071428571428572e-05\n",
      "epoch: 1, loss: 4.952, avg: 3.89, latest lr: 2.805714285714286e-05\n",
      "epoch: 1, loss: 4.913, avg: 3.89, latest lr: 2.8042857142857143e-05\n",
      "epoch: 1, loss: 4.116, avg: 3.89, latest lr: 2.8028571428571433e-05\n",
      "epoch: 1, loss: 4.590, avg: 3.89, latest lr: 2.8014285714285716e-05\n",
      "epoch: 1, loss: 4.197, avg: 3.89, latest lr: 2.8000000000000003e-05\n",
      "epoch: 1, loss: 4.914, avg: 3.89, latest lr: 2.7985714285714286e-05\n",
      "epoch: 1, loss: 4.568, avg: 3.89, latest lr: 2.797142857142857e-05\n",
      "epoch: 1, loss: 3.944, avg: 3.89, latest lr: 2.795714285714286e-05\n",
      "epoch: 1, loss: 4.065, avg: 3.90, latest lr: 2.7942857142857143e-05\n",
      "epoch: 1, loss: 4.021, avg: 3.90, latest lr: 2.792857142857143e-05\n",
      "epoch: 1, loss: 3.759, avg: 3.90, latest lr: 2.7914285714285714e-05\n",
      "epoch: 1, loss: 5.702, avg: 3.90, latest lr: 2.7900000000000004e-05\n",
      "epoch: 1, loss: 5.104, avg: 3.90, latest lr: 2.7885714285714287e-05\n",
      "epoch: 1, loss: 5.387, avg: 3.90, latest lr: 2.787142857142857e-05\n",
      "epoch: 1, loss: 3.128, avg: 3.90, latest lr: 2.785714285714286e-05\n",
      "epoch: 1, loss: 5.550, avg: 3.90, latest lr: 2.7842857142857144e-05\n",
      "epoch: 1, loss: 4.456, avg: 3.90, latest lr: 2.782857142857143e-05\n",
      "epoch: 1, loss: 4.318, avg: 3.90, latest lr: 2.7814285714285715e-05\n",
      "epoch: 1, loss: 6.133, avg: 3.90, latest lr: 2.7800000000000005e-05\n",
      "epoch: 1, loss: 4.679, avg: 3.90, latest lr: 2.778571428571429e-05\n",
      "epoch: 1, loss: 3.744, avg: 3.90, latest lr: 2.7771428571428572e-05\n",
      "epoch: 1, loss: 4.681, avg: 3.90, latest lr: 2.775714285714286e-05\n",
      "epoch: 1, loss: 6.349, avg: 3.90, latest lr: 2.7742857142857142e-05\n",
      "epoch: 1, loss: 4.389, avg: 3.91, latest lr: 2.7728571428571432e-05\n",
      "epoch: 1, loss: 4.696, avg: 3.91, latest lr: 2.7714285714285716e-05\n",
      "epoch: 1, loss: 3.274, avg: 3.91, latest lr: 2.7700000000000002e-05\n",
      "epoch: 1, loss: 5.970, avg: 3.91, latest lr: 2.7685714285714286e-05\n",
      "epoch: 1, loss: 4.126, avg: 3.91, latest lr: 2.767142857142857e-05\n",
      "epoch: 1, loss: 4.738, avg: 3.91, latest lr: 2.765714285714286e-05\n",
      "epoch: 1, loss: 4.806, avg: 3.91, latest lr: 2.7642857142857143e-05\n",
      "epoch: 1, loss: 3.610, avg: 3.91, latest lr: 2.762857142857143e-05\n",
      "epoch: 1, loss: 6.269, avg: 3.91, latest lr: 2.7614285714285713e-05\n",
      "epoch: 1, loss: 4.493, avg: 3.91, latest lr: 2.7600000000000003e-05\n",
      "epoch: 1, loss: 4.723, avg: 3.91, latest lr: 2.7585714285714287e-05\n",
      "epoch: 1, loss: 4.591, avg: 3.91, latest lr: 2.757142857142857e-05\n",
      "epoch: 1, loss: 4.435, avg: 3.91, latest lr: 2.755714285714286e-05\n",
      "epoch: 1, loss: 5.089, avg: 3.91, latest lr: 2.7542857142857144e-05\n",
      "epoch: 1, loss: 3.662, avg: 3.91, latest lr: 2.752857142857143e-05\n",
      "epoch: 1, loss: 4.427, avg: 3.92, latest lr: 2.7514285714285714e-05\n",
      "epoch: 1, loss: 4.191, avg: 3.92, latest lr: 2.7500000000000004e-05\n",
      "epoch: 1, loss: 4.837, avg: 3.92, latest lr: 2.7485714285714288e-05\n",
      "epoch: 1, loss: 5.491, avg: 3.92, latest lr: 2.747142857142857e-05\n",
      "epoch: 1, loss: 5.206, avg: 3.92, latest lr: 2.7457142857142858e-05\n",
      "epoch: 1, loss: 5.703, avg: 3.92, latest lr: 2.744285714285714e-05\n",
      "epoch: 1, loss: 5.833, avg: 3.92, latest lr: 2.742857142857143e-05\n",
      "epoch: 1, loss: 4.041, avg: 3.92, latest lr: 2.7414285714285715e-05\n",
      "epoch: 1, loss: 4.618, avg: 3.92, latest lr: 2.7400000000000002e-05\n",
      "epoch: 1, loss: 4.642, avg: 3.92, latest lr: 2.7385714285714285e-05\n",
      "epoch: 1, loss: 5.295, avg: 3.92, latest lr: 2.737142857142857e-05\n",
      "epoch: 1, loss: 4.416, avg: 3.92, latest lr: 2.735714285714286e-05\n",
      "epoch: 1, loss: 4.924, avg: 3.92, latest lr: 2.7342857142857142e-05\n",
      "epoch: 1, loss: 4.723, avg: 3.92, latest lr: 2.7328571428571433e-05\n",
      "epoch: 1, loss: 4.464, avg: 3.92, latest lr: 2.7314285714285716e-05\n",
      "epoch: 1, loss: 5.682, avg: 3.93, latest lr: 2.7300000000000003e-05\n",
      "epoch: 1, loss: 4.909, avg: 3.93, latest lr: 2.7285714285714286e-05\n",
      "epoch: 1, loss: 5.258, avg: 3.93, latest lr: 2.727142857142857e-05\n",
      "epoch: 1, loss: 4.421, avg: 3.93, latest lr: 2.725714285714286e-05\n",
      "epoch: 1, loss: 3.898, avg: 3.93, latest lr: 2.7242857142857143e-05\n",
      "epoch: 1, loss: 3.214, avg: 3.93, latest lr: 2.722857142857143e-05\n",
      "epoch: 1, loss: 3.468, avg: 3.93, latest lr: 2.7214285714285714e-05\n",
      "epoch: 1, loss: 5.350, avg: 3.93, latest lr: 2.7200000000000004e-05\n",
      "epoch: 1, loss: 3.723, avg: 3.93, latest lr: 2.7185714285714287e-05\n",
      "epoch: 1, loss: 4.570, avg: 3.93, latest lr: 2.7171428571428574e-05\n",
      "epoch: 1, loss: 4.333, avg: 3.93, latest lr: 2.7157142857142858e-05\n",
      "epoch: 1, loss: 5.017, avg: 3.93, latest lr: 2.714285714285714e-05\n",
      "epoch: 1, loss: 4.173, avg: 3.93, latest lr: 2.712857142857143e-05\n",
      "epoch: 1, loss: 4.938, avg: 3.93, latest lr: 2.7114285714285715e-05\n",
      "epoch: 1, loss: 4.398, avg: 3.93, latest lr: 2.7100000000000005e-05\n",
      "epoch: 1, loss: 5.983, avg: 3.94, latest lr: 2.7085714285714285e-05\n",
      "epoch: 1, loss: 5.174, avg: 3.94, latest lr: 2.7071428571428575e-05\n",
      "epoch: 1, loss: 5.232, avg: 3.94, latest lr: 2.705714285714286e-05\n",
      "epoch: 1, loss: 4.368, avg: 3.94, latest lr: 2.7042857142857142e-05\n",
      "epoch: 1, loss: 5.559, avg: 3.94, latest lr: 2.7028571428571432e-05\n",
      "epoch: 1, loss: 2.871, avg: 3.94, latest lr: 2.7014285714285716e-05\n",
      "epoch: 1, loss: 5.096, avg: 3.94, latest lr: 2.7000000000000002e-05\n",
      "epoch: 1, loss: 4.224, avg: 3.94, latest lr: 2.6985714285714286e-05\n",
      "epoch: 1, loss: 4.682, avg: 3.94, latest lr: 2.6971428571428576e-05\n",
      "epoch: 1, loss: 3.994, avg: 3.94, latest lr: 2.695714285714286e-05\n",
      "epoch: 1, loss: 5.046, avg: 3.94, latest lr: 2.6942857142857143e-05\n",
      "epoch: 1, loss: 5.100, avg: 3.94, latest lr: 2.692857142857143e-05\n",
      "epoch: 1, loss: 5.293, avg: 3.94, latest lr: 2.6914285714285713e-05\n",
      "epoch: 1, loss: 4.347, avg: 3.94, latest lr: 2.6900000000000003e-05\n",
      "epoch: 1, loss: 3.276, avg: 3.94, latest lr: 2.6885714285714287e-05\n",
      "epoch: 1, loss: 4.414, avg: 3.95, latest lr: 2.6871428571428574e-05\n",
      "epoch: 1, loss: 4.947, avg: 3.95, latest lr: 2.6857142857142857e-05\n",
      "epoch: 1, loss: 4.886, avg: 3.95, latest lr: 2.684285714285714e-05\n",
      "epoch: 1, loss: 6.665, avg: 3.95, latest lr: 2.682857142857143e-05\n",
      "epoch: 1, loss: 4.613, avg: 3.95, latest lr: 2.6814285714285714e-05\n",
      "epoch: 1, loss: 3.472, avg: 3.95, latest lr: 2.6800000000000004e-05\n",
      "epoch: 1, loss: 4.949, avg: 3.95, latest lr: 2.6785714285714288e-05\n",
      "epoch: 1, loss: 5.730, avg: 3.95, latest lr: 2.6771428571428575e-05\n",
      "epoch: 1, loss: 5.447, avg: 3.95, latest lr: 2.6757142857142858e-05\n",
      "epoch: 1, loss: 5.616, avg: 3.95, latest lr: 2.674285714285714e-05\n",
      "epoch: 1, loss: 4.219, avg: 3.95, latest lr: 2.672857142857143e-05\n",
      "epoch: 1, loss: 4.350, avg: 3.95, latest lr: 2.6714285714285715e-05\n",
      "epoch: 1, loss: 3.839, avg: 3.95, latest lr: 2.6700000000000002e-05\n",
      "epoch: 1, loss: 3.942, avg: 3.95, latest lr: 2.6685714285714285e-05\n",
      "epoch: 1, loss: 2.919, avg: 3.95, latest lr: 2.6671428571428576e-05\n",
      "epoch: 1, loss: 4.418, avg: 3.96, latest lr: 2.665714285714286e-05\n",
      "epoch: 1, loss: 4.134, avg: 3.96, latest lr: 2.6642857142857142e-05\n",
      "epoch: 1, loss: 3.735, avg: 3.96, latest lr: 2.662857142857143e-05\n",
      "epoch: 1, loss: 3.550, avg: 3.96, latest lr: 2.6614285714285713e-05\n",
      "epoch: 1, loss: 4.917, avg: 3.96, latest lr: 2.6600000000000003e-05\n",
      "epoch: 1, loss: 5.001, avg: 3.96, latest lr: 2.6585714285714286e-05\n",
      "epoch: 1, loss: 6.009, avg: 3.96, latest lr: 2.6571428571428576e-05\n",
      "epoch: 1, loss: 4.516, avg: 3.96, latest lr: 2.655714285714286e-05\n",
      "epoch: 1, loss: 3.941, avg: 3.96, latest lr: 2.654285714285714e-05\n",
      "epoch: 1, loss: 3.883, avg: 3.96, latest lr: 2.652857142857143e-05\n",
      "epoch: 1, loss: 4.068, avg: 3.96, latest lr: 2.6514285714285714e-05\n",
      "epoch: 1, loss: 5.035, avg: 3.96, latest lr: 2.6500000000000004e-05\n",
      "epoch: 1, loss: 3.716, avg: 3.96, latest lr: 2.6485714285714287e-05\n",
      "epoch: 1, loss: 4.099, avg: 3.96, latest lr: 2.6471428571428574e-05\n",
      "epoch: 1, loss: 4.689, avg: 3.96, latest lr: 2.6457142857142857e-05\n",
      "epoch: 1, loss: 3.794, avg: 3.96, latest lr: 2.644285714285714e-05\n",
      "epoch: 1, loss: 6.021, avg: 3.97, latest lr: 2.642857142857143e-05\n",
      "epoch: 1, loss: 3.234, avg: 3.97, latest lr: 2.6414285714285715e-05\n",
      "epoch: 1, loss: 3.968, avg: 3.97, latest lr: 2.64e-05\n",
      "epoch: 1, loss: 4.367, avg: 3.97, latest lr: 2.6385714285714285e-05\n",
      "epoch: 1, loss: 4.304, avg: 3.97, latest lr: 2.6371428571428575e-05\n",
      "epoch: 1, loss: 4.662, avg: 3.97, latest lr: 2.635714285714286e-05\n",
      "epoch: 1, loss: 3.836, avg: 3.97, latest lr: 2.6342857142857142e-05\n",
      "epoch: 1, loss: 3.644, avg: 3.97, latest lr: 2.632857142857143e-05\n",
      "epoch: 1, loss: 5.417, avg: 3.97, latest lr: 2.6314285714285712e-05\n",
      "epoch: 1, loss: 4.645, avg: 3.97, latest lr: 2.6300000000000002e-05\n",
      "epoch: 1, loss: 5.653, avg: 3.97, latest lr: 2.6285714285714286e-05\n",
      "epoch: 1, loss: 4.875, avg: 3.97, latest lr: 2.6271428571428576e-05\n",
      "epoch: 1, loss: 3.156, avg: 3.97, latest lr: 2.625714285714286e-05\n",
      "epoch: 1, loss: 4.235, avg: 3.97, latest lr: 2.6242857142857146e-05\n",
      "epoch: 1, loss: 4.576, avg: 3.97, latest lr: 2.622857142857143e-05\n",
      "epoch: 1, loss: 4.715, avg: 3.97, latest lr: 2.6214285714285713e-05\n",
      "epoch: 1, loss: 4.304, avg: 3.98, latest lr: 2.6200000000000003e-05\n",
      "epoch: 1, loss: 4.791, avg: 3.98, latest lr: 2.6185714285714287e-05\n",
      "epoch: 1, loss: 3.592, avg: 3.98, latest lr: 2.6171428571428574e-05\n",
      "epoch: 1, loss: 4.695, avg: 3.98, latest lr: 2.6157142857142857e-05\n",
      "epoch: 1, loss: 5.152, avg: 3.98, latest lr: 2.6142857142857147e-05\n",
      "epoch: 1, loss: 4.102, avg: 3.98, latest lr: 2.612857142857143e-05\n",
      "epoch: 1, loss: 3.965, avg: 3.98, latest lr: 2.6114285714285714e-05\n",
      "epoch: 1, loss: 4.670, avg: 3.98, latest lr: 2.61e-05\n",
      "epoch: 1, loss: 5.605, avg: 3.98, latest lr: 2.6085714285714284e-05\n",
      "epoch: 1, loss: 5.429, avg: 3.98, latest lr: 2.6071428571428574e-05\n",
      "epoch: 1, loss: 4.687, avg: 3.98, latest lr: 2.6057142857142858e-05\n",
      "epoch: 1, loss: 3.792, avg: 3.98, latest lr: 2.6042857142857148e-05\n",
      "epoch: 1, loss: 5.742, avg: 3.98, latest lr: 2.602857142857143e-05\n",
      "epoch: 1, loss: 4.467, avg: 3.98, latest lr: 2.601428571428571e-05\n",
      "epoch: 1, loss: 3.831, avg: 3.98, latest lr: 2.6000000000000002e-05\n",
      "epoch: 1, loss: 3.376, avg: 3.98, latest lr: 2.5985714285714285e-05\n",
      "epoch: 1, loss: 5.039, avg: 3.99, latest lr: 2.5971428571428575e-05\n",
      "epoch: 1, loss: 5.300, avg: 3.99, latest lr: 2.595714285714286e-05\n",
      "epoch: 1, loss: 5.140, avg: 3.99, latest lr: 2.5942857142857146e-05\n",
      "epoch: 1, loss: 4.108, avg: 3.99, latest lr: 2.592857142857143e-05\n",
      "epoch: 1, loss: 5.034, avg: 3.99, latest lr: 2.5914285714285713e-05\n",
      "epoch: 1, loss: 4.411, avg: 3.99, latest lr: 2.5900000000000003e-05\n",
      "epoch: 1, loss: 5.183, avg: 3.99, latest lr: 2.5885714285714286e-05\n",
      "epoch: 1, loss: 4.300, avg: 3.99, latest lr: 2.5871428571428573e-05\n",
      "epoch: 1, loss: 5.620, avg: 3.99, latest lr: 2.5857142857142856e-05\n",
      "epoch: 1, loss: 4.590, avg: 3.99, latest lr: 2.5842857142857147e-05\n",
      "epoch: 1, loss: 4.145, avg: 3.99, latest lr: 2.582857142857143e-05\n",
      "epoch: 1, loss: 4.636, avg: 3.99, latest lr: 2.5814285714285713e-05\n",
      "epoch: 1, loss: 4.260, avg: 3.99, latest lr: 2.58e-05\n",
      "epoch: 1, loss: 6.115, avg: 3.99, latest lr: 2.5785714285714284e-05\n",
      "epoch: 1, loss: 5.026, avg: 4.00, latest lr: 2.5771428571428574e-05\n",
      "epoch: 1, loss: 4.178, avg: 4.00, latest lr: 2.5757142857142857e-05\n",
      "epoch: 1, loss: 3.733, avg: 4.00, latest lr: 2.5742857142857148e-05\n",
      "epoch: 1, loss: 4.905, avg: 4.00, latest lr: 2.572857142857143e-05\n",
      "epoch: 1, loss: 5.242, avg: 4.00, latest lr: 2.5714285714285714e-05\n",
      "epoch: 1, loss: 3.381, avg: 4.00, latest lr: 2.57e-05\n",
      "epoch: 1, loss: 6.087, avg: 4.00, latest lr: 2.5685714285714285e-05\n",
      "epoch: 1, loss: 4.386, avg: 4.00, latest lr: 2.5671428571428575e-05\n",
      "epoch: 1, loss: 4.674, avg: 4.00, latest lr: 2.565714285714286e-05\n",
      "epoch: 1, loss: 2.927, avg: 4.00, latest lr: 2.5642857142857145e-05\n",
      "epoch: 1, loss: 4.694, avg: 4.00, latest lr: 2.562857142857143e-05\n",
      "epoch: 1, loss: 2.682, avg: 4.00, latest lr: 2.5614285714285712e-05\n",
      "epoch: 1, loss: 5.346, avg: 4.00, latest lr: 2.5600000000000002e-05\n",
      "epoch: 1, loss: 4.587, avg: 4.00, latest lr: 2.5585714285714286e-05\n",
      "epoch: 1, loss: 4.884, avg: 4.00, latest lr: 2.5571428571428572e-05\n",
      "epoch: 1, loss: 3.356, avg: 4.00, latest lr: 2.5557142857142856e-05\n",
      "epoch: 1, loss: 5.806, avg: 4.01, latest lr: 2.5542857142857146e-05\n",
      "epoch: 1, loss: 4.986, avg: 4.01, latest lr: 2.552857142857143e-05\n",
      "epoch: 1, loss: 4.602, avg: 4.01, latest lr: 2.5514285714285713e-05\n",
      "epoch: 1, loss: 3.295, avg: 4.01, latest lr: 2.5500000000000003e-05\n",
      "epoch: 1, loss: 5.007, avg: 4.01, latest lr: 2.5485714285714287e-05\n",
      "epoch: 1, loss: 5.162, avg: 4.01, latest lr: 2.5471428571428573e-05\n",
      "epoch: 1, loss: 4.060, avg: 4.01, latest lr: 2.5457142857142857e-05\n",
      "epoch: 1, loss: 4.353, avg: 4.01, latest lr: 2.5442857142857147e-05\n",
      "epoch: 1, loss: 3.967, avg: 4.01, latest lr: 2.542857142857143e-05\n",
      "epoch: 1, loss: 5.994, avg: 4.01, latest lr: 2.5414285714285717e-05\n",
      "epoch: 1, loss: 3.288, avg: 4.01, latest lr: 2.54e-05\n",
      "epoch: 1, loss: 4.291, avg: 4.01, latest lr: 2.5385714285714284e-05\n",
      "epoch: 1, loss: 3.355, avg: 4.01, latest lr: 2.5371428571428574e-05\n",
      "epoch: 1, loss: 4.779, avg: 4.01, latest lr: 2.5357142857142858e-05\n",
      "epoch: 1, loss: 3.327, avg: 4.01, latest lr: 2.5342857142857145e-05\n",
      "epoch: 1, loss: 5.489, avg: 4.01, latest lr: 2.5328571428571428e-05\n",
      "epoch: 1, loss: 3.996, avg: 4.02, latest lr: 2.5314285714285718e-05\n",
      "epoch: 1, loss: 4.740, avg: 4.02, latest lr: 2.5300000000000002e-05\n",
      "epoch: 1, loss: 5.172, avg: 4.02, latest lr: 2.5285714285714285e-05\n",
      "epoch: 1, loss: 6.828, avg: 4.02, latest lr: 2.5271428571428575e-05\n",
      "epoch: 1, loss: 4.983, avg: 4.02, latest lr: 2.5257142857142855e-05\n",
      "epoch: 1, loss: 4.395, avg: 4.02, latest lr: 2.5242857142857146e-05\n",
      "epoch: 1, loss: 5.843, avg: 4.02, latest lr: 2.522857142857143e-05\n",
      "epoch: 1, loss: 6.704, avg: 4.02, latest lr: 2.521428571428572e-05\n",
      "epoch: 1, loss: 4.722, avg: 4.02, latest lr: 2.5200000000000003e-05\n",
      "epoch: 1, loss: 5.883, avg: 4.02, latest lr: 2.5185714285714286e-05\n",
      "epoch: 1, loss: 3.556, avg: 4.02, latest lr: 2.5171428571428573e-05\n",
      "epoch: 1, loss: 6.057, avg: 4.02, latest lr: 2.5157142857142856e-05\n",
      "epoch: 1, loss: 4.860, avg: 4.02, latest lr: 2.5142857142857147e-05\n",
      "epoch: 1, loss: 5.163, avg: 4.03, latest lr: 2.512857142857143e-05\n",
      "epoch: 1, loss: 5.495, avg: 4.03, latest lr: 2.5114285714285717e-05\n",
      "epoch: 1, loss: 4.221, avg: 4.03, latest lr: 2.51e-05\n",
      "epoch: 1, loss: 3.931, avg: 4.03, latest lr: 2.5085714285714284e-05\n",
      "epoch: 1, loss: 5.464, avg: 4.03, latest lr: 2.5071428571428574e-05\n",
      "epoch: 1, loss: 6.135, avg: 4.03, latest lr: 2.5057142857142857e-05\n",
      "epoch: 1, loss: 3.302, avg: 4.03, latest lr: 2.5042857142857144e-05\n",
      "epoch: 1, loss: 4.748, avg: 4.03, latest lr: 2.5028571428571428e-05\n",
      "epoch: 1, loss: 5.090, avg: 4.03, latest lr: 2.5014285714285718e-05\n",
      "epoch: 1, loss: 4.100, avg: 4.03, latest lr: 2.5e-05\n",
      "epoch: 1, loss: 4.473, avg: 4.03, latest lr: 2.4985714285714288e-05\n",
      "epoch: 1, loss: 5.245, avg: 4.03, latest lr: 2.4971428571428575e-05\n",
      "epoch: 1, loss: 3.796, avg: 4.03, latest lr: 2.4957142857142858e-05\n",
      "epoch: 1, loss: 4.000, avg: 4.03, latest lr: 2.4942857142857142e-05\n",
      "epoch: 1, loss: 5.052, avg: 4.03, latest lr: 2.492857142857143e-05\n",
      "epoch: 1, loss: 4.500, avg: 4.04, latest lr: 2.4914285714285715e-05\n",
      "epoch: 1, loss: 5.188, avg: 4.04, latest lr: 2.4900000000000002e-05\n",
      "epoch: 1, loss: 4.840, avg: 4.04, latest lr: 2.4885714285714286e-05\n",
      "epoch: 1, loss: 3.488, avg: 4.04, latest lr: 2.4871428571428572e-05\n",
      "epoch: 1, loss: 3.857, avg: 4.04, latest lr: 2.485714285714286e-05\n",
      "epoch: 1, loss: 6.425, avg: 4.04, latest lr: 2.4842857142857143e-05\n",
      "epoch: 1, loss: 5.077, avg: 4.04, latest lr: 2.482857142857143e-05\n",
      "epoch: 1, loss: 5.232, avg: 4.04, latest lr: 2.4814285714285716e-05\n",
      "epoch: 1, loss: 4.210, avg: 4.04, latest lr: 2.48e-05\n",
      "epoch: 1, loss: 4.473, avg: 4.04, latest lr: 2.4785714285714287e-05\n",
      "epoch: 1, loss: 4.104, avg: 4.04, latest lr: 2.4771428571428573e-05\n",
      "epoch: 1, loss: 5.075, avg: 4.04, latest lr: 2.475714285714286e-05\n",
      "epoch: 1, loss: 4.661, avg: 4.04, latest lr: 2.4742857142857147e-05\n",
      "epoch: 1, loss: 4.687, avg: 4.04, latest lr: 2.4728571428571427e-05\n",
      "epoch: 1, loss: 3.890, avg: 4.04, latest lr: 2.4714285714285714e-05\n",
      "epoch: 1, loss: 4.470, avg: 4.05, latest lr: 2.47e-05\n",
      "epoch: 1, loss: 3.974, avg: 4.05, latest lr: 2.4685714285714288e-05\n",
      "epoch: 1, loss: 4.950, avg: 4.05, latest lr: 2.4671428571428574e-05\n",
      "epoch: 1, loss: 4.202, avg: 4.05, latest lr: 2.4657142857142858e-05\n",
      "epoch: 1, loss: 4.251, avg: 4.05, latest lr: 2.4642857142857145e-05\n",
      "epoch: 1, loss: 4.203, avg: 4.05, latest lr: 2.4628571428571428e-05\n",
      "epoch: 1, loss: 5.495, avg: 4.05, latest lr: 2.4614285714285715e-05\n",
      "epoch: 1, loss: 3.895, avg: 4.05, latest lr: 2.46e-05\n",
      "epoch: 1, loss: 5.207, avg: 4.05, latest lr: 2.458571428571429e-05\n",
      "epoch: 1, loss: 4.407, avg: 4.05, latest lr: 2.4571428571428572e-05\n",
      "epoch: 1, loss: 4.141, avg: 4.05, latest lr: 2.455714285714286e-05\n",
      "epoch: 1, loss: 5.410, avg: 4.05, latest lr: 2.4542857142857146e-05\n",
      "epoch: 1, loss: 5.867, avg: 4.05, latest lr: 2.452857142857143e-05\n",
      "epoch: 1, loss: 4.484, avg: 4.05, latest lr: 2.4514285714285716e-05\n",
      "epoch: 1, loss: 3.784, avg: 4.05, latest lr: 2.45e-05\n",
      "epoch: 1, loss: 3.073, avg: 4.05, latest lr: 2.4485714285714286e-05\n",
      "epoch: 1, loss: 5.264, avg: 4.06, latest lr: 2.4471428571428573e-05\n",
      "epoch: 1, loss: 4.506, avg: 4.06, latest lr: 2.445714285714286e-05\n",
      "epoch: 1, loss: 4.755, avg: 4.06, latest lr: 2.4442857142857146e-05\n",
      "epoch: 1, loss: 4.733, avg: 4.06, latest lr: 2.442857142857143e-05\n",
      "epoch: 1, loss: 5.101, avg: 4.06, latest lr: 2.4414285714285713e-05\n",
      "epoch: 1, loss: 5.461, avg: 4.06, latest lr: 2.44e-05\n",
      "epoch: 1, loss: 4.364, avg: 4.06, latest lr: 2.4385714285714287e-05\n",
      "epoch: 1, loss: 5.032, avg: 4.06, latest lr: 2.4371428571428574e-05\n",
      "epoch: 1, loss: 5.035, avg: 4.06, latest lr: 2.4357142857142857e-05\n",
      "epoch: 1, loss: 4.264, avg: 4.06, latest lr: 2.4342857142857144e-05\n",
      "epoch: 1, loss: 4.524, avg: 4.06, latest lr: 2.432857142857143e-05\n",
      "epoch: 1, loss: 5.269, avg: 4.06, latest lr: 2.4314285714285714e-05\n",
      "epoch: 1, loss: 5.339, avg: 4.06, latest lr: 2.43e-05\n",
      "epoch: 1, loss: 4.759, avg: 4.06, latest lr: 2.4285714285714288e-05\n",
      "epoch: 1, loss: 4.838, avg: 4.07, latest lr: 2.427142857142857e-05\n",
      "epoch: 1, loss: 4.180, avg: 4.07, latest lr: 2.4257142857142858e-05\n",
      "epoch: 1, loss: 3.569, avg: 4.07, latest lr: 2.4242857142857145e-05\n",
      "epoch: 1, loss: 4.083, avg: 4.07, latest lr: 2.4228571428571432e-05\n",
      "epoch: 1, loss: 4.044, avg: 4.07, latest lr: 2.4214285714285715e-05\n",
      "epoch: 1, loss: 3.795, avg: 4.07, latest lr: 2.4200000000000002e-05\n",
      "epoch: 1, loss: 4.611, avg: 4.07, latest lr: 2.4185714285714286e-05\n",
      "epoch: 1, loss: 3.771, avg: 4.07, latest lr: 2.4171428571428572e-05\n",
      "epoch: 1, loss: 5.535, avg: 4.07, latest lr: 2.415714285714286e-05\n",
      "epoch: 1, loss: 4.605, avg: 4.07, latest lr: 2.4142857142857146e-05\n",
      "epoch: 1, loss: 3.986, avg: 4.07, latest lr: 2.412857142857143e-05\n",
      "epoch: 1, loss: 3.497, avg: 4.07, latest lr: 2.4114285714285713e-05\n",
      "epoch: 1, loss: 3.967, avg: 4.07, latest lr: 2.41e-05\n",
      "epoch: 1, loss: 4.873, avg: 4.07, latest lr: 2.4085714285714286e-05\n",
      "epoch: 1, loss: 5.270, avg: 4.07, latest lr: 2.4071428571428573e-05\n",
      "epoch: 1, loss: 4.390, avg: 4.07, latest lr: 2.405714285714286e-05\n",
      "epoch: 1, loss: 4.232, avg: 4.08, latest lr: 2.4042857142857144e-05\n",
      "epoch: 1, loss: 4.666, avg: 4.08, latest lr: 2.402857142857143e-05\n",
      "epoch: 1, loss: 5.236, avg: 4.08, latest lr: 2.4014285714285714e-05\n",
      "epoch: 1, loss: 5.715, avg: 4.08, latest lr: 2.4e-05\n",
      "epoch: 1, loss: 3.869, avg: 4.08, latest lr: 2.3985714285714287e-05\n",
      "epoch: 1, loss: 5.639, avg: 4.08, latest lr: 2.397142857142857e-05\n",
      "epoch: 1, loss: 3.974, avg: 4.08, latest lr: 2.3957142857142858e-05\n",
      "epoch: 1, loss: 3.924, avg: 4.08, latest lr: 2.3942857142857144e-05\n",
      "epoch: 1, loss: 5.178, avg: 4.08, latest lr: 2.392857142857143e-05\n",
      "epoch: 1, loss: 5.322, avg: 4.08, latest lr: 2.3914285714285715e-05\n",
      "epoch: 1, loss: 4.576, avg: 4.08, latest lr: 2.39e-05\n",
      "epoch: 1, loss: 3.971, avg: 4.08, latest lr: 2.3885714285714285e-05\n",
      "epoch: 1, loss: 4.573, avg: 4.08, latest lr: 2.3871428571428572e-05\n",
      "epoch: 1, loss: 3.861, avg: 4.08, latest lr: 2.385714285714286e-05\n",
      "epoch: 1, loss: 3.974, avg: 4.08, latest lr: 2.3842857142857145e-05\n",
      "epoch: 1, loss: 5.881, avg: 4.09, latest lr: 2.3828571428571432e-05\n",
      "epoch: 1, loss: 4.893, avg: 4.09, latest lr: 2.3814285714285716e-05\n",
      "epoch: 1, loss: 3.961, avg: 4.09, latest lr: 2.38e-05\n",
      "epoch: 1, loss: 4.998, avg: 4.09, latest lr: 2.3785714285714286e-05\n",
      "epoch: 1, loss: 4.057, avg: 4.09, latest lr: 2.3771428571428573e-05\n",
      "epoch: 1, loss: 5.228, avg: 4.09, latest lr: 2.375714285714286e-05\n",
      "epoch: 1, loss: 5.717, avg: 4.09, latest lr: 2.3742857142857143e-05\n",
      "epoch: 1, loss: 4.554, avg: 4.09, latest lr: 2.372857142857143e-05\n",
      "epoch: 1, loss: 4.134, avg: 4.09, latest lr: 2.3714285714285717e-05\n",
      "epoch: 1, loss: 3.768, avg: 4.09, latest lr: 2.37e-05\n",
      "epoch: 1, loss: 5.287, avg: 4.09, latest lr: 2.3685714285714287e-05\n",
      "epoch: 1, loss: 5.604, avg: 4.09, latest lr: 2.3671428571428574e-05\n",
      "epoch: 1, loss: 2.718, avg: 4.09, latest lr: 2.3657142857142857e-05\n",
      "epoch: 1, loss: 3.870, avg: 4.09, latest lr: 2.3642857142857144e-05\n",
      "epoch: 1, loss: 5.641, avg: 4.09, latest lr: 2.362857142857143e-05\n",
      "epoch: 1, loss: 4.427, avg: 4.09, latest lr: 2.3614285714285718e-05\n",
      "epoch: 1, loss: 4.030, avg: 4.10, latest lr: 2.36e-05\n",
      "epoch: 1, loss: 4.876, avg: 4.10, latest lr: 2.3585714285714284e-05\n",
      "epoch: 1, loss: 4.529, avg: 4.10, latest lr: 2.357142857142857e-05\n",
      "epoch: 1, loss: 4.246, avg: 4.10, latest lr: 2.3557142857142858e-05\n",
      "epoch: 1, loss: 3.906, avg: 4.10, latest lr: 2.3542857142857145e-05\n",
      "epoch: 1, loss: 4.802, avg: 4.10, latest lr: 2.3528571428571432e-05\n",
      "epoch: 1, loss: 5.220, avg: 4.10, latest lr: 2.3514285714285715e-05\n",
      "epoch: 1, loss: 3.995, avg: 4.10, latest lr: 2.35e-05\n",
      "epoch: 1, loss: 4.494, avg: 4.10, latest lr: 2.3485714285714285e-05\n",
      "epoch: 1, loss: 3.667, avg: 4.10, latest lr: 2.3471428571428572e-05\n",
      "epoch: 1, loss: 5.697, avg: 4.10, latest lr: 2.345714285714286e-05\n",
      "epoch: 1, loss: 4.188, avg: 4.10, latest lr: 2.3442857142857143e-05\n",
      "epoch: 1, loss: 5.316, avg: 4.10, latest lr: 2.342857142857143e-05\n",
      "epoch: 1, loss: 4.929, avg: 4.10, latest lr: 2.3414285714285716e-05\n",
      "epoch: 1, loss: 5.618, avg: 4.10, latest lr: 2.3400000000000003e-05\n",
      "epoch: 1, loss: 4.917, avg: 4.11, latest lr: 2.3385714285714286e-05\n",
      "epoch: 1, loss: 3.075, avg: 4.11, latest lr: 2.3371428571428573e-05\n",
      "epoch: 1, loss: 4.373, avg: 4.11, latest lr: 2.3357142857142857e-05\n",
      "epoch: 1, loss: 3.026, avg: 4.11, latest lr: 2.3342857142857143e-05\n",
      "epoch: 1, loss: 5.174, avg: 4.11, latest lr: 2.332857142857143e-05\n",
      "epoch: 1, loss: 4.768, avg: 4.11, latest lr: 2.3314285714285717e-05\n",
      "epoch: 1, loss: 4.926, avg: 4.11, latest lr: 2.3300000000000004e-05\n",
      "epoch: 1, loss: 3.967, avg: 4.11, latest lr: 2.3285714285714287e-05\n",
      "epoch: 1, loss: 5.829, avg: 4.11, latest lr: 2.327142857142857e-05\n",
      "epoch: 1, loss: 5.802, avg: 4.11, latest lr: 2.3257142857142858e-05\n",
      "epoch: 1, loss: 5.628, avg: 4.11, latest lr: 2.3242857142857144e-05\n",
      "epoch: 1, loss: 4.761, avg: 4.11, latest lr: 2.322857142857143e-05\n",
      "epoch: 1, loss: 4.052, avg: 4.11, latest lr: 2.3214285714285715e-05\n",
      "epoch: 1, loss: 5.332, avg: 4.11, latest lr: 2.32e-05\n",
      "epoch: 1, loss: 3.511, avg: 4.11, latest lr: 2.3185714285714285e-05\n",
      "epoch: 1, loss: 6.569, avg: 4.12, latest lr: 2.3171428571428572e-05\n",
      "epoch: 1, loss: 4.162, avg: 4.12, latest lr: 2.315714285714286e-05\n",
      "epoch: 1, loss: 4.992, avg: 4.12, latest lr: 2.3142857142857145e-05\n",
      "epoch: 1, loss: 4.733, avg: 4.12, latest lr: 2.312857142857143e-05\n",
      "epoch: 1, loss: 4.089, avg: 4.12, latest lr: 2.3114285714285716e-05\n",
      "epoch: 1, loss: 4.005, avg: 4.12, latest lr: 2.3100000000000002e-05\n",
      "epoch: 1, loss: 3.498, avg: 4.12, latest lr: 2.3085714285714286e-05\n",
      "epoch: 1, loss: 3.785, avg: 4.12, latest lr: 2.3071428571428573e-05\n",
      "epoch: 1, loss: 5.413, avg: 4.12, latest lr: 2.3057142857142856e-05\n",
      "epoch: 1, loss: 4.349, avg: 4.12, latest lr: 2.3042857142857143e-05\n",
      "epoch: 1, loss: 5.527, avg: 4.12, latest lr: 2.302857142857143e-05\n",
      "epoch: 1, loss: 6.360, avg: 4.12, latest lr: 2.3014285714285717e-05\n",
      "epoch: 1, loss: 4.253, avg: 4.12, latest lr: 2.3000000000000003e-05\n",
      "epoch: 1, loss: 4.907, avg: 4.12, latest lr: 2.2985714285714287e-05\n",
      "epoch: 1, loss: 5.365, avg: 4.13, latest lr: 2.297142857142857e-05\n",
      "epoch: 1, loss: 4.464, avg: 4.13, latest lr: 2.2957142857142857e-05\n",
      "epoch: 1, loss: 4.477, avg: 4.13, latest lr: 2.2942857142857144e-05\n",
      "epoch: 1, loss: 4.845, avg: 4.13, latest lr: 2.292857142857143e-05\n",
      "epoch: 1, loss: 6.234, avg: 4.13, latest lr: 2.2914285714285718e-05\n",
      "epoch: 1, loss: 4.901, avg: 4.13, latest lr: 2.29e-05\n",
      "epoch: 1, loss: 4.392, avg: 4.13, latest lr: 2.2885714285714288e-05\n",
      "epoch: 1, loss: 4.986, avg: 4.13, latest lr: 2.287142857142857e-05\n",
      "epoch: 1, loss: 5.141, avg: 4.13, latest lr: 2.2857142857142858e-05\n",
      "epoch: 1, loss: 3.344, avg: 4.13, latest lr: 2.2842857142857145e-05\n",
      "epoch: 1, loss: 4.955, avg: 4.13, latest lr: 2.2828571428571428e-05\n",
      "epoch: 1, loss: 4.096, avg: 4.13, latest lr: 2.2814285714285715e-05\n",
      "epoch: 1, loss: 4.032, avg: 4.13, latest lr: 2.2800000000000002e-05\n",
      "epoch: 1, loss: 4.731, avg: 4.13, latest lr: 2.278571428571429e-05\n",
      "epoch: 1, loss: 4.204, avg: 4.13, latest lr: 2.2771428571428572e-05\n",
      "epoch: 1, loss: 4.081, avg: 4.13, latest lr: 2.275714285714286e-05\n",
      "epoch: 1, loss: 4.248, avg: 4.14, latest lr: 2.2742857142857142e-05\n",
      "epoch: 1, loss: 4.817, avg: 4.14, latest lr: 2.272857142857143e-05\n",
      "epoch: 1, loss: 3.071, avg: 4.14, latest lr: 2.2714285714285716e-05\n",
      "epoch: 1, loss: 3.922, avg: 4.14, latest lr: 2.2700000000000003e-05\n",
      "epoch: 1, loss: 4.967, avg: 4.14, latest lr: 2.2685714285714286e-05\n",
      "epoch: 1, loss: 4.219, avg: 4.14, latest lr: 2.267142857142857e-05\n",
      "epoch: 1, loss: 4.342, avg: 4.14, latest lr: 2.2657142857142857e-05\n",
      "epoch: 1, loss: 4.074, avg: 4.14, latest lr: 2.2642857142857143e-05\n",
      "epoch: 1, loss: 4.933, avg: 4.14, latest lr: 2.262857142857143e-05\n",
      "epoch: 1, loss: 3.538, avg: 4.14, latest lr: 2.2614285714285717e-05\n",
      "epoch: 1, loss: 2.498, avg: 4.14, latest lr: 2.26e-05\n",
      "epoch: 1, loss: 5.870, avg: 4.14, latest lr: 2.2585714285714287e-05\n",
      "epoch: 1, loss: 3.566, avg: 4.14, latest lr: 2.257142857142857e-05\n",
      "epoch: 1, loss: 5.185, avg: 4.14, latest lr: 2.2557142857142858e-05\n",
      "epoch: 1, loss: 4.742, avg: 4.14, latest lr: 2.2542857142857144e-05\n",
      "epoch: 1, loss: 4.219, avg: 4.14, latest lr: 2.2528571428571428e-05\n",
      "epoch: 1, loss: 6.315, avg: 4.15, latest lr: 2.2514285714285715e-05\n",
      "epoch: 1, loss: 5.457, avg: 4.15, latest lr: 2.25e-05\n",
      "epoch: 1, loss: 4.230, avg: 4.15, latest lr: 2.2485714285714288e-05\n",
      "epoch: 1, loss: 4.603, avg: 4.15, latest lr: 2.2471428571428575e-05\n",
      "epoch: 1, loss: 5.932, avg: 4.15, latest lr: 2.245714285714286e-05\n",
      "epoch: 1, loss: 4.390, avg: 4.15, latest lr: 2.2442857142857142e-05\n",
      "epoch: 1, loss: 4.456, avg: 4.15, latest lr: 2.242857142857143e-05\n",
      "epoch: 1, loss: 4.283, avg: 4.15, latest lr: 2.2414285714285716e-05\n",
      "epoch: 1, loss: 4.796, avg: 4.15, latest lr: 2.2400000000000002e-05\n",
      "epoch: 1, loss: 3.994, avg: 4.15, latest lr: 2.238571428571429e-05\n",
      "epoch: 1, loss: 5.531, avg: 4.15, latest lr: 2.2371428571428573e-05\n",
      "epoch: 1, loss: 4.630, avg: 4.15, latest lr: 2.2357142857142856e-05\n",
      "epoch: 1, loss: 4.237, avg: 4.15, latest lr: 2.2342857142857143e-05\n",
      "epoch: 1, loss: 5.296, avg: 4.15, latest lr: 2.232857142857143e-05\n",
      "epoch: 1, loss: 4.882, avg: 4.16, latest lr: 2.2314285714285717e-05\n",
      "epoch: 1, loss: 5.215, avg: 4.16, latest lr: 2.23e-05\n",
      "epoch: 1, loss: 4.354, avg: 4.16, latest lr: 2.2285714285714287e-05\n",
      "epoch: 1, loss: 4.724, avg: 4.16, latest lr: 2.2271428571428574e-05\n",
      "epoch: 1, loss: 4.617, avg: 4.16, latest lr: 2.2257142857142857e-05\n",
      "epoch: 1, loss: 5.732, avg: 4.16, latest lr: 2.2242857142857144e-05\n",
      "epoch: 1, loss: 3.774, avg: 4.16, latest lr: 2.222857142857143e-05\n",
      "epoch: 1, loss: 5.488, avg: 4.16, latest lr: 2.2214285714285714e-05\n",
      "epoch: 1, loss: 4.326, avg: 4.16, latest lr: 2.22e-05\n",
      "epoch: 1, loss: 5.225, avg: 4.16, latest lr: 2.2185714285714288e-05\n",
      "epoch: 1, loss: 5.079, avg: 4.16, latest lr: 2.2171428571428575e-05\n",
      "epoch: 1, loss: 4.863, avg: 4.16, latest lr: 2.2157142857142858e-05\n",
      "epoch: 1, loss: 6.240, avg: 4.16, latest lr: 2.214285714285714e-05\n",
      "epoch: 1, loss: 3.347, avg: 4.16, latest lr: 2.2128571428571428e-05\n",
      "epoch: 1, loss: 3.478, avg: 4.16, latest lr: 2.2114285714285715e-05\n",
      "epoch: 1, loss: 4.747, avg: 4.17, latest lr: 2.2100000000000002e-05\n",
      "epoch: 1, loss: 4.653, avg: 4.17, latest lr: 2.208571428571429e-05\n",
      "epoch: 1, loss: 4.221, avg: 4.17, latest lr: 2.2071428571428572e-05\n",
      "epoch: 1, loss: 3.973, avg: 4.17, latest lr: 2.205714285714286e-05\n",
      "epoch: 1, loss: 4.432, avg: 4.17, latest lr: 2.2042857142857142e-05\n",
      "epoch: 1, loss: 4.245, avg: 4.17, latest lr: 2.202857142857143e-05\n",
      "epoch: 1, loss: 6.253, avg: 4.17, latest lr: 2.2014285714285716e-05\n",
      "epoch: 1, loss: 4.178, avg: 4.17, latest lr: 2.2000000000000003e-05\n",
      "epoch: 1, loss: 3.669, avg: 4.17, latest lr: 2.1985714285714286e-05\n",
      "epoch: 1, loss: 5.489, avg: 4.17, latest lr: 2.1971428571428573e-05\n",
      "epoch: 1, loss: 4.157, avg: 4.17, latest lr: 2.195714285714286e-05\n",
      "epoch: 1, loss: 3.999, avg: 4.17, latest lr: 2.1942857142857143e-05\n",
      "epoch: 1, loss: 3.923, avg: 4.17, latest lr: 2.192857142857143e-05\n",
      "epoch: 1, loss: 4.469, avg: 4.17, latest lr: 2.1914285714285714e-05\n",
      "epoch: 1, loss: 5.450, avg: 4.17, latest lr: 2.19e-05\n",
      "epoch: 1, loss: 2.641, avg: 4.17, latest lr: 2.1885714285714287e-05\n",
      "epoch: 1, loss: 4.601, avg: 4.18, latest lr: 2.1871428571428574e-05\n",
      "epoch: 1, loss: 3.587, avg: 4.18, latest lr: 2.185714285714286e-05\n",
      "epoch: 1, loss: 4.949, avg: 4.18, latest lr: 2.1842857142857144e-05\n",
      "epoch: 1, loss: 4.326, avg: 4.18, latest lr: 2.1828571428571428e-05\n",
      "epoch: 1, loss: 4.562, avg: 4.18, latest lr: 2.1814285714285715e-05\n",
      "epoch: 1, loss: 4.624, avg: 4.18, latest lr: 2.18e-05\n",
      "epoch: 1, loss: 4.638, avg: 4.18, latest lr: 2.1785714285714288e-05\n",
      "epoch: 1, loss: 5.026, avg: 4.18, latest lr: 2.177142857142857e-05\n",
      "epoch: 1, loss: 4.625, avg: 4.18, latest lr: 2.175714285714286e-05\n",
      "epoch: 1, loss: 4.373, avg: 4.18, latest lr: 2.1742857142857142e-05\n",
      "epoch: 1, loss: 5.513, avg: 4.18, latest lr: 2.172857142857143e-05\n",
      "epoch: 1, loss: 5.022, avg: 4.18, latest lr: 2.1714285714285715e-05\n",
      "epoch: 1, loss: 3.995, avg: 4.18, latest lr: 2.1700000000000002e-05\n",
      "epoch: 1, loss: 4.420, avg: 4.18, latest lr: 2.1685714285714286e-05\n",
      "epoch: 1, loss: 5.777, avg: 4.18, latest lr: 2.1671428571428573e-05\n",
      "epoch: 1, loss: 4.880, avg: 4.19, latest lr: 2.165714285714286e-05\n",
      "epoch: 1, loss: 6.106, avg: 4.19, latest lr: 2.1642857142857146e-05\n",
      "epoch: 1, loss: 4.476, avg: 4.19, latest lr: 2.162857142857143e-05\n",
      "epoch: 1, loss: 4.449, avg: 4.19, latest lr: 2.1614285714285713e-05\n",
      "epoch: 1, loss: 4.131, avg: 4.19, latest lr: 2.16e-05\n",
      "epoch: 1, loss: 5.365, avg: 4.19, latest lr: 2.1585714285714287e-05\n",
      "epoch: 1, loss: 4.571, avg: 4.19, latest lr: 2.1571428571428574e-05\n",
      "epoch: 1, loss: 4.973, avg: 4.19, latest lr: 2.155714285714286e-05\n",
      "epoch: 1, loss: 5.182, avg: 4.19, latest lr: 2.1542857142857144e-05\n",
      "epoch: 1, loss: 4.542, avg: 4.19, latest lr: 2.1528571428571427e-05\n",
      "epoch: 1, loss: 4.920, avg: 4.19, latest lr: 2.1514285714285714e-05\n",
      "epoch: 1, loss: 3.743, avg: 4.19, latest lr: 2.15e-05\n",
      "epoch: 1, loss: 4.945, avg: 4.19, latest lr: 2.1485714285714288e-05\n",
      "epoch: 1, loss: 4.959, avg: 4.19, latest lr: 2.1471428571428574e-05\n",
      "epoch: 1, loss: 5.145, avg: 4.20, latest lr: 2.1457142857142858e-05\n",
      "epoch: 1, loss: 5.397, avg: 4.20, latest lr: 2.1442857142857145e-05\n",
      "epoch: 1, loss: 5.747, avg: 4.20, latest lr: 2.1428571428571428e-05\n",
      "epoch: 1, loss: 4.244, avg: 4.20, latest lr: 2.1414285714285715e-05\n",
      "epoch: 1, loss: 5.419, avg: 4.20, latest lr: 2.1400000000000002e-05\n",
      "epoch: 1, loss: 5.247, avg: 4.20, latest lr: 2.1385714285714285e-05\n",
      "epoch: 1, loss: 4.140, avg: 4.20, latest lr: 2.1371428571428572e-05\n",
      "epoch: 1, loss: 4.993, avg: 4.20, latest lr: 2.135714285714286e-05\n",
      "epoch: 1, loss: 4.623, avg: 4.20, latest lr: 2.1342857142857146e-05\n",
      "epoch: 1, loss: 4.372, avg: 4.20, latest lr: 2.132857142857143e-05\n",
      "epoch: 1, loss: 5.716, avg: 4.20, latest lr: 2.1314285714285716e-05\n",
      "epoch: 1, loss: 5.482, avg: 4.20, latest lr: 2.13e-05\n",
      "epoch: 1, loss: 4.533, avg: 4.20, latest lr: 2.1285714285714286e-05\n",
      "epoch: 1, loss: 4.160, avg: 4.20, latest lr: 2.1271428571428573e-05\n",
      "epoch: 1, loss: 4.445, avg: 4.20, latest lr: 2.125714285714286e-05\n",
      "epoch: 1, loss: 4.597, avg: 4.21, latest lr: 2.1242857142857143e-05\n",
      "epoch: 1, loss: 4.885, avg: 4.21, latest lr: 2.1228571428571427e-05\n",
      "epoch: 1, loss: 5.624, avg: 4.21, latest lr: 2.1214285714285713e-05\n",
      "epoch: 1, loss: 5.358, avg: 4.21, latest lr: 2.12e-05\n",
      "epoch: 1, loss: 5.339, avg: 4.21, latest lr: 2.1185714285714287e-05\n",
      "epoch: 1, loss: 5.281, avg: 4.21, latest lr: 2.1171428571428574e-05\n",
      "epoch: 1, loss: 3.110, avg: 4.21, latest lr: 2.1157142857142857e-05\n",
      "epoch: 1, loss: 4.769, avg: 4.21, latest lr: 2.1142857142857144e-05\n",
      "epoch: 1, loss: 5.903, avg: 4.21, latest lr: 2.112857142857143e-05\n",
      "epoch: 1, loss: 5.003, avg: 4.21, latest lr: 2.1114285714285714e-05\n",
      "epoch: 1, loss: 4.502, avg: 4.21, latest lr: 2.11e-05\n",
      "epoch: 1, loss: 4.987, avg: 4.21, latest lr: 2.1085714285714288e-05\n",
      "epoch: 1, loss: 4.860, avg: 4.21, latest lr: 2.107142857142857e-05\n",
      "epoch: 1, loss: 4.740, avg: 4.21, latest lr: 2.105714285714286e-05\n",
      "epoch: 1, loss: 5.534, avg: 4.22, latest lr: 2.1042857142857145e-05\n",
      "epoch: 1, loss: 5.716, avg: 4.22, latest lr: 2.1028571428571432e-05\n",
      "epoch: 1, loss: 4.523, avg: 4.22, latest lr: 2.1014285714285715e-05\n",
      "epoch: 1, loss: 5.867, avg: 4.22, latest lr: 2.1e-05\n",
      "epoch: 1, loss: 4.707, avg: 4.22, latest lr: 2.0985714285714286e-05\n",
      "epoch: 1, loss: 5.080, avg: 4.22, latest lr: 2.0971428571428572e-05\n",
      "epoch: 1, loss: 5.444, avg: 4.22, latest lr: 2.095714285714286e-05\n",
      "epoch: 1, loss: 3.603, avg: 4.22, latest lr: 2.0942857142857146e-05\n",
      "epoch: 1, loss: 2.790, avg: 4.22, latest lr: 2.092857142857143e-05\n",
      "epoch: 1, loss: 4.088, avg: 4.22, latest lr: 2.0914285714285713e-05\n",
      "epoch: 1, loss: 4.486, avg: 4.22, latest lr: 2.09e-05\n",
      "epoch: 1, loss: 4.085, avg: 4.22, latest lr: 2.0885714285714287e-05\n",
      "epoch: 1, loss: 5.125, avg: 4.22, latest lr: 2.0871428571428573e-05\n",
      "epoch: 1, loss: 4.955, avg: 4.22, latest lr: 2.0857142857142857e-05\n",
      "epoch: 1, loss: 3.569, avg: 4.22, latest lr: 2.0842857142857144e-05\n",
      "epoch: 1, loss: 5.315, avg: 4.23, latest lr: 2.082857142857143e-05\n",
      "epoch: 1, loss: 4.634, avg: 4.23, latest lr: 2.0814285714285714e-05\n",
      "epoch: 1, loss: 5.659, avg: 4.23, latest lr: 2.08e-05\n",
      "epoch: 1, loss: 4.872, avg: 4.23, latest lr: 2.0785714285714288e-05\n",
      "epoch: 1, loss: 3.546, avg: 4.23, latest lr: 2.077142857142857e-05\n",
      "epoch: 1, loss: 4.308, avg: 4.23, latest lr: 2.0757142857142858e-05\n",
      "epoch: 1, loss: 4.743, avg: 4.23, latest lr: 2.0742857142857145e-05\n",
      "epoch: 1, loss: 4.543, avg: 4.23, latest lr: 2.072857142857143e-05\n",
      "epoch: 1, loss: 4.946, avg: 4.23, latest lr: 2.0714285714285718e-05\n",
      "epoch: 1, loss: 3.346, avg: 4.23, latest lr: 2.07e-05\n",
      "epoch: 1, loss: 4.111, avg: 4.23, latest lr: 2.0685714285714285e-05\n",
      "epoch: 1, loss: 4.197, avg: 4.23, latest lr: 2.0671428571428572e-05\n",
      "epoch: 1, loss: 4.810, avg: 4.23, latest lr: 2.065714285714286e-05\n",
      "epoch: 1, loss: 5.376, avg: 4.23, latest lr: 2.0642857142857146e-05\n",
      "epoch: 1, loss: 4.387, avg: 4.23, latest lr: 2.062857142857143e-05\n",
      "epoch: 1, loss: 4.061, avg: 4.23, latest lr: 2.0614285714285716e-05\n",
      "epoch: 1, loss: 3.463, avg: 4.24, latest lr: 2.06e-05\n",
      "epoch: 1, loss: 4.151, avg: 4.24, latest lr: 2.0585714285714286e-05\n",
      "epoch: 1, loss: 5.304, avg: 4.24, latest lr: 2.0571428571428573e-05\n",
      "epoch: 1, loss: 4.178, avg: 4.24, latest lr: 2.055714285714286e-05\n",
      "epoch: 1, loss: 4.429, avg: 4.24, latest lr: 2.0542857142857143e-05\n",
      "epoch: 1, loss: 5.029, avg: 4.24, latest lr: 2.052857142857143e-05\n",
      "epoch: 1, loss: 4.260, avg: 4.24, latest lr: 2.0514285714285717e-05\n",
      "epoch: 1, loss: 3.863, avg: 4.24, latest lr: 2.05e-05\n",
      "epoch: 1, loss: 5.766, avg: 4.24, latest lr: 2.0485714285714287e-05\n",
      "epoch: 1, loss: 4.380, avg: 4.24, latest lr: 2.047142857142857e-05\n",
      "epoch: 1, loss: 2.683, avg: 4.24, latest lr: 2.0457142857142857e-05\n",
      "epoch: 1, loss: 3.983, avg: 4.24, latest lr: 2.0442857142857144e-05\n",
      "epoch: 1, loss: 5.974, avg: 4.24, latest lr: 2.042857142857143e-05\n",
      "epoch: 1, loss: 3.754, avg: 4.24, latest lr: 2.0414285714285718e-05\n",
      "epoch: 1, loss: 5.009, avg: 4.24, latest lr: 2.04e-05\n",
      "epoch: 1, loss: 4.858, avg: 4.25, latest lr: 2.0385714285714285e-05\n",
      "epoch: 1, loss: 4.843, avg: 4.25, latest lr: 2.037142857142857e-05\n",
      "epoch: 1, loss: 3.090, avg: 4.25, latest lr: 2.0357142857142858e-05\n",
      "epoch: 1, loss: 4.805, avg: 4.25, latest lr: 2.0342857142857145e-05\n",
      "epoch: 1, loss: 5.323, avg: 4.25, latest lr: 2.032857142857143e-05\n",
      "epoch: 1, loss: 4.943, avg: 4.25, latest lr: 2.0314285714285715e-05\n",
      "epoch: 1, loss: 5.284, avg: 4.25, latest lr: 2.0300000000000002e-05\n",
      "epoch: 1, loss: 4.856, avg: 4.25, latest lr: 2.0285714285714286e-05\n",
      "epoch: 1, loss: 2.945, avg: 4.25, latest lr: 2.0271428571428572e-05\n",
      "epoch: 1, loss: 3.922, avg: 4.25, latest lr: 2.025714285714286e-05\n",
      "epoch: 1, loss: 3.314, avg: 4.25, latest lr: 2.0242857142857143e-05\n",
      "epoch: 1, loss: 3.915, avg: 4.25, latest lr: 2.022857142857143e-05\n",
      "epoch: 1, loss: 5.096, avg: 4.25, latest lr: 2.0214285714285716e-05\n",
      "epoch: 1, loss: 3.638, avg: 4.25, latest lr: 2.0200000000000003e-05\n",
      "epoch: 1, loss: 4.724, avg: 4.25, latest lr: 2.0185714285714287e-05\n",
      "epoch: 1, loss: 5.575, avg: 4.25, latest lr: 2.0171428571428573e-05\n",
      "epoch: 1, loss: 4.328, avg: 4.26, latest lr: 2.0157142857142857e-05\n",
      "epoch: 1, loss: 2.850, avg: 4.26, latest lr: 2.0142857142857144e-05\n",
      "epoch: 1, loss: 5.991, avg: 4.26, latest lr: 2.012857142857143e-05\n",
      "epoch: 1, loss: 4.367, avg: 4.26, latest lr: 2.0114285714285717e-05\n",
      "epoch: 1, loss: 4.994, avg: 4.26, latest lr: 2.01e-05\n",
      "epoch: 1, loss: 2.835, avg: 4.26, latest lr: 2.0085714285714284e-05\n",
      "epoch: 1, loss: 2.782, avg: 4.26, latest lr: 2.007142857142857e-05\n",
      "epoch: 1, loss: 3.781, avg: 4.26, latest lr: 2.0057142857142858e-05\n",
      "epoch: 1, loss: 4.526, avg: 4.26, latest lr: 2.0042857142857145e-05\n",
      "epoch: 1, loss: 4.467, avg: 4.26, latest lr: 2.002857142857143e-05\n",
      "epoch: 1, loss: 4.528, avg: 4.26, latest lr: 2.0014285714285715e-05\n",
      "epoch: 1, loss: 4.131, avg: 4.26, latest lr: 2e-05\n",
      "epoch: 1, loss: 4.098, avg: 4.26, latest lr: 1.9985714285714285e-05\n",
      "epoch: 1, loss: 4.641, avg: 4.26, latest lr: 1.9971428571428572e-05\n",
      "epoch: 1, loss: 4.712, avg: 4.26, latest lr: 1.995714285714286e-05\n",
      "epoch: 1, loss: 5.716, avg: 4.26, latest lr: 1.9942857142857142e-05\n",
      "epoch: 1, loss: 3.812, avg: 4.26, latest lr: 1.992857142857143e-05\n",
      "epoch: 1, loss: 4.003, avg: 4.27, latest lr: 1.9914285714285716e-05\n",
      "epoch: 1, loss: 5.074, avg: 4.27, latest lr: 1.9900000000000003e-05\n",
      "epoch: 1, loss: 4.699, avg: 4.27, latest lr: 1.9885714285714286e-05\n",
      "epoch: 1, loss: 4.336, avg: 4.27, latest lr: 1.9871428571428573e-05\n",
      "epoch: 1, loss: 4.944, avg: 4.27, latest lr: 1.9857142857142856e-05\n",
      "epoch: 1, loss: 4.287, avg: 4.27, latest lr: 1.9842857142857143e-05\n",
      "epoch: 1, loss: 3.782, avg: 4.27, latest lr: 1.982857142857143e-05\n",
      "epoch: 1, loss: 4.502, avg: 4.27, latest lr: 1.9814285714285717e-05\n",
      "epoch: 1, loss: 5.953, avg: 4.27, latest lr: 1.9800000000000004e-05\n",
      "epoch: 1, loss: 5.368, avg: 4.27, latest lr: 1.9785714285714287e-05\n",
      "epoch: 1, loss: 5.683, avg: 4.27, latest lr: 1.977142857142857e-05\n",
      "epoch: 1, loss: 5.636, avg: 4.27, latest lr: 1.9757142857142857e-05\n",
      "epoch: 1, loss: 5.344, avg: 4.27, latest lr: 1.9742857142857144e-05\n",
      "epoch: 1, loss: 3.429, avg: 4.27, latest lr: 1.972857142857143e-05\n",
      "epoch: 1, loss: 3.192, avg: 4.28, latest lr: 1.9714285714285714e-05\n",
      "epoch: 1, loss: 4.148, avg: 4.28, latest lr: 1.97e-05\n",
      "epoch: 1, loss: 5.758, avg: 4.28, latest lr: 1.9685714285714288e-05\n",
      "epoch: 1, loss: 5.037, avg: 4.28, latest lr: 1.967142857142857e-05\n",
      "epoch: 1, loss: 4.001, avg: 4.28, latest lr: 1.9657142857142858e-05\n",
      "epoch: 1, loss: 5.530, avg: 4.28, latest lr: 1.9642857142857145e-05\n",
      "epoch: 1, loss: 5.230, avg: 4.28, latest lr: 1.962857142857143e-05\n",
      "epoch: 1, loss: 5.999, avg: 4.28, latest lr: 1.9614285714285715e-05\n",
      "epoch: 1, loss: 4.526, avg: 4.28, latest lr: 1.9600000000000002e-05\n",
      "epoch: 1, loss: 4.630, avg: 4.28, latest lr: 1.958571428571429e-05\n",
      "epoch: 1, loss: 5.184, avg: 4.28, latest lr: 1.9571428571428572e-05\n",
      "epoch: 1, loss: 3.931, avg: 4.28, latest lr: 1.9557142857142856e-05\n",
      "epoch: 1, loss: 5.082, avg: 4.28, latest lr: 1.9542857142857143e-05\n",
      "epoch: 1, loss: 3.968, avg: 4.28, latest lr: 1.952857142857143e-05\n",
      "epoch: 1, loss: 5.624, avg: 4.28, latest lr: 1.9514285714285716e-05\n",
      "epoch: 1, loss: 4.737, avg: 4.29, latest lr: 1.9500000000000003e-05\n",
      "epoch: 1, loss: 4.819, avg: 4.29, latest lr: 1.9485714285714286e-05\n",
      "epoch: 1, loss: 5.301, avg: 4.29, latest lr: 1.947142857142857e-05\n",
      "epoch: 1, loss: 4.993, avg: 4.29, latest lr: 1.9457142857142857e-05\n",
      "epoch: 1, loss: 4.175, avg: 4.29, latest lr: 1.9442857142857144e-05\n",
      "epoch: 1, loss: 4.159, avg: 4.29, latest lr: 1.942857142857143e-05\n",
      "epoch: 1, loss: 4.317, avg: 4.29, latest lr: 1.9414285714285714e-05\n",
      "epoch: 1, loss: 5.834, avg: 4.29, latest lr: 1.94e-05\n",
      "epoch: 1, loss: 5.023, avg: 4.29, latest lr: 1.9385714285714287e-05\n",
      "epoch: 1, loss: 4.274, avg: 4.29, latest lr: 1.9371428571428574e-05\n",
      "epoch: 1, loss: 4.430, avg: 4.29, latest lr: 1.9357142857142858e-05\n",
      "epoch: 1, loss: 4.809, avg: 4.29, latest lr: 1.9342857142857144e-05\n",
      "epoch: 1, loss: 5.005, avg: 4.29, latest lr: 1.9328571428571428e-05\n",
      "epoch: 1, loss: 3.265, avg: 4.29, latest lr: 1.9314285714285715e-05\n",
      "epoch: 1, loss: 5.233, avg: 4.29, latest lr: 1.93e-05\n",
      "epoch: 1, loss: 5.382, avg: 4.30, latest lr: 1.928571428571429e-05\n",
      "epoch: 1, loss: 5.567, avg: 4.30, latest lr: 1.9271428571428575e-05\n",
      "epoch: 1, loss: 4.531, avg: 4.30, latest lr: 1.9257142857142855e-05\n",
      "epoch: 1, loss: 3.776, avg: 4.30, latest lr: 1.9242857142857142e-05\n",
      "epoch: 1, loss: 3.946, avg: 4.30, latest lr: 1.922857142857143e-05\n",
      "epoch: 1, loss: 4.270, avg: 4.30, latest lr: 1.9214285714285716e-05\n",
      "epoch: 1, loss: 3.549, avg: 4.30, latest lr: 1.9200000000000003e-05\n",
      "epoch: 1, loss: 6.154, avg: 4.30, latest lr: 1.9185714285714286e-05\n",
      "epoch: 1, loss: 5.250, avg: 4.30, latest lr: 1.9171428571428573e-05\n",
      "epoch: 1, loss: 5.589, avg: 4.30, latest lr: 1.9157142857142856e-05\n",
      "epoch: 1, loss: 4.643, avg: 4.30, latest lr: 1.9142857142857143e-05\n",
      "epoch: 1, loss: 3.975, avg: 4.30, latest lr: 1.912857142857143e-05\n",
      "epoch: 1, loss: 4.278, avg: 4.30, latest lr: 1.9114285714285717e-05\n",
      "epoch: 1, loss: 4.701, avg: 4.30, latest lr: 1.91e-05\n",
      "epoch: 1, loss: 4.477, avg: 4.30, latest lr: 1.9085714285714287e-05\n",
      "epoch: 1, loss: 5.003, avg: 4.31, latest lr: 1.9071428571428574e-05\n",
      "epoch: 1, loss: 4.143, avg: 4.31, latest lr: 1.9057142857142857e-05\n",
      "epoch: 1, loss: 4.346, avg: 4.31, latest lr: 1.9042857142857144e-05\n",
      "epoch: 1, loss: 5.184, avg: 4.31, latest lr: 1.9028571428571427e-05\n",
      "epoch: 1, loss: 5.767, avg: 4.31, latest lr: 1.9014285714285714e-05\n",
      "epoch: 1, loss: 5.342, avg: 4.31, latest lr: 1.9e-05\n",
      "epoch: 1, loss: 5.232, avg: 4.31, latest lr: 1.8985714285714288e-05\n",
      "epoch: 1, loss: 3.749, avg: 4.31, latest lr: 1.8971428571428575e-05\n",
      "epoch: 1, loss: 5.147, avg: 4.31, latest lr: 1.8957142857142858e-05\n",
      "epoch: 1, loss: 3.683, avg: 4.31, latest lr: 1.894285714285714e-05\n",
      "epoch: 1, loss: 3.504, avg: 4.31, latest lr: 1.892857142857143e-05\n",
      "epoch: 1, loss: 5.462, avg: 4.31, latest lr: 1.8914285714285715e-05\n",
      "epoch: 1, loss: 5.211, avg: 4.31, latest lr: 1.8900000000000002e-05\n",
      "epoch: 1, loss: 5.090, avg: 4.31, latest lr: 1.888571428571429e-05\n",
      "epoch: 1, loss: 4.214, avg: 4.32, latest lr: 1.8871428571428572e-05\n",
      "epoch: 1, loss: 5.334, avg: 4.32, latest lr: 1.885714285714286e-05\n",
      "epoch: 1, loss: 4.759, avg: 4.32, latest lr: 1.8842857142857143e-05\n",
      "epoch: 1, loss: 3.985, avg: 4.32, latest lr: 1.882857142857143e-05\n",
      "epoch: 1, loss: 4.385, avg: 4.32, latest lr: 1.8814285714285716e-05\n",
      "epoch: 1, loss: 5.016, avg: 4.32, latest lr: 1.88e-05\n",
      "epoch: 1, loss: 5.539, avg: 4.32, latest lr: 1.8785714285714286e-05\n",
      "epoch: 1, loss: 5.121, avg: 4.32, latest lr: 1.8771428571428573e-05\n",
      "epoch: 1, loss: 5.055, avg: 4.32, latest lr: 1.875714285714286e-05\n",
      "epoch: 1, loss: 4.826, avg: 4.32, latest lr: 1.8742857142857143e-05\n",
      "epoch: 1, loss: 5.048, avg: 4.32, latest lr: 1.872857142857143e-05\n",
      "epoch: 1, loss: 5.050, avg: 4.32, latest lr: 1.8714285714285714e-05\n",
      "epoch: 1, loss: 4.724, avg: 4.32, latest lr: 1.87e-05\n",
      "epoch: 1, loss: 4.664, avg: 4.32, latest lr: 1.8685714285714287e-05\n",
      "epoch: 1, loss: 3.373, avg: 4.32, latest lr: 1.8671428571428574e-05\n",
      "epoch: 1, loss: 4.664, avg: 4.33, latest lr: 1.8657142857142858e-05\n",
      "epoch: 1, loss: 4.984, avg: 4.33, latest lr: 1.864285714285714e-05\n",
      "epoch: 1, loss: 5.050, avg: 4.33, latest lr: 1.8628571428571428e-05\n",
      "epoch: 1, loss: 5.681, avg: 4.33, latest lr: 1.8614285714285715e-05\n",
      "epoch: 1, loss: 4.321, avg: 4.33, latest lr: 1.86e-05\n",
      "epoch: 1, loss: 3.828, avg: 4.33, latest lr: 1.858571428571429e-05\n",
      "epoch: 1, loss: 5.736, avg: 4.33, latest lr: 1.8571428571428572e-05\n",
      "epoch: 1, loss: 4.681, avg: 4.33, latest lr: 1.855714285714286e-05\n",
      "epoch: 1, loss: 5.212, avg: 4.33, latest lr: 1.8542857142857142e-05\n",
      "epoch: 1, loss: 4.807, avg: 4.33, latest lr: 1.852857142857143e-05\n",
      "epoch: 1, loss: 4.545, avg: 4.33, latest lr: 1.8514285714285716e-05\n",
      "epoch: 1, loss: 4.080, avg: 4.33, latest lr: 1.85e-05\n",
      "epoch: 1, loss: 5.361, avg: 4.33, latest lr: 1.8485714285714286e-05\n",
      "epoch: 1, loss: 6.192, avg: 4.33, latest lr: 1.8471428571428573e-05\n",
      "epoch: 1, loss: 4.579, avg: 4.34, latest lr: 1.845714285714286e-05\n",
      "epoch: 1, loss: 3.840, avg: 4.34, latest lr: 1.8442857142857146e-05\n",
      "epoch: 1, loss: 4.055, avg: 4.34, latest lr: 1.842857142857143e-05\n",
      "epoch: 1, loss: 4.154, avg: 4.34, latest lr: 1.8414285714285713e-05\n",
      "epoch: 1, loss: 6.219, avg: 4.34, latest lr: 1.84e-05\n",
      "epoch: 1, loss: 3.835, avg: 4.34, latest lr: 1.8385714285714287e-05\n",
      "epoch: 1, loss: 5.081, avg: 4.34, latest lr: 1.8371428571428574e-05\n",
      "epoch: 1, loss: 4.424, avg: 4.34, latest lr: 1.835714285714286e-05\n",
      "epoch: 1, loss: 3.618, avg: 4.34, latest lr: 1.8342857142857144e-05\n",
      "epoch: 1, loss: 4.224, avg: 4.34, latest lr: 1.8328571428571427e-05\n",
      "epoch: 1, loss: 4.388, avg: 4.34, latest lr: 1.8314285714285714e-05\n",
      "epoch: 1, loss: 5.936, avg: 4.34, latest lr: 1.83e-05\n",
      "epoch: 1, loss: 3.364, avg: 4.34, latest lr: 1.8285714285714288e-05\n",
      "epoch: 1, loss: 5.579, avg: 4.34, latest lr: 1.827142857142857e-05\n",
      "epoch: 1, loss: 4.101, avg: 4.34, latest lr: 1.8257142857142858e-05\n",
      "epoch: 1, loss: 4.388, avg: 4.34, latest lr: 1.8242857142857145e-05\n",
      "epoch: 1, loss: 5.097, avg: 4.35, latest lr: 1.8228571428571428e-05\n",
      "epoch: 1, loss: 5.956, avg: 4.35, latest lr: 1.8214285714285715e-05\n",
      "epoch: 1, loss: 4.865, avg: 4.35, latest lr: 1.8200000000000002e-05\n",
      "epoch: 1, loss: 5.400, avg: 4.35, latest lr: 1.8185714285714285e-05\n",
      "epoch: 1, loss: 4.499, avg: 4.35, latest lr: 1.8171428571428572e-05\n",
      "epoch: 1, loss: 4.025, avg: 4.35, latest lr: 1.815714285714286e-05\n",
      "epoch: 1, loss: 5.229, avg: 4.35, latest lr: 1.8142857142857146e-05\n",
      "epoch: 1, loss: 5.633, avg: 4.35, latest lr: 1.812857142857143e-05\n",
      "epoch: 1, loss: 4.958, avg: 4.35, latest lr: 1.8114285714285713e-05\n",
      "epoch: 1, loss: 3.969, avg: 4.35, latest lr: 1.81e-05\n",
      "epoch: 1, loss: 4.414, avg: 4.35, latest lr: 1.8085714285714286e-05\n",
      "epoch: 1, loss: 3.462, avg: 4.35, latest lr: 1.8071428571428573e-05\n",
      "epoch: 1, loss: 4.380, avg: 4.35, latest lr: 1.805714285714286e-05\n",
      "epoch: 1, loss: 5.145, avg: 4.35, latest lr: 1.8042857142857143e-05\n",
      "epoch: 1, loss: 5.160, avg: 4.36, latest lr: 1.802857142857143e-05\n",
      "epoch: 1, loss: 4.349, avg: 4.36, latest lr: 1.8014285714285714e-05\n",
      "epoch: 1, loss: 5.459, avg: 4.36, latest lr: 1.8e-05\n",
      "epoch: 1, loss: 5.309, avg: 4.36, latest lr: 1.7985714285714287e-05\n",
      "epoch: 1, loss: 3.036, avg: 4.36, latest lr: 1.797142857142857e-05\n",
      "epoch: 1, loss: 5.385, avg: 4.36, latest lr: 1.7957142857142858e-05\n",
      "epoch: 1, loss: 4.900, avg: 4.36, latest lr: 1.7942857142857144e-05\n",
      "epoch: 1, loss: 3.123, avg: 4.36, latest lr: 1.792857142857143e-05\n",
      "epoch: 1, loss: 5.420, avg: 4.36, latest lr: 1.7914285714285715e-05\n",
      "epoch: 1, loss: 4.945, avg: 4.36, latest lr: 1.79e-05\n",
      "epoch: 1, loss: 4.002, avg: 4.36, latest lr: 1.7885714285714285e-05\n",
      "epoch: 1, loss: 5.098, avg: 4.36, latest lr: 1.787142857142857e-05\n",
      "epoch: 1, loss: 2.968, avg: 4.36, latest lr: 1.785714285714286e-05\n",
      "epoch: 1, loss: 3.111, avg: 4.36, latest lr: 1.7842857142857145e-05\n",
      "epoch: 1, loss: 4.585, avg: 4.36, latest lr: 1.7828571428571432e-05\n",
      "epoch: 1, loss: 4.576, avg: 4.36, latest lr: 1.7814285714285716e-05\n",
      "epoch: 1, loss: 5.733, avg: 4.37, latest lr: 1.78e-05\n",
      "epoch: 1, loss: 2.897, avg: 4.37, latest lr: 1.7785714285714286e-05\n",
      "epoch: 1, loss: 4.004, avg: 4.37, latest lr: 1.7771428571428573e-05\n",
      "epoch: 1, loss: 5.377, avg: 4.37, latest lr: 1.775714285714286e-05\n",
      "epoch: 1, loss: 5.461, avg: 4.37, latest lr: 1.7742857142857143e-05\n",
      "epoch: 1, loss: 3.578, avg: 4.37, latest lr: 1.772857142857143e-05\n",
      "epoch: 1, loss: 3.972, avg: 4.37, latest lr: 1.7714285714285713e-05\n",
      "epoch: 1, loss: 4.265, avg: 4.37, latest lr: 1.77e-05\n",
      "epoch: 1, loss: 5.689, avg: 4.37, latest lr: 1.7685714285714287e-05\n",
      "epoch: 1, loss: 3.334, avg: 4.37, latest lr: 1.7671428571428574e-05\n",
      "epoch: 1, loss: 3.379, avg: 4.37, latest lr: 1.7657142857142857e-05\n",
      "epoch: 1, loss: 5.344, avg: 4.37, latest lr: 1.7642857142857144e-05\n",
      "epoch: 1, loss: 4.754, avg: 4.37, latest lr: 1.762857142857143e-05\n",
      "epoch: 1, loss: 3.440, avg: 4.37, latest lr: 1.7614285714285717e-05\n",
      "epoch: 1, loss: 4.975, avg: 4.37, latest lr: 1.76e-05\n",
      "epoch: 1, loss: 5.106, avg: 4.37, latest lr: 1.7585714285714284e-05\n",
      "epoch: 1, loss: 5.288, avg: 4.38, latest lr: 1.757142857142857e-05\n",
      "epoch: 1, loss: 5.041, avg: 4.38, latest lr: 1.7557142857142858e-05\n",
      "epoch: 1, loss: 4.823, avg: 4.38, latest lr: 1.7542857142857145e-05\n",
      "epoch: 1, loss: 4.020, avg: 4.38, latest lr: 1.752857142857143e-05\n",
      "epoch: 1, loss: 5.051, avg: 4.38, latest lr: 1.7514285714285715e-05\n",
      "epoch: 1, loss: 4.974, avg: 4.38, latest lr: 1.75e-05\n",
      "epoch: 1, loss: 4.766, avg: 4.38, latest lr: 1.7485714285714285e-05\n",
      "epoch: 1, loss: 3.816, avg: 4.38, latest lr: 1.7471428571428572e-05\n",
      "epoch: 1, loss: 5.808, avg: 4.38, latest lr: 1.745714285714286e-05\n",
      "epoch: 1, loss: 5.339, avg: 4.38, latest lr: 1.7442857142857146e-05\n",
      "epoch: 1, loss: 4.705, avg: 4.38, latest lr: 1.742857142857143e-05\n",
      "epoch: 1, loss: 4.600, avg: 4.38, latest lr: 1.7414285714285716e-05\n",
      "epoch: 1, loss: 4.389, avg: 4.38, latest lr: 1.74e-05\n",
      "epoch: 1, loss: 4.487, avg: 4.38, latest lr: 1.7385714285714286e-05\n",
      "epoch: 1, loss: 4.645, avg: 4.38, latest lr: 1.7371428571428573e-05\n",
      "epoch: 1, loss: 4.806, avg: 4.39, latest lr: 1.7357142857142856e-05\n",
      "epoch: 1, loss: 4.043, avg: 4.39, latest lr: 1.7342857142857143e-05\n",
      "epoch: 1, loss: 4.661, avg: 4.39, latest lr: 1.732857142857143e-05\n",
      "epoch: 1, loss: 3.953, avg: 4.39, latest lr: 1.7314285714285717e-05\n",
      "epoch: 1, loss: 4.531, avg: 4.39, latest lr: 1.73e-05\n",
      "epoch: 1, loss: 4.406, avg: 4.39, latest lr: 1.7285714285714287e-05\n",
      "epoch: 1, loss: 4.090, avg: 4.39, latest lr: 1.727142857142857e-05\n",
      "epoch: 1, loss: 4.521, avg: 4.39, latest lr: 1.7257142857142857e-05\n",
      "epoch: 1, loss: 2.984, avg: 4.39, latest lr: 1.7242857142857144e-05\n",
      "epoch: 1, loss: 5.104, avg: 4.39, latest lr: 1.722857142857143e-05\n",
      "epoch: 1, loss: 4.897, avg: 4.39, latest lr: 1.7214285714285715e-05\n",
      "epoch: 1, loss: 3.759, avg: 4.39, latest lr: 1.7199999999999998e-05\n",
      "epoch: 1, loss: 4.474, avg: 4.39, latest lr: 1.7185714285714285e-05\n",
      "epoch: 1, loss: 4.808, avg: 4.39, latest lr: 1.717142857142857e-05\n",
      "epoch: 1, loss: 5.447, avg: 4.39, latest lr: 1.715714285714286e-05\n",
      "epoch: 1, loss: 5.006, avg: 4.40, latest lr: 1.7142857142857145e-05\n",
      "epoch: 1, loss: 4.032, avg: 4.40, latest lr: 1.712857142857143e-05\n",
      "epoch: 1, loss: 4.072, avg: 4.40, latest lr: 1.7114285714285715e-05\n",
      "epoch: 1, loss: 3.844, avg: 4.40, latest lr: 1.7100000000000002e-05\n",
      "epoch: 1, loss: 3.480, avg: 4.40, latest lr: 1.7085714285714286e-05\n",
      "epoch: 1, loss: 4.077, avg: 4.40, latest lr: 1.7071428571428573e-05\n",
      "epoch: 1, loss: 4.561, avg: 4.40, latest lr: 1.7057142857142856e-05\n",
      "epoch: 1, loss: 5.176, avg: 4.40, latest lr: 1.7042857142857143e-05\n",
      "epoch: 1, loss: 4.196, avg: 4.40, latest lr: 1.702857142857143e-05\n",
      "epoch: 1, loss: 5.857, avg: 4.40, latest lr: 1.7014285714285716e-05\n",
      "epoch: 1, loss: 4.210, avg: 4.40, latest lr: 1.7000000000000003e-05\n",
      "epoch: 1, loss: 3.409, avg: 4.40, latest lr: 1.6985714285714287e-05\n",
      "epoch: 1, loss: 3.960, avg: 4.40, latest lr: 1.697142857142857e-05\n",
      "epoch: 1, loss: 4.621, avg: 4.40, latest lr: 1.6957142857142857e-05\n",
      "epoch: 1, loss: 3.744, avg: 4.40, latest lr: 1.6942857142857144e-05\n",
      "epoch: 1, loss: 3.510, avg: 4.40, latest lr: 1.692857142857143e-05\n",
      "epoch: 1, loss: 3.868, avg: 4.40, latest lr: 1.6914285714285717e-05\n",
      "epoch: 1, loss: 4.736, avg: 4.41, latest lr: 1.69e-05\n",
      "epoch: 1, loss: 3.944, avg: 4.41, latest lr: 1.6885714285714284e-05\n",
      "epoch: 1, loss: 5.097, avg: 4.41, latest lr: 1.687142857142857e-05\n",
      "epoch: 1, loss: 4.305, avg: 4.41, latest lr: 1.6857142857142858e-05\n",
      "epoch: 1, loss: 4.860, avg: 4.41, latest lr: 1.6842857142857145e-05\n",
      "epoch: 1, loss: 5.763, avg: 4.41, latest lr: 1.6828571428571428e-05\n",
      "epoch: 1, loss: 3.204, avg: 4.41, latest lr: 1.6814285714285715e-05\n",
      "epoch: 1, loss: 4.552, avg: 4.41, latest lr: 1.6800000000000002e-05\n",
      "epoch: 1, loss: 4.185, avg: 4.41, latest lr: 1.6785714285714285e-05\n",
      "epoch: 1, loss: 5.879, avg: 4.41, latest lr: 1.6771428571428572e-05\n",
      "epoch: 1, loss: 4.676, avg: 4.41, latest lr: 1.675714285714286e-05\n",
      "epoch: 1, loss: 3.692, avg: 4.41, latest lr: 1.6742857142857142e-05\n",
      "epoch: 1, loss: 5.098, avg: 4.41, latest lr: 1.672857142857143e-05\n",
      "epoch: 1, loss: 6.153, avg: 4.41, latest lr: 1.6714285714285716e-05\n",
      "epoch: 1, loss: 5.459, avg: 4.41, latest lr: 1.6700000000000003e-05\n",
      "epoch: 1, loss: 4.690, avg: 4.42, latest lr: 1.6685714285714286e-05\n",
      "epoch: 1, loss: 4.255, avg: 4.42, latest lr: 1.667142857142857e-05\n",
      "epoch: 1, loss: 5.091, avg: 4.42, latest lr: 1.6657142857142856e-05\n",
      "epoch: 1, loss: 3.570, avg: 4.42, latest lr: 1.6642857142857143e-05\n",
      "epoch: 1, loss: 4.346, avg: 4.42, latest lr: 1.662857142857143e-05\n",
      "epoch: 1, loss: 4.608, avg: 4.42, latest lr: 1.6614285714285717e-05\n",
      "epoch: 1, loss: 4.894, avg: 4.42, latest lr: 1.66e-05\n",
      "epoch: 1, loss: 5.200, avg: 4.42, latest lr: 1.6585714285714287e-05\n",
      "epoch: 1, loss: 4.627, avg: 4.42, latest lr: 1.657142857142857e-05\n",
      "epoch: 1, loss: 5.996, avg: 4.42, latest lr: 1.6557142857142857e-05\n",
      "epoch: 1, loss: 5.132, avg: 4.42, latest lr: 1.6542857142857144e-05\n",
      "epoch: 1, loss: 4.396, avg: 4.42, latest lr: 1.652857142857143e-05\n",
      "epoch: 1, loss: 4.013, avg: 4.42, latest lr: 1.6514285714285714e-05\n",
      "epoch: 1, loss: 5.070, avg: 4.42, latest lr: 1.65e-05\n",
      "epoch: 1, loss: 2.797, avg: 4.42, latest lr: 1.6485714285714288e-05\n",
      "epoch: 1, loss: 3.987, avg: 4.43, latest lr: 1.647142857142857e-05\n",
      "epoch: 1, loss: 5.032, avg: 4.43, latest lr: 1.645714285714286e-05\n",
      "epoch: 1, loss: 4.150, avg: 4.43, latest lr: 1.6442857142857142e-05\n",
      "epoch: 1, loss: 5.090, avg: 4.43, latest lr: 1.642857142857143e-05\n",
      "epoch: 1, loss: 5.188, avg: 4.43, latest lr: 1.6414285714285715e-05\n",
      "epoch: 1, loss: 3.927, avg: 4.43, latest lr: 1.6400000000000002e-05\n",
      "epoch: 1, loss: 5.598, avg: 4.43, latest lr: 1.638571428571429e-05\n",
      "epoch: 1, loss: 5.016, avg: 4.43, latest lr: 1.6371428571428572e-05\n",
      "epoch: 1, loss: 4.216, avg: 4.43, latest lr: 1.6357142857142856e-05\n",
      "epoch: 1, loss: 5.572, avg: 4.43, latest lr: 1.6342857142857143e-05\n",
      "epoch: 1, loss: 4.983, avg: 4.43, latest lr: 1.632857142857143e-05\n",
      "epoch: 1, loss: 5.629, avg: 4.43, latest lr: 1.6314285714285716e-05\n",
      "epoch: 1, loss: 3.731, avg: 4.43, latest lr: 1.63e-05\n",
      "epoch: 1, loss: 4.090, avg: 4.43, latest lr: 1.6285714285714287e-05\n",
      "epoch: 1, loss: 4.437, avg: 4.43, latest lr: 1.6271428571428573e-05\n",
      "epoch: 1, loss: 6.183, avg: 4.44, latest lr: 1.6257142857142857e-05\n",
      "epoch: 1, loss: 4.893, avg: 4.44, latest lr: 1.6242857142857144e-05\n",
      "epoch: 1, loss: 4.275, avg: 4.44, latest lr: 1.622857142857143e-05\n",
      "epoch: 1, loss: 5.579, avg: 4.44, latest lr: 1.6214285714285714e-05\n",
      "epoch: 1, loss: 4.253, avg: 4.44, latest lr: 1.62e-05\n",
      "epoch: 1, loss: 3.712, avg: 4.44, latest lr: 1.6185714285714288e-05\n",
      "epoch: 1, loss: 5.285, avg: 4.44, latest lr: 1.6171428571428574e-05\n",
      "epoch: 1, loss: 5.490, avg: 4.44, latest lr: 1.6157142857142858e-05\n",
      "epoch: 1, loss: 5.345, avg: 4.44, latest lr: 1.614285714285714e-05\n",
      "epoch: 1, loss: 5.301, avg: 4.44, latest lr: 1.6128571428571428e-05\n",
      "epoch: 1, loss: 4.087, avg: 4.44, latest lr: 1.6114285714285715e-05\n",
      "epoch: 1, loss: 4.487, avg: 4.44, latest lr: 1.6100000000000002e-05\n",
      "epoch: 1, loss: 6.054, avg: 4.44, latest lr: 1.608571428571429e-05\n",
      "epoch: 1, loss: 4.682, avg: 4.44, latest lr: 1.6071428571428572e-05\n",
      "epoch: 1, loss: 3.972, avg: 4.45, latest lr: 1.6057142857142855e-05\n",
      "epoch: 1, loss: 4.090, avg: 4.45, latest lr: 1.6042857142857142e-05\n",
      "epoch: 1, loss: 5.348, avg: 4.45, latest lr: 1.602857142857143e-05\n",
      "epoch: 1, loss: 4.603, avg: 4.45, latest lr: 1.6014285714285716e-05\n",
      "epoch: 1, loss: 5.501, avg: 4.45, latest lr: 1.6000000000000003e-05\n",
      "epoch: 1, loss: 3.775, avg: 4.45, latest lr: 1.5985714285714286e-05\n",
      "epoch: 1, loss: 5.141, avg: 4.45, latest lr: 1.5971428571428573e-05\n",
      "epoch: 1, loss: 5.217, avg: 4.45, latest lr: 1.5957142857142856e-05\n",
      "epoch: 1, loss: 5.249, avg: 4.45, latest lr: 1.5942857142857143e-05\n",
      "epoch: 1, loss: 3.450, avg: 4.45, latest lr: 1.592857142857143e-05\n",
      "epoch: 1, loss: 5.862, avg: 4.45, latest lr: 1.5914285714285713e-05\n",
      "epoch: 1, loss: 5.685, avg: 4.45, latest lr: 1.59e-05\n",
      "epoch: 1, loss: 5.700, avg: 4.45, latest lr: 1.5885714285714287e-05\n",
      "epoch: 1, loss: 3.381, avg: 4.45, latest lr: 1.5871428571428574e-05\n",
      "epoch: 1, loss: 6.040, avg: 4.46, latest lr: 1.5857142857142857e-05\n",
      "epoch: 1, loss: 5.038, avg: 4.46, latest lr: 1.5842857142857144e-05\n",
      "epoch: 1, loss: 4.150, avg: 4.46, latest lr: 1.5828571428571428e-05\n",
      "epoch: 1, loss: 4.199, avg: 4.46, latest lr: 1.5814285714285714e-05\n",
      "epoch: 1, loss: 4.287, avg: 4.46, latest lr: 1.58e-05\n",
      "epoch: 1, loss: 5.995, avg: 4.46, latest lr: 1.5785714285714288e-05\n",
      "epoch: 1, loss: 6.339, avg: 4.46, latest lr: 1.577142857142857e-05\n",
      "epoch: 1, loss: 6.386, avg: 4.46, latest lr: 1.5757142857142858e-05\n",
      "epoch: 1, loss: 4.561, avg: 4.46, latest lr: 1.574285714285714e-05\n",
      "epoch: 1, loss: 3.125, avg: 4.46, latest lr: 1.572857142857143e-05\n",
      "epoch: 1, loss: 5.465, avg: 4.46, latest lr: 1.5714285714285715e-05\n",
      "epoch: 1, loss: 3.878, avg: 4.46, latest lr: 1.5700000000000002e-05\n",
      "epoch: 1, loss: 5.512, avg: 4.46, latest lr: 1.5685714285714286e-05\n",
      "epoch: 1, loss: 5.099, avg: 4.46, latest lr: 1.5671428571428572e-05\n",
      "epoch: 1, loss: 3.893, avg: 4.46, latest lr: 1.565714285714286e-05\n",
      "epoch: 1, loss: 3.724, avg: 4.47, latest lr: 1.5642857142857143e-05\n",
      "epoch: 1, loss: 5.064, avg: 4.47, latest lr: 1.562857142857143e-05\n",
      "epoch: 1, loss: 4.154, avg: 4.47, latest lr: 1.5614285714285716e-05\n",
      "epoch: 1, loss: 3.355, avg: 4.47, latest lr: 1.56e-05\n",
      "epoch: 1, loss: 4.902, avg: 4.47, latest lr: 1.5585714285714287e-05\n",
      "epoch: 1, loss: 4.570, avg: 4.47, latest lr: 1.5571428571428573e-05\n",
      "epoch: 1, loss: 4.937, avg: 4.47, latest lr: 1.555714285714286e-05\n",
      "epoch: 1, loss: 4.634, avg: 4.47, latest lr: 1.5542857142857144e-05\n",
      "epoch: 1, loss: 5.567, avg: 4.47, latest lr: 1.5528571428571427e-05\n",
      "epoch: 1, loss: 5.108, avg: 4.47, latest lr: 1.5514285714285714e-05\n",
      "epoch: 1, loss: 4.178, avg: 4.47, latest lr: 1.55e-05\n",
      "epoch: 1, loss: 3.530, avg: 4.47, latest lr: 1.5485714285714287e-05\n",
      "epoch: 1, loss: 4.669, avg: 4.47, latest lr: 1.5471428571428574e-05\n",
      "epoch: 1, loss: 5.438, avg: 4.47, latest lr: 1.5457142857142858e-05\n",
      "epoch: 1, loss: 5.202, avg: 4.47, latest lr: 1.544285714285714e-05\n",
      "epoch: 1, loss: 5.093, avg: 4.48, latest lr: 1.5428571428571428e-05\n",
      "epoch: 1, loss: 4.142, avg: 4.48, latest lr: 1.5414285714285715e-05\n",
      "epoch: 1, loss: 4.109, avg: 4.48, latest lr: 1.54e-05\n",
      "epoch: 1, loss: 3.476, avg: 4.48, latest lr: 1.5385714285714285e-05\n",
      "epoch: 1, loss: 3.005, avg: 4.48, latest lr: 1.5371428571428572e-05\n",
      "epoch: 1, loss: 3.961, avg: 4.48, latest lr: 1.535714285714286e-05\n",
      "epoch: 1, loss: 4.812, avg: 4.48, latest lr: 1.5342857142857146e-05\n",
      "epoch: 1, loss: 5.595, avg: 4.48, latest lr: 1.532857142857143e-05\n",
      "epoch: 1, loss: 4.745, avg: 4.48, latest lr: 1.5314285714285716e-05\n",
      "epoch: 1, loss: 3.021, avg: 4.48, latest lr: 1.53e-05\n",
      "epoch: 1, loss: 5.361, avg: 4.48, latest lr: 1.5285714285714286e-05\n",
      "epoch: 1, loss: 5.064, avg: 4.48, latest lr: 1.5271428571428573e-05\n",
      "epoch: 1, loss: 5.010, avg: 4.48, latest lr: 1.5257142857142858e-05\n",
      "epoch: 1, loss: 4.917, avg: 4.48, latest lr: 1.5242857142857145e-05\n",
      "epoch: 1, loss: 5.660, avg: 4.48, latest lr: 1.5228571428571428e-05\n",
      "epoch: 1, loss: 4.886, avg: 4.49, latest lr: 1.5214285714285715e-05\n",
      "epoch: 1, loss: 4.851, avg: 4.49, latest lr: 1.52e-05\n",
      "epoch: 1, loss: 3.723, avg: 4.49, latest lr: 1.5185714285714287e-05\n",
      "epoch: 1, loss: 4.581, avg: 4.49, latest lr: 1.5171428571428572e-05\n",
      "epoch: 1, loss: 3.941, avg: 4.49, latest lr: 1.5157142857142859e-05\n",
      "epoch: 1, loss: 4.335, avg: 4.49, latest lr: 1.5142857142857144e-05\n",
      "epoch: 1, loss: 4.171, avg: 4.49, latest lr: 1.5128571428571427e-05\n",
      "epoch: 1, loss: 4.620, avg: 4.49, latest lr: 1.5114285714285714e-05\n",
      "epoch: 1, loss: 5.001, avg: 4.49, latest lr: 1.51e-05\n",
      "epoch: 1, loss: 4.545, avg: 4.49, latest lr: 1.5085714285714286e-05\n",
      "epoch: 1, loss: 5.515, avg: 4.49, latest lr: 1.5071428571428573e-05\n",
      "epoch: 1, loss: 4.473, avg: 4.49, latest lr: 1.5057142857142858e-05\n",
      "epoch: 1, loss: 4.870, avg: 4.49, latest lr: 1.5042857142857145e-05\n",
      "epoch: 1, loss: 3.215, avg: 4.49, latest lr: 1.5028571428571428e-05\n",
      "epoch: 1, loss: 5.723, avg: 4.49, latest lr: 1.5014285714285714e-05\n",
      "epoch: 1, loss: 4.702, avg: 4.49, latest lr: 1.5e-05\n",
      "epoch: 1, loss: 5.780, avg: 4.50, latest lr: 1.4985714285714286e-05\n",
      "epoch: 1, loss: 4.079, avg: 4.50, latest lr: 1.4971428571428572e-05\n",
      "epoch: 1, loss: 5.053, avg: 4.50, latest lr: 1.4957142857142859e-05\n",
      "epoch: 1, loss: 5.921, avg: 4.50, latest lr: 1.4942857142857144e-05\n",
      "epoch: 1, loss: 4.669, avg: 4.50, latest lr: 1.4928571428571431e-05\n",
      "epoch: 1, loss: 6.066, avg: 4.50, latest lr: 1.4914285714285715e-05\n",
      "epoch: 1, loss: 4.742, avg: 4.50, latest lr: 1.49e-05\n",
      "epoch: 1, loss: 4.478, avg: 4.50, latest lr: 1.4885714285714286e-05\n",
      "epoch: 1, loss: 4.484, avg: 4.50, latest lr: 1.4871428571428572e-05\n",
      "epoch: 1, loss: 4.141, avg: 4.50, latest lr: 1.4857142857142858e-05\n",
      "epoch: 1, loss: 5.541, avg: 4.50, latest lr: 1.4842857142857145e-05\n",
      "epoch: 1, loss: 5.348, avg: 4.50, latest lr: 1.482857142857143e-05\n",
      "epoch: 1, loss: 5.737, avg: 4.50, latest lr: 1.4814285714285714e-05\n",
      "epoch: 1, loss: 5.430, avg: 4.51, latest lr: 1.48e-05\n",
      "epoch: 1, loss: 6.338, avg: 4.51, latest lr: 1.4785714285714286e-05\n",
      "epoch: 1, loss: 4.168, avg: 4.51, latest lr: 1.4771428571428573e-05\n",
      "epoch: 1, loss: 5.093, avg: 4.51, latest lr: 1.4757142857142858e-05\n",
      "epoch: 1, loss: 4.495, avg: 4.51, latest lr: 1.4742857142857144e-05\n",
      "epoch: 1, loss: 5.750, avg: 4.51, latest lr: 1.4728571428571431e-05\n",
      "epoch: 1, loss: 3.205, avg: 4.51, latest lr: 1.4714285714285713e-05\n",
      "epoch: 1, loss: 4.487, avg: 4.51, latest lr: 1.47e-05\n",
      "epoch: 1, loss: 4.971, avg: 4.51, latest lr: 1.4685714285714287e-05\n",
      "epoch: 1, loss: 4.354, avg: 4.51, latest lr: 1.4671428571428572e-05\n",
      "epoch: 1, loss: 4.802, avg: 4.51, latest lr: 1.4657142857142859e-05\n",
      "epoch: 1, loss: 5.170, avg: 4.51, latest lr: 1.4642857142857144e-05\n",
      "epoch: 1, loss: 5.712, avg: 4.51, latest lr: 1.462857142857143e-05\n",
      "epoch: 1, loss: 5.029, avg: 4.51, latest lr: 1.4614285714285714e-05\n",
      "epoch: 1, loss: 4.668, avg: 4.51, latest lr: 1.4599999999999999e-05\n",
      "epoch: 1, loss: 4.592, avg: 4.52, latest lr: 1.4585714285714286e-05\n",
      "epoch: 1, loss: 3.909, avg: 4.52, latest lr: 1.4571428571428573e-05\n",
      "epoch: 1, loss: 5.340, avg: 4.52, latest lr: 1.4557142857142858e-05\n",
      "epoch: 1, loss: 5.478, avg: 4.52, latest lr: 1.4542857142857145e-05\n",
      "epoch: 1, loss: 5.172, avg: 4.52, latest lr: 1.452857142857143e-05\n",
      "epoch: 1, loss: 5.333, avg: 4.52, latest lr: 1.4514285714285713e-05\n",
      "epoch: 1, loss: 5.530, avg: 4.52, latest lr: 1.45e-05\n",
      "epoch: 1, loss: 5.289, avg: 4.52, latest lr: 1.4485714285714285e-05\n",
      "epoch: 1, loss: 5.124, avg: 4.52, latest lr: 1.4471428571428572e-05\n",
      "epoch: 1, loss: 5.913, avg: 4.52, latest lr: 1.4457142857142857e-05\n",
      "epoch: 1, loss: 4.765, avg: 4.52, latest lr: 1.4442857142857144e-05\n",
      "epoch: 1, loss: 3.728, avg: 4.52, latest lr: 1.442857142857143e-05\n",
      "epoch: 1, loss: 5.850, avg: 4.52, latest lr: 1.4414285714285716e-05\n",
      "epoch: 1, loss: 5.205, avg: 4.53, latest lr: 1.44e-05\n",
      "epoch: 1, loss: 5.434, avg: 4.53, latest lr: 1.4385714285714286e-05\n",
      "epoch: 1, loss: 4.550, avg: 4.53, latest lr: 1.4371428571428571e-05\n",
      "epoch: 1, loss: 3.054, avg: 4.53, latest lr: 1.4357142857142858e-05\n",
      "epoch: 1, loss: 4.874, avg: 4.53, latest lr: 1.4342857142857143e-05\n",
      "epoch: 1, loss: 5.012, avg: 4.53, latest lr: 1.432857142857143e-05\n",
      "epoch: 1, loss: 4.877, avg: 4.53, latest lr: 1.4314285714285717e-05\n",
      "epoch: 1, loss: 5.391, avg: 4.53, latest lr: 1.43e-05\n",
      "epoch: 1, loss: 3.900, avg: 4.53, latest lr: 1.4285714285714285e-05\n",
      "epoch: 1, loss: 4.493, avg: 4.53, latest lr: 1.4271428571428572e-05\n",
      "epoch: 1, loss: 3.702, avg: 4.53, latest lr: 1.4257142857142857e-05\n",
      "epoch: 1, loss: 3.350, avg: 4.53, latest lr: 1.4242857142857144e-05\n",
      "epoch: 1, loss: 4.904, avg: 4.53, latest lr: 1.422857142857143e-05\n",
      "epoch: 1, loss: 3.096, avg: 4.53, latest lr: 1.4214285714285716e-05\n",
      "epoch: 1, loss: 5.539, avg: 4.53, latest lr: 1.42e-05\n",
      "epoch: 1, loss: 4.285, avg: 4.53, latest lr: 1.4185714285714285e-05\n",
      "epoch: 1, loss: 4.746, avg: 4.54, latest lr: 1.4171428571428572e-05\n",
      "epoch: 1, loss: 5.170, avg: 4.54, latest lr: 1.4157142857142858e-05\n",
      "epoch: 1, loss: 5.416, avg: 4.54, latest lr: 1.4142857142857143e-05\n",
      "epoch: 1, loss: 4.216, avg: 4.54, latest lr: 1.412857142857143e-05\n",
      "epoch: 1, loss: 4.483, avg: 4.54, latest lr: 1.4114285714285715e-05\n",
      "epoch: 1, loss: 4.280, avg: 4.54, latest lr: 1.4099999999999999e-05\n",
      "epoch: 1, loss: 4.553, avg: 4.54, latest lr: 1.4085714285714286e-05\n",
      "epoch: 1, loss: 4.508, avg: 4.54, latest lr: 1.407142857142857e-05\n",
      "epoch: 1, loss: 4.031, avg: 4.54, latest lr: 1.4057142857142858e-05\n",
      "epoch: 1, loss: 5.008, avg: 4.54, latest lr: 1.4042857142857144e-05\n",
      "epoch: 1, loss: 4.157, avg: 4.54, latest lr: 1.402857142857143e-05\n",
      "epoch: 1, loss: 4.307, avg: 4.54, latest lr: 1.4014285714285716e-05\n",
      "epoch: 1, loss: 5.245, avg: 4.54, latest lr: 1.4000000000000001e-05\n",
      "epoch: 1, loss: 5.096, avg: 4.54, latest lr: 1.3985714285714285e-05\n",
      "epoch: 1, loss: 4.246, avg: 4.54, latest lr: 1.3971428571428572e-05\n",
      "epoch: 1, loss: 3.341, avg: 4.54, latest lr: 1.3957142857142857e-05\n",
      "epoch: 1, loss: 3.830, avg: 4.55, latest lr: 1.3942857142857144e-05\n",
      "epoch: 1, loss: 4.096, avg: 4.55, latest lr: 1.392857142857143e-05\n",
      "epoch: 1, loss: 4.769, avg: 4.55, latest lr: 1.3914285714285716e-05\n",
      "epoch: 1, loss: 4.525, avg: 4.55, latest lr: 1.3900000000000002e-05\n",
      "epoch: 1, loss: 3.564, avg: 4.55, latest lr: 1.3885714285714286e-05\n",
      "epoch: 1, loss: 4.393, avg: 4.55, latest lr: 1.3871428571428571e-05\n",
      "epoch: 1, loss: 3.681, avg: 4.55, latest lr: 1.3857142857142858e-05\n",
      "epoch: 1, loss: 4.958, avg: 4.55, latest lr: 1.3842857142857143e-05\n",
      "epoch: 1, loss: 4.911, avg: 4.55, latest lr: 1.382857142857143e-05\n",
      "epoch: 1, loss: 5.357, avg: 4.55, latest lr: 1.3814285714285715e-05\n",
      "epoch: 1, loss: 4.056, avg: 4.55, latest lr: 1.3800000000000002e-05\n",
      "epoch: 1, loss: 4.352, avg: 4.55, latest lr: 1.3785714285714285e-05\n",
      "epoch: 1, loss: 4.890, avg: 4.55, latest lr: 1.3771428571428572e-05\n",
      "epoch: 1, loss: 4.785, avg: 4.55, latest lr: 1.3757142857142857e-05\n",
      "epoch: 1, loss: 4.552, avg: 4.55, latest lr: 1.3742857142857144e-05\n",
      "epoch: 1, loss: 4.235, avg: 4.56, latest lr: 1.3728571428571429e-05\n",
      "epoch: 1, loss: 4.680, avg: 4.56, latest lr: 1.3714285714285716e-05\n",
      "epoch: 1, loss: 4.364, avg: 4.56, latest lr: 1.3700000000000001e-05\n",
      "epoch: 1, loss: 4.674, avg: 4.56, latest lr: 1.3685714285714284e-05\n",
      "epoch: 1, loss: 5.247, avg: 4.56, latest lr: 1.3671428571428571e-05\n",
      "epoch: 1, loss: 4.057, avg: 4.56, latest lr: 1.3657142857142858e-05\n",
      "epoch: 1, loss: 5.250, avg: 4.56, latest lr: 1.3642857142857143e-05\n",
      "epoch: 1, loss: 4.935, avg: 4.56, latest lr: 1.362857142857143e-05\n",
      "epoch: 1, loss: 4.080, avg: 4.56, latest lr: 1.3614285714285715e-05\n",
      "epoch: 1, loss: 3.146, avg: 4.56, latest lr: 1.3600000000000002e-05\n",
      "epoch: 1, loss: 5.326, avg: 4.56, latest lr: 1.3585714285714287e-05\n",
      "epoch: 1, loss: 3.972, avg: 4.56, latest lr: 1.357142857142857e-05\n",
      "epoch: 1, loss: 5.119, avg: 4.56, latest lr: 1.3557142857142857e-05\n",
      "epoch: 1, loss: 4.716, avg: 4.56, latest lr: 1.3542857142857142e-05\n",
      "epoch: 1, loss: 4.666, avg: 4.56, latest lr: 1.352857142857143e-05\n",
      "epoch: 1, loss: 3.259, avg: 4.56, latest lr: 1.3514285714285716e-05\n",
      "epoch: 1, loss: 4.013, avg: 4.57, latest lr: 1.3500000000000001e-05\n",
      "epoch: 1, loss: 4.812, avg: 4.57, latest lr: 1.3485714285714288e-05\n",
      "epoch: 1, loss: 4.283, avg: 4.57, latest lr: 1.3471428571428571e-05\n",
      "epoch: 1, loss: 3.832, avg: 4.57, latest lr: 1.3457142857142857e-05\n",
      "epoch: 1, loss: 5.416, avg: 4.57, latest lr: 1.3442857142857143e-05\n",
      "epoch: 1, loss: 6.046, avg: 4.57, latest lr: 1.3428571428571429e-05\n",
      "epoch: 1, loss: 4.006, avg: 4.57, latest lr: 1.3414285714285715e-05\n",
      "epoch: 1, loss: 4.870, avg: 4.57, latest lr: 1.3400000000000002e-05\n",
      "epoch: 1, loss: 5.314, avg: 4.57, latest lr: 1.3385714285714287e-05\n",
      "epoch: 1, loss: 4.564, avg: 4.57, latest lr: 1.337142857142857e-05\n",
      "epoch: 1, loss: 4.254, avg: 4.57, latest lr: 1.3357142857142858e-05\n",
      "epoch: 1, loss: 5.056, avg: 4.57, latest lr: 1.3342857142857143e-05\n",
      "epoch: 1, loss: 3.975, avg: 4.57, latest lr: 1.332857142857143e-05\n",
      "epoch: 1, loss: 2.840, avg: 4.57, latest lr: 1.3314285714285715e-05\n",
      "epoch: 1, loss: 4.754, avg: 4.57, latest lr: 1.3300000000000001e-05\n",
      "epoch: 1, loss: 3.890, avg: 4.57, latest lr: 1.3285714285714288e-05\n",
      "epoch: 1, loss: 3.877, avg: 4.58, latest lr: 1.327142857142857e-05\n",
      "epoch: 1, loss: 6.713, avg: 4.58, latest lr: 1.3257142857142857e-05\n",
      "epoch: 1, loss: 4.930, avg: 4.58, latest lr: 1.3242857142857144e-05\n",
      "epoch: 1, loss: 4.977, avg: 4.58, latest lr: 1.3228571428571429e-05\n",
      "epoch: 1, loss: 3.473, avg: 4.58, latest lr: 1.3214285714285716e-05\n",
      "epoch: 1, loss: 4.672, avg: 4.58, latest lr: 1.32e-05\n",
      "epoch: 1, loss: 6.169, avg: 4.58, latest lr: 1.3185714285714287e-05\n",
      "epoch: 1, loss: 3.654, avg: 4.58, latest lr: 1.3171428571428571e-05\n",
      "epoch: 1, loss: 4.964, avg: 4.58, latest lr: 1.3157142857142856e-05\n",
      "epoch: 1, loss: 3.658, avg: 4.58, latest lr: 1.3142857142857143e-05\n",
      "epoch: 1, loss: 3.320, avg: 4.58, latest lr: 1.312857142857143e-05\n",
      "epoch: 1, loss: 4.463, avg: 4.58, latest lr: 1.3114285714285715e-05\n",
      "epoch: 1, loss: 4.648, avg: 4.58, latest lr: 1.3100000000000002e-05\n",
      "epoch: 1, loss: 4.484, avg: 4.58, latest lr: 1.3085714285714287e-05\n",
      "epoch: 1, loss: 3.572, avg: 4.58, latest lr: 1.3071428571428574e-05\n",
      "epoch: 1, loss: 4.787, avg: 4.59, latest lr: 1.3057142857142857e-05\n",
      "epoch: 1, loss: 4.485, avg: 4.59, latest lr: 1.3042857142857142e-05\n",
      "epoch: 1, loss: 4.371, avg: 4.59, latest lr: 1.3028571428571429e-05\n",
      "epoch: 1, loss: 3.784, avg: 4.59, latest lr: 1.3014285714285716e-05\n",
      "epoch: 1, loss: 4.589, avg: 4.59, latest lr: 1.3000000000000001e-05\n",
      "epoch: 1, loss: 3.999, avg: 4.59, latest lr: 1.2985714285714288e-05\n",
      "epoch: 1, loss: 4.602, avg: 4.59, latest lr: 1.2971428571428573e-05\n",
      "epoch: 1, loss: 3.628, avg: 4.59, latest lr: 1.2957142857142856e-05\n",
      "epoch: 1, loss: 3.430, avg: 4.59, latest lr: 1.2942857142857143e-05\n",
      "epoch: 1, loss: 4.220, avg: 4.59, latest lr: 1.2928571428571428e-05\n",
      "epoch: 1, loss: 4.196, avg: 4.59, latest lr: 1.2914285714285715e-05\n",
      "epoch: 1, loss: 3.758, avg: 4.59, latest lr: 1.29e-05\n",
      "epoch: 1, loss: 4.769, avg: 4.59, latest lr: 1.2885714285714287e-05\n",
      "epoch: 1, loss: 3.639, avg: 4.59, latest lr: 1.2871428571428574e-05\n",
      "epoch: 1, loss: 4.897, avg: 4.59, latest lr: 1.2857142857142857e-05\n",
      "epoch: 1, loss: 3.196, avg: 4.59, latest lr: 1.2842857142857142e-05\n",
      "epoch: 1, loss: 4.767, avg: 4.59, latest lr: 1.282857142857143e-05\n",
      "epoch: 1, loss: 4.329, avg: 4.60, latest lr: 1.2814285714285714e-05\n",
      "epoch: 1, loss: 3.990, avg: 4.60, latest lr: 1.2800000000000001e-05\n",
      "epoch: 1, loss: 3.750, avg: 4.60, latest lr: 1.2785714285714286e-05\n",
      "epoch: 1, loss: 6.140, avg: 4.60, latest lr: 1.2771428571428573e-05\n",
      "epoch: 1, loss: 4.893, avg: 4.60, latest lr: 1.2757142857142856e-05\n",
      "epoch: 1, loss: 3.813, avg: 4.60, latest lr: 1.2742857142857143e-05\n",
      "epoch: 1, loss: 4.501, avg: 4.60, latest lr: 1.2728571428571428e-05\n",
      "epoch: 1, loss: 5.584, avg: 4.60, latest lr: 1.2714285714285715e-05\n",
      "epoch: 1, loss: 5.737, avg: 4.60, latest lr: 1.27e-05\n",
      "epoch: 1, loss: 5.038, avg: 4.60, latest lr: 1.2685714285714287e-05\n",
      "epoch: 1, loss: 3.970, avg: 4.60, latest lr: 1.2671428571428572e-05\n",
      "epoch: 1, loss: 5.095, avg: 4.60, latest lr: 1.2657142857142859e-05\n",
      "epoch: 1, loss: 4.850, avg: 4.60, latest lr: 1.2642857142857143e-05\n",
      "epoch: 1, loss: 5.482, avg: 4.60, latest lr: 1.2628571428571428e-05\n",
      "epoch: 1, loss: 2.977, avg: 4.60, latest lr: 1.2614285714285715e-05\n",
      "epoch: 1, loss: 4.780, avg: 4.61, latest lr: 1.2600000000000001e-05\n",
      "epoch: 1, loss: 5.410, avg: 4.61, latest lr: 1.2585714285714286e-05\n",
      "epoch: 1, loss: 5.176, avg: 4.61, latest lr: 1.2571428571428573e-05\n",
      "epoch: 1, loss: 5.590, avg: 4.61, latest lr: 1.2557142857142858e-05\n",
      "epoch: 1, loss: 3.959, avg: 4.61, latest lr: 1.2542857142857142e-05\n",
      "epoch: 1, loss: 4.779, avg: 4.61, latest lr: 1.2528571428571429e-05\n",
      "epoch: 1, loss: 4.836, avg: 4.61, latest lr: 1.2514285714285714e-05\n",
      "epoch: 1, loss: 3.852, avg: 4.61, latest lr: 1.25e-05\n",
      "epoch: 1, loss: 5.179, avg: 4.61, latest lr: 1.2485714285714287e-05\n",
      "epoch: 1, loss: 3.225, avg: 4.61, latest lr: 1.2471428571428571e-05\n",
      "epoch: 1, loss: 5.200, avg: 4.61, latest lr: 1.2457142857142858e-05\n",
      "epoch: 1, loss: 2.694, avg: 4.61, latest lr: 1.2442857142857143e-05\n",
      "epoch: 1, loss: 2.735, avg: 4.61, latest lr: 1.242857142857143e-05\n",
      "epoch: 1, loss: 5.240, avg: 4.61, latest lr: 1.2414285714285715e-05\n",
      "epoch: 1, loss: 4.495, avg: 4.61, latest lr: 1.24e-05\n",
      "epoch: 1, loss: 3.593, avg: 4.61, latest lr: 1.2385714285714287e-05\n",
      "epoch: 1, loss: 3.240, avg: 4.62, latest lr: 1.2371428571428574e-05\n",
      "epoch: 1, loss: 3.237, avg: 4.62, latest lr: 1.2357142857142857e-05\n",
      "epoch: 1, loss: 5.182, avg: 4.62, latest lr: 1.2342857142857144e-05\n",
      "epoch: 1, loss: 4.132, avg: 4.62, latest lr: 1.2328571428571429e-05\n",
      "epoch: 1, loss: 5.173, avg: 4.62, latest lr: 1.2314285714285714e-05\n",
      "epoch: 1, loss: 3.688, avg: 4.62, latest lr: 1.23e-05\n",
      "epoch: 1, loss: 3.886, avg: 4.62, latest lr: 1.2285714285714286e-05\n",
      "epoch: 1, loss: 5.395, avg: 4.62, latest lr: 1.2271428571428573e-05\n",
      "epoch: 1, loss: 3.718, avg: 4.62, latest lr: 1.2257142857142858e-05\n",
      "epoch: 1, loss: 5.132, avg: 4.62, latest lr: 1.2242857142857143e-05\n",
      "epoch: 1, loss: 4.118, avg: 4.62, latest lr: 1.222857142857143e-05\n",
      "epoch: 1, loss: 4.435, avg: 4.62, latest lr: 1.2214285714285715e-05\n",
      "epoch: 1, loss: 3.623, avg: 4.62, latest lr: 1.22e-05\n",
      "epoch: 1, loss: 3.988, avg: 4.62, latest lr: 1.2185714285714287e-05\n",
      "epoch: 1, loss: 3.497, avg: 4.62, latest lr: 1.2171428571428572e-05\n",
      "epoch: 1, loss: 5.030, avg: 4.62, latest lr: 1.2157142857142857e-05\n",
      "epoch: 1, loss: 4.071, avg: 4.63, latest lr: 1.2142857142857144e-05\n",
      "epoch: 1, loss: 5.191, avg: 4.63, latest lr: 1.2128571428571429e-05\n",
      "epoch: 1, loss: 5.525, avg: 4.63, latest lr: 1.2114285714285716e-05\n",
      "epoch: 1, loss: 5.172, avg: 4.63, latest lr: 1.2100000000000001e-05\n",
      "epoch: 1, loss: 3.911, avg: 4.63, latest lr: 1.2085714285714286e-05\n",
      "epoch: 1, loss: 4.747, avg: 4.63, latest lr: 1.2071428571428573e-05\n",
      "epoch: 1, loss: 4.655, avg: 4.63, latest lr: 1.2057142857142856e-05\n",
      "epoch: 1, loss: 3.781, avg: 4.63, latest lr: 1.2042857142857143e-05\n",
      "epoch: 1, loss: 5.121, avg: 4.63, latest lr: 1.202857142857143e-05\n",
      "epoch: 1, loss: 5.796, avg: 4.63, latest lr: 1.2014285714285715e-05\n",
      "epoch: 1, loss: 3.994, avg: 4.63, latest lr: 1.2e-05\n",
      "epoch: 1, loss: 4.750, avg: 4.63, latest lr: 1.1985714285714285e-05\n",
      "epoch: 1, loss: 3.084, avg: 4.63, latest lr: 1.1971428571428572e-05\n",
      "epoch: 1, loss: 4.420, avg: 4.63, latest lr: 1.1957142857142857e-05\n",
      "epoch: 1, loss: 3.386, avg: 4.63, latest lr: 1.1942857142857142e-05\n",
      "epoch: 1, loss: 5.137, avg: 4.63, latest lr: 1.192857142857143e-05\n",
      "epoch: 1, loss: 5.416, avg: 4.64, latest lr: 1.1914285714285716e-05\n",
      "epoch: 1, loss: 3.894, avg: 4.64, latest lr: 1.19e-05\n",
      "epoch: 1, loss: 4.224, avg: 4.64, latest lr: 1.1885714285714286e-05\n",
      "epoch: 1, loss: 3.687, avg: 4.64, latest lr: 1.1871428571428572e-05\n",
      "epoch: 1, loss: 2.757, avg: 4.64, latest lr: 1.1857142857142858e-05\n",
      "epoch: 1, loss: 4.915, avg: 4.64, latest lr: 1.1842857142857143e-05\n",
      "epoch: 1, loss: 3.052, avg: 4.64, latest lr: 1.1828571428571429e-05\n",
      "epoch: 1, loss: 3.937, avg: 4.64, latest lr: 1.1814285714285715e-05\n",
      "epoch: 1, loss: 4.561, avg: 4.64, latest lr: 1.18e-05\n",
      "epoch: 1, loss: 4.686, avg: 4.64, latest lr: 1.1785714285714286e-05\n",
      "epoch: 1, loss: 5.333, avg: 4.64, latest lr: 1.1771428571428572e-05\n",
      "epoch: 1, loss: 4.683, avg: 4.64, latest lr: 1.1757142857142858e-05\n",
      "epoch: 1, loss: 4.618, avg: 4.64, latest lr: 1.1742857142857143e-05\n",
      "epoch: 1, loss: 5.978, avg: 4.64, latest lr: 1.172857142857143e-05\n",
      "epoch: 1, loss: 4.693, avg: 4.64, latest lr: 1.1714285714285715e-05\n",
      "epoch: 1, loss: 4.195, avg: 4.65, latest lr: 1.1700000000000001e-05\n",
      "epoch: 1, loss: 4.909, avg: 4.65, latest lr: 1.1685714285714287e-05\n",
      "epoch: 1, loss: 5.251, avg: 4.65, latest lr: 1.1671428571428572e-05\n",
      "epoch: 1, loss: 5.746, avg: 4.65, latest lr: 1.1657142857142859e-05\n",
      "epoch: 1, loss: 4.452, avg: 4.65, latest lr: 1.1642857142857144e-05\n",
      "epoch: 1, loss: 4.954, avg: 4.65, latest lr: 1.1628571428571429e-05\n",
      "epoch: 1, loss: 5.380, avg: 4.65, latest lr: 1.1614285714285716e-05\n",
      "epoch: 1, loss: 4.825, avg: 4.65, latest lr: 1.16e-05\n",
      "epoch: 1, loss: 4.162, avg: 4.65, latest lr: 1.1585714285714286e-05\n",
      "epoch: 1, loss: 4.491, avg: 4.65, latest lr: 1.1571428571428573e-05\n",
      "epoch: 1, loss: 4.849, avg: 4.65, latest lr: 1.1557142857142858e-05\n",
      "epoch: 1, loss: 4.540, avg: 4.65, latest lr: 1.1542857142857143e-05\n",
      "epoch: 1, loss: 4.862, avg: 4.65, latest lr: 1.1528571428571428e-05\n",
      "epoch: 1, loss: 3.639, avg: 4.65, latest lr: 1.1514285714285715e-05\n",
      "epoch: 1, loss: 3.734, avg: 4.65, latest lr: 1.1500000000000002e-05\n",
      "epoch: 1, loss: 4.813, avg: 4.66, latest lr: 1.1485714285714285e-05\n",
      "epoch: 1, loss: 4.811, avg: 4.66, latest lr: 1.1471428571428572e-05\n",
      "epoch: 1, loss: 4.962, avg: 4.66, latest lr: 1.1457142857142859e-05\n",
      "epoch: 1, loss: 4.266, avg: 4.66, latest lr: 1.1442857142857144e-05\n",
      "epoch: 1, loss: 4.427, avg: 4.66, latest lr: 1.1428571428571429e-05\n",
      "epoch: 1, loss: 4.214, avg: 4.66, latest lr: 1.1414285714285714e-05\n",
      "epoch: 1, loss: 5.166, avg: 4.66, latest lr: 1.1400000000000001e-05\n",
      "epoch: 1, loss: 4.398, avg: 4.66, latest lr: 1.1385714285714286e-05\n",
      "epoch: 1, loss: 3.628, avg: 4.66, latest lr: 1.1371428571428571e-05\n",
      "epoch: 1, loss: 3.003, avg: 4.66, latest lr: 1.1357142857142858e-05\n",
      "epoch: 1, loss: 5.824, avg: 4.66, latest lr: 1.1342857142857143e-05\n",
      "epoch: 1, loss: 4.353, avg: 4.66, latest lr: 1.1328571428571428e-05\n",
      "epoch: 1, loss: 5.034, avg: 4.66, latest lr: 1.1314285714285715e-05\n",
      "epoch: 1, loss: 5.066, avg: 4.66, latest lr: 1.13e-05\n",
      "epoch: 1, loss: 5.560, avg: 4.66, latest lr: 1.1285714285714285e-05\n",
      "epoch: 1, loss: 3.731, avg: 4.66, latest lr: 1.1271428571428572e-05\n",
      "epoch: 1, loss: 3.505, avg: 4.67, latest lr: 1.1257142857142857e-05\n",
      "epoch: 1, loss: 4.587, avg: 4.67, latest lr: 1.1242857142857144e-05\n",
      "epoch: 1, loss: 2.644, avg: 4.67, latest lr: 1.122857142857143e-05\n",
      "epoch: 1, loss: 6.523, avg: 4.67, latest lr: 1.1214285714285714e-05\n",
      "epoch: 1, loss: 5.694, avg: 4.67, latest lr: 1.1200000000000001e-05\n",
      "epoch: 1, loss: 3.859, avg: 4.67, latest lr: 1.1185714285714286e-05\n",
      "epoch: 1, loss: 3.894, avg: 4.67, latest lr: 1.1171428571428571e-05\n",
      "epoch: 1, loss: 3.967, avg: 4.67, latest lr: 1.1157142857142858e-05\n",
      "epoch: 1, loss: 4.296, avg: 4.67, latest lr: 1.1142857142857143e-05\n",
      "epoch: 1, loss: 5.351, avg: 4.67, latest lr: 1.1128571428571429e-05\n",
      "epoch: 1, loss: 4.097, avg: 4.67, latest lr: 1.1114285714285715e-05\n",
      "epoch: 1, loss: 4.614, avg: 4.67, latest lr: 1.11e-05\n",
      "epoch: 1, loss: 5.009, avg: 4.67, latest lr: 1.1085714285714287e-05\n",
      "epoch: 1, loss: 4.461, avg: 4.67, latest lr: 1.107142857142857e-05\n",
      "epoch: 1, loss: 5.599, avg: 4.67, latest lr: 1.1057142857142858e-05\n",
      "epoch: 1, loss: 4.219, avg: 4.68, latest lr: 1.1042857142857144e-05\n",
      "epoch: 1, loss: 3.534, avg: 4.68, latest lr: 1.102857142857143e-05\n",
      "epoch: 1, loss: 4.210, avg: 4.68, latest lr: 1.1014285714285715e-05\n",
      "epoch: 1, loss: 4.191, avg: 4.68, latest lr: 1.1000000000000001e-05\n",
      "epoch: 1, loss: 4.899, avg: 4.68, latest lr: 1.0985714285714287e-05\n",
      "epoch: 1, loss: 4.105, avg: 4.68, latest lr: 1.0971428571428572e-05\n",
      "epoch: 1, loss: 5.304, avg: 4.68, latest lr: 1.0957142857142857e-05\n",
      "epoch: 1, loss: 4.593, avg: 4.68, latest lr: 1.0942857142857144e-05\n",
      "epoch: 1, loss: 3.700, avg: 4.68, latest lr: 1.092857142857143e-05\n",
      "epoch: 1, loss: 4.520, avg: 4.68, latest lr: 1.0914285714285714e-05\n",
      "epoch: 1, loss: 4.175, avg: 4.68, latest lr: 1.09e-05\n",
      "epoch: 1, loss: 2.566, avg: 4.68, latest lr: 1.0885714285714286e-05\n",
      "epoch: 1, loss: 4.705, avg: 4.68, latest lr: 1.0871428571428571e-05\n",
      "epoch: 1, loss: 4.181, avg: 4.68, latest lr: 1.0857142857142858e-05\n",
      "epoch: 1, loss: 6.057, avg: 4.68, latest lr: 1.0842857142857143e-05\n",
      "epoch: 1, loss: 4.024, avg: 4.68, latest lr: 1.082857142857143e-05\n",
      "epoch: 1, loss: 4.348, avg: 4.69, latest lr: 1.0814285714285715e-05\n",
      "epoch: 1, loss: 5.935, avg: 4.69, latest lr: 1.08e-05\n",
      "epoch: 1, loss: 4.983, avg: 4.69, latest lr: 1.0785714285714287e-05\n",
      "epoch: 1, loss: 3.055, avg: 4.69, latest lr: 1.0771428571428572e-05\n",
      "epoch: 1, loss: 3.807, avg: 4.69, latest lr: 1.0757142857142857e-05\n",
      "epoch: 1, loss: 4.610, avg: 4.69, latest lr: 1.0742857142857144e-05\n",
      "epoch: 1, loss: 4.763, avg: 4.69, latest lr: 1.0728571428571429e-05\n",
      "epoch: 1, loss: 4.728, avg: 4.69, latest lr: 1.0714285714285714e-05\n",
      "epoch: 1, loss: 3.666, avg: 4.69, latest lr: 1.0700000000000001e-05\n",
      "epoch: 1, loss: 5.094, avg: 4.69, latest lr: 1.0685714285714286e-05\n",
      "epoch: 1, loss: 5.475, avg: 4.69, latest lr: 1.0671428571428573e-05\n",
      "epoch: 1, loss: 4.320, avg: 4.69, latest lr: 1.0657142857142858e-05\n",
      "epoch: 1, loss: 3.968, avg: 4.69, latest lr: 1.0642857142857143e-05\n",
      "epoch: 1, loss: 4.733, avg: 4.69, latest lr: 1.062857142857143e-05\n",
      "epoch: 1, loss: 4.830, avg: 4.69, latest lr: 1.0614285714285713e-05\n",
      "epoch: 1, loss: 4.565, avg: 4.69, latest lr: 1.06e-05\n",
      "epoch: 1, loss: 4.104, avg: 4.70, latest lr: 1.0585714285714287e-05\n",
      "epoch: 1, loss: 5.284, avg: 4.70, latest lr: 1.0571428571428572e-05\n",
      "epoch: 1, loss: 5.338, avg: 4.70, latest lr: 1.0557142857142857e-05\n",
      "epoch: 1, loss: 5.674, avg: 4.70, latest lr: 1.0542857142857144e-05\n",
      "epoch: 1, loss: 4.769, avg: 4.70, latest lr: 1.052857142857143e-05\n",
      "epoch: 1, loss: 4.164, avg: 4.70, latest lr: 1.0514285714285716e-05\n",
      "epoch: 1, loss: 5.206, avg: 4.70, latest lr: 1.05e-05\n",
      "epoch: 1, loss: 3.169, avg: 4.70, latest lr: 1.0485714285714286e-05\n",
      "epoch: 1, loss: 3.223, avg: 4.70, latest lr: 1.0471428571428573e-05\n",
      "epoch: 1, loss: 5.571, avg: 4.70, latest lr: 1.0457142857142856e-05\n",
      "epoch: 1, loss: 2.860, avg: 4.70, latest lr: 1.0442857142857143e-05\n",
      "epoch: 1, loss: 5.310, avg: 4.70, latest lr: 1.0428571428571428e-05\n",
      "epoch: 1, loss: 4.095, avg: 4.70, latest lr: 1.0414285714285715e-05\n",
      "epoch: 1, loss: 4.335, avg: 4.70, latest lr: 1.04e-05\n",
      "epoch: 1, loss: 4.032, avg: 4.70, latest lr: 1.0385714285714286e-05\n",
      "epoch: 1, loss: 4.972, avg: 4.71, latest lr: 1.0371428571428572e-05\n",
      "epoch: 1, loss: 3.762, avg: 4.71, latest lr: 1.0357142857142859e-05\n",
      "epoch: 1, loss: 3.753, avg: 4.71, latest lr: 1.0342857142857143e-05\n",
      "epoch: 1, loss: 3.621, avg: 4.71, latest lr: 1.032857142857143e-05\n",
      "epoch: 1, loss: 4.000, avg: 4.71, latest lr: 1.0314285714285715e-05\n",
      "epoch: 1, loss: 3.675, avg: 4.71, latest lr: 1.03e-05\n",
      "epoch: 1, loss: 5.049, avg: 4.71, latest lr: 1.0285714285714286e-05\n",
      "epoch: 1, loss: 3.665, avg: 4.71, latest lr: 1.0271428571428572e-05\n",
      "epoch: 1, loss: 4.618, avg: 4.71, latest lr: 1.0257142857142858e-05\n",
      "epoch: 1, loss: 5.126, avg: 4.71, latest lr: 1.0242857142857144e-05\n",
      "epoch: 1, loss: 4.188, avg: 4.71, latest lr: 1.0228571428571429e-05\n",
      "epoch: 1, loss: 4.882, avg: 4.71, latest lr: 1.0214285714285715e-05\n",
      "epoch: 1, loss: 4.209, avg: 4.71, latest lr: 1.02e-05\n",
      "epoch: 1, loss: 4.603, avg: 4.71, latest lr: 1.0185714285714286e-05\n",
      "epoch: 1, loss: 4.514, avg: 4.71, latest lr: 1.0171428571428573e-05\n",
      "epoch: 1, loss: 4.001, avg: 4.71, latest lr: 1.0157142857142858e-05\n",
      "epoch: 1, loss: 4.913, avg: 4.72, latest lr: 1.0142857142857143e-05\n",
      "epoch: 1, loss: 5.254, avg: 4.72, latest lr: 1.012857142857143e-05\n",
      "epoch: 1, loss: 4.820, avg: 4.72, latest lr: 1.0114285714285715e-05\n",
      "epoch: 1, loss: 4.407, avg: 4.72, latest lr: 1.0100000000000002e-05\n",
      "epoch: 1, loss: 4.271, avg: 4.72, latest lr: 1.0085714285714287e-05\n",
      "epoch: 1, loss: 3.146, avg: 4.72, latest lr: 1.0071428571428572e-05\n",
      "epoch: 1, loss: 5.362, avg: 4.72, latest lr: 1.0057142857142859e-05\n",
      "epoch: 1, loss: 4.632, avg: 4.72, latest lr: 1.0042857142857142e-05\n",
      "epoch: 1, loss: 2.967, avg: 4.72, latest lr: 1.0028571428571429e-05\n",
      "epoch: 1, loss: 5.124, avg: 4.72, latest lr: 1.0014285714285716e-05\n",
      "epoch: 1, loss: 4.589, avg: 4.72, latest lr: 1e-05\n",
      "epoch: 1, loss: 5.594, avg: 4.72, latest lr: 9.985714285714286e-06\n",
      "epoch: 1, loss: 3.462, avg: 4.72, latest lr: 9.971428571428571e-06\n",
      "epoch: 1, loss: 3.512, avg: 4.72, latest lr: 9.957142857142858e-06\n",
      "epoch: 1, loss: 6.455, avg: 4.72, latest lr: 9.942857142857143e-06\n",
      "epoch: 1, loss: 3.614, avg: 4.72, latest lr: 9.928571428571428e-06\n",
      "epoch: 1, loss: 3.873, avg: 4.73, latest lr: 9.914285714285715e-06\n",
      "epoch: 1, loss: 5.650, avg: 4.73, latest lr: 9.900000000000002e-06\n",
      "epoch: 1, loss: 3.976, avg: 4.73, latest lr: 9.885714285714285e-06\n",
      "epoch: 1, loss: 4.316, avg: 4.73, latest lr: 9.871428571428572e-06\n",
      "epoch: 1, loss: 4.641, avg: 4.73, latest lr: 9.857142857142857e-06\n",
      "epoch: 1, loss: 4.412, avg: 4.73, latest lr: 9.842857142857144e-06\n",
      "epoch: 1, loss: 4.030, avg: 4.73, latest lr: 9.828571428571429e-06\n",
      "epoch: 1, loss: 4.286, avg: 4.73, latest lr: 9.814285714285714e-06\n",
      "epoch: 1, loss: 5.093, avg: 4.73, latest lr: 9.800000000000001e-06\n",
      "epoch: 1, loss: 5.229, avg: 4.73, latest lr: 9.785714285714286e-06\n",
      "epoch: 1, loss: 4.810, avg: 4.73, latest lr: 9.771428571428571e-06\n",
      "epoch: 1, loss: 5.307, avg: 4.73, latest lr: 9.757142857142858e-06\n",
      "epoch: 1, loss: 4.575, avg: 4.73, latest lr: 9.742857142857143e-06\n",
      "epoch: 1, loss: 4.913, avg: 4.73, latest lr: 9.728571428571428e-06\n",
      "epoch: 1, loss: 5.414, avg: 4.73, latest lr: 9.714285714285715e-06\n",
      "epoch: 1, loss: 5.596, avg: 4.74, latest lr: 9.7e-06\n",
      "epoch: 1, loss: 5.004, avg: 4.74, latest lr: 9.685714285714287e-06\n",
      "epoch: 1, loss: 5.028, avg: 4.74, latest lr: 9.671428571428572e-06\n",
      "epoch: 1, loss: 4.711, avg: 4.74, latest lr: 9.657142857142857e-06\n",
      "epoch: 1, loss: 4.590, avg: 4.74, latest lr: 9.642857142857144e-06\n",
      "epoch: 1, loss: 5.523, avg: 4.74, latest lr: 9.628571428571428e-06\n",
      "epoch: 1, loss: 3.688, avg: 4.74, latest lr: 9.614285714285714e-06\n",
      "epoch: 1, loss: 4.852, avg: 4.74, latest lr: 9.600000000000001e-06\n",
      "epoch: 1, loss: 5.087, avg: 4.74, latest lr: 9.585714285714286e-06\n",
      "epoch: 1, loss: 4.424, avg: 4.74, latest lr: 9.571428571428572e-06\n",
      "epoch: 1, loss: 4.664, avg: 4.74, latest lr: 9.557142857142858e-06\n",
      "epoch: 1, loss: 5.966, avg: 4.74, latest lr: 9.542857142857143e-06\n",
      "epoch: 1, loss: 5.147, avg: 4.74, latest lr: 9.528571428571429e-06\n",
      "epoch: 1, loss: 4.267, avg: 4.74, latest lr: 9.514285714285714e-06\n",
      "epoch: 1, loss: 4.841, avg: 4.75, latest lr: 9.5e-06\n",
      "epoch: 1, loss: 3.973, avg: 4.75, latest lr: 9.485714285714287e-06\n",
      "epoch: 1, loss: 4.077, avg: 4.75, latest lr: 9.47142857142857e-06\n",
      "epoch: 1, loss: 4.532, avg: 4.75, latest lr: 9.457142857142858e-06\n",
      "epoch: 1, loss: 4.291, avg: 4.75, latest lr: 9.442857142857144e-06\n",
      "epoch: 1, loss: 5.064, avg: 4.75, latest lr: 9.42857142857143e-06\n",
      "epoch: 1, loss: 4.649, avg: 4.75, latest lr: 9.414285714285715e-06\n",
      "epoch: 1, loss: 3.516, avg: 4.75, latest lr: 9.4e-06\n",
      "epoch: 1, loss: 3.459, avg: 4.75, latest lr: 9.385714285714287e-06\n",
      "epoch: 1, loss: 4.231, avg: 4.75, latest lr: 9.371428571428572e-06\n",
      "epoch: 1, loss: 4.361, avg: 4.75, latest lr: 9.357142857142857e-06\n",
      "epoch: 1, loss: 3.870, avg: 4.75, latest lr: 9.342857142857144e-06\n",
      "epoch: 1, loss: 4.198, avg: 4.75, latest lr: 9.328571428571429e-06\n",
      "epoch: 1, loss: 4.532, avg: 4.75, latest lr: 9.314285714285714e-06\n",
      "epoch: 1, loss: 4.911, avg: 4.75, latest lr: 9.3e-06\n",
      "epoch: 1, loss: 4.102, avg: 4.75, latest lr: 9.285714285714286e-06\n",
      "epoch: 1, loss: 3.164, avg: 4.75, latest lr: 9.271428571428571e-06\n",
      "epoch: 1, loss: 4.303, avg: 4.76, latest lr: 9.257142857142858e-06\n",
      "epoch: 1, loss: 4.475, avg: 4.76, latest lr: 9.242857142857143e-06\n",
      "epoch: 1, loss: 4.351, avg: 4.76, latest lr: 9.22857142857143e-06\n",
      "epoch: 1, loss: 5.320, avg: 4.76, latest lr: 9.214285714285715e-06\n",
      "epoch: 1, loss: 5.311, avg: 4.76, latest lr: 9.2e-06\n",
      "epoch: 1, loss: 3.314, avg: 4.76, latest lr: 9.185714285714287e-06\n",
      "epoch: 1, loss: 5.097, avg: 4.76, latest lr: 9.171428571428572e-06\n",
      "epoch: 1, loss: 4.264, avg: 4.76, latest lr: 9.157142857142857e-06\n",
      "epoch: 1, loss: 4.355, avg: 4.76, latest lr: 9.142857142857144e-06\n",
      "epoch: 1, loss: 3.705, avg: 4.76, latest lr: 9.128571428571429e-06\n",
      "epoch: 1, loss: 4.878, avg: 4.76, latest lr: 9.114285714285714e-06\n",
      "epoch: 1, loss: 5.683, avg: 4.76, latest lr: 9.100000000000001e-06\n",
      "epoch: 1, loss: 4.439, avg: 4.76, latest lr: 9.085714285714286e-06\n",
      "epoch: 1, loss: 5.493, avg: 4.76, latest lr: 9.071428571428573e-06\n",
      "epoch: 1, loss: 4.643, avg: 4.76, latest lr: 9.057142857142856e-06\n",
      "epoch: 1, loss: 4.948, avg: 4.77, latest lr: 9.042857142857143e-06\n",
      "epoch: 1, loss: 6.160, avg: 4.77, latest lr: 9.02857142857143e-06\n",
      "epoch: 1, loss: 5.868, avg: 4.77, latest lr: 9.014285714285715e-06\n",
      "epoch: 1, loss: 5.747, avg: 4.77, latest lr: 9e-06\n",
      "epoch: 1, loss: 5.417, avg: 4.77, latest lr: 8.985714285714285e-06\n",
      "epoch: 1, loss: 5.150, avg: 4.77, latest lr: 8.971428571428572e-06\n",
      "epoch: 1, loss: 6.900, avg: 4.77, latest lr: 8.957142857142857e-06\n",
      "epoch: 1, loss: 3.776, avg: 4.77, latest lr: 8.942857142857142e-06\n",
      "epoch: 1, loss: 4.009, avg: 4.77, latest lr: 8.92857142857143e-06\n",
      "epoch: 1, loss: 4.471, avg: 4.77, latest lr: 8.914285714285716e-06\n",
      "epoch: 1, loss: 5.691, avg: 4.77, latest lr: 8.9e-06\n",
      "epoch: 1, loss: 4.857, avg: 4.77, latest lr: 8.885714285714286e-06\n",
      "epoch: 1, loss: 3.695, avg: 4.77, latest lr: 8.871428571428571e-06\n",
      "epoch: 1, loss: 4.048, avg: 4.77, latest lr: 8.857142857142857e-06\n",
      "epoch: 1, loss: 5.104, avg: 4.78, latest lr: 8.842857142857143e-06\n",
      "epoch: 1, loss: 5.864, avg: 4.78, latest lr: 8.828571428571429e-06\n",
      "epoch: 1, loss: 4.367, avg: 4.78, latest lr: 8.814285714285715e-06\n",
      "epoch: 1, loss: 3.991, avg: 4.78, latest lr: 8.8e-06\n",
      "epoch: 1, loss: 3.577, avg: 4.78, latest lr: 8.785714285714286e-06\n",
      "epoch: 1, loss: 6.341, avg: 4.78, latest lr: 8.771428571428572e-06\n",
      "epoch: 1, loss: 4.597, avg: 4.78, latest lr: 8.757142857142858e-06\n",
      "epoch: 1, loss: 5.117, avg: 4.78, latest lr: 8.742857142857143e-06\n",
      "epoch: 1, loss: 4.792, avg: 4.78, latest lr: 8.72857142857143e-06\n",
      "epoch: 1, loss: 3.851, avg: 4.78, latest lr: 8.714285714285715e-06\n",
      "epoch: 1, loss: 3.418, avg: 4.78, latest lr: 8.7e-06\n",
      "epoch: 1, loss: 4.753, avg: 4.78, latest lr: 8.685714285714287e-06\n",
      "epoch: 1, loss: 5.430, avg: 4.78, latest lr: 8.671428571428572e-06\n",
      "epoch: 1, loss: 4.429, avg: 4.78, latest lr: 8.657142857142858e-06\n",
      "epoch: 1, loss: 4.176, avg: 4.78, latest lr: 8.642857142857144e-06\n",
      "epoch: 1, loss: 4.737, avg: 4.79, latest lr: 8.628571428571429e-06\n",
      "epoch: 1, loss: 5.105, avg: 4.79, latest lr: 8.614285714285716e-06\n",
      "epoch: 1, loss: 5.556, avg: 4.79, latest lr: 8.599999999999999e-06\n",
      "epoch: 1, loss: 5.359, avg: 4.79, latest lr: 8.585714285714286e-06\n",
      "epoch: 1, loss: 5.530, avg: 4.79, latest lr: 8.571428571428573e-06\n",
      "epoch: 1, loss: 4.562, avg: 4.79, latest lr: 8.557142857142858e-06\n",
      "epoch: 1, loss: 4.380, avg: 4.79, latest lr: 8.542857142857143e-06\n",
      "epoch: 1, loss: 3.437, avg: 4.79, latest lr: 8.528571428571428e-06\n",
      "epoch: 1, loss: 5.350, avg: 4.79, latest lr: 8.514285714285715e-06\n",
      "epoch: 1, loss: 4.249, avg: 4.79, latest lr: 8.500000000000002e-06\n",
      "epoch: 1, loss: 3.762, avg: 4.79, latest lr: 8.485714285714285e-06\n",
      "epoch: 1, loss: 3.700, avg: 4.79, latest lr: 8.471428571428572e-06\n",
      "epoch: 1, loss: 5.108, avg: 4.79, latest lr: 8.457142857142859e-06\n",
      "epoch: 1, loss: 3.737, avg: 4.79, latest lr: 8.442857142857142e-06\n",
      "epoch: 1, loss: 4.572, avg: 4.79, latest lr: 8.428571428571429e-06\n",
      "epoch: 1, loss: 4.390, avg: 4.80, latest lr: 8.414285714285714e-06\n",
      "epoch: 1, loss: 4.849, avg: 4.80, latest lr: 8.400000000000001e-06\n",
      "epoch: 1, loss: 3.841, avg: 4.80, latest lr: 8.385714285714286e-06\n",
      "epoch: 1, loss: 4.072, avg: 4.80, latest lr: 8.371428571428571e-06\n",
      "epoch: 1, loss: 5.763, avg: 4.80, latest lr: 8.357142857142858e-06\n",
      "epoch: 1, loss: 4.993, avg: 4.80, latest lr: 8.342857142857143e-06\n",
      "epoch: 1, loss: 3.947, avg: 4.80, latest lr: 8.328571428571428e-06\n",
      "epoch: 1, loss: 5.236, avg: 4.80, latest lr: 8.314285714285715e-06\n",
      "epoch: 1, loss: 4.516, avg: 4.80, latest lr: 8.3e-06\n",
      "epoch: 1, loss: 3.349, avg: 4.80, latest lr: 8.285714285714285e-06\n",
      "epoch: 1, loss: 4.736, avg: 4.80, latest lr: 8.271428571428572e-06\n",
      "epoch: 1, loss: 4.564, avg: 4.80, latest lr: 8.257142857142857e-06\n",
      "epoch: 1, loss: 3.586, avg: 4.80, latest lr: 8.242857142857144e-06\n",
      "epoch: 1, loss: 3.758, avg: 4.80, latest lr: 8.22857142857143e-06\n",
      "epoch: 1, loss: 4.258, avg: 4.80, latest lr: 8.214285714285714e-06\n",
      "epoch: 1, loss: 4.576, avg: 4.80, latest lr: 8.200000000000001e-06\n",
      "epoch: 1, loss: 4.826, avg: 4.81, latest lr: 8.185714285714286e-06\n",
      "epoch: 1, loss: 3.720, avg: 4.81, latest lr: 8.171428571428571e-06\n",
      "epoch: 1, loss: 4.711, avg: 4.81, latest lr: 8.157142857142858e-06\n",
      "epoch: 1, loss: 5.945, avg: 4.81, latest lr: 8.142857142857143e-06\n",
      "epoch: 1, loss: 5.741, avg: 4.81, latest lr: 8.128571428571428e-06\n",
      "epoch: 1, loss: 3.447, avg: 4.81, latest lr: 8.114285714285715e-06\n",
      "epoch: 1, loss: 3.300, avg: 4.81, latest lr: 8.1e-06\n",
      "epoch: 1, loss: 3.241, avg: 4.81, latest lr: 8.085714285714287e-06\n",
      "epoch: 1, loss: 3.866, avg: 4.81, latest lr: 8.07142857142857e-06\n",
      "epoch: 1, loss: 3.286, avg: 4.81, latest lr: 8.057142857142857e-06\n",
      "epoch: 1, loss: 3.949, avg: 4.81, latest lr: 8.042857142857144e-06\n",
      "epoch: 1, loss: 4.260, avg: 4.81, latest lr: 8.028571428571428e-06\n",
      "epoch: 1, loss: 4.953, avg: 4.81, latest lr: 8.014285714285715e-06\n",
      "epoch: 1, loss: 3.905, avg: 4.81, latest lr: 8.000000000000001e-06\n",
      "epoch: 1, loss: 4.262, avg: 4.81, latest lr: 7.985714285714286e-06\n",
      "epoch: 1, loss: 5.251, avg: 4.81, latest lr: 7.971428571428572e-06\n",
      "epoch: 1, loss: 4.215, avg: 4.82, latest lr: 7.957142857142857e-06\n",
      "epoch: 1, loss: 4.605, avg: 4.82, latest lr: 7.942857142857144e-06\n",
      "epoch: 1, loss: 3.696, avg: 4.82, latest lr: 7.928571428571429e-06\n",
      "epoch: 1, loss: 4.965, avg: 4.82, latest lr: 7.914285714285714e-06\n",
      "epoch: 1, loss: 3.404, avg: 4.82, latest lr: 7.9e-06\n",
      "epoch: 1, loss: 3.804, avg: 4.82, latest lr: 7.885714285714286e-06\n",
      "epoch: 1, loss: 4.178, avg: 4.82, latest lr: 7.87142857142857e-06\n",
      "epoch: 1, loss: 5.032, avg: 4.82, latest lr: 7.857142857142858e-06\n",
      "epoch: 1, loss: 3.428, avg: 4.82, latest lr: 7.842857142857143e-06\n",
      "epoch: 1, loss: 2.896, avg: 4.82, latest lr: 7.82857142857143e-06\n",
      "epoch: 1, loss: 4.983, avg: 4.82, latest lr: 7.814285714285715e-06\n",
      "epoch: 1, loss: 7.932, avg: 4.82, latest lr: 7.8e-06\n",
      "epoch: 1, loss: 4.892, avg: 4.82, latest lr: 7.785714285714287e-06\n",
      "epoch: 1, loss: 4.387, avg: 4.82, latest lr: 7.771428571428572e-06\n",
      "epoch: 1, loss: 5.190, avg: 4.82, latest lr: 7.757142857142857e-06\n",
      "epoch: 1, loss: 4.986, avg: 4.82, latest lr: 7.742857142857144e-06\n",
      "epoch: 1, loss: 5.696, avg: 4.83, latest lr: 7.728571428571429e-06\n",
      "epoch: 1, loss: 4.063, avg: 4.83, latest lr: 7.714285714285714e-06\n",
      "epoch: 1, loss: 4.009, avg: 4.83, latest lr: 7.7e-06\n",
      "epoch: 1, loss: 4.650, avg: 4.83, latest lr: 7.685714285714286e-06\n",
      "epoch: 1, loss: 5.346, avg: 4.83, latest lr: 7.671428571428573e-06\n",
      "epoch: 1, loss: 3.013, avg: 4.83, latest lr: 7.657142857142858e-06\n",
      "epoch: 1, loss: 4.925, avg: 4.83, latest lr: 7.642857142857143e-06\n",
      "epoch: 1, loss: 5.916, avg: 4.83, latest lr: 7.628571428571429e-06\n",
      "epoch: 1, loss: 4.288, avg: 4.83, latest lr: 7.614285714285714e-06\n",
      "epoch: 1, loss: 3.733, avg: 4.83, latest lr: 7.6e-06\n",
      "epoch: 1, loss: 4.280, avg: 4.83, latest lr: 7.585714285714286e-06\n",
      "epoch: 1, loss: 4.257, avg: 4.83, latest lr: 7.571428571428572e-06\n",
      "epoch: 1, loss: 4.985, avg: 4.83, latest lr: 7.557142857142857e-06\n",
      "epoch: 1, loss: 5.230, avg: 4.83, latest lr: 7.542857142857143e-06\n",
      "epoch: 1, loss: 4.157, avg: 4.83, latest lr: 7.528571428571429e-06\n",
      "epoch: 1, loss: 4.001, avg: 4.84, latest lr: 7.514285714285714e-06\n",
      "epoch: 1, loss: 4.417, avg: 4.84, latest lr: 7.5e-06\n",
      "epoch: 1, loss: 4.414, avg: 4.84, latest lr: 7.485714285714286e-06\n",
      "epoch: 1, loss: 4.337, avg: 4.84, latest lr: 7.471428571428572e-06\n",
      "epoch: 1, loss: 4.588, avg: 4.84, latest lr: 7.457142857142857e-06\n",
      "epoch: 1, loss: 4.844, avg: 4.84, latest lr: 7.442857142857143e-06\n",
      "epoch: 1, loss: 4.227, avg: 4.84, latest lr: 7.428571428571429e-06\n",
      "epoch: 1, loss: 4.511, avg: 4.84, latest lr: 7.414285714285715e-06\n",
      "epoch: 1, loss: 4.700, avg: 4.84, latest lr: 7.4e-06\n",
      "epoch: 1, loss: 4.923, avg: 4.84, latest lr: 7.385714285714286e-06\n",
      "epoch: 1, loss: 5.275, avg: 4.84, latest lr: 7.371428571428572e-06\n",
      "epoch: 1, loss: 4.664, avg: 4.84, latest lr: 7.3571428571428565e-06\n",
      "epoch: 1, loss: 5.637, avg: 4.84, latest lr: 7.342857142857143e-06\n",
      "epoch: 1, loss: 3.315, avg: 4.84, latest lr: 7.328571428571429e-06\n",
      "epoch: 1, loss: 4.145, avg: 4.84, latest lr: 7.314285714285715e-06\n",
      "epoch: 1, loss: 3.730, avg: 4.84, latest lr: 7.2999999999999996e-06\n",
      "epoch: 1, loss: 4.035, avg: 4.85, latest lr: 7.285714285714286e-06\n",
      "epoch: 1, loss: 4.446, avg: 4.85, latest lr: 7.271428571428572e-06\n",
      "epoch: 1, loss: 5.460, avg: 4.85, latest lr: 7.257142857142857e-06\n",
      "epoch: 1, loss: 4.322, avg: 4.85, latest lr: 7.242857142857143e-06\n",
      "epoch: 1, loss: 4.387, avg: 4.85, latest lr: 7.228571428571429e-06\n",
      "epoch: 1, loss: 4.532, avg: 4.85, latest lr: 7.214285714285715e-06\n",
      "epoch: 1, loss: 4.482, avg: 4.85, latest lr: 7.2e-06\n",
      "epoch: 1, loss: 4.806, avg: 4.85, latest lr: 7.185714285714286e-06\n",
      "epoch: 1, loss: 3.495, avg: 4.85, latest lr: 7.171428571428572e-06\n",
      "epoch: 1, loss: 4.154, avg: 4.85, latest lr: 7.1571428571428584e-06\n",
      "epoch: 1, loss: 4.732, avg: 4.85, latest lr: 7.142857142857143e-06\n",
      "epoch: 1, loss: 5.378, avg: 4.85, latest lr: 7.128571428571429e-06\n",
      "epoch: 1, loss: 5.378, avg: 4.85, latest lr: 7.114285714285715e-06\n",
      "epoch: 1, loss: 5.647, avg: 4.85, latest lr: 7.1e-06\n",
      "epoch: 1, loss: 5.775, avg: 4.86, latest lr: 7.085714285714286e-06\n",
      "epoch: 1, loss: 4.448, avg: 4.86, latest lr: 7.071428571428572e-06\n",
      "epoch: 1, loss: 3.912, avg: 4.86, latest lr: 7.057142857142858e-06\n",
      "epoch: 1, loss: 4.922, avg: 4.86, latest lr: 7.042857142857143e-06\n",
      "epoch: 1, loss: 4.503, avg: 4.86, latest lr: 7.028571428571429e-06\n",
      "epoch: 1, loss: 4.576, avg: 4.86, latest lr: 7.014285714285715e-06\n",
      "epoch: 1, loss: 4.559, avg: 4.86, latest lr: 7.000000000000001e-06\n",
      "epoch: 1, loss: 4.015, avg: 4.86, latest lr: 6.985714285714286e-06\n",
      "epoch: 1, loss: 4.198, avg: 4.86, latest lr: 6.971428571428572e-06\n",
      "epoch: 1, loss: 3.760, avg: 4.86, latest lr: 6.957142857142858e-06\n",
      "epoch: 1, loss: 3.838, avg: 4.86, latest lr: 6.942857142857143e-06\n",
      "epoch: 1, loss: 4.509, avg: 4.86, latest lr: 6.928571428571429e-06\n",
      "epoch: 1, loss: 4.116, avg: 4.86, latest lr: 6.914285714285715e-06\n",
      "epoch: 1, loss: 4.696, avg: 4.86, latest lr: 6.900000000000001e-06\n",
      "epoch: 1, loss: 4.835, avg: 4.86, latest lr: 6.885714285714286e-06\n",
      "epoch: 1, loss: 5.097, avg: 4.86, latest lr: 6.871428571428572e-06\n",
      "epoch: 1, loss: 2.621, avg: 4.86, latest lr: 6.857142857142858e-06\n",
      "epoch: 1, loss: 4.601, avg: 4.87, latest lr: 6.842857142857142e-06\n",
      "epoch: 1, loss: 3.965, avg: 4.87, latest lr: 6.828571428571429e-06\n",
      "epoch: 1, loss: 5.035, avg: 4.87, latest lr: 6.814285714285715e-06\n",
      "epoch: 1, loss: 3.819, avg: 4.87, latest lr: 6.800000000000001e-06\n",
      "epoch: 1, loss: 4.626, avg: 4.87, latest lr: 6.785714285714285e-06\n",
      "epoch: 1, loss: 5.071, avg: 4.87, latest lr: 6.771428571428571e-06\n",
      "epoch: 1, loss: 4.461, avg: 4.87, latest lr: 6.757142857142858e-06\n",
      "epoch: 1, loss: 3.893, avg: 4.87, latest lr: 6.742857142857144e-06\n",
      "epoch: 1, loss: 4.199, avg: 4.87, latest lr: 6.728571428571428e-06\n",
      "epoch: 1, loss: 6.361, avg: 4.87, latest lr: 6.714285714285714e-06\n",
      "epoch: 1, loss: 4.097, avg: 4.87, latest lr: 6.700000000000001e-06\n",
      "epoch: 1, loss: 4.637, avg: 4.87, latest lr: 6.685714285714285e-06\n",
      "epoch: 1, loss: 5.594, avg: 4.87, latest lr: 6.671428571428571e-06\n",
      "epoch: 1, loss: 4.441, avg: 4.87, latest lr: 6.657142857142857e-06\n",
      "epoch: 1, loss: 3.049, avg: 4.87, latest lr: 6.642857142857144e-06\n",
      "epoch: 1, loss: 5.358, avg: 4.88, latest lr: 6.628571428571428e-06\n",
      "epoch: 1, loss: 4.335, avg: 4.88, latest lr: 6.614285714285714e-06\n",
      "epoch: 1, loss: 3.415, avg: 4.88, latest lr: 6.6e-06\n",
      "epoch: 1, loss: 4.860, avg: 4.88, latest lr: 6.5857142857142855e-06\n",
      "epoch: 1, loss: 5.200, avg: 4.88, latest lr: 6.5714285714285714e-06\n",
      "epoch: 1, loss: 4.878, avg: 4.88, latest lr: 6.557142857142857e-06\n",
      "epoch: 1, loss: 5.019, avg: 4.88, latest lr: 6.542857142857143e-06\n",
      "epoch: 1, loss: 4.451, avg: 4.88, latest lr: 6.5285714285714285e-06\n",
      "epoch: 1, loss: 5.434, avg: 4.88, latest lr: 6.5142857142857145e-06\n",
      "epoch: 1, loss: 3.564, avg: 4.88, latest lr: 6.5000000000000004e-06\n",
      "epoch: 1, loss: 4.879, avg: 4.88, latest lr: 6.485714285714286e-06\n",
      "epoch: 1, loss: 4.156, avg: 4.88, latest lr: 6.4714285714285715e-06\n",
      "epoch: 1, loss: 4.428, avg: 4.88, latest lr: 6.4571428571428575e-06\n",
      "epoch: 1, loss: 5.129, avg: 4.88, latest lr: 6.4428571428571435e-06\n",
      "epoch: 1, loss: 5.625, avg: 4.88, latest lr: 6.428571428571429e-06\n",
      "epoch: 1, loss: 5.455, avg: 4.89, latest lr: 6.414285714285715e-06\n",
      "epoch: 1, loss: 4.585, avg: 4.89, latest lr: 6.4000000000000006e-06\n",
      "epoch: 1, loss: 3.885, avg: 4.89, latest lr: 6.3857142857142865e-06\n",
      "epoch: 1, loss: 4.913, avg: 4.89, latest lr: 6.371428571428572e-06\n",
      "epoch: 1, loss: 4.079, avg: 4.89, latest lr: 6.357142857142858e-06\n",
      "epoch: 1, loss: 5.138, avg: 4.89, latest lr: 6.342857142857144e-06\n",
      "epoch: 1, loss: 5.286, avg: 4.89, latest lr: 6.3285714285714296e-06\n",
      "epoch: 1, loss: 5.279, avg: 4.89, latest lr: 6.314285714285714e-06\n",
      "epoch: 1, loss: 4.853, avg: 4.89, latest lr: 6.300000000000001e-06\n",
      "epoch: 1, loss: 3.977, avg: 4.89, latest lr: 6.285714285714287e-06\n",
      "epoch: 1, loss: 5.734, avg: 4.89, latest lr: 6.271428571428571e-06\n",
      "epoch: 1, loss: 3.978, avg: 4.89, latest lr: 6.257142857142857e-06\n",
      "epoch: 1, loss: 4.469, avg: 4.89, latest lr: 6.242857142857144e-06\n",
      "epoch: 1, loss: 3.283, avg: 4.89, latest lr: 6.228571428571429e-06\n",
      "epoch: 1, loss: 4.453, avg: 4.89, latest lr: 6.214285714285715e-06\n",
      "epoch: 1, loss: 5.044, avg: 4.90, latest lr: 6.2e-06\n",
      "epoch: 1, loss: 3.589, avg: 4.90, latest lr: 6.185714285714287e-06\n",
      "epoch: 1, loss: 4.459, avg: 4.90, latest lr: 6.171428571428572e-06\n",
      "epoch: 1, loss: 6.368, avg: 4.90, latest lr: 6.157142857142857e-06\n",
      "epoch: 1, loss: 5.183, avg: 4.90, latest lr: 6.142857142857143e-06\n",
      "epoch: 1, loss: 5.134, avg: 4.90, latest lr: 6.128571428571429e-06\n",
      "epoch: 1, loss: 4.229, avg: 4.90, latest lr: 6.114285714285715e-06\n",
      "epoch: 1, loss: 2.778, avg: 4.90, latest lr: 6.1e-06\n",
      "epoch: 1, loss: 4.665, avg: 4.90, latest lr: 6.085714285714286e-06\n",
      "epoch: 1, loss: 4.989, avg: 4.90, latest lr: 6.071428571428572e-06\n",
      "epoch: 1, loss: 5.453, avg: 4.90, latest lr: 6.057142857142858e-06\n",
      "epoch: 1, loss: 4.337, avg: 4.90, latest lr: 6.042857142857143e-06\n",
      "epoch: 1, loss: 3.799, avg: 4.90, latest lr: 6.028571428571428e-06\n",
      "epoch: 1, loss: 4.746, avg: 4.90, latest lr: 6.014285714285715e-06\n",
      "epoch: 1, loss: 4.657, avg: 4.90, latest lr: 6e-06\n",
      "epoch: 1, loss: 4.190, avg: 4.91, latest lr: 5.985714285714286e-06\n",
      "epoch: 1, loss: 4.847, avg: 4.91, latest lr: 5.971428571428571e-06\n",
      "epoch: 1, loss: 4.432, avg: 4.91, latest lr: 5.957142857142858e-06\n",
      "epoch: 1, loss: 4.701, avg: 4.91, latest lr: 5.942857142857143e-06\n",
      "epoch: 1, loss: 4.552, avg: 4.91, latest lr: 5.928571428571429e-06\n",
      "epoch: 1, loss: 5.848, avg: 4.91, latest lr: 5.914285714285714e-06\n",
      "epoch: 1, loss: 5.124, avg: 4.91, latest lr: 5.9e-06\n",
      "epoch: 1, loss: 4.250, avg: 4.91, latest lr: 5.885714285714286e-06\n",
      "epoch: 1, loss: 6.167, avg: 4.91, latest lr: 5.871428571428571e-06\n",
      "epoch: 1, loss: 5.318, avg: 4.91, latest lr: 5.857142857142857e-06\n",
      "epoch: 1, loss: 5.179, avg: 4.91, latest lr: 5.842857142857143e-06\n",
      "epoch: 1, loss: 3.694, avg: 4.91, latest lr: 5.828571428571429e-06\n",
      "epoch: 1, loss: 4.738, avg: 4.91, latest lr: 5.814285714285714e-06\n",
      "epoch: 1, loss: 3.859, avg: 4.91, latest lr: 5.8e-06\n",
      "epoch: 1, loss: 4.414, avg: 4.91, latest lr: 5.785714285714286e-06\n",
      "epoch: 1, loss: 4.097, avg: 4.92, latest lr: 5.7714285714285715e-06\n",
      "epoch: 1, loss: 4.348, avg: 4.92, latest lr: 5.7571428571428574e-06\n",
      "epoch: 1, loss: 5.187, avg: 4.92, latest lr: 5.7428571428571426e-06\n",
      "epoch: 1, loss: 3.361, avg: 4.92, latest lr: 5.728571428571429e-06\n",
      "epoch: 1, loss: 4.470, avg: 4.92, latest lr: 5.7142857142857145e-06\n",
      "epoch: 1, loss: 3.728, avg: 4.92, latest lr: 5.7000000000000005e-06\n",
      "epoch: 1, loss: 4.020, avg: 4.92, latest lr: 5.685714285714286e-06\n",
      "epoch: 1, loss: 4.421, avg: 4.92, latest lr: 5.671428571428572e-06\n",
      "epoch: 1, loss: 4.166, avg: 4.92, latest lr: 5.6571428571428576e-06\n",
      "epoch: 1, loss: 3.602, avg: 4.92, latest lr: 5.642857142857143e-06\n",
      "epoch: 1, loss: 4.133, avg: 4.92, latest lr: 5.628571428571429e-06\n",
      "epoch: 1, loss: 4.251, avg: 4.92, latest lr: 5.614285714285715e-06\n",
      "epoch: 1, loss: 3.418, avg: 4.92, latest lr: 5.600000000000001e-06\n",
      "epoch: 1, loss: 4.466, avg: 4.92, latest lr: 5.585714285714286e-06\n",
      "epoch: 1, loss: 3.391, avg: 4.92, latest lr: 5.571428571428572e-06\n",
      "epoch: 1, loss: 6.210, avg: 4.92, latest lr: 5.557142857142858e-06\n",
      "epoch: 1, loss: 6.026, avg: 4.93, latest lr: 5.542857142857144e-06\n",
      "epoch: 1, loss: 4.456, avg: 4.93, latest lr: 5.528571428571429e-06\n",
      "epoch: 1, loss: 3.743, avg: 4.93, latest lr: 5.514285714285715e-06\n",
      "epoch: 1, loss: 4.845, avg: 4.93, latest lr: 5.500000000000001e-06\n",
      "epoch: 1, loss: 3.787, avg: 4.93, latest lr: 5.485714285714286e-06\n",
      "epoch: 1, loss: 3.950, avg: 4.93, latest lr: 5.471428571428572e-06\n",
      "epoch: 1, loss: 3.567, avg: 4.93, latest lr: 5.457142857142857e-06\n",
      "epoch: 1, loss: 4.808, avg: 4.93, latest lr: 5.442857142857143e-06\n",
      "epoch: 1, loss: 3.963, avg: 4.93, latest lr: 5.428571428571429e-06\n",
      "epoch: 1, loss: 3.726, avg: 4.93, latest lr: 5.414285714285715e-06\n",
      "epoch: 1, loss: 4.367, avg: 4.93, latest lr: 5.4e-06\n",
      "epoch: 1, loss: 3.149, avg: 4.93, latest lr: 5.385714285714286e-06\n",
      "epoch: 1, loss: 5.542, avg: 4.93, latest lr: 5.371428571428572e-06\n",
      "epoch: 1, loss: 3.291, avg: 4.93, latest lr: 5.357142857142857e-06\n",
      "epoch: 1, loss: 4.232, avg: 4.93, latest lr: 5.342857142857143e-06\n",
      "epoch: 1, loss: 3.604, avg: 4.93, latest lr: 5.328571428571429e-06\n",
      "epoch: 1, loss: 3.259, avg: 4.93, latest lr: 5.314285714285715e-06\n",
      "epoch: 1, loss: 3.992, avg: 4.93, latest lr: 5.3e-06\n",
      "epoch: 1, loss: 4.181, avg: 4.94, latest lr: 5.285714285714286e-06\n",
      "epoch: 1, loss: 4.519, avg: 4.94, latest lr: 5.271428571428572e-06\n",
      "epoch: 1, loss: 4.522, avg: 4.94, latest lr: 5.257142857142858e-06\n",
      "epoch: 1, loss: 4.017, avg: 4.94, latest lr: 5.242857142857143e-06\n",
      "epoch: 1, loss: 4.473, avg: 4.94, latest lr: 5.228571428571428e-06\n",
      "epoch: 1, loss: 3.395, avg: 4.94, latest lr: 5.214285714285714e-06\n",
      "epoch: 1, loss: 3.691, avg: 4.94, latest lr: 5.2e-06\n",
      "epoch: 1, loss: 4.999, avg: 4.94, latest lr: 5.185714285714286e-06\n",
      "epoch: 1, loss: 4.027, avg: 4.94, latest lr: 5.171428571428571e-06\n",
      "epoch: 1, loss: 4.944, avg: 4.94, latest lr: 5.157142857142857e-06\n",
      "epoch: 1, loss: 5.073, avg: 4.94, latest lr: 5.142857142857143e-06\n",
      "epoch: 1, loss: 4.889, avg: 4.94, latest lr: 5.128571428571429e-06\n",
      "epoch: 1, loss: 7.271, avg: 4.94, latest lr: 5.114285714285714e-06\n",
      "epoch: 1, loss: 4.275, avg: 4.94, latest lr: 5.1e-06\n",
      "epoch: 1, loss: 5.461, avg: 4.94, latest lr: 5.085714285714286e-06\n",
      "epoch: 1, loss: 4.538, avg: 4.95, latest lr: 5.071428571428571e-06\n",
      "epoch: 1, loss: 4.353, avg: 4.95, latest lr: 5.057142857142857e-06\n",
      "epoch: 1, loss: 4.574, avg: 4.95, latest lr: 5.042857142857143e-06\n",
      "epoch: 1, loss: 4.041, avg: 4.95, latest lr: 5.028571428571429e-06\n",
      "epoch: 1, loss: 3.539, avg: 4.95, latest lr: 5.0142857142857144e-06\n",
      "epoch: 1, loss: 4.816, avg: 4.95, latest lr: 5e-06\n",
      "epoch: 1, loss: 4.685, avg: 4.95, latest lr: 4.9857142857142855e-06\n",
      "epoch: 1, loss: 4.535, avg: 4.95, latest lr: 4.9714285714285715e-06\n",
      "epoch: 1, loss: 3.796, avg: 4.95, latest lr: 4.9571428571428575e-06\n",
      "epoch: 1, loss: 4.298, avg: 4.95, latest lr: 4.942857142857143e-06\n",
      "epoch: 1, loss: 4.738, avg: 4.95, latest lr: 4.9285714285714286e-06\n",
      "epoch: 1, loss: 4.784, avg: 4.95, latest lr: 4.9142857142857145e-06\n",
      "epoch: 1, loss: 5.203, avg: 4.95, latest lr: 4.9000000000000005e-06\n",
      "epoch: 1, loss: 4.613, avg: 4.95, latest lr: 4.885714285714286e-06\n",
      "epoch: 1, loss: 3.031, avg: 4.95, latest lr: 4.871428571428572e-06\n",
      "epoch: 1, loss: 5.218, avg: 4.95, latest lr: 4.857142857142858e-06\n",
      "epoch: 1, loss: 3.808, avg: 4.96, latest lr: 4.8428571428571436e-06\n",
      "epoch: 1, loss: 4.970, avg: 4.96, latest lr: 4.828571428571429e-06\n",
      "epoch: 1, loss: 5.705, avg: 4.96, latest lr: 4.814285714285714e-06\n",
      "epoch: 1, loss: 4.662, avg: 4.96, latest lr: 4.800000000000001e-06\n",
      "epoch: 1, loss: 3.764, avg: 4.96, latest lr: 4.785714285714286e-06\n",
      "epoch: 1, loss: 4.191, avg: 4.96, latest lr: 4.771428571428572e-06\n",
      "epoch: 1, loss: 4.312, avg: 4.96, latest lr: 4.757142857142857e-06\n",
      "epoch: 1, loss: 5.928, avg: 4.96, latest lr: 4.742857142857144e-06\n",
      "epoch: 1, loss: 5.655, avg: 4.96, latest lr: 4.728571428571429e-06\n",
      "epoch: 1, loss: 3.332, avg: 4.96, latest lr: 4.714285714285715e-06\n",
      "epoch: 1, loss: 6.180, avg: 4.96, latest lr: 4.7e-06\n",
      "epoch: 1, loss: 4.029, avg: 4.96, latest lr: 4.685714285714286e-06\n",
      "epoch: 1, loss: 4.640, avg: 4.96, latest lr: 4.671428571428572e-06\n",
      "epoch: 1, loss: 4.890, avg: 4.96, latest lr: 4.657142857142857e-06\n",
      "epoch: 1, loss: 4.875, avg: 4.97, latest lr: 4.642857142857143e-06\n",
      "epoch: 1, loss: 3.285, avg: 4.97, latest lr: 4.628571428571429e-06\n",
      "epoch: 1, loss: 4.818, avg: 4.97, latest lr: 4.614285714285715e-06\n",
      "epoch: 1, loss: 4.711, avg: 4.97, latest lr: 4.6e-06\n",
      "epoch: 1, loss: 4.012, avg: 4.97, latest lr: 4.585714285714286e-06\n",
      "epoch: 1, loss: 3.813, avg: 4.97, latest lr: 4.571428571428572e-06\n",
      "epoch: 1, loss: 4.807, avg: 4.97, latest lr: 4.557142857142857e-06\n",
      "epoch: 1, loss: 4.323, avg: 4.97, latest lr: 4.542857142857143e-06\n",
      "epoch: 1, loss: 4.728, avg: 4.97, latest lr: 4.528571428571428e-06\n",
      "epoch: 1, loss: 5.318, avg: 4.97, latest lr: 4.514285714285715e-06\n",
      "epoch: 1, loss: 4.592, avg: 4.97, latest lr: 4.5e-06\n",
      "epoch: 1, loss: 4.646, avg: 4.97, latest lr: 4.485714285714286e-06\n",
      "epoch: 1, loss: 5.351, avg: 4.97, latest lr: 4.471428571428571e-06\n",
      "epoch: 1, loss: 4.225, avg: 4.97, latest lr: 4.457142857142858e-06\n",
      "epoch: 1, loss: 3.133, avg: 4.97, latest lr: 4.442857142857143e-06\n",
      "epoch: 1, loss: 5.204, avg: 4.97, latest lr: 4.428571428571428e-06\n",
      "epoch: 1, loss: 4.484, avg: 4.98, latest lr: 4.414285714285714e-06\n",
      "epoch: 1, loss: 4.671, avg: 4.98, latest lr: 4.4e-06\n",
      "epoch: 1, loss: 3.122, avg: 4.98, latest lr: 4.385714285714286e-06\n",
      "epoch: 1, loss: 4.742, avg: 4.98, latest lr: 4.371428571428571e-06\n",
      "epoch: 1, loss: 5.835, avg: 4.98, latest lr: 4.357142857142857e-06\n",
      "epoch: 1, loss: 3.670, avg: 4.98, latest lr: 4.342857142857143e-06\n",
      "epoch: 1, loss: 3.894, avg: 4.98, latest lr: 4.328571428571429e-06\n",
      "epoch: 1, loss: 5.153, avg: 4.98, latest lr: 4.314285714285714e-06\n",
      "epoch: 1, loss: 3.741, avg: 4.98, latest lr: 4.2999999999999995e-06\n",
      "epoch: 1, loss: 4.732, avg: 4.98, latest lr: 4.285714285714286e-06\n",
      "epoch: 1, loss: 4.059, avg: 4.98, latest lr: 4.2714285714285714e-06\n",
      "epoch: 1, loss: 3.870, avg: 4.98, latest lr: 4.257142857142857e-06\n",
      "epoch: 1, loss: 5.428, avg: 4.98, latest lr: 4.2428571428571425e-06\n",
      "epoch: 1, loss: 4.526, avg: 4.98, latest lr: 4.228571428571429e-06\n",
      "epoch: 1, loss: 3.772, avg: 4.98, latest lr: 4.2142857142857145e-06\n",
      "epoch: 1, loss: 4.897, avg: 4.98, latest lr: 4.2000000000000004e-06\n",
      "epoch: 1, loss: 4.954, avg: 4.99, latest lr: 4.1857142857142856e-06\n",
      "epoch: 1, loss: 4.869, avg: 4.99, latest lr: 4.1714285714285715e-06\n",
      "epoch: 1, loss: 5.613, avg: 4.99, latest lr: 4.1571428571428575e-06\n",
      "epoch: 1, loss: 4.237, avg: 4.99, latest lr: 4.142857142857143e-06\n",
      "epoch: 1, loss: 4.702, avg: 4.99, latest lr: 4.128571428571429e-06\n",
      "epoch: 1, loss: 3.893, avg: 4.99, latest lr: 4.114285714285715e-06\n",
      "epoch: 1, loss: 3.693, avg: 4.99, latest lr: 4.1000000000000006e-06\n",
      "epoch: 1, loss: 5.462, avg: 4.99, latest lr: 4.085714285714286e-06\n",
      "epoch: 1, loss: 3.199, avg: 4.99, latest lr: 4.071428571428572e-06\n",
      "epoch: 1, loss: 5.407, avg: 4.99, latest lr: 4.057142857142858e-06\n",
      "epoch: 1, loss: 4.180, avg: 4.99, latest lr: 4.042857142857144e-06\n",
      "epoch: 1, loss: 4.666, avg: 4.99, latest lr: 4.028571428571429e-06\n",
      "epoch: 1, loss: 3.752, avg: 4.99, latest lr: 4.014285714285714e-06\n",
      "epoch: 1, loss: 5.679, avg: 4.99, latest lr: 4.000000000000001e-06\n",
      "epoch: 1, loss: 5.462, avg: 4.99, latest lr: 3.985714285714286e-06\n",
      "epoch: 1, loss: 4.440, avg: 5.00, latest lr: 3.971428571428572e-06\n",
      "epoch: 1, loss: 4.264, avg: 5.00, latest lr: 3.957142857142857e-06\n",
      "epoch: 1, loss: 4.611, avg: 5.00, latest lr: 3.942857142857143e-06\n",
      "epoch: 1, loss: 4.151, avg: 5.00, latest lr: 3.928571428571429e-06\n",
      "epoch: 1, loss: 5.212, avg: 5.00, latest lr: 3.914285714285715e-06\n",
      "epoch: 1, loss: 5.451, avg: 5.00, latest lr: 3.9e-06\n",
      "epoch: 1, loss: 3.830, avg: 5.00, latest lr: 3.885714285714286e-06\n",
      "epoch: 1, loss: 4.105, avg: 5.00, latest lr: 3.871428571428572e-06\n",
      "epoch: 1, loss: 4.007, avg: 5.00, latest lr: 3.857142857142857e-06\n",
      "epoch: 1, loss: 3.539, avg: 5.00, latest lr: 3.842857142857143e-06\n",
      "epoch: 1, loss: 3.505, avg: 5.00, latest lr: 3.828571428571429e-06\n",
      "epoch: 1, loss: 6.231, avg: 5.00, latest lr: 3.8142857142857145e-06\n",
      "epoch: 1, loss: 4.858, avg: 5.00, latest lr: 3.8e-06\n",
      "epoch: 1, loss: 3.847, avg: 5.00, latest lr: 3.785714285714286e-06\n",
      "epoch: 1, loss: 6.902, avg: 5.00, latest lr: 3.7714285714285716e-06\n",
      "epoch: 1, loss: 5.261, avg: 5.01, latest lr: 3.757142857142857e-06\n",
      "epoch: 1, loss: 3.993, avg: 5.01, latest lr: 3.742857142857143e-06\n",
      "epoch: 1, loss: 4.538, avg: 5.01, latest lr: 3.7285714285714286e-06\n",
      "epoch: 1, loss: 4.976, avg: 5.01, latest lr: 3.7142857142857146e-06\n",
      "epoch: 1, loss: 5.454, avg: 5.01, latest lr: 3.7e-06\n",
      "epoch: 1, loss: 4.758, avg: 5.01, latest lr: 3.685714285714286e-06\n",
      "epoch: 1, loss: 3.635, avg: 5.01, latest lr: 3.6714285714285717e-06\n",
      "epoch: 1, loss: 5.371, avg: 5.01, latest lr: 3.6571428571428576e-06\n",
      "epoch: 1, loss: 3.108, avg: 5.01, latest lr: 3.642857142857143e-06\n",
      "epoch: 1, loss: 6.613, avg: 5.01, latest lr: 3.6285714285714283e-06\n",
      "epoch: 1, loss: 4.329, avg: 5.01, latest lr: 3.6142857142857143e-06\n",
      "epoch: 1, loss: 4.865, avg: 5.01, latest lr: 3.6e-06\n",
      "epoch: 1, loss: 3.595, avg: 5.01, latest lr: 3.585714285714286e-06\n",
      "epoch: 1, loss: 5.018, avg: 5.01, latest lr: 3.5714285714285714e-06\n",
      "epoch: 1, loss: 4.588, avg: 5.01, latest lr: 3.5571428571428573e-06\n",
      "epoch: 1, loss: 4.934, avg: 5.02, latest lr: 3.542857142857143e-06\n",
      "epoch: 1, loss: 3.976, avg: 5.02, latest lr: 3.528571428571429e-06\n",
      "epoch: 1, loss: 5.076, avg: 5.02, latest lr: 3.5142857142857144e-06\n",
      "epoch: 1, loss: 3.781, avg: 5.02, latest lr: 3.5000000000000004e-06\n",
      "epoch: 1, loss: 4.245, avg: 5.02, latest lr: 3.485714285714286e-06\n",
      "epoch: 1, loss: 5.291, avg: 5.02, latest lr: 3.4714285714285715e-06\n",
      "epoch: 1, loss: 5.954, avg: 5.02, latest lr: 3.4571428571428574e-06\n",
      "epoch: 1, loss: 4.123, avg: 5.02, latest lr: 3.442857142857143e-06\n",
      "epoch: 1, loss: 3.838, avg: 5.02, latest lr: 3.428571428571429e-06\n",
      "epoch: 1, loss: 3.723, avg: 5.02, latest lr: 3.4142857142857145e-06\n",
      "epoch: 1, loss: 4.229, avg: 5.02, latest lr: 3.4000000000000005e-06\n",
      "epoch: 1, loss: 4.083, avg: 5.02, latest lr: 3.3857142857142856e-06\n",
      "epoch: 1, loss: 4.020, avg: 5.02, latest lr: 3.371428571428572e-06\n",
      "epoch: 1, loss: 3.463, avg: 5.02, latest lr: 3.357142857142857e-06\n",
      "epoch: 1, loss: 3.698, avg: 5.02, latest lr: 3.3428571428571427e-06\n",
      "epoch: 1, loss: 5.047, avg: 5.02, latest lr: 3.3285714285714286e-06\n",
      "epoch: 1, loss: 3.333, avg: 5.02, latest lr: 3.314285714285714e-06\n",
      "epoch: 1, loss: 3.620, avg: 5.03, latest lr: 3.3e-06\n",
      "epoch: 1, loss: 4.871, avg: 5.03, latest lr: 3.2857142857142857e-06\n",
      "epoch: 1, loss: 4.132, avg: 5.03, latest lr: 3.2714285714285717e-06\n",
      "epoch: 1, loss: 4.220, avg: 5.03, latest lr: 3.2571428571428572e-06\n",
      "epoch: 1, loss: 6.010, avg: 5.03, latest lr: 3.242857142857143e-06\n",
      "epoch: 1, loss: 3.802, avg: 5.03, latest lr: 3.2285714285714288e-06\n",
      "epoch: 1, loss: 4.548, avg: 5.03, latest lr: 3.2142857142857143e-06\n",
      "epoch: 1, loss: 3.415, avg: 5.03, latest lr: 3.2000000000000003e-06\n",
      "epoch: 1, loss: 5.225, avg: 5.03, latest lr: 3.185714285714286e-06\n",
      "epoch: 1, loss: 3.799, avg: 5.03, latest lr: 3.171428571428572e-06\n",
      "epoch: 1, loss: 4.520, avg: 5.03, latest lr: 3.157142857142857e-06\n",
      "epoch: 1, loss: 4.162, avg: 5.03, latest lr: 3.1428571428571433e-06\n",
      "epoch: 1, loss: 4.436, avg: 5.03, latest lr: 3.1285714285714284e-06\n",
      "epoch: 1, loss: 3.723, avg: 5.03, latest lr: 3.1142857142857144e-06\n",
      "epoch: 1, loss: 5.139, avg: 5.03, latest lr: 3.1e-06\n",
      "epoch: 1, loss: 5.013, avg: 5.04, latest lr: 3.085714285714286e-06\n",
      "epoch: 1, loss: 4.750, avg: 5.04, latest lr: 3.0714285714285715e-06\n",
      "epoch: 1, loss: 3.559, avg: 5.04, latest lr: 3.0571428571428575e-06\n",
      "epoch: 1, loss: 3.543, avg: 5.04, latest lr: 3.042857142857143e-06\n",
      "epoch: 1, loss: 3.305, avg: 5.04, latest lr: 3.028571428571429e-06\n",
      "epoch: 1, loss: 3.324, avg: 5.04, latest lr: 3.014285714285714e-06\n",
      "epoch: 1, loss: 4.800, avg: 5.04, latest lr: 3e-06\n",
      "epoch: 1, loss: 4.079, avg: 5.04, latest lr: 2.9857142857142856e-06\n",
      "epoch: 1, loss: 4.862, avg: 5.04, latest lr: 2.9714285714285716e-06\n",
      "epoch: 1, loss: 4.174, avg: 5.04, latest lr: 2.957142857142857e-06\n",
      "epoch: 1, loss: 5.313, avg: 5.04, latest lr: 2.942857142857143e-06\n",
      "epoch: 1, loss: 4.025, avg: 5.04, latest lr: 2.9285714285714287e-06\n",
      "epoch: 1, loss: 5.235, avg: 5.04, latest lr: 2.9142857142857146e-06\n",
      "epoch: 1, loss: 4.492, avg: 5.04, latest lr: 2.9e-06\n",
      "epoch: 1, loss: 3.980, avg: 5.04, latest lr: 2.8857142857142857e-06\n",
      "epoch: 1, loss: 4.371, avg: 5.04, latest lr: 2.8714285714285713e-06\n",
      "epoch: 1, loss: 5.503, avg: 5.04, latest lr: 2.8571428571428573e-06\n",
      "epoch: 1, loss: 4.491, avg: 5.05, latest lr: 2.842857142857143e-06\n",
      "epoch: 1, loss: 4.216, avg: 5.05, latest lr: 2.8285714285714288e-06\n",
      "epoch: 1, loss: 4.821, avg: 5.05, latest lr: 2.8142857142857143e-06\n",
      "epoch: 1, loss: 3.806, avg: 5.05, latest lr: 2.8000000000000003e-06\n",
      "epoch: 1, loss: 3.363, avg: 5.05, latest lr: 2.785714285714286e-06\n",
      "epoch: 1, loss: 4.886, avg: 5.05, latest lr: 2.771428571428572e-06\n",
      "epoch: 1, loss: 5.075, avg: 5.05, latest lr: 2.7571428571428574e-06\n",
      "epoch: 1, loss: 3.623, avg: 5.05, latest lr: 2.742857142857143e-06\n",
      "epoch: 1, loss: 4.785, avg: 5.05, latest lr: 2.7285714285714285e-06\n",
      "epoch: 1, loss: 5.536, avg: 5.05, latest lr: 2.7142857142857144e-06\n",
      "epoch: 1, loss: 3.712, avg: 5.05, latest lr: 2.7e-06\n",
      "epoch: 1, loss: 3.267, avg: 5.05, latest lr: 2.685714285714286e-06\n",
      "epoch: 1, loss: 3.813, avg: 5.05, latest lr: 2.6714285714285715e-06\n",
      "epoch: 1, loss: 3.460, avg: 5.05, latest lr: 2.6571428571428575e-06\n",
      "epoch: 1, loss: 4.623, avg: 5.05, latest lr: 2.642857142857143e-06\n",
      "epoch: 1, loss: 4.310, avg: 5.05, latest lr: 2.628571428571429e-06\n",
      "epoch: 1, loss: 3.773, avg: 5.06, latest lr: 2.614285714285714e-06\n",
      "epoch: 1, loss: 3.785, avg: 5.06, latest lr: 2.6e-06\n",
      "epoch: 1, loss: 5.535, avg: 5.06, latest lr: 2.5857142857142856e-06\n",
      "epoch: 1, loss: 5.007, avg: 5.06, latest lr: 2.5714285714285716e-06\n",
      "epoch: 1, loss: 4.126, avg: 5.06, latest lr: 2.557142857142857e-06\n",
      "epoch: 1, loss: 4.997, avg: 5.06, latest lr: 2.542857142857143e-06\n",
      "epoch: 1, loss: 4.282, avg: 5.06, latest lr: 2.5285714285714287e-06\n",
      "epoch: 1, loss: 4.740, avg: 5.06, latest lr: 2.5142857142857147e-06\n",
      "epoch: 1, loss: 3.988, avg: 5.06, latest lr: 2.5e-06\n",
      "epoch: 1, loss: 4.415, avg: 5.06, latest lr: 2.4857142857142858e-06\n",
      "epoch: 1, loss: 6.233, avg: 5.06, latest lr: 2.4714285714285713e-06\n",
      "epoch: 1, loss: 4.647, avg: 5.06, latest lr: 2.4571428571428573e-06\n",
      "epoch: 1, loss: 3.837, avg: 5.06, latest lr: 2.442857142857143e-06\n",
      "epoch: 1, loss: 3.114, avg: 5.06, latest lr: 2.428571428571429e-06\n",
      "epoch: 1, loss: 5.052, avg: 5.06, latest lr: 2.4142857142857143e-06\n",
      "epoch: 1, loss: 5.806, avg: 5.07, latest lr: 2.4000000000000003e-06\n",
      "epoch: 1, loss: 5.084, avg: 5.07, latest lr: 2.385714285714286e-06\n",
      "epoch: 1, loss: 5.886, avg: 5.07, latest lr: 2.371428571428572e-06\n",
      "epoch: 1, loss: 3.950, avg: 5.07, latest lr: 2.3571428571428574e-06\n",
      "epoch: 1, loss: 4.917, avg: 5.07, latest lr: 2.342857142857143e-06\n",
      "epoch: 1, loss: 4.841, avg: 5.07, latest lr: 2.3285714285714285e-06\n",
      "epoch: 1, loss: 4.487, avg: 5.07, latest lr: 2.3142857142857145e-06\n",
      "epoch: 1, loss: 3.842, avg: 5.07, latest lr: 2.3e-06\n",
      "epoch: 1, loss: 5.791, avg: 5.07, latest lr: 2.285714285714286e-06\n",
      "epoch: 1, loss: 3.677, avg: 5.07, latest lr: 2.2714285714285715e-06\n",
      "epoch: 1, loss: 3.274, avg: 5.07, latest lr: 2.2571428571428575e-06\n",
      "epoch: 1, loss: 4.729, avg: 5.07, latest lr: 2.242857142857143e-06\n",
      "epoch: 1, loss: 3.727, avg: 5.07, latest lr: 2.228571428571429e-06\n",
      "epoch: 1, loss: 4.952, avg: 5.07, latest lr: 2.214285714285714e-06\n",
      "epoch: 1, loss: 4.796, avg: 5.07, latest lr: 2.2e-06\n",
      "epoch: 1, loss: 4.291, avg: 5.07, latest lr: 2.1857142857142857e-06\n",
      "epoch: 1, loss: 3.808, avg: 5.08, latest lr: 2.1714285714285716e-06\n",
      "epoch: 1, loss: 4.867, avg: 5.08, latest lr: 2.157142857142857e-06\n",
      "epoch: 1, loss: 3.938, avg: 5.08, latest lr: 2.142857142857143e-06\n",
      "epoch: 1, loss: 4.348, avg: 5.08, latest lr: 2.1285714285714287e-06\n",
      "epoch: 1, loss: 3.595, avg: 5.08, latest lr: 2.1142857142857147e-06\n",
      "epoch: 1, loss: 4.298, avg: 5.08, latest lr: 2.1000000000000002e-06\n",
      "epoch: 1, loss: 4.400, avg: 5.08, latest lr: 2.0857142857142858e-06\n",
      "epoch: 1, loss: 5.022, avg: 5.08, latest lr: 2.0714285714285713e-06\n",
      "epoch: 1, loss: 4.115, avg: 5.08, latest lr: 2.0571428571428573e-06\n",
      "epoch: 1, loss: 4.611, avg: 5.08, latest lr: 2.042857142857143e-06\n",
      "epoch: 1, loss: 3.028, avg: 5.08, latest lr: 2.028571428571429e-06\n",
      "epoch: 1, loss: 4.543, avg: 5.08, latest lr: 2.0142857142857144e-06\n",
      "epoch: 1, loss: 5.448, avg: 5.08, latest lr: 2.0000000000000003e-06\n",
      "epoch: 1, loss: 4.426, avg: 5.08, latest lr: 1.985714285714286e-06\n",
      "epoch: 1, loss: 4.316, avg: 5.08, latest lr: 1.9714285714285714e-06\n",
      "epoch: 1, loss: 4.516, avg: 5.08, latest lr: 1.9571428571428574e-06\n",
      "epoch: 1, loss: 4.373, avg: 5.09, latest lr: 1.942857142857143e-06\n",
      "epoch: 1, loss: 3.646, avg: 5.09, latest lr: 1.9285714285714285e-06\n",
      "epoch: 1, loss: 4.315, avg: 5.09, latest lr: 1.9142857142857145e-06\n",
      "epoch: 1, loss: 4.757, avg: 5.09, latest lr: 1.9e-06\n",
      "epoch: 1, loss: 4.395, avg: 5.09, latest lr: 1.8857142857142858e-06\n",
      "epoch: 1, loss: 3.898, avg: 5.09, latest lr: 1.8714285714285715e-06\n",
      "epoch: 1, loss: 4.345, avg: 5.09, latest lr: 1.8571428571428573e-06\n",
      "epoch: 1, loss: 3.119, avg: 5.09, latest lr: 1.842857142857143e-06\n",
      "epoch: 1, loss: 5.247, avg: 5.09, latest lr: 1.8285714285714288e-06\n",
      "epoch: 1, loss: 4.994, avg: 5.09, latest lr: 1.8142857142857142e-06\n",
      "epoch: 1, loss: 5.097, avg: 5.09, latest lr: 1.8e-06\n",
      "epoch: 1, loss: 5.236, avg: 5.09, latest lr: 1.7857142857142857e-06\n",
      "epoch: 1, loss: 5.118, avg: 5.09, latest lr: 1.7714285714285714e-06\n",
      "epoch: 1, loss: 5.273, avg: 5.09, latest lr: 1.7571428571428572e-06\n",
      "epoch: 1, loss: 2.432, avg: 5.09, latest lr: 1.742857142857143e-06\n",
      "epoch: 1, loss: 4.523, avg: 5.09, latest lr: 1.7285714285714287e-06\n",
      "epoch: 1, loss: 3.913, avg: 5.10, latest lr: 1.7142857142857145e-06\n",
      "epoch: 1, loss: 5.169, avg: 5.10, latest lr: 1.7000000000000002e-06\n",
      "epoch: 1, loss: 4.041, avg: 5.10, latest lr: 1.685714285714286e-06\n",
      "epoch: 1, loss: 3.580, avg: 5.10, latest lr: 1.6714285714285713e-06\n",
      "epoch: 1, loss: 4.409, avg: 5.10, latest lr: 1.657142857142857e-06\n",
      "epoch: 1, loss: 5.113, avg: 5.10, latest lr: 1.6428571428571429e-06\n",
      "epoch: 1, loss: 3.348, avg: 5.10, latest lr: 1.6285714285714286e-06\n",
      "epoch: 1, loss: 4.903, avg: 5.10, latest lr: 1.6142857142857144e-06\n",
      "epoch: 1, loss: 6.018, avg: 5.10, latest lr: 1.6000000000000001e-06\n",
      "epoch: 1, loss: 4.831, avg: 5.10, latest lr: 1.585714285714286e-06\n",
      "epoch: 1, loss: 3.986, avg: 5.10, latest lr: 1.5714285714285717e-06\n",
      "epoch: 1, loss: 3.353, avg: 5.10, latest lr: 1.5571428571428572e-06\n",
      "epoch: 1, loss: 4.104, avg: 5.10, latest lr: 1.542857142857143e-06\n",
      "epoch: 1, loss: 3.291, avg: 5.10, latest lr: 1.5285714285714287e-06\n",
      "epoch: 1, loss: 4.856, avg: 5.10, latest lr: 1.5142857142857145e-06\n",
      "epoch: 1, loss: 4.985, avg: 5.10, latest lr: 1.5e-06\n",
      "epoch: 1, loss: 4.952, avg: 5.11, latest lr: 1.4857142857142858e-06\n",
      "epoch: 1, loss: 5.588, avg: 5.11, latest lr: 1.4714285714285716e-06\n",
      "epoch: 1, loss: 3.839, avg: 5.11, latest lr: 1.4571428571428573e-06\n",
      "epoch: 1, loss: 3.628, avg: 5.11, latest lr: 1.4428571428571429e-06\n",
      "epoch: 1, loss: 5.117, avg: 5.11, latest lr: 1.4285714285714286e-06\n",
      "epoch: 1, loss: 3.768, avg: 5.11, latest lr: 1.4142857142857144e-06\n",
      "epoch: 1, loss: 4.542, avg: 5.11, latest lr: 1.4000000000000001e-06\n",
      "epoch: 1, loss: 3.355, avg: 5.11, latest lr: 1.385714285714286e-06\n",
      "epoch: 1, loss: 4.717, avg: 5.11, latest lr: 1.3714285714285715e-06\n",
      "epoch: 1, loss: 4.707, avg: 5.11, latest lr: 1.3571428571428572e-06\n",
      "epoch: 1, loss: 5.834, avg: 5.11, latest lr: 1.342857142857143e-06\n",
      "epoch: 1, loss: 4.570, avg: 5.11, latest lr: 1.3285714285714287e-06\n",
      "epoch: 1, loss: 4.389, avg: 5.11, latest lr: 1.3142857142857145e-06\n",
      "epoch: 1, loss: 4.392, avg: 5.11, latest lr: 1.3e-06\n",
      "epoch: 1, loss: 4.043, avg: 5.11, latest lr: 1.2857142857142858e-06\n",
      "epoch: 1, loss: 3.102, avg: 5.11, latest lr: 1.2714285714285716e-06\n",
      "epoch: 1, loss: 3.589, avg: 5.12, latest lr: 1.2571428571428573e-06\n",
      "epoch: 1, loss: 4.584, avg: 5.12, latest lr: 1.2428571428571429e-06\n",
      "epoch: 1, loss: 4.198, avg: 5.12, latest lr: 1.2285714285714286e-06\n",
      "epoch: 1, loss: 4.549, avg: 5.12, latest lr: 1.2142857142857144e-06\n",
      "epoch: 1, loss: 4.447, avg: 5.12, latest lr: 1.2000000000000002e-06\n",
      "epoch: 1, loss: 4.403, avg: 5.12, latest lr: 1.185714285714286e-06\n",
      "epoch: 1, loss: 4.866, avg: 5.12, latest lr: 1.1714285714285715e-06\n",
      "epoch: 1, loss: 5.528, avg: 5.12, latest lr: 1.1571428571428572e-06\n",
      "epoch: 1, loss: 5.068, avg: 5.12, latest lr: 1.142857142857143e-06\n",
      "epoch: 1, loss: 4.621, avg: 5.12, latest lr: 1.1285714285714287e-06\n",
      "epoch: 1, loss: 5.061, avg: 5.12, latest lr: 1.1142857142857145e-06\n",
      "epoch: 1, loss: 4.445, avg: 5.12, latest lr: 1.1e-06\n",
      "epoch: 1, loss: 4.308, avg: 5.12, latest lr: 1.0857142857142858e-06\n",
      "epoch: 1, loss: 3.600, avg: 5.12, latest lr: 1.0714285714285716e-06\n",
      "epoch: 1, loss: 4.471, avg: 5.12, latest lr: 1.0571428571428573e-06\n",
      "epoch: 1, loss: 4.525, avg: 5.13, latest lr: 1.0428571428571429e-06\n",
      "epoch: 1, loss: 5.239, avg: 5.13, latest lr: 1.0285714285714286e-06\n",
      "epoch: 1, loss: 5.476, avg: 5.13, latest lr: 1.0142857142857144e-06\n",
      "epoch: 1, loss: 4.221, avg: 5.13, latest lr: 1.0000000000000002e-06\n",
      "epoch: 1, loss: 5.270, avg: 5.13, latest lr: 9.857142857142857e-07\n",
      "epoch: 1, loss: 5.188, avg: 5.13, latest lr: 9.714285714285715e-07\n",
      "epoch: 1, loss: 4.241, avg: 5.13, latest lr: 9.571428571428572e-07\n",
      "epoch: 1, loss: 3.985, avg: 5.13, latest lr: 9.428571428571429e-07\n",
      "epoch: 1, loss: 5.466, avg: 5.13, latest lr: 9.285714285714287e-07\n",
      "epoch: 1, loss: 5.307, avg: 5.13, latest lr: 9.142857142857144e-07\n",
      "epoch: 1, loss: 4.425, avg: 5.13, latest lr: 9e-07\n",
      "epoch: 1, loss: 4.110, avg: 5.13, latest lr: 8.857142857142857e-07\n",
      "epoch: 1, loss: 4.957, avg: 5.13, latest lr: 8.714285714285715e-07\n",
      "epoch: 1, loss: 6.411, avg: 5.13, latest lr: 8.571428571428572e-07\n",
      "epoch: 1, loss: 4.498, avg: 5.14, latest lr: 8.42857142857143e-07\n",
      "epoch: 1, loss: 3.223, avg: 5.14, latest lr: 8.285714285714285e-07\n",
      "epoch: 1, loss: 4.595, avg: 5.14, latest lr: 8.142857142857143e-07\n",
      "epoch: 1, loss: 5.430, avg: 5.14, latest lr: 8.000000000000001e-07\n",
      "epoch: 1, loss: 4.406, avg: 5.14, latest lr: 7.857142857142858e-07\n",
      "epoch: 1, loss: 4.861, avg: 5.14, latest lr: 7.714285714285715e-07\n",
      "epoch: 1, loss: 4.955, avg: 5.14, latest lr: 7.571428571428572e-07\n",
      "epoch: 1, loss: 4.102, avg: 5.14, latest lr: 7.428571428571429e-07\n",
      "epoch: 1, loss: 4.414, avg: 5.14, latest lr: 7.285714285714287e-07\n",
      "epoch: 1, loss: 5.310, avg: 5.14, latest lr: 7.142857142857143e-07\n",
      "epoch: 1, loss: 4.839, avg: 5.14, latest lr: 7.000000000000001e-07\n",
      "epoch: 1, loss: 3.974, avg: 5.14, latest lr: 6.857142857142857e-07\n",
      "epoch: 1, loss: 4.683, avg: 5.14, latest lr: 6.714285714285715e-07\n",
      "epoch: 1, loss: 5.920, avg: 5.14, latest lr: 6.571428571428572e-07\n",
      "epoch: 1, loss: 4.589, avg: 5.14, latest lr: 6.428571428571429e-07\n",
      "epoch: 1, loss: 5.125, avg: 5.15, latest lr: 6.285714285714287e-07\n",
      "epoch: 1, loss: 3.945, avg: 5.15, latest lr: 6.142857142857143e-07\n",
      "epoch: 1, loss: 4.456, avg: 5.15, latest lr: 6.000000000000001e-07\n",
      "epoch: 1, loss: 4.976, avg: 5.15, latest lr: 5.857142857142857e-07\n",
      "epoch: 1, loss: 4.613, avg: 5.15, latest lr: 5.714285714285715e-07\n",
      "epoch: 1, loss: 4.019, avg: 5.15, latest lr: 5.571428571428573e-07\n",
      "epoch: 1, loss: 5.093, avg: 5.15, latest lr: 5.428571428571429e-07\n",
      "epoch: 1, loss: 3.943, avg: 5.15, latest lr: 5.285714285714287e-07\n",
      "epoch: 1, loss: 4.985, avg: 5.15, latest lr: 5.142857142857143e-07\n",
      "epoch: 1, loss: 5.526, avg: 5.15, latest lr: 5.000000000000001e-07\n",
      "epoch: 1, loss: 4.680, avg: 5.15, latest lr: 4.857142857142857e-07\n",
      "epoch: 1, loss: 3.972, avg: 5.15, latest lr: 4.7142857142857145e-07\n",
      "epoch: 1, loss: 5.361, avg: 5.15, latest lr: 4.571428571428572e-07\n",
      "epoch: 1, loss: 4.373, avg: 5.15, latest lr: 4.4285714285714286e-07\n",
      "epoch: 1, loss: 4.432, avg: 5.15, latest lr: 4.285714285714286e-07\n",
      "epoch: 1, loss: 3.943, avg: 5.15, latest lr: 4.142857142857143e-07\n",
      "epoch: 1, loss: 5.029, avg: 5.16, latest lr: 4.0000000000000003e-07\n",
      "epoch: 1, loss: 3.548, avg: 5.16, latest lr: 3.8571428571428574e-07\n",
      "epoch: 1, loss: 6.361, avg: 5.16, latest lr: 3.7142857142857145e-07\n",
      "epoch: 1, loss: 3.718, avg: 5.16, latest lr: 3.5714285714285716e-07\n",
      "epoch: 1, loss: 5.432, avg: 5.16, latest lr: 3.4285714285714286e-07\n",
      "epoch: 1, loss: 3.778, avg: 5.16, latest lr: 3.285714285714286e-07\n",
      "epoch: 1, loss: 4.609, avg: 5.16, latest lr: 3.1428571428571433e-07\n",
      "epoch: 1, loss: 4.649, avg: 5.16, latest lr: 3.0000000000000004e-07\n",
      "epoch: 1, loss: 4.536, avg: 5.16, latest lr: 2.8571428571428575e-07\n",
      "epoch: 1, loss: 4.626, avg: 5.16, latest lr: 2.7142857142857145e-07\n",
      "epoch: 1, loss: 2.971, avg: 5.16, latest lr: 2.5714285714285716e-07\n",
      "epoch: 1, loss: 3.539, avg: 5.16, latest lr: 2.4285714285714287e-07\n",
      "epoch: 1, loss: 3.826, avg: 5.16, latest lr: 2.285714285714286e-07\n",
      "epoch: 1, loss: 4.817, avg: 5.16, latest lr: 2.142857142857143e-07\n",
      "epoch: 1, loss: 4.947, avg: 5.16, latest lr: 2.0000000000000002e-07\n",
      "epoch: 1, loss: 5.007, avg: 5.17, latest lr: 1.8571428571428572e-07\n",
      "epoch: 1, loss: 4.551, avg: 5.17, latest lr: 1.7142857142857143e-07\n",
      "epoch: 1, loss: 4.437, avg: 5.17, latest lr: 1.5714285714285717e-07\n",
      "epoch: 1, loss: 3.689, avg: 5.17, latest lr: 1.4285714285714287e-07\n",
      "epoch: 1, loss: 4.737, avg: 5.17, latest lr: 1.2857142857142858e-07\n",
      "epoch: 1, loss: 5.026, avg: 5.17, latest lr: 1.142857142857143e-07\n",
      "epoch: 1, loss: 4.854, avg: 5.17, latest lr: 1.0000000000000001e-07\n",
      "epoch: 1, loss: 3.685, avg: 5.17, latest lr: 8.571428571428572e-08\n",
      "epoch: 1, loss: 5.605, avg: 5.17, latest lr: 7.142857142857144e-08\n",
      "epoch: 1, loss: 4.221, avg: 5.17, latest lr: 5.714285714285715e-08\n",
      "epoch: 1, loss: 5.327, avg: 5.17, latest lr: 4.285714285714286e-08\n",
      "epoch: 1, loss: 4.842, avg: 5.17, latest lr: 2.8571428571428575e-08\n",
      "epoch: 1, loss: 3.889, avg: 5.17, latest lr: 1.4285714285714288e-08\n",
      "epoch: 1, loss: 3.525, avg: 5.17, latest lr: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "5.173477611064909"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "m = trainer.model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  introduction the covid 19 pandemic created challenges nursing students. the current pandemic created challenges nursing students\n",
      "outputs:  tensor([[  101,   102,  2067,   111, 21004,   173,   371, 26196,  4467,  5212,\n",
      "          7822,  2584,   205,   111,  1073, 26196,  4467,  5212,  7822,  2584]],\n",
      "       device='cuda:0') len:  20\n"
     ]
    }
   ],
   "source": [
    "# sample_input = bert_trainloader[3]\n",
    "# print(f\"input text: {tokenizer.decode(sample_input['input_ids'])}\")\n",
    "# res = m(*sample_input)\n",
    "# res\n",
    "# # .unsqueeze(0)\n",
    "\n",
    "idx = 5\n",
    "input_ids = bert_trainloader[idx]['input_ids'].to('cuda')#.unsqueeze(0).to('cuda')\n",
    "attention_mask = bert_trainloader[idx]['attention_mask'].to('cuda')#.unsqueeze(0).to('cuda')\n",
    "\n",
    "# body_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "# print(body_text)\n",
    "outputs = m.generate(input_ids, attention_mask=attention_mask)\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n",
    "print('summary: ',summary)\n",
    "print('outputs: ',outputs, 'len: ', len(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. T5: https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb\n",
    "2. BERT2BERT : https://github.com/asceznyk/bert2bert\n",
    "3. BER2BERT: https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb#scrollTo=68IHmFYLx09W\n",
    "4. https://colab.research.google.com/drive/1WIk2bxglElfZewOHboPFNj8H44_VAyKE?usp=sharing"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "scispacy",
   "language": "python",
   "display_name": "scispacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
